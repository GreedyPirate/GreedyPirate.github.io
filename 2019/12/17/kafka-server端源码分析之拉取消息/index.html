<!DOCTYPE html><html><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="kafka-server端源码分析之拉取消息"><meta name="keywords" content="kafka,中间件,消息"><meta name="author" content="紫夜,undefined"><meta name="copyright" content="紫夜"><title>kafka-server端源码分析之拉取消息 | 紫夜の博客</title><link rel="shortcut icon" href="/my-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.5.6"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css?version=1.5.6"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/gh/upupming/gitalk@36368e5dffd049e956cdbbd751ff96c28d8255cf/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="dns-prefetch" href="https://hm.baidu.com"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6ba54465c1ff0c31b169e7a89d3dbe37";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#术语回顾"><span class="toc-number">1.</span> <span class="toc-text">术语回顾</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#源码分析"><span class="toc-number">2.</span> <span class="toc-text">源码分析</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#client端发送的FETCH请求"><span class="toc-number">2.1.</span> <span class="toc-text">client端发送的FETCH请求</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#FetchSession背景"><span class="toc-number">2.1.1.</span> <span class="toc-text">FetchSession背景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#FETCH请求"><span class="toc-number">2.2.</span> <span class="toc-text">FETCH请求</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ReplicaManager-fetchMessages"><span class="toc-number">3.</span> <span class="toc-text">ReplicaManager#fetchMessages</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#readFromLocalLog方法"><span class="toc-number">3.1.</span> <span class="toc-text">readFromLocalLog方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Log-read"><span class="toc-number">3.2.</span> <span class="toc-text">Log#read</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LogSegment-read"><span class="toc-number">3.3.</span> <span class="toc-text">LogSegment#read</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#返回结果处理"><span class="toc-number">3.4.</span> <span class="toc-text">返回结果处理</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#总结"><span class="toc-number">4.</span> <span class="toc-text">总结</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://ae01.alicdn.com/kf/He0f82cbc452e4e99b7da670575752df0l.png"></div><div class="author-info__name text-center">紫夜</div><div class="author-info__description text-center">stay hungry, stay foolish</div><div class="follow-button"><a href="https://github.com/GreedyPirate" target="_blank">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">59</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">23</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">11</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" href="https://blog.csdn.net/yj7758423" target="_blank">我的CSDN</a><a class="author-info-links__name text-center" href="https://segmentfault.com/blog/code-craft" target="_blank">膜拜大神</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://ae01.alicdn.com/kf/H6e9ae455bca04f4098243e3f73a85c4fb.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">紫夜の博客</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">kafka-server端源码分析之拉取消息</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-12-17</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Kafka-Tutorial/">Kafka Tutorial</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">5,529</span><span class="post-meta__separator">|</span><span>Reading time: 26 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><blockquote>
<p>发送fetch请求的对象有2类：client和follower，client拉取时有高水位线的限制，follower则没有，本文仅介绍client，<br>follower拉取时涉及到副本同步，以后单独分析</p>
</blockquote>
<h1 id="术语回顾"><a href="#术语回顾" class="headerlink" title="术语回顾"></a>术语回顾</h1><p><img src="https://ae01.alicdn.com/kf/H7a61234572984b95a98cc61ef9abf1f4C.png" alt=""><br>在kafka消息中有2个重要的术语：HW(HighWatermark)，LEO(Log End Offset)</p>
<p>HW会在生产者发送的消息写入后，等待follower副本同步完成后更新, HW之前的消息称之为committed(已提交的消息)，消费者只能消费HW之前的消息<br>而LEO则是在消息写入到本地leader副本后立即更新，它的值是最后一条消息的下一个位移，图中15被虚线标注，表示LEO处没有消息</p>
<h1 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h1><h2 id="client端发送的FETCH请求"><a href="#client端发送的FETCH请求" class="headerlink" title="client端发送的FETCH请求"></a>client端发送的FETCH请求</h2><p>截止到2.0.1版本，Fetch请求已经是V8版本了，client端发送的FetchRequest在Fetcher#sendFetches方法中初始化</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> FetchSessionHandler.FetchRequestData data = entry.getValue();</span><br><span class="line"><span class="keyword">final</span> FetchRequest.Builder request = FetchRequest.Builder</span><br><span class="line">        <span class="comment">// fetch.max.wait.ms: 拉取的等待时间</span></span><br><span class="line">        <span class="comment">// fetch.min.bytes: 至少拉取的字节数，没有达到则等待</span></span><br><span class="line">        .forConsumer(<span class="keyword">this</span>.maxWaitMs, <span class="keyword">this</span>.minBytes, data.toSend())</span><br><span class="line">        <span class="comment">// 事务隔离级别，read_uncommited</span></span><br><span class="line">        .isolationLevel(isolationLevel)</span><br><span class="line">        <span class="comment">// fetch.max.bytes: 拉取的最大字节</span></span><br><span class="line">        .setMaxBytes(<span class="keyword">this</span>.maxBytes)</span><br><span class="line">        .metadata(data.metadata())</span><br><span class="line">        .toForget(data.toForget());</span><br></pre></td></tr></table></figure>
<p>该请求体略微复杂，首先关注下data.toSend方法，它返回的是一个Map&lt;TopicPartition, PartitionData&gt;，表示一个消费者可以消费多个topic的多个分区<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">PartitionData</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 拉取的offset</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">long</span> fetchOffset;</span><br><span class="line">    <span class="comment">// </span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">long</span> logStartOffset;</span><br><span class="line">    <span class="comment">// max.partition.fetch.bytes：每个分区拉取的最大值</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> maxBytes;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>data.metadata方法返回的FetchMetadata主要包含epoch和sessionId两个字段，data.toForget返回的是一个分区数组<br>相信大部分参数大家都是熟悉的，而epoch，sessionId和toForget是专门用于FetchSession的实现，它是1.1.0版本新增的功能，这里我只说它出现的背景</p>
<h3 id="FetchSession背景"><a href="#FetchSession背景" class="headerlink" title="FetchSession背景"></a>FetchSession背景</h3><p>FetchSession出现是为了解决什么问题？<br>在kafka集群中的topic和partition达到一定规模后，会产生大量的Fetch请求，既包含消息拉取，也包含副本同步，而后者的请求量会很大。<br>假设100个topic，每个topic有3个分区，每个分区有3个副本，那么同时就有600个follower副本发送Fetch请求，再加上活动期间的业务量猛增的消费者的请求，Fetch请求的QPS将会很高<br>并且Fetch的请求体本身就很大，通常有几十KB，但是大部分参数都是不变的，比如订阅的分区，拉取参数等，因此可以将这些参数缓存在server端，client用一个session id来代替一次会话<br>这对Fetch请求的性能将是一个瓶颈，因此需要对请求体优化</p>
<p>其中大部分的参数大家都很熟悉，主要说2个不常见的参数：metadata和toForget<br>这两个参数是kafka 1.1.0版本之后新加的，用于FetchSession的实现，主要解决了在server端没有接收到消息时，消费者会空轮询，在topic分区较多时，FetchSession为Fetch请求体起到了瘦身的作用</p>
<p>想象一下每个client不止订阅一个topic，也会不止分配到一个TopicPartition，消费者在发送FETCH请求之前，要知道每个partition的leader副本在哪个broker上，然后按照broker分组，fetch请求体很大并不是空穴来风，kafka对此进行优化是很有必要的</p>
<p>以下是Fetch请求体格式，红框内的参数先不必关注，之后分析FetchSession相关内容<br><img src="https://ae01.alicdn.com/kf/Haf611a59880e479d953217e41e26eaf47.png" alt="FetchRequest"></p>
<h2 id="FETCH请求"><a href="#FETCH请求" class="headerlink" title="FETCH请求"></a>FETCH请求</h2><p>FETCH请求同样也是在KafkaApis类中处理，此处省略部分代码，如FetchSession相关，关注拉取的核心流程</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">handleFetchRequest</span><span class="params">(request: RequestChannel.Request)</span> </span>&#123;</span><br><span class="line">    val versionId = request.header.apiVersion</span><br><span class="line">    val clientId = request.header.clientId</span><br><span class="line">    val fetchRequest = request.body[FetchRequest]</span><br><span class="line"></span><br><span class="line">    <span class="comment">// FetchSession来做增量的fetch请求</span></span><br><span class="line">    val fetchContext = fetchManager.newContext(fetchRequest.metadata(),</span><br><span class="line">          fetchRequest.fetchData(),</span><br><span class="line">          fetchRequest.toForget(),</span><br><span class="line">          <span class="comment">// isFromFollower： replicaId是否大于0表示是follower</span></span><br><span class="line">          fetchRequest.isFromFollower())</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 异常响应方法：传入一个Error，返回发送异常时的Response</span></span><br><span class="line">    def errorResponse[T &gt;: MemoryRecords &lt;: BaseRecords](error: Errors): FetchResponse.PartitionData[T] = &#123;</span><br><span class="line">      <span class="keyword">new</span> FetchResponse.PartitionData[T](error, FetchResponse.INVALID_HIGHWATERMARK, FetchResponse.INVALID_LAST_STABLE_OFFSET,</span><br><span class="line">        FetchResponse.INVALID_LOG_START_OFFSET, <span class="keyword">null</span>, MemoryRecords.EMPTY)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    val erroneous = mutable.ArrayBuffer[(TopicPartition, FetchResponse.PartitionData[Records])]()</span><br><span class="line">    val interesting = mutable.ArrayBuffer[(TopicPartition, FetchRequest.PartitionData)]()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 筛选TP, 放入interesting集合中</span></span><br><span class="line">    <span class="keyword">if</span> (fetchRequest.isFromFollower()) &#123;</span><br><span class="line">    	<span class="comment">// 暂不关心follower fetch</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// foreachPartition由FullFetchContext和IncrementalFetchContext实现</span></span><br><span class="line">      fetchContext.foreachPartition &#123; (topicPartition, data) =&gt;</span><br><span class="line">      	<span class="comment">// consumer要有READ读权限，而且在metadata里有记录</span></span><br><span class="line">        <span class="keyword">if</span> (!authorize(request.session, Read, Resource(Topic, topicPartition.topic, LITERAL)))</span><br><span class="line">          erroneous += topicPartition -&gt; errorResponse(Errors.TOPIC_AUTHORIZATION_FAILED)</span><br><span class="line">        <span class="comment">// 元数据中要有该topicPartition</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (!metadataCache.contains(topicPartition))</span><br><span class="line">          erroneous += topicPartition -&gt; errorResponse(Errors.UNKNOWN_TOPIC_OR_PARTITION)</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">          interesting += (topicPartition -&gt; data)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 响应的回调函数，最后分析</span></span><br><span class="line">    <span class="function">def <span class="title">processResponseCallback</span><span class="params">(responsePartitionData: Seq[(TopicPartition, FetchPartitionData)</span>]): Unit </span>= &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (interesting.isEmpty)</span><br><span class="line">      processResponseCallback(Seq.empty)</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// replicaManager为入口调用</span></span><br><span class="line">      <span class="comment">// call the replica manager to fetch messages from the local replica</span></span><br><span class="line">      replicaManager.fetchMessages(</span><br><span class="line">        fetchRequest.maxWait.toLong,</span><br><span class="line">        fetchRequest.replicaId,</span><br><span class="line">        fetchRequest.minBytes,</span><br><span class="line">        fetchRequest.maxBytes,</span><br><span class="line">        versionId &lt;= <span class="number">2</span>, <span class="comment">// 从后面的代码看，version &lt;= 2时，至少返回第一条消息，哪怕它的大小超出了maxBytes</span></span><br><span class="line">        interesting,</span><br><span class="line">        replicationQuota(fetchRequest),</span><br><span class="line">        processResponseCallback,</span><br><span class="line">        fetchRequest.isolationLevel)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>handleFetchRequest方法主要是过滤请求中可用的TopicPartition作为interesting参数，最后连带响应的回调函数一起传给replicaManager的fetchMessages方法，processResponseCallback响应回调最终再分析</p>
<h1 id="ReplicaManager-fetchMessages"><a href="#ReplicaManager-fetchMessages" class="headerlink" title="ReplicaManager#fetchMessages"></a>ReplicaManager#fetchMessages</h1><p>fetchMessages方法中主要调用了readFromLog-&gt;readFromLocalLog方法来读取消息</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">fetchMessages</span><span class="params">(timeout: Long,</span></span></span><br><span class="line"><span class="function"><span class="params">                    replicaId: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                    fetchMinBytes: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                    fetchMaxBytes: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                    hardMaxBytesLimit: Boolean,</span></span></span><br><span class="line"><span class="function"><span class="params">                    fetchInfos: Seq[(TopicPartition, PartitionData)</span>],</span></span><br><span class="line"><span class="function">                    quota: ReplicaQuota </span>= UnboundedQuota,</span><br><span class="line">                    responseCallback: Seq[(TopicPartition, FetchPartitionData)] =&gt; Unit,</span><br><span class="line">                    isolationLevel: IsolationLevel) &#123;</span><br><span class="line">    val isFromFollower = Request.isValidBrokerId(replicaId)</span><br><span class="line">    val fetchOnlyFromLeader = replicaId != Request.DebuggingConsumerId &amp;&amp; replicaId != Request.FutureLocalReplicaId <span class="comment">// 还有不从leader同步的？</span></span><br><span class="line">    <span class="comment">// follower fetch时没有高水位线的限制</span></span><br><span class="line">    val fetchOnlyCommitted = !isFromFollower &amp;&amp; replicaId != Request.FutureLocalReplicaId</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 先定义后调用</span></span><br><span class="line">    <span class="function">def <span class="title">readFromLog</span><span class="params">()</span>: Seq[<span class="params">(TopicPartition, LogReadResult)</span>] </span>= &#123;</span><br><span class="line">      val result = readFromLocalLog(</span><br><span class="line">        replicaId = replicaId,</span><br><span class="line">        fetchOnlyFromLeader = fetchOnlyFromLeader,</span><br><span class="line">        readOnlyCommitted = fetchOnlyCommitted,</span><br><span class="line">        fetchMaxBytes = fetchMaxBytes,</span><br><span class="line">        <span class="comment">// vision&lt;=2，目前=8，说明为false，v2版本有最大字节限制吗？</span></span><br><span class="line">        hardMaxBytesLimit = hardMaxBytesLimit,</span><br><span class="line">        <span class="comment">// fetchInfos是读取的关键，这是fetch参数，注意要读取多个分区，这是个</span></span><br><span class="line">        readPartitionInfo = fetchInfos,</span><br><span class="line">        <span class="comment">// 配额</span></span><br><span class="line">        quota = quota,</span><br><span class="line">        <span class="comment">// 事务隔离级别，默认read_uncommited</span></span><br><span class="line">        isolationLevel = isolationLevel)</span><br><span class="line">      <span class="comment">// 这里是follower的fetch结果处理</span></span><br><span class="line">      <span class="keyword">if</span> (isFromFollower) updateFollowerLogReadResults(replicaId, result)</span><br><span class="line">      <span class="keyword">else</span> result</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 调用并返回一个(TopicPartition, LogReadResult)集合</span></span><br><span class="line">    val logReadResults = readFromLog()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// check if this fetch request can be satisfied right away</span></span><br><span class="line">    <span class="comment">// LogReadResult集合</span></span><br><span class="line">    val logReadResultValues = logReadResults.map &#123; <span class="keyword">case</span> (_, v) =&gt; v &#125;</span><br><span class="line">    <span class="comment">// 读取的消息大小之和</span></span><br><span class="line">    val bytesReadable = logReadResultValues.map(_.info.records.sizeInBytes).sum</span><br><span class="line">    <span class="comment">// 结果中是否有错误</span></span><br><span class="line">    val errorReadingData = logReadResultValues.foldLeft(<span class="keyword">false</span>) ((errorIncurred, readResult) =&gt;</span><br><span class="line">      errorIncurred || (readResult.error != Errors.NONE))</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">      * 能够立即返回给客户端的4种情况</span></span><br><span class="line"><span class="comment">      * 1. fetch请求没有大于0的wait时间,参考fetch.max.wait.ms设置</span></span><br><span class="line"><span class="comment">      * 2. fetch请求要拉取的分区为空</span></span><br><span class="line"><span class="comment">      * 3. 根据fetch.min.bytes的设置，有足够的数据返回</span></span><br><span class="line"><span class="comment">      * 4. 出现异常</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">    <span class="keyword">if</span> (timeout &lt;= <span class="number">0</span> || fetchInfos.isEmpty || bytesReadable &gt;= fetchMinBytes || errorReadingData) &#123;</span><br><span class="line">      <span class="comment">// fetchPartitionData是一个TopicPartition -&gt; FetchPartitionData 的map集合</span></span><br><span class="line">      val fetchPartitionData = logReadResults.map &#123; <span class="keyword">case</span> (tp, result) =&gt;</span><br><span class="line">        tp -&gt; FetchPartitionData(result.error, result.highWatermark, result.leaderLogStartOffset, result.info.records,</span><br><span class="line">          result.lastStableOffset, result.info.abortedTransactions)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 调用响应回调函数</span></span><br><span class="line">      responseCallback(fetchPartitionData)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; <span class="comment">// 创建响应的DelayOption，放入purgatory中，等待完成</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// construct the fetch results from the read results</span></span><br><span class="line">      val fetchPartitionStatus = logReadResults.map &#123; <span class="keyword">case</span> (topicPartition, result) =&gt;</span><br><span class="line">        <span class="comment">// collectFirst：根据function find first element</span></span><br><span class="line">        <span class="comment">// fetchInfos是请求参数(TopicPartition, PartitionData)集合，</span></span><br><span class="line">        <span class="comment">// 意思就是从读取结果logReadResults里的TopicPartition和fetchInfos里的TopicPartition匹配</span></span><br><span class="line">        <span class="comment">// 找出该TopicPartition的PartitionData请求参数</span></span><br><span class="line">        val fetchInfo = fetchInfos.collectFirst &#123;</span><br><span class="line">          <span class="keyword">case</span> (tp, v) <span class="keyword">if</span> tp == topicPartition =&gt; v</span><br><span class="line">        &#125;.getOrElse(sys.error(s<span class="string">"Partition $topicPartition not found in fetchInfos"</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 赋值给外层的fetchPartitionStatus</span></span><br><span class="line">        (topicPartition, FetchPartitionStatus(result.info.fetchOffsetMetadata, fetchInfo))</span><br><span class="line">      &#125;</span><br><span class="line">      val fetchMetadata = FetchMetadata(fetchMinBytes, fetchMaxBytes, hardMaxBytesLimit, fetchOnlyFromLeader,</span><br><span class="line">        fetchOnlyCommitted, isFromFollower, replicaId, fetchPartitionStatus)</span><br><span class="line">      val delayedFetch = <span class="keyword">new</span> DelayedFetch(timeout, fetchMetadata, <span class="keyword">this</span>, quota, isolationLevel, responseCallback)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// create a list of (topic, partition) pairs to use as keys for this delayed fetch operation</span></span><br><span class="line">      <span class="comment">// 以分区为delay的watchKey</span></span><br><span class="line">      val delayedFetchKeys = fetchPartitionStatus.map &#123; <span class="keyword">case</span> (tp, _) =&gt; <span class="keyword">new</span> TopicPartitionOperationKey(tp) &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// try to complete the request immediately, otherwise put it into the purgatory;</span></span><br><span class="line">      <span class="comment">// this is because while the delayed fetch operation is being created, new requests</span></span><br><span class="line">      <span class="comment">// may arrive and hence make this operation completable.</span></span><br><span class="line">      <span class="comment">// 先尝试一次，不行就放入Purgatory中</span></span><br><span class="line">      delayedFetchPurgatory.tryCompleteElseWatch(delayedFetch, delayedFetchKeys)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法还是有一定的复杂度，需要点耐心，但是思路也很清晰，以下这行代码读取消息，之后对结果进行处理<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val logReadResults = readFromLog()</span><br></pre></td></tr></table></figure></p>
<p>由于Consumer有一系列的参数控制，如fetch.max.wait.ms，fetch.min.bytes等，让本次fetch不能立即完成<br>需要新建一个DelayedOption对象，放入Purgatory中，等待后续操作触发本次请求的完成(complete)</p>
<p>接下来就从readFromLocalLog方法看看如何读取消息</p>
<h2 id="readFromLocalLog方法"><a href="#readFromLocalLog方法" class="headerlink" title="readFromLocalLog方法"></a>readFromLocalLog方法</h2><p>首先明确性该方法的入参和返回值，入参前文有详细注释，返回值则是一个(TopicPartition, LogReadResult)集合，前文也已提到</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Read from multiple topic partitions at the given offset up to maxSize bytes</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"><span class="function">def <span class="title">readFromLocalLog</span><span class="params">(replicaId: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                       fetchOnlyFromLeader: Boolean,</span></span></span><br><span class="line"><span class="function"><span class="params">                       readOnlyCommitted: Boolean,</span></span></span><br><span class="line"><span class="function"><span class="params">                       fetchMaxBytes: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                       hardMaxBytesLimit: Boolean,</span></span></span><br><span class="line"><span class="function"><span class="params">                       readPartitionInfo: Seq[(TopicPartition, PartitionData)</span>],</span></span><br><span class="line"><span class="function">                       quota: ReplicaQuota,</span></span><br><span class="line"><span class="function">                       isolationLevel: IsolationLevel): Seq[<span class="params">(TopicPartition, LogReadResult)</span>] </span>= &#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">      * 又是先定义后调用，从后面的代码块这是在遍历请求参数中的TopicPartition集合</span></span><br><span class="line"><span class="comment">      * 作用是读取一个分区里的消息</span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> tp 要读取的分区</span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> fetchInfo 读取的参数，如从哪里开始读，读多少</span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> limitBytes fetchMaxBytes参数</span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> minOneMessage 是否至少读第一条后立即返回，即使它比fetchMaxBytes大，true</span></span><br><span class="line"><span class="comment">      * <span class="doctag">@return</span> 读取的结果</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">	<span class="function">def <span class="title">read</span><span class="params">(tp: TopicPartition, fetchInfo: PartitionData, limitBytes: Int, minOneMessage: Boolean)</span>: LogReadResult </span>= &#123;</span><br><span class="line">		val offset = fetchInfo.fetchOffset <span class="comment">//从哪fetch</span></span><br><span class="line">		val partitionFetchSize = fetchInfo.maxBytes <span class="comment">// fetch多少</span></span><br><span class="line">		val followerLogStartOffset = fetchInfo.logStartOffset <span class="comment">// 这应该是针对follower的，consumer始终为-1</span></span><br><span class="line"></span><br><span class="line">		<span class="comment">// decide whether to only fetch from leader</span></span><br><span class="line">		val localReplica = <span class="keyword">if</span> (fetchOnlyFromLeader)</span><br><span class="line">		  <span class="comment">//先找leader副本</span></span><br><span class="line">		  getLeaderReplicaIfLocal(tp)</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		  getReplicaOrException(tp)</span><br><span class="line"></span><br><span class="line">		<span class="comment">// hw</span></span><br><span class="line">		val initialHighWatermark = localReplica.highWatermark.messageOffset</span><br><span class="line">		<span class="comment">// 事务相关</span></span><br><span class="line">		val lastStableOffset = <span class="keyword">if</span> (isolationLevel == IsolationLevel.READ_COMMITTED)</span><br><span class="line">		  Some(localReplica.lastStableOffset.messageOffset)</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		  None</span><br><span class="line"></span><br><span class="line">		<span class="comment">// decide whether to only fetch committed data (i.e. messages below high watermark)</span></span><br><span class="line">		val maxOffsetOpt = <span class="keyword">if</span> (readOnlyCommitted)</span><br><span class="line">		  <span class="comment">// 没开启事务时lastStableOffset应该为None</span></span><br><span class="line">		  <span class="comment">// 这里返回的还是initialHighWatermark</span></span><br><span class="line">		  Some(lastStableOffset.getOrElse(initialHighWatermark))</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		  None</span><br><span class="line">		val initialLogEndOffset = localReplica.logEndOffset.messageOffset <span class="comment">// LEO</span></span><br><span class="line">		<span class="comment">// 这应该是副本目前所有Segment的初始位移(第一个Segment的baseOffset),会随着日志清理改变</span></span><br><span class="line">		val initialLogStartOffset = localReplica.logStartOffset</span><br><span class="line">		val fetchTimeMs = time.milliseconds <span class="comment">// 当前时间</span></span><br><span class="line">		val logReadInfo = localReplica.log match &#123;</span><br><span class="line">		  <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(log)</span> </span>=&gt;</span><br><span class="line">		    <span class="comment">// TODO 目前还没搞清楚PartitionData里的maxBytes和FetchRequest的maxBytes什么区别</span></span><br><span class="line">		    <span class="comment">// limitBytes是请求参数中的maxBytes</span></span><br><span class="line">		    val adjustedFetchSize = math.min(partitionFetchSize, limitBytes)</span><br><span class="line"></span><br><span class="line">		    <span class="comment">// Try the read first, this tells us whether we need all of adjustedFetchSize for this partition</span></span><br><span class="line">		   	<span class="comment">// 从Log对象中读取</span></span><br><span class="line">		    val fetch = log.read(offset, adjustedFetchSize, maxOffsetOpt, minOneMessage, isolationLevel)</span><br><span class="line"></span><br><span class="line">		    <span class="comment">// If the partition is being throttled, simply return an empty set.</span></span><br><span class="line">		    <span class="comment">// 超出配额(被限流)时返回一个空消息</span></span><br><span class="line">		    <span class="keyword">if</span> (shouldLeaderThrottle(quota, tp, replicaId))</span><br><span class="line">		      FetchDataInfo(fetch.fetchOffsetMetadata, MemoryRecords.EMPTY)</span><br><span class="line">		    <span class="comment">// For FetchRequest version 3, we replace incomplete message sets with an empty one as consumers can make</span></span><br><span class="line">		    <span class="comment">// progress in such cases and don't need to report a `RecordTooLargeException`</span></span><br><span class="line">		    <span class="keyword">else</span> <span class="keyword">if</span> (!hardMaxBytesLimit &amp;&amp; fetch.firstEntryIncomplete)</span><br><span class="line">		      FetchDataInfo(fetch.fetchOffsetMetadata, MemoryRecords.EMPTY)</span><br><span class="line">		    <span class="keyword">else</span> fetch <span class="comment">// 返回正常的结果给logReadInfo变量</span></span><br><span class="line"></span><br><span class="line">		  <span class="keyword">case</span> None =&gt;</span><br><span class="line">		    error(s<span class="string">"Leader for partition $tp does not have a local log"</span>)</span><br><span class="line">		    FetchDataInfo(LogOffsetMetadata.UnknownOffsetMetadata, MemoryRecords.EMPTY)</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 返回结果</span></span><br><span class="line">		LogReadResult(info = logReadInfo,</span><br><span class="line">		              highWatermark = initialHighWatermark,</span><br><span class="line">		              leaderLogStartOffset = initialLogStartOffset,</span><br><span class="line">		              leaderLogEndOffset = initialLogEndOffset,</span><br><span class="line">		              followerLogStartOffset = followerLogStartOffset,</span><br><span class="line">		              fetchTimeMs = fetchTimeMs,</span><br><span class="line">		              readSize = partitionFetchSize,</span><br><span class="line">		              lastStableOffset = lastStableOffset,</span><br><span class="line">		              exception = None)</span><br><span class="line">	  </span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	var limitBytes = fetchMaxBytes</span><br><span class="line">	val result = <span class="keyword">new</span> mutable.ArrayBuffer[(TopicPartition, LogReadResult)]</span><br><span class="line">	var minOneMessage = !hardMaxBytesLimit <span class="comment">// true</span></span><br><span class="line">	readPartitionInfo.foreach &#123; <span class="keyword">case</span> (tp, fetchInfo) =&gt; <span class="comment">// 遍历每个tp，按照消费者的参数读取日志</span></span><br><span class="line">	  val readResult = read(tp, fetchInfo, limitBytes, minOneMessage)</span><br><span class="line"></span><br><span class="line">	  <span class="comment">// 拿到读取结果后，更新limitBytes，添加到result集合中</span></span><br><span class="line">	  val recordBatchSize = readResult.info.records.sizeInBytes</span><br><span class="line">	  <span class="comment">// Once we read from a non-empty partition, we stop ignoring request and partition level size limits</span></span><br><span class="line">	  <span class="keyword">if</span> (recordBatchSize &gt; <span class="number">0</span>)</span><br><span class="line">	    minOneMessage = <span class="keyword">false</span></span><br><span class="line">	  <span class="comment">// fetchMaxBytes 减去 已读取的消息大小</span></span><br><span class="line">	  limitBytes = math.max(<span class="number">0</span>, limitBytes - recordBatchSize)</span><br><span class="line">	  result += (tp -&gt; readResult)</span><br><span class="line">	&#125;</span><br><span class="line">	result</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>readFromLocalLog主要是遍历请求中的分区，调用事先定义好的嵌套方法read，read方法会先找到leader副本，并且准备好读取的各种参数，最终调用Log对象的read方法</p>
<p>而外层的readFromLocalLog在拿到结果之后，会在循环中从fetchMaxBytes里减去已读取的消息大小</p>
<h2 id="Log-read"><a href="#Log-read" class="headerlink" title="Log#read"></a>Log#read</h2><p>我们知道Log只是个逻辑上的概念，本质是一个个Segment文件，每个Segment文件都有自己的起始位移(baseOffset)，<br>fetch请求要从fetchOffset处开始读取消息，我们常规的做法是先找到要读取的Segment文件，kafka为了加快寻找速度，增加了索引文件的概念，找到后根据fetchMaxBytes参数(当前在循环中，会一直变化)， 在高水位线的限制下调用Segment对象read方法读取消息，返回FetchDataInfo结果对象</p>
<p>以上就是该方法要做的事，Log对象的read方法源码如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Read messages from the log.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> startOffset 从哪里fetch，fetch请求中的fetchOffset参数:</span></span><br><span class="line"><span class="comment">    *                    The offset to begin reading at</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> maxLength fetch的maxBytes-已读取的消息大小:</span></span><br><span class="line"><span class="comment">    *                  The maximum number of bytes to read</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> maxOffset fetch的上限，即高水位线:</span></span><br><span class="line"><span class="comment">    *                  The offset to read up to, exclusive. (i.e. this offset NOT included in the resulting message set)</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> minOneMessage 是否至少fetch一条，即使的大小它已经超出了maxBytes:</span></span><br><span class="line"><span class="comment">    *                      If this is true, the first message will be returned even if it exceeds `maxLength` (if one exists)</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function">def <span class="title">read</span><span class="params">(startOffset: Long, maxLength: Int, maxOffset: Option[Long] = None, minOneMessage: Boolean = <span class="keyword">false</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">           isolationLevel: IsolationLevel)</span>: FetchDataInfo </span>= &#123;</span><br><span class="line">    maybeHandleIOException(s<span class="string">"Exception while reading from $topicPartition in dir $&#123;dir.getParent&#125;"</span>) &#123;</span><br><span class="line">      trace(s<span class="string">"Reading $maxLength bytes from offset $startOffset of length $size bytes"</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Because we don't use lock for reading, the synchronization is a little bit tricky.</span></span><br><span class="line">      <span class="comment">// We create the local variables to avoid race conditions with updates to the log.</span></span><br><span class="line">      <span class="comment">// 使用局部变量来避免并发锁竞争，nextOffsetMetadata.messageOffset就是LEO</span></span><br><span class="line">      val currentNextOffsetMetadata = nextOffsetMetadata</span><br><span class="line">      val next = currentNextOffsetMetadata.messageOffset</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 事务部分，先不关心</span></span><br><span class="line">      <span class="keyword">if</span> (startOffset == next) &#123;</span><br><span class="line">        val abortedTransactions =</span><br><span class="line">          <span class="keyword">if</span> (isolationLevel == IsolationLevel.READ_COMMITTED) Some(List.empty[AbortedTransaction])</span><br><span class="line">          <span class="keyword">else</span> None</span><br><span class="line">        <span class="keyword">return</span> FetchDataInfo(currentNextOffsetMetadata, MemoryRecords.EMPTY, firstEntryIncomplete = <span class="keyword">false</span>,</span><br><span class="line">          abortedTransactions = abortedTransactions)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// segments是一个跳表做的map，key为Segment的baseOffset，value是LogSegment对象</span></span><br><span class="line">      <span class="comment">// floorEntry是干嘛的？看哪个LogSegment的baseOffset &lt;= startOffset，其实就是在找要读取的LogSegment</span></span><br><span class="line">      <span class="comment">// segmentEntry是一个entry: &lt;baseOffset,LogSegment&gt;</span></span><br><span class="line">      var segmentEntry = segments.floorEntry(startOffset)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// return error on attempt to read beyond the log end offset or read below log start offset</span></span><br><span class="line">      <span class="comment">// 异常处理，大于LEO肯定不对，没找到合适的LogSegment也是不对的，至于startOffset &lt; logStartOffset感觉很多余</span></span><br><span class="line">      <span class="keyword">if</span> (startOffset &gt; next || segmentEntry == <span class="keyword">null</span> || startOffset &lt; logStartOffset)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> OffsetOutOfRangeException(s<span class="string">"Received request for offset $startOffset for partition $topicPartition, "</span> +</span><br><span class="line">          s<span class="string">"but we only have log segments in the range $logStartOffset to $next."</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 从baseOffset小于指定offset的Segment里读取消息，但如果Segment里没有消息，</span></span><br><span class="line"><span class="comment">        * 就继续往后面的Segment读,直到读取到了消息，或者到达了log的末尾</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">      <span class="comment">// Do the read on the segment with a base offset less than the target offset</span></span><br><span class="line">      <span class="comment">// but if that segment doesn't contain any messages with an offset greater than that</span></span><br><span class="line">      <span class="comment">// continue to read from successive segments until we get some messages or we reach the end of the log</span></span><br><span class="line">      <span class="keyword">while</span> (segmentEntry != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 取出LogSegment</span></span><br><span class="line">        val segment = segmentEntry.getValue</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果fetch读取了active Segment(最后一个正在写入的LogSegment)，在LEO更新前，发生了两次fetch会产生并发竞争，</span></span><br><span class="line">        <span class="comment">// 那么第二次fetch可能会发生OffsetOutOfRangeException，因此我们限制读取已暴露的位置(下面的maxPosition变量)，而不是active Segment的LEO</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// If the fetch occurs on the active segment, there might be a race condition where two fetch requests occur after</span></span><br><span class="line">        <span class="comment">// the message is appended but before the nextOffsetMetadata is updated. In that case the second fetch may</span></span><br><span class="line">        <span class="comment">// cause OffsetOutOfRangeException. To solve that, we cap the reading up to exposed position instead of the log</span></span><br><span class="line">        <span class="comment">// end of the active segment.</span></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">          * maxPosition大概是说segmentEntry如果是最后一个(active Segment)就返回LEO，</span></span><br><span class="line"><span class="comment">          * 否则返回当前Segment的大小</span></span><br><span class="line"><span class="comment">          */</span></span><br><span class="line">        val maxPosition = &#123;</span><br><span class="line">          <span class="keyword">if</span> (segmentEntry == segments.lastEntry) &#123;</span><br><span class="line">            val exposedPos = nextOffsetMetadata.relativePositionInSegment.toLong</span><br><span class="line">            <span class="comment">// 这个check again真的有用吗，为了解决bug？有点low</span></span><br><span class="line">            <span class="comment">// Check the segment again in case a new segment has just rolled out.</span></span><br><span class="line">            <span class="keyword">if</span> (segmentEntry != segments.lastEntry)</span><br><span class="line">            <span class="comment">// New log segment has rolled out, we can read up to the file end.</span></span><br><span class="line">              segment.size</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">              exposedPos</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            segment.size</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">          * 总结一下这几个入参</span></span><br><span class="line"><span class="comment">          * startOffset：从哪个位置开始读</span></span><br><span class="line"><span class="comment">          * maxOffset：读取的上限，高水位线</span></span><br><span class="line"><span class="comment">          * maxLength：读取的maxBytes</span></span><br><span class="line"><span class="comment">          * maxPosition：目前不知道什么用，LEO或者Segment的size</span></span><br><span class="line"><span class="comment">          * minOneMessage：是否至少读第一条</span></span><br><span class="line"><span class="comment">          */</span></span><br><span class="line">        val fetchInfo = segment.read(startOffset, maxOffset, maxLength, maxPosition, minOneMessage)</span><br><span class="line">        <span class="keyword">if</span> (fetchInfo == <span class="keyword">null</span>) &#123;</span><br><span class="line">          segmentEntry = segments.higherEntry(segmentEntry.getKey)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">return</span> isolationLevel match &#123;</span><br><span class="line">            <span class="comment">// 默认是READ_UNCOMMITTED，这里的fetchInfo作为返回值</span></span><br><span class="line">            <span class="keyword">case</span> IsolationLevel.READ_UNCOMMITTED =&gt; fetchInfo</span><br><span class="line">            <span class="keyword">case</span> IsolationLevel.READ_COMMITTED =&gt; addAbortedTransactions(startOffset, segmentEntry, fetchInfo)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 上面的while执行到最后一个Segment都还没return，说明我们要读取的消息都被删除了，这种情况返回空消息</span></span><br><span class="line">      <span class="comment">// okay we are beyond the end of the last segment with no data fetched although the start offset is in range,</span></span><br><span class="line">      <span class="comment">// this can happen when all messages with offset larger than start offsets have been deleted.</span></span><br><span class="line">      <span class="comment">// In this case, we will return the empty set with log end offset metadata</span></span><br><span class="line">      FetchDataInfo(nextOffsetMetadata, MemoryRecords.EMPTY)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="LogSegment-read"><a href="#LogSegment-read" class="headerlink" title="LogSegment#read"></a>LogSegment#read</h2><p>LogSegment#read属于接近底层的方法了，上一小节已经根据一个&lt;baseOffset, Segment&gt;的map找到了相应的Segment，但是要知道默认一个Segment大小为1G，想要在这么大的文件中查询数据，必须依赖索引。</p>
<p>kafka的读取逻辑是先根据二分法找到相应的offset和position，最终通过FileRecords.slice读取区间内的消息<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> startOffset 从哪个位置开始读：</span></span><br><span class="line"><span class="comment">    *                    A lower bound on the first offset to include in the message set we read</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> maxOffset 读取的上限，高水位线：</span></span><br><span class="line"><span class="comment">    *                  An optional maximum offset for the message set we read</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> maxSize fetch的maxBytes-已读取的消息大小：</span></span><br><span class="line"><span class="comment">    *                The maximum number of bytes to include in the message set we read</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> maxPosition 目前不知道什么用，LEO或者Segment的size：</span></span><br><span class="line"><span class="comment">    *                    The maximum position in the log segment that should be exposed for read</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> minOneMessage 是否至少读第一条：</span></span><br><span class="line"><span class="comment">    *                      If this is true, the first message will be returned even if it exceeds `maxSize` (if one exists)</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span> The fetched data and the offset metadata of the first message whose offset is &gt;= startOffset,</span></span><br><span class="line"><span class="comment">   *         or null if the startOffset is larger than the largest offset in this log</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="meta">@threadsafe</span></span><br><span class="line">  <span class="function">def <span class="title">read</span><span class="params">(startOffset: Long, maxOffset: Option[Long], maxSize: Int, maxPosition: Long = size,</span></span></span><br><span class="line"><span class="function"><span class="params">           minOneMessage: Boolean = <span class="keyword">false</span>)</span>: FetchDataInfo </span>= &#123;</span><br><span class="line">   </span><br><span class="line">    <span class="comment">// 日志文件字节数大小</span></span><br><span class="line">    val logSize = log.sizeInBytes <span class="comment">// this may change, need to save a consistent copy</span></span><br><span class="line">    <span class="comment">// 从index文件里查找offset,position</span></span><br><span class="line">    val startOffsetAndSize = translateOffset(startOffset)</span><br><span class="line"></span><br><span class="line">    val startPosition = startOffsetAndSize.position</span><br><span class="line">    val offsetMetadata = <span class="keyword">new</span> LogOffsetMetadata(startOffset, <span class="keyword">this</span>.baseOffset, startPosition)</span><br><span class="line"></span><br><span class="line">    val adjustedMaxSize =</span><br><span class="line">      <span class="keyword">if</span> (minOneMessage) math.max(maxSize, startOffsetAndSize.size)</span><br><span class="line">      <span class="keyword">else</span> maxSize</span><br><span class="line"></span><br><span class="line">    <span class="comment">// calculate the length of the message set to read based on whether or not they gave us a maxOffset</span></span><br><span class="line">    val fetchSize: Int = maxOffset match &#123;</span><br><span class="line">      <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(offset)</span> </span>=&gt;</span><br><span class="line">        val mapping = translateOffset(offset, startPosition)</span><br><span class="line">        val endPosition =</span><br><span class="line">          <span class="keyword">if</span> (mapping == <span class="keyword">null</span>)</span><br><span class="line">            logSize <span class="comment">// the max offset is off the end of the log, use the end of the file</span></span><br><span class="line">          <span class="keyword">else</span></span><br><span class="line">            mapping.position</span><br><span class="line">        min(min(maxPosition, endPosition) - startPosition, adjustedMaxSize).toInt</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// log.slice方法是在真正的获取消息</span></span><br><span class="line">    FetchDataInfo(offsetMetadata, log.slice(startPosition, fetchSize),</span><br><span class="line">      firstEntryIncomplete = adjustedMaxSize &lt; startOffsetAndSize.size)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="返回结果处理"><a href="#返回结果处理" class="headerlink" title="返回结果处理"></a>返回结果处理</h2><p>经过层层返回，回到最初的的handleFetchRequest方法中，看看processResponseCallback方法中是如何对读取结果进行处理并返回给consumer的</p>
<p>省略配额限流相关代码…</p>
<p>该方法的入参是一个(TopicPartition, FetchPartitionData)，表示每个分区对应的读取结果<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// the callback for process a fetch response, invoked before throttling</span></span><br><span class="line"><span class="function">def <span class="title">processResponseCallback</span><span class="params">(responsePartitionData: Seq[(TopicPartition, FetchPartitionData)</span>]): Unit </span>= &#123;</span><br><span class="line">  <span class="comment">// FetchPartitionData转PartitionData</span></span><br><span class="line">  val partitions = <span class="keyword">new</span> util.LinkedHashMap[TopicPartition, FetchResponse.PartitionData[Records]]</span><br><span class="line">  responsePartitionData.foreach &#123; <span class="keyword">case</span> (tp, data) =&gt;</span><br><span class="line">    val abortedTransactions = data.abortedTransactions.map(_.asJava).orNull</span><br><span class="line">    val lastStableOffset = data.lastStableOffset.getOrElse(FetchResponse.INVALID_LAST_STABLE_OFFSET)</span><br><span class="line">    partitions.put(tp, <span class="keyword">new</span> FetchResponse.PartitionData(data.error, data.highWatermark, lastStableOffset,</span><br><span class="line">      data.logStartOffset, abortedTransactions, data.records))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 错误的分区也要返回各自的错误信息</span></span><br><span class="line">  erroneous.foreach &#123; <span class="keyword">case</span> (tp, data) =&gt; partitions.put(tp, data) &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// When this callback is triggered, the remote API call has completed.</span></span><br><span class="line">  <span class="comment">// Record time before any byte-rate throttling.</span></span><br><span class="line">  request.apiRemoteCompleteTimeNanos = time.nanoseconds</span><br><span class="line"></span><br><span class="line">  var unconvertedFetchResponse: FetchResponse[Records] = <span class="keyword">null</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// follower同步的fetch</span></span><br><span class="line">  <span class="keyword">if</span> (fetchRequest.isFromFollower) &#123;</span><br><span class="line">    <span class="comment">// We've already evaluated against the quota and are good to go. Just need to record it now.</span></span><br><span class="line">    unconvertedFetchResponse = fetchContext.updateAndGenerateResponseData(partitions)</span><br><span class="line">    val responseSize = sizeOfThrottledPartitions(versionId, unconvertedFetchResponse, quotas.leader)</span><br><span class="line">    quotas.leader.record(responseSize)</span><br><span class="line">    trace(s<span class="string">"Sending Fetch response with partitions.size=$&#123;unconvertedFetchResponse.responseData().size()&#125;, "</span> +</span><br><span class="line">      s<span class="string">"metadata=$&#123;unconvertedFetchResponse.sessionId()&#125;"</span>)</span><br><span class="line">    sendResponseExemptThrottle(request, createResponse(<span class="number">0</span>), Some(updateConversionStats))</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// Fetch size used to determine throttle time is calculated before any down conversions.</span></span><br><span class="line">    <span class="comment">// This may be slightly different from the actual response size. But since down conversions</span></span><br><span class="line">    <span class="comment">// result in data being loaded into memory, we should do this only when we are not going to throttle.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Record both bandwidth and request quota-specific values and throttle by muting the channel if any of the</span></span><br><span class="line">    <span class="comment">// quotas have been violated. If both quotas have been violated, use the max throttle time between the two</span></span><br><span class="line">    <span class="comment">// quotas. When throttled, we unrecord the recorded bandwidth quota value</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 大部分都是限流先关代码，先忽略</span></span><br><span class="line">    val responseSize = fetchContext.getResponseSize(partitions, versionId)</span><br><span class="line">    val timeMs = time.milliseconds()</span><br><span class="line">    val requestThrottleTimeMs = quotas.request.maybeRecordAndGetThrottleTimeMs(request)</span><br><span class="line">    val bandwidthThrottleTimeMs = quotas.fetch.maybeRecordAndGetThrottleTimeMs(request, responseSize, timeMs)</span><br><span class="line"></span><br><span class="line">    val maxThrottleTimeMs = math.max(bandwidthThrottleTimeMs, requestThrottleTimeMs)</span><br><span class="line">    <span class="keyword">if</span> (maxThrottleTimeMs &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// Even if we need to throttle for request quota violation, we should "unrecord" the already recorded value</span></span><br><span class="line">      <span class="comment">// from the fetch quota because we are going to return an empty response.</span></span><br><span class="line">      quotas.fetch.unrecordQuotaSensor(request, responseSize, timeMs)</span><br><span class="line">      <span class="keyword">if</span> (bandwidthThrottleTimeMs &gt; requestThrottleTimeMs) &#123;</span><br><span class="line">        quotas.fetch.throttle(request, bandwidthThrottleTimeMs, sendResponse)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        quotas.request.throttle(request, requestThrottleTimeMs, sendResponse)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// If throttling is required, return an empty response.</span></span><br><span class="line">      unconvertedFetchResponse = fetchContext.getThrottledResponse(maxThrottleTimeMs)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// Get the actual response. This will update the fetch context.</span></span><br><span class="line">      <span class="comment">// 这是很关键的一行代码，创建了Response对象，全量和增量的方式有所不同，后续的FetchSession再说</span></span><br><span class="line">      unconvertedFetchResponse = fetchContext.updateAndGenerateResponseData(partitions)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Send the response immediately.</span></span><br><span class="line">    <span class="comment">// 发送响应到Processor的responseQueue中</span></span><br><span class="line">    sendResponse(request, Some(createResponse(maxThrottleTimeMs)), Some(updateConversionStats))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 很简单的一个方法，里面用maybeConvertFetchedData方法处理版本兼容引起的消息降级转换</span></span><br><span class="line"><span class="comment">    * 然后统计了下bytes out的metric，最终返回FetchResponse</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  <span class="function">def <span class="title">createResponse</span><span class="params">(throttleTimeMs: Int)</span>: FetchResponse[BaseRecords] </span>= &#123;</span><br><span class="line">    <span class="comment">// Down-convert messages for each partition if required</span></span><br><span class="line">    val convertedData = <span class="keyword">new</span> util.LinkedHashMap[TopicPartition, FetchResponse.PartitionData[BaseRecords]]</span><br><span class="line">    unconvertedFetchResponse.responseData().asScala.foreach &#123; <span class="keyword">case</span> (tp, unconvertedPartitionData) =&gt;</span><br><span class="line">      <span class="keyword">if</span> (unconvertedPartitionData.error != Errors.NONE)</span><br><span class="line">        debug(s<span class="string">"Fetch request with correlation id $&#123;request.header.correlationId&#125; from client $clientId "</span> +</span><br><span class="line">          s<span class="string">"on partition $tp failed due to $&#123;unconvertedPartitionData.error.exceptionName&#125;"</span>)</span><br><span class="line">      convertedData.put(tp, maybeConvertFetchedData(tp, unconvertedPartitionData))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Prepare fetch response from converted data</span></span><br><span class="line">    val response = <span class="keyword">new</span> FetchResponse(unconvertedFetchResponse.error(), convertedData, throttleTimeMs,</span><br><span class="line">      unconvertedFetchResponse.sessionId())</span><br><span class="line">    response.responseData.asScala.foreach &#123; <span class="keyword">case</span> (topicPartition, data) =&gt;</span><br><span class="line">      <span class="comment">// record the bytes out metrics only when the response is being sent</span></span><br><span class="line">      brokerTopicStats.updateBytesOut(topicPartition.topic, fetchRequest.isFromFollower, data.records.sizeInBytes)</span><br><span class="line">    &#125;</span><br><span class="line">    info(s<span class="string">"fetch response is $&#123;response&#125;"</span>)</span><br><span class="line">    response</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">updateConversionStats</span><span class="params">(send: Send)</span>: Unit </span>= &#123;</span><br><span class="line">    send match &#123;</span><br><span class="line">      <span class="keyword">case</span> send: MultiRecordsSend <span class="keyword">if</span> send.recordConversionStats != <span class="keyword">null</span> =&gt;</span><br><span class="line">        send.recordConversionStats.asScala.toMap.foreach &#123;</span><br><span class="line">          <span class="keyword">case</span> (tp, stats) =&gt; updateRecordConversionStats(request, tp, stats)</span><br><span class="line">        &#125;</span><br><span class="line">      <span class="keyword">case</span> _ =&gt;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>fetch请求处理流程调用的对象基本和produce请求类似，需要注意的几点是：</p>
<ol>
<li>fetch请求分为consumer和follower，server端用一个replicaId字段判断，consumer为-1</li>
<li>consumer读取有高水位线的限制，follower则没有</li>
<li>consumer受限于各种参数，不会立即响应，需要放入purgatory延迟队列中等待完成</li>
<li>响应回调中遇到了限流，FetchSession，消息降级等过程</li>
</ol>
<p><img src="https://ae01.alicdn.com/kf/Hfe405813f8c148df945920680455868dt.png" alt="consumer fetch流程"></p>
<p>部分图片引用：<br><a href="https://www.cnblogs.com/huxi2b/p/9335064.html" target="_blank" rel="noopener">https://www.cnblogs.com/huxi2b/p/9335064.html</a><br><a href="https://www.cnblogs.com/huxi2b/p/7453543.html" target="_blank" rel="noopener">https://www.cnblogs.com/huxi2b/p/7453543.html</a></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">紫夜</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://greedypirate.github.io/2019/12/17/kafka-server端源码分析之拉取消息/">https://greedypirate.github.io/2019/12/17/kafka-server端源码分析之拉取消息/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/kafka/">kafka</a><a class="post-meta__tags" href="/tags/中间件/">中间件</a><a class="post-meta__tags" href="/tags/消息/">消息</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="https://ae01.alicdn.com/kf/H50b5d4d79e454447974210dae2d054435.png"><div class="post-qr-code__desc">支付宝打赏</div></div><div class="post-qr-code-item"><img class="post-qr-code__img" src="https://ae01.alicdn.com/kf/H45f5b133580045879faaa5fcbe9b598fu.png"><div class="post-qr-code__desc">微信打赏</div></div></div><div class="addthis_inline_share_toolbox pull-right"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5b6532776de86c85" async></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2020/01/25/kafka本地启动后不打印日志问题/"><i class="fa fa-chevron-left">  </i><span>kafka本地启动后不打印日志问题</span></a></div><div class="next-post pull-right"><a href="/2019/12/10/kafka-server端源码分析之接收消息/"><span>kafka server端源码分析之接收消息</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '0349a7a18b86f2a653e3',
  clientSecret: '567ba8cefbe2ecffbbc04e676652ae4b43e7f952',
  repo: 'GreedyPirate.github.io',
  owner: 'GreedyPirate',
  admin: 'GreedyPirate',
  id: md5(decodeURI(location.pathname)),
  language: ''
})
gitalk.render('gitalk-container')</script></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2018 - 2020 By 紫夜</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://GreedyPirate.github.io">blog</a>!</div><div class="busuanzi"><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.5.6"></script><script src="/js/fancybox.js?version=1.5.6"></script><script src="/js/sidebar.js?version=1.5.6"></script><script src="/js/copy.js?version=1.5.6"></script><script src="/js/fireworks.js?version=1.5.6"></script><script src="/js/transition.js?version=1.5.6"></script><script src="/js/scroll.js?version=1.5.6"></script><script src="/js/head.js?version=1.5.6"></script><script src="/js/search/local-search.js"></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>