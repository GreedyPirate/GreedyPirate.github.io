<!DOCTYPE html><html><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="kafka消息格式与日志存储原理分析"><meta name="keywords" content="kafka,中间件,消息"><meta name="author" content="紫夜,undefined"><meta name="copyright" content="紫夜"><title>kafka消息格式与日志存储原理分析 | 紫夜の博客</title><link rel="shortcut icon" href="/my-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.5.6"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css?version=1.5.6"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/gh/upupming/gitalk@36368e5dffd049e956cdbbd751ff96c28d8255cf/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="dns-prefetch" href="https://hm.baidu.com"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6ba54465c1ff0c31b169e7a89d3dbe37";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#写入"><span class="toc-number">1.</span> <span class="toc-text">写入</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#消息批与消息格式"><span class="toc-number">1.1.</span> <span class="toc-text">消息批与消息格式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#日志段Segment"><span class="toc-number">1.2.</span> <span class="toc-text">日志段Segment</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#导出"><span class="toc-number">1.3.</span> <span class="toc-text">导出</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#读取"><span class="toc-number">1.4.</span> <span class="toc-text">读取</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#时间索引"><span class="toc-number">1.4.1.</span> <span class="toc-text">时间索引</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#二分查找过程"><span class="toc-number">1.4.1.1.</span> <span class="toc-text">二分查找过程</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://ae01.alicdn.com/kf/He0f82cbc452e4e99b7da670575752df0l.png"></div><div class="author-info__name text-center">紫夜</div><div class="author-info__description text-center">stay hungry, stay foolish</div><div class="follow-button"><a href="https://github.com/GreedyPirate" target="_blank">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">65</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">24</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">11</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" href="https://blog.csdn.net/yj7758423" target="_blank">我的CSDN</a><a class="author-info-links__name text-center" href="https://segmentfault.com/blog/code-craft" target="_blank">膜拜大神</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://ae01.alicdn.com/kf/H6e9ae455bca04f4098243e3f73a85c4fb.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">紫夜の博客</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">kafka消息格式与日志存储原理分析</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-02-01</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Kafka-Tutorial/">Kafka Tutorial</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">2,289</span><span class="post-meta__separator">|</span><span>Reading time: 10 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p>kafka自0.11.0.0版本之后消息体升级到了V2版本，本文从生产者消息发送，broker消息存储，消息读取等几个部分作为切入点，来分析kafka的消息流转</p>
<h1 id="写入"><a href="#写入" class="headerlink" title="写入"></a>写入</h1><p>producer通过PRODUCE请求将消息发送给broker，我们来看一下发送的内容是什么</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">short</span> acks;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> timeout;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> String transactionalId;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Map&lt;TopicPartition, Integer&gt; partitionSizes;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> Map&lt;TopicPartition, MemoryRecords&gt; partitionRecords;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">boolean</span> transactional = <span class="keyword">false</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">boolean</span> idempotent = <span class="keyword">false</span>;</span><br></pre></td></tr></table></figure>
<p>以上代码摘取自ProduceRequest类，它是producer发送消息的请求对象，其中消息载体为：Map&lt;TopicPartition, MemoryRecords&gt; partitionRecords</p>
<p>该map对象表示每一个分区对应的消息，那么MemoryRecords是如何包装消息的呢</p>
<p>MemoryRecords中一个重要的变量是: Iterable[MutableRecordBatch] batches， 如何理解这个对象呢，有个很取巧的办法，看MemoryRecords的toString方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    StringBuilder builder = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">    builder.append(<span class="string">'['</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 自己定义的counter</span></span><br><span class="line">    <span class="keyword">int</span> batchCounter = <span class="number">0</span>, recordCounter = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    Iterator&lt;MutableRecordBatch&gt; batchIterator = batches.iterator();</span><br><span class="line">    <span class="keyword">while</span> (batchIterator.hasNext()) &#123;</span><br><span class="line">        batchCounter++;</span><br><span class="line"></span><br><span class="line">        RecordBatch batch = batchIterator.next();</span><br><span class="line">        <span class="keyword">try</span> (CloseableIterator&lt;Record&gt; recordsIterator = batch.streamingIterator(BufferSupplier.create())) &#123;</span><br><span class="line">            <span class="keyword">while</span> (recordsIterator.hasNext()) &#123;</span><br><span class="line">                recordCounter++;</span><br><span class="line">                Record record = recordsIterator.next();</span><br><span class="line">                appendRecordToStringBuilder(builder, record.toString());</span><br><span class="line">                <span class="keyword">if</span> (recordsIterator.hasNext())</span><br><span class="line">                    builder.append(<span class="string">", "</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (KafkaException e) &#123;</span><br><span class="line">            appendRecordToStringBuilder(builder, <span class="string">"CORRUPTED"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (batchIterator.hasNext())</span><br><span class="line">            builder.append(<span class="string">", "</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    builder.append(<span class="string">']'</span>);</span><br><span class="line">    builder.append(<span class="string">", batch count is "</span>).append(batchCounter).append(<span class="string">", record count is "</span>).append(recordCounter);</span><br><span class="line">    <span class="keyword">return</span> builder.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到MemoryRecords中有一个RecordBatch(MutableRecordBatch是它的子接口)集合，而一个RecordBatch中又有一个Record集合</p>
<p>MemoryRecords，RecordBatch，Record三者的关系如下</p>
<p><img src="https://ae01.alicdn.com/kf/H69850c700b184507b2b6019442356429P.png" alt="消息类图"></p>
<p>其中大部分都是接口，具体实现就是MemoryRecords，DefaultRecordBatch，DefaultRecord三者的关系</p>
<p>小结一下：producer给broker发送一批消息：Map&lt;TopicPartition, MemoryRecords&gt;，每个分区对应的消息用MemoryRecords表示，它有一个batchs变量，表示一个DefaultRecordBatch集合<br>而每一个DefaultRecordBatch表示一批消息，里面的每一条消息用DefaultRecord对象表示</p>
<p>但是大家也应该发现一个问题了，一批消息用一个DefaultRecordBatch表示就好了，为什么要包装一层Iterable[MutableRecordBatch] batches<br>其实在上面的toString发送中，笔者已经做了测试，该集合的大小始终为1，只需要关心DefaultRecordBatch与DefaultRecord即可</p>
<h2 id="消息批与消息格式"><a href="#消息批与消息格式" class="headerlink" title="消息批与消息格式"></a>消息批与消息格式</h2><p>DefaultRecordBatch与DefaultRecord的结构在各自的类注释中已写明</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">RecordBatch =&gt;</span><br><span class="line">	BaseOffset =&gt; Int64</span><br><span class="line">	Length =&gt; Int32</span><br><span class="line">	PartitionLeaderEpoch =&gt; Int32</span><br><span class="line">	Magic =&gt; Int8</span><br><span class="line">	CRC =&gt; Uint32</span><br><span class="line">	Attributes =&gt; Int16</span><br><span class="line">	LastOffsetDelta =&gt; Int32 <span class="comment">// also serves as LastSequenceDelta</span></span><br><span class="line">	FirstTimestamp =&gt; Int64</span><br><span class="line">	MaxTimestamp =&gt; Int64</span><br><span class="line">	ProducerId =&gt; Int64</span><br><span class="line">	ProducerEpoch =&gt; Int16</span><br><span class="line">	BaseSequence =&gt; Int32</span><br><span class="line">	Records =&gt; [Record]</span><br><span class="line"></span><br><span class="line">Record =&gt;</span><br><span class="line">	Length =&gt; Varint</span><br><span class="line">	Attributes =&gt; Int8</span><br><span class="line">	TimestampDelta =&gt; Varlong</span><br><span class="line">	OffsetDelta =&gt; Varint</span><br><span class="line">	Key =&gt; Bytes</span><br><span class="line">	Value =&gt; Bytes</span><br><span class="line">	Headers =&gt; [HeaderKey HeaderValue]</span><br><span class="line">		HeaderKey =&gt; String</span><br><span class="line">		HeaderValue =&gt; Bytes</span><br></pre></td></tr></table></figure>
<p>为了方便观看，截取两张书中的图片<br><img src="https://ae01.alicdn.com/kf/H9687116c6b684543acc6b46a5c217098H.png" alt="单条消息Record结构"><br><img src="https://ae01.alicdn.com/kf/Hdad2d4d8764c434a8486ee90080aecbeM.png" alt="批量消息RecordBatch结构"></p>
<h2 id="日志段Segment"><a href="#日志段Segment" class="headerlink" title="日志段Segment"></a>日志段Segment</h2><p>消息真正落盘到文件系统是以日志存储，每一个分区，注意是分区级别，都对应了一个日志<strong>目录</strong>，下图是一个典型的分区目录，表示topic test-1的第0个分区<br><img src="https://ae01.alicdn.com/kf/H6501d183d9804508ba634d0ef45947e8k.png" alt="分区日志目录"></p>
<p>而日志更细颗粒度的存储方式是一个个以.log结尾的Segment(日志段)，以下介绍几个关于日志的概念，对大家阅读源码有很大帮助</p>
<p>首先大家要回忆下log4j，它在线上服务器一般是这样使用的：不论何时，只有一个日志文件在写入，一到整点，就不再写入，新建下一个日志文件，继续写入，设置日志最大保留时间为30天，30天以前的日志自动删除</p>
<p>以上关于log4j的使用对大家理解kafka日志的运作大有帮助，二者有很多相似之处</p>
<ol>
<li>activeSegment：活动的日志段，只有该Segment写入日志</li>
<li>roll Segment：在kafka中，每个Segment默认为1G，由log.segment.bytes参数控制，当达到1G时(已经写不下新消息了)，就会新建下一个Segment，文件名是offset.log，同时原来的文件变为只读</li>
<li><p>Segment的baseOffset：baseOffset就是Segment的第一条消息的位移，这也是Segment的文件名，读取消息时，只要我们知道了第一个比消息的offset大的baseOffset，那么它的前一个Segment就是消息所在的Segment，通过这样可以很快定位到消息在哪个Segment文件，所以见到Map&lt;Long, Segment&gt;的对象大家一看就懂了</p>
</li>
<li><p>logStartOffset: 它表示<strong>第一个Segment</strong>的起始offset，也是当前所有Segment的起始offset，在上图中它的值为203000。我们知道，kafka的日志是会过期的，也就是说logStartOffset在过期的Segment被删除之后是会变的</p>
</li>
<li><p>largestTimestamp: 每个Segment中最大的时间戳，也就是最后一条消息的时间戳</p>
</li>
</ol>
<h2 id="导出"><a href="#导出" class="headerlink" title="导出"></a>导出</h2><p>.log文件是不能直接打开的，我们使用以下命令将其保存到本地文件中。注：Segment默认1G，不要在线上随意上使用，可先下载到内存较大的机器上执行<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 消息</span></span><br><span class="line">./kafka-run-class.sh kafka.tools.DumpLogSegments --files /Users/admin/private/kafka/data/<span class="built_in">test</span>-1-0/00000000000000203000.log --<span class="built_in">print</span>-data-log &gt; ~/message.log</span><br><span class="line"></span><br><span class="line"><span class="comment">#索引</span></span><br><span class="line">./kafka-run-class.sh kafka.tools.DumpLogSegments --files /Users/admin/private/kafka/data/<span class="built_in">test</span>-1-0/00000000000000203000.index --<span class="built_in">print</span>-data-log &gt; ~/index.log</span><br></pre></td></tr></table></figure></p>
<p>截取部分日志内容如下<br>日志<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Dumping /Users/admin/private/kafka/data/<span class="built_in">test</span>-1-0/00000000000000203000.log</span><br><span class="line">Starting offset: 203000</span><br><span class="line">offset: 203000 position: 0 CreateTime: 1581597478310 isvalid: <span class="literal">true</span> keysize: -1 valuesize: 21 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: -1 isTransactional: <span class="literal">false</span> headerKeys: [] payload: <span class="built_in">local</span> <span class="built_in">test</span> -------- 0</span><br><span class="line">offset: 203001 position: 0 CreateTime: 1581597478320 isvalid: <span class="literal">true</span> keysize: -1 valuesize: 21 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: -1 isTransactional: <span class="literal">false</span> headerKeys: [] payload: <span class="built_in">local</span> <span class="built_in">test</span> -------- 1</span><br><span class="line">offset: 203002 position: 0 CreateTime: 1581597478321 isvalid: <span class="literal">true</span> keysize: -1 valuesize: 21 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: -1 isTransactional: <span class="literal">false</span> headerKeys: [] payload: <span class="built_in">local</span> <span class="built_in">test</span> -------- 2</span><br><span class="line">offset: 203003 position: 0 CreateTime: 1581597478321 isvalid: <span class="literal">true</span> keysize: -1 valuesize: 21 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: -1 isTransactional: <span class="literal">false</span> headerKeys: [] payload: <span class="built_in">local</span> <span class="built_in">test</span> -------- 3</span><br><span class="line">offset: 203004 position: 0 CreateTime: 1581597478321 isvalid: <span class="literal">true</span> keysize: -1 valuesize: 21 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: -1 isTransactional: <span class="literal">false</span> headerKeys: [] payload: <span class="built_in">local</span> <span class="built_in">test</span> -------- 4</span><br></pre></td></tr></table></figure></p>
<p>索引<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Dumping /Users/admin/private/kafka/data/<span class="built_in">test</span>-1-0/00000000000000203000.index</span><br><span class="line">offset: 203299 position: 8738</span><br><span class="line">offset: 204657 position: 34953</span><br><span class="line">offset: 205169 position: 51314</span><br><span class="line">offset: 205681 position: 67695</span><br><span class="line">offset: 206193 position: 84076</span><br><span class="line">offset: 206705 position: 100457</span><br><span class="line">offset: 207217 position: 116838</span><br><span class="line">offset: 207729 position: 133219</span><br><span class="line">offset: 208241 position: 149600</span><br><span class="line">offset: 208753 position: 165981</span><br><span class="line">offset: 209265 position: 182362</span><br></pre></td></tr></table></figure></p>
<h2 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h2><p>在以上日志文件的基础上，我们来看看kafka是如何读取日志的。 假设我要们读取offset为203500的消息，查找过程如下</p>
<p>首先通过Segment的baseOffset确定在哪个Segment，只需要遍历segments对象，找到第一个baseOffset比206000小的Segment，也就是00000000000000203000这个Segment</p>
<p>这里不要狭隘的把Segment理解为.log日志文件，在新建LogSegment对象的时候，会创建.log, .index, .timeindex, .txn(事务)4个文件<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> LogSegment(</span><br><span class="line">  FileRecords.open(Log.logFile(dir, baseOffset, fileSuffix), fileAlreadyExists, initFileSize, preallocate),</span><br><span class="line">  <span class="keyword">new</span> OffsetIndex(Log.offsetIndexFile(dir, baseOffset, fileSuffix), baseOffset = baseOffset, maxIndexSize = maxIndexSize),</span><br><span class="line">  <span class="keyword">new</span> TimeIndex(Log.timeIndexFile(dir, baseOffset, fileSuffix), baseOffset = baseOffset, maxIndexSize = maxIndexSize),</span><br><span class="line">  <span class="keyword">new</span> TransactionIndex(baseOffset, Log.transactionIndexFile(dir, baseOffset, fileSuffix)),</span><br><span class="line">  baseOffset,</span><br><span class="line">  indexIntervalBytes = config.indexInterval,</span><br><span class="line">  rollJitterMs = config.randomSegmentJitter,</span><br><span class="line">  maxSegmentMs = config.segmentMs,</span><br><span class="line">  maxSegmentBytes = config.segmentSize,</span><br><span class="line">  time)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>查找Segment相关代码如下，segments类型为ConcurrentSkipListMap&lt;baseOffset, Segment&gt;，startOffset是消费时要拉取的起始offset<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var segmentEntry = segments.floorEntry(startOffset)</span><br></pre></td></tr></table></figure></p>
<p>通过二分法，找出第一个比203500大的offset索引是[204657, 34953], 那么在.log文件中从物理位置34953开始查找，即可找到offset为203500的消息</p>
<h3 id="时间索引"><a href="#时间索引" class="headerlink" title="时间索引"></a>时间索引</h3><p>时间索引为.timeindex文件，它的原理是根据要查找的时间戳(targetTimestamp)，先找到相应的Segment，但是并没有一个Map保存了时间戳和Segment的映射关系，而Segment保存了当前分段中最大的时间戳(largestTimestamp)，所以需要遍历所有的Segment，找出第一个最大时间戳比targetTimestamp大的Segment<br>找到Segment后，通过查找.timeindex索引文件，查询先找到offset，然后再去.index文件找到相应的position，最后再去.log日志文件中查找</p>
<p>以上过程发生在Log类的fetchOffsetsByTimestamp方法，关键部分的代码如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">fetchOffsetsByTimestamp</span><span class="params">(targetTimestamp: Long)</span>: Option[TimestampOffset] </span>= &#123;</span><br><span class="line">  val targetSeg = &#123;</span><br><span class="line">    <span class="comment">// Get all the segments whose largest timestamp is smaller than target timestamp</span></span><br><span class="line">    <span class="comment">// 先找segments，找第一个Segment的最大Timestamp大于请求中的Timestamp，可以看下takeWhile源码</span></span><br><span class="line">    val earlierSegs = segmentsCopy.takeWhile(_.largestTimestamp &lt; targetTimestamp) <span class="comment">//一直循环，只要不满足表示式停止</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  targetSeg.flatMap(_.findOffsetByTimestamp(targetTimestamp, logStartOffset))</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">def <span class="title">findOffsetByTimestamp</span><span class="params">(timestamp: Long, startingOffset: Long = baseOffset)</span>: Option[TimestampOffset] </span>= &#123;</span><br><span class="line">  <span class="comment">// Get the index entry with a timestamp less than or equal to the target timestamp</span></span><br><span class="line">  val timestampOffset = timeIndex.lookup(timestamp)</span><br><span class="line">  val position = offsetIndex.lookup(math.max(timestampOffset.offset, startingOffset)).position</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Search the timestamp</span></span><br><span class="line">  Option(log.searchForTimestamp(timestamp, position, startingOffset)).map &#123; timestampAndOffset =&gt;</span><br><span class="line">    TimestampOffset(timestampAndOffset.timestamp, timestampAndOffset.offset)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="二分查找过程"><a href="#二分查找过程" class="headerlink" title="二分查找过程"></a>二分查找过程</h4><p>先说说3个参数，分别是：索引文件，要查找的目标值，查找类型，kafka将索引文件中的每一条数据抽象成一个entry，查找类型就是指按Key还是按Value查找</p>
<p>查找过程是一个十分简单的二分查找算法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">indexSlotRangeFor</span><span class="params">(idx: ByteBuffer, target: Long, searchEntity: IndexSearchEntity)</span>: <span class="params">(Int, Int)</span> </span>= &#123;</span><br><span class="line">    <span class="comment">// check if the index is empty</span></span><br><span class="line">    <span class="keyword">if</span>(_entries == <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span> (-<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// check if the target offset is smaller than the least offset</span></span><br><span class="line">    <span class="keyword">if</span>(compareIndexEntry(parseEntry(idx, <span class="number">0</span>), target, searchEntity) &gt; <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span> (-<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// binary search for the entry</span></span><br><span class="line">    var lo = <span class="number">0</span></span><br><span class="line">    var hi = _entries - <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span>(lo &lt; hi) &#123;</span><br><span class="line">      val mid = ceil(hi/<span class="number">2.0</span> + lo/<span class="number">2.0</span>).toInt</span><br><span class="line">      val found = parseEntry(idx, mid)</span><br><span class="line">      val compareResult = compareIndexEntry(found, target, searchEntity)</span><br><span class="line">      <span class="keyword">if</span>(compareResult &gt; <span class="number">0</span>)</span><br><span class="line">        hi = mid - <span class="number">1</span></span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span>(compareResult &lt; <span class="number">0</span>)</span><br><span class="line">        lo = mid</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> (mid, mid)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    (lo, <span class="keyword">if</span> (lo == _entries - <span class="number">1</span>) -<span class="number">1</span> <span class="keyword">else</span> lo + <span class="number">1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">紫夜</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://greedypirate.github.io/2020/02/01/kafka消息格式与日志存储原理分析/">https://greedypirate.github.io/2020/02/01/kafka消息格式与日志存储原理分析/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/kafka/">kafka</a><a class="post-meta__tags" href="/tags/中间件/">中间件</a><a class="post-meta__tags" href="/tags/消息/">消息</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="https://ae01.alicdn.com/kf/H50b5d4d79e454447974210dae2d054435.png"><div class="post-qr-code__desc">支付宝打赏</div></div><div class="post-qr-code-item"><img class="post-qr-code__img" src="https://ae01.alicdn.com/kf/H45f5b133580045879faaa5fcbe9b598fu.png"><div class="post-qr-code__desc">微信打赏</div></div></div><div class="addthis_inline_share_toolbox pull-right"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5b6532776de86c85" async></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2020/02/03/Spring-IOC容器启动之初始化上下文/"><i class="fa fa-chevron-left">  </i><span>Spring IOC容器启动之初始化上下文</span></a></div><div class="next-post pull-right"><a href="/2020/01/25/kafka本地启动后不打印日志问题/"><span>kafka本地启动后不打印日志问题</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '0349a7a18b86f2a653e3',
  clientSecret: '567ba8cefbe2ecffbbc04e676652ae4b43e7f952',
  repo: 'GreedyPirate.github.io',
  owner: 'GreedyPirate',
  admin: 'GreedyPirate',
  id: md5(decodeURI(location.pathname)),
  language: ''
})
gitalk.render('gitalk-container')</script></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2018 - 2020 By 紫夜</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://GreedyPirate.github.io">blog</a>!</div><div class="busuanzi"><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.5.6"></script><script src="/js/fancybox.js?version=1.5.6"></script><script src="/js/sidebar.js?version=1.5.6"></script><script src="/js/copy.js?version=1.5.6"></script><script src="/js/fireworks.js?version=1.5.6"></script><script src="/js/transition.js?version=1.5.6"></script><script src="/js/scroll.js?version=1.5.6"></script><script src="/js/head.js?version=1.5.6"></script><script src="/js/search/local-search.js"></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>