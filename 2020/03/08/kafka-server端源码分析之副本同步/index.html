<!DOCTYPE html><html><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="kafka server端源码分析之副本同步"><meta name="keywords" content="kafka,中间件,消息"><meta name="author" content="紫夜,undefined"><meta name="copyright" content="紫夜"><title>kafka server端源码分析之副本同步 | 紫夜の博客</title><link rel="shortcut icon" href="/my-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.5.6"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css?version=1.5.6"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/gh/upupming/gitalk@36368e5dffd049e956cdbbd751ff96c28d8255cf/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="dns-prefetch" href="https://hm.baidu.com"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6ba54465c1ff0c31b169e7a89d3dbe37";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#正文"><span class="toc-number">2.</span> <span class="toc-text">正文</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#副本拉取管理器"><span class="toc-number">2.1.</span> <span class="toc-text">副本拉取管理器</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#副本同步"><span class="toc-number">3.</span> <span class="toc-text">副本同步</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#何时同步"><span class="toc-number">3.1.</span> <span class="toc-text">何时同步</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#同步过程分解"><span class="toc-number">3.2.</span> <span class="toc-text">同步过程分解</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#follower副本端同步"><span class="toc-number">4.</span> <span class="toc-text">follower副本端同步</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#同步线程doWork"><span class="toc-number">4.1.</span> <span class="toc-text">同步线程doWork</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#发送fetch请求"><span class="toc-number">4.2.</span> <span class="toc-text">发送fetch请求</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#leader记录follower副本的同步状态"><span class="toc-number">5.</span> <span class="toc-text">leader记录follower副本的同步状态</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#重点"><span class="toc-number">5.0.0.1.</span> <span class="toc-text">重点</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Partition更新同步状态"><span class="toc-number">5.1.</span> <span class="toc-text">Partition更新同步状态</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Replica更新同步状态"><span class="toc-number">5.1.1.</span> <span class="toc-text">Replica更新同步状态</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#maybeExpandIsr扩充ISR列表"><span class="toc-number">5.1.2.</span> <span class="toc-text">maybeExpandIsr扩充ISR列表</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#follower副本端处理响应"><span class="toc-number">6.</span> <span class="toc-text">follower副本端处理响应</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#总结"><span class="toc-number">7.</span> <span class="toc-text">总结</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://ae01.alicdn.com/kf/He0f82cbc452e4e99b7da670575752df0l.png"></div><div class="author-info__name text-center">紫夜</div><div class="author-info__description text-center">stay hungry, stay foolish</div><div class="follow-button"><a href="https://github.com/GreedyPirate" target="_blank">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">65</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">24</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">11</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" href="https://blog.csdn.net/yj7758423" target="_blank">我的CSDN</a><a class="author-info-links__name text-center" href="https://segmentfault.com/blog/code-craft" target="_blank">膜拜大神</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://ae01.alicdn.com/kf/H6e9ae455bca04f4098243e3f73a85c4fb.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">紫夜の博客</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">kafka server端源码分析之副本同步</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-03-08</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Kafka-Tutorial/">Kafka Tutorial</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">3,750</span><span class="post-meta__separator">|</span><span>Reading time: 16 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>为什么我现在才写副本同步的解析呢，因为它太复杂了，仅仅是什么时候触发的副本同步，就涉及到KafkaController，LeaderAndIsr请求等，经过前面文章的梳理，现在时机正好</p>
<h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><p>通常我们会为了提高系统并发能力、可伸缩性，为topic设置多个分区，每个分区副本数通常设置为3个，其中1个为leader副本，其余2个follower副本为冗余备份使用。在producer端为了保证消息不丢失，通常设置ack=-1，并搭配失败重试机制</p>
<p>本文主要讨论broker端写入leader副本后，follower副本如何同步消息，以及如何更新HighWatermark，并使Purgatory延迟队列中的PRODUCE请求完成(complete)，响应客户端</p>
<h2 id="副本拉取管理器"><a href="#副本拉取管理器" class="headerlink" title="副本拉取管理器"></a>副本拉取管理器</h2><p>在Kafka启动时，会初始化ReplicaManager副本管理器，同时该类中有一行初始化语句<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val replicaFetcherManager = createReplicaFetcherManager(metrics, time, threadNamePrefix, quotaManagers.follower)</span><br></pre></td></tr></table></figure></p>
<p>其实就是new了一个ReplicaFetcherManager对象，该对象的功能十分简单，就是创建和关闭Fetch线程</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class ReplicaFetcherManager(brokerConfig: KafkaConfig, protected val replicaManager: ReplicaManager, metrics: Metrics,</span><br><span class="line">                            time: Time, threadNamePrefix: Option[String] = None, quotaManager: ReplicationQuotaManager)</span><br><span class="line">      <span class="function">extends <span class="title">AbstractFetcherManager</span><span class="params">(<span class="string">"ReplicaFetcherManager on broker "</span> + brokerConfig.brokerId,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="string">"Replica"</span>, brokerConfig.numReplicaFetchers)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">override def <span class="title">createFetcherThread</span><span class="params">(fetcherId: Int, sourceBroker: BrokerEndPoint)</span>: AbstractFetcherThread </span>= &#123;</span><br><span class="line">    val prefix = threadNamePrefix.map(tp =&gt; s<span class="string">"$&#123;tp&#125;:"</span>).getOrElse(<span class="string">""</span>)</span><br><span class="line">    val threadName = s<span class="string">"$&#123;prefix&#125;ReplicaFetcherThread-$fetcherId-$&#123;sourceBroker.id&#125;"</span></span><br><span class="line">    <span class="keyword">new</span> ReplicaFetcherThread(threadName, fetcherId, sourceBroker, brokerConfig, replicaManager, metrics, time, quotaManager)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">shutdown</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    info(<span class="string">"shutting down"</span>)</span><br><span class="line">    closeAllFetchers()</span><br><span class="line">    info(<span class="string">"shutdown completed"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="副本同步"><a href="#副本同步" class="headerlink" title="副本同步"></a>副本同步</h1><p>在分析副本同步过程之前，我们先想一想什么时候开始同步，也就是上面的createFetcherThread什么时候创建并启动的</p>
<h2 id="何时同步"><a href="#何时同步" class="headerlink" title="何时同步"></a>何时同步</h2><p>这里就要回顾<a href="">KafkaController源码分析之LeaderAndIsr请求</a>一文了，这也是我先写LeaderAndIsr，然后才分析副本同步的原因</p>
<p>在前文中，提到了becomeLeaderOrFollower方法会将分区添加到副本同步线程中，具体实现就在addFetcherForPartitions方法中</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">addFetcherForPartitions</span><span class="params">(partitionAndOffsets: Map[TopicPartition, BrokerAndInitialOffset])</span> </span>&#123;</span><br><span class="line">    lock <span class="keyword">synchronized</span> &#123;</span><br><span class="line">      <span class="comment">// partitionsPerFetcher = Map[BrokerAndFetcherId, Map[TopicPartition, BrokerAndInitialOffset]]</span></span><br><span class="line">      <span class="comment">// 分组的key是目标broker+同步线程，也就是同一个fetcher线程向同一个broker同步 为一组</span></span><br><span class="line">      val partitionsPerFetcher = partitionAndOffsets.groupBy &#123; <span class="keyword">case</span>(topicPartition, brokerAndInitialFetchOffset) =&gt;</span><br><span class="line">        BrokerAndFetcherId(brokerAndInitialFetchOffset.broker, getFetcherId(topicPartition.topic, topicPartition.partition))&#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 事先定义好创建并启动的方法</span></span><br><span class="line">      <span class="function">def <span class="title">addAndStartFetcherThread</span><span class="params">(brokerAndFetcherId: BrokerAndFetcherId, brokerIdAndFetcherId: BrokerIdAndFetcherId)</span> </span>&#123;</span><br><span class="line">        val fetcherThread = createFetcherThread(brokerAndFetcherId.fetcherId, brokerAndFetcherId.broker)</span><br><span class="line">        fetcherThreadMap.put(brokerIdAndFetcherId, fetcherThread)</span><br><span class="line">        fetcherThread.start</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> ((brokerAndFetcherId, initialFetchOffsets) &lt;- partitionsPerFetcher) &#123;</span><br><span class="line">        val brokerIdAndFetcherId = BrokerIdAndFetcherId(brokerAndFetcherId.broker.id, brokerAndFetcherId.fetcherId)</span><br><span class="line">        <span class="comment">// fetcherThreadMap: Map[BrokerIdAndFetcherId, AbstractFetcherThread]</span></span><br><span class="line">        <span class="comment">// 这里的逻辑还是很清晰的</span></span><br><span class="line">        fetcherThreadMap.get(brokerIdAndFetcherId) match &#123;</span><br><span class="line">            <span class="comment">// 已存在对应的Thread，并且线程的broker和分区要同步的broker相同，直接复用就行了</span></span><br><span class="line">          <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(f)</span> <span class="keyword">if</span> f.sourceBroker.host </span>== brokerAndFetcherId.broker.host &amp;&amp; f.sourceBroker.port == brokerAndFetcherId.broker.port =&gt;</span><br><span class="line">            <span class="comment">// reuse the fetcher thread</span></span><br><span class="line">          <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(f)</span> </span>=&gt;</span><br><span class="line">            <span class="comment">// 如果前面的if不成立，就需要关闭，重新添加并启动</span></span><br><span class="line">            f.shutdown()</span><br><span class="line">            addAndStartFetcherThread(brokerAndFetcherId, brokerIdAndFetcherId)</span><br><span class="line">          <span class="keyword">case</span> None =&gt;</span><br><span class="line">            <span class="comment">// 没有就创建</span></span><br><span class="line">            addAndStartFetcherThread(brokerAndFetcherId, brokerIdAndFetcherId)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        fetcherThreadMap(brokerIdAndFetcherId).addPartitions(initialFetchOffsets.map &#123; <span class="keyword">case</span> (tp, brokerAndInitOffset) =&gt;</span><br><span class="line">          tp -&gt; brokerAndInitOffset.initOffset</span><br><span class="line">        &#125;)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到Fetcher线程的启动是通过addAndStartFetcherThread方法实现的，createFetcherThread刚好调用了前面的ReplicaFetcherManager</p>
<p>同时我们注意一下createFetcherThread方法的第二个参数传入的是broker，那么我们可以得出以下结论</p>
<ol>
<li>一个fetcher线程只会向一个broker同步</li>
<li>一个fetcher线程管理了本地broker多个分区的同步，它和消费者一样都是发送的FETCH请求，此时我们就把它看做一个消费者，和消费者线程一样可以拉取多个分区的消息</li>
</ol>
<p>ReplicaFetcherThread的类图如下，执行的主体在它的父类AbstractFetcherThread的doWork方法中，具体的fetch逻辑由子类实现，典型的模板模式<br><img src="https://pic.downk.cc/item/5e96a9c6c2a9a83be5876153.png" alt="fetch-thread"></p>
<h2 id="同步过程分解"><a href="#同步过程分解" class="headerlink" title="同步过程分解"></a>同步过程分解</h2><p>副本同步表面看只是follower单向地向leader发送fetch请求，但不要忘了ISR这个概念，follower同步不及时会触发ISR的shrink，那么怎么判断follower同步是否及时能？很简单，在leader副本端维护一个时间戳，记录follower副本每次同步的时间，超出replica.lag.time.max.ms(默认10s)就代表follower副本同步太慢</p>
<p>那么我们在看副本同步时，就要站在更高的一个视角去看，一边是follower，一边是leader。</p>
<h1 id="follower副本端同步"><a href="#follower副本端同步" class="headerlink" title="follower副本端同步"></a>follower副本端同步</h1><p>通过前面的信息我们知道同步是从AbstractFetcherThread的doWork方法开始的，需要说明的是该方法是在一个while循环中一直执行，也就是说副本同步是一个不间断的操作，下面就从它的源码开始分析</p>
<h2 id="同步线程doWork"><a href="#同步线程doWork" class="headerlink" title="同步线程doWork"></a>同步线程doWork</h2><p>AbstractFetcherThread的doWork方法是副本同步的入口，其中maybeTruncate是0.11版本之后，副本恢复的截断协议从HW改为leader epoch方式，过程较为复杂，后续会单独分析<br>剩下的步骤就是构建fetch请求，然后调用processFetchRequest进行请求发送及响应处理<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">override def <span class="title">doWork</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  maybeTruncate()</span><br><span class="line">  <span class="comment">// 构建fetch请求</span></span><br><span class="line">  val fetchRequest = inLock(partitionMapLock) &#123;</span><br><span class="line">    <span class="function">val <span class="title">ResultWithPartitions</span><span class="params">(fetchRequest, partitionsWithError)</span> </span>= buildFetchRequest(states)</span><br><span class="line">    <span class="keyword">if</span> (fetchRequest.isEmpty) &#123;</span><br><span class="line">      trace(s<span class="string">"There are no active partitions. Back off for $fetchBackOffMs ms before sending a fetch request"</span>)</span><br><span class="line">      <span class="comment">// replica.fetch.backoff.ms</span></span><br><span class="line">      partitionMapCond.await(fetchBackOffMs, TimeUnit.MILLISECONDS)</span><br><span class="line">    &#125;</span><br><span class="line">    handlePartitionsWithErrors(partitionsWithError)</span><br><span class="line">    fetchRequest</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!fetchRequest.isEmpty)</span><br><span class="line">    processFetchRequest(fetchRequest)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="发送fetch请求"><a href="#发送fetch请求" class="headerlink" title="发送fetch请求"></a>发送fetch请求</h2><p>processFetchRequest表示follower向leader发送fetch请求，然后对响应结果处理。而在leader副本端是如何处理该请求的，在<a href="">kafka-server端源码分析之拉取消息</a>一文中已基本描述，但是留下了一个ReplicaManager的updateFollowerLogReadResults方法没有讲解，我们按照顺序，先补一下leader端的处理，看看updateFollowerLogReadResults到底做了什么</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">processFetchRequest</span><span class="params">(fetchRequest: REQ)</span> </span>&#123;</span><br><span class="line">    val partitionsWithError = mutable.Set[TopicPartition]()</span><br><span class="line">    var responseData: Seq[(TopicPartition, PD)] = Seq.empty</span><br><span class="line"></span><br><span class="line">    responseData = fetch(fetchRequest)</span><br><span class="line">    </span><br><span class="line">    fetcherStats.requestRate.mark()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 响应结果处理下文讲解 ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="leader记录follower副本的同步状态"><a href="#leader记录follower副本的同步状态" class="headerlink" title="leader记录follower副本的同步状态"></a>leader记录follower副本的同步状态</h1><p>updateFollowerLogReadResults的作用就是leader端记录follower副本的同步状态，例如上一次达到同步状态的时间点，上一次follower副本发送fetch请求的时间点等，依据这些信息，leader副本才能判断出follower副本能否在ISR列表中。<br>下面看看源码是如何实现的</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">updateFollowerLogReadResults</span><span class="params">(replicaId: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                                           readResults: Seq[(TopicPartition, LogReadResult)</span>]): Seq[<span class="params">(TopicPartition, LogReadResult)</span>] </span>= &#123;</span><br><span class="line">    debug(s<span class="string">"Recording follower broker $replicaId log end offsets: $readResults"</span>)</span><br><span class="line">    readResults.map &#123; <span class="keyword">case</span> (topicPartition, readResult) =&gt;</span><br><span class="line">      var updatedReadResult = readResult</span><br><span class="line">      nonOfflinePartition(topicPartition) match &#123;</span><br><span class="line">        <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(partition)</span> </span>=&gt;</span><br><span class="line">          partition.getReplica(replicaId) match &#123;</span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(replica)</span> </span>=&gt;</span><br><span class="line">              partition.updateReplicaLogReadResult(replica, readResult)</span><br><span class="line">            <span class="keyword">case</span> None =&gt;</span><br><span class="line">              <span class="comment">// 如果副本不存在则不更新</span></span><br><span class="line">              updatedReadResult = readResult.withEmptyFetchInfo</span><br><span class="line">          &#125;</span><br><span class="line">        <span class="keyword">case</span> None =&gt;</span><br><span class="line">          warn(s<span class="string">"While recording the replica LEO, the partition $topicPartition hasn't been created."</span>)</span><br><span class="line">      &#125;</span><br><span class="line">      topicPartition -&gt; updatedReadResult</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>updateFollowerLogReadResults方法比较简单，但也有不少的细节。先回顾下它的两个参数:</p>
<ol>
<li>replicaId表示follower副本的id，也就是我一直强调的follower副本所在的broker id，二者等价</li>
<li>readResults是本次fetch请求读取的结果，和消费者一样，可以拉取多个分区</li>
</ol>
<h4 id="重点"><a href="#重点" class="headerlink" title="重点"></a>重点</h4><p>真正的调用是以下代码，表示Partition更新某一个follower的同步状态，该方法的难点在于replica参数，结合Partition类的allReplicasMap来看，此处的replica代表了在leader端，follower副本对应的Replica对象，根据后面的代码来看，leader会维护每一个follower副本的同步状态<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 成员变量</span></span><br><span class="line"><span class="keyword">private</span> val allReplicasMap = <span class="keyword">new</span> Pool[Int, Replica]</span><br><span class="line"></span><br><span class="line"><span class="comment">// updateFollowerLogReadResults里的</span></span><br><span class="line">partition.getReplica(replicaId) match &#123;</span><br><span class="line">  <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(replica)</span> </span>=&gt;</span><br><span class="line">    partition.updateReplicaLogReadResult(replica, readResult)</span><br></pre></td></tr></table></figure></p>
<h2 id="Partition更新同步状态"><a href="#Partition更新同步状态" class="headerlink" title="Partition更新同步状态"></a>Partition更新同步状态</h2><p>Partition对象的updateReplicaLogReadResult方法，它主要做了3件事：</p>
<ol>
<li>调用Replica对象的updateLogReadResult，更新该follower副本的同步状态</li>
<li>尝试扩充ISR列表</li>
<li>尝试完成一些延迟操作: produce,fetch,deleteRecords</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">updateReplicaLogReadResult</span><span class="params">(replica: Replica, logReadResult: LogReadResult)</span>: Boolean </span>= &#123;</span><br><span class="line">    <span class="comment">// 此处的replica就是远程的follower副本</span></span><br><span class="line">    val replicaId = replica.brokerId</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// No need to calculate low watermark if there is no delayed DeleteRecordsRequest</span></span><br><span class="line">    <span class="comment">// LW就是所有副本logStartOffset的最小值</span></span><br><span class="line">    val oldLeaderLW = <span class="keyword">if</span> (replicaManager.delayedDeleteRecordsPurgatory.delayed &gt; <span class="number">0</span>) lowWatermarkIfLeader <span class="keyword">else</span> -<span class="number">1L</span></span><br><span class="line">    <span class="comment">// 更新同步信息</span></span><br><span class="line">    replica.updateLogReadResult(logReadResult)</span><br><span class="line">    <span class="comment">// 新的LW</span></span><br><span class="line">    val newLeaderLW = <span class="keyword">if</span> (replicaManager.delayedDeleteRecordsPurgatory.delayed &gt; <span class="number">0</span>) lowWatermarkIfLeader <span class="keyword">else</span> -<span class="number">1L</span></span><br><span class="line">    <span class="comment">// check if the LW of the partition has incremented</span></span><br><span class="line">    <span class="comment">// since the replica's logStartOffset may have incremented</span></span><br><span class="line">    val leaderLWIncremented = newLeaderLW &gt; oldLeaderLW</span><br><span class="line">    <span class="comment">// check if we need to expand ISR to include this replica</span></span><br><span class="line">    <span class="comment">// if it is not in the ISR yet</span></span><br><span class="line">    <span class="comment">// 扩充ISR列表</span></span><br><span class="line">    val leaderHWIncremented = maybeExpandIsr(replicaId, logReadResult)</span><br><span class="line"></span><br><span class="line">    val result = leaderLWIncremented || leaderHWIncremented</span><br><span class="line">    <span class="comment">// some delayed operations may be unblocked after HW or LW changed</span></span><br><span class="line">    <span class="keyword">if</span> (result)</span><br><span class="line">      <span class="comment">// 尝试完成一些延迟操作:produce,fetch,deleteRecords</span></span><br><span class="line">      tryCompleteDelayedRequests()</span><br><span class="line"></span><br><span class="line">    debug(s<span class="string">"Recorded replica $replicaId log end offset (LEO) position $&#123;logReadResult.info.fetchOffsetMetadata.messageOffset&#125;."</span>)</span><br><span class="line">    result</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先看下第一步，follower同步状态的更新</p>
<h3 id="Replica更新同步状态"><a href="#Replica更新同步状态" class="headerlink" title="Replica更新同步状态"></a>Replica更新同步状态</h3><p>大体思路很清晰，首先更新_lastCaughtUpTimeMs，它记录的follower达到同步状态的时间，至于如何判定达到了同步状态，该方法的2个if给出了答案，<br> 而lastFetchTimeMs仅仅是leader收到fetch请求的时间<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">updateLogReadResult</span><span class="params">(logReadResult: LogReadResult)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// fetchOffsetMetadata就是fetch请求中的fetchOffset，表示从哪里开始拉取，leaderLogEndOffset就是LEO</span></span><br><span class="line">    <span class="comment">// 通过debug，大部分情况是走第一个if，二者是相等的，表示生产消息和follower同步消息的速率在一个水平线上</span></span><br><span class="line">    <span class="keyword">if</span> (logReadResult.info.fetchOffsetMetadata.messageOffset &gt;= logReadResult.leaderLogEndOffset)</span><br><span class="line">      <span class="comment">// _lastCaughtUpTimeMs更新为fetchTimeMs，表示拉取时的当前时间</span></span><br><span class="line">      _lastCaughtUpTimeMs = math.max(_lastCaughtUpTimeMs, logReadResult.fetchTimeMs)</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (logReadResult.info.fetchOffsetMetadata.messageOffset &gt;= lastFetchLeaderLogEndOffset)</span><br><span class="line">      _lastCaughtUpTimeMs = math.max(_lastCaughtUpTimeMs, lastFetchTimeMs)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// followerLogStartOffset是fetch请求中的，表示的是follower副本的LogStartOffset</span></span><br><span class="line">    <span class="comment">// 注意里面有if local的判断，这里其实更新的是follower副本的LogStartOffset</span></span><br><span class="line">    <span class="comment">// _logStartOffset = followerLogStartOffset</span></span><br><span class="line">    logStartOffset = logReadResult.followerLogStartOffset</span><br><span class="line">    <span class="comment">// 和上面一样，这个LEO表示的是follower副本的LEO</span></span><br><span class="line">    logEndOffset = logReadResult.info.fetchOffsetMetadata</span><br><span class="line">    <span class="comment">// 记录fetch时， leader的LEO</span></span><br><span class="line">    lastFetchLeaderLogEndOffset = logReadResult.leaderLogEndOffset</span><br><span class="line">    <span class="comment">// 记录fetch的时间</span></span><br><span class="line">    lastFetchTimeMs = logReadResult.fetchTimeMs</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>logStartOffset，logEndOffset表示的是_logStartOffset和_logEndOffset，即记录的是follower的logStartOffset和logEndOffset</p>
<p>logStartOffset变量之前的文章也经常提到，这里再解释一遍，副本对应一个Log对象，一个日志用多个Segment存储，第一个Segment的第一条消息的offset就是logStartOffset，因为kafka会定时删除日志，所以它是会变的，也就可以简单理解为目前副本的第一个消息的offset；至于logEndOffset就不再解释了<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def logStartOffset: Long =</span><br><span class="line">  <span class="keyword">if</span> (isLocal)</span><br><span class="line">    log.get.logStartOffset</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    _logStartOffset</span><br></pre></td></tr></table></figure></p>
<h3 id="maybeExpandIsr扩充ISR列表"><a href="#maybeExpandIsr扩充ISR列表" class="headerlink" title="maybeExpandIsr扩充ISR列表"></a>maybeExpandIsr扩充ISR列表</h3><p>在看完Partition更新同步状态的第一步后，接下来看第二步maybeExpandIsr，首先判断是否需要添加到ISR副本中，有以下4个条件</p>
<ol>
<li>follower副本目前不在ISR列表中</li>
<li>是已分配的副本</li>
<li>follower的LEO &gt; Leader的HW，从前面看follower的LEO就是本次fetch请求的fetchOffset</li>
<li>follower的fetchOffset至少比一个leader epoch的start offset大<br>前2个条件很好理解，第3个条件表示已达到同步，第4个条件则是确保fetchOffset的正确性，防止数据丢失</li>
</ol>
<p>更新的过程也十分简单，就是将新的Isr更新到zk的/brokers/topics/xxxTopic/partitions/0/state节点，并更新到本地缓存isrChangeSet中</p>
<p>最后在ISR新加入了一个副本之后，有可能触发leader副本的HW更新</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">maybeExpandIsr</span><span class="params">(replicaId: Int, logReadResult: LogReadResult)</span>: Boolean </span>= &#123;</span><br><span class="line">    inWriteLock(leaderIsrUpdateLock) &#123;</span><br><span class="line">      <span class="comment">// check if this replica needs to be added to the ISR</span></span><br><span class="line">      leaderReplicaIfLocal match &#123;</span><br><span class="line">        <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(leaderReplica)</span> </span>=&gt;</span><br><span class="line">          val replica = getReplica(replicaId).get</span><br><span class="line">          val leaderHW = leaderReplica.highWatermark</span><br><span class="line">          val fetchOffset = logReadResult.info.fetchOffsetMetadata.messageOffset</span><br><span class="line"></span><br><span class="line">          <span class="comment">// 目前不在ISR列表中 &amp;&amp; 是已分配的副本 &amp;&amp; follower的LEO &gt; Leader的HW &amp;&amp; follower的fetchOffset至少比一个leader epoch的start offset大</span></span><br><span class="line">          <span class="keyword">if</span> (!inSyncReplicas.contains(replica)</span><br><span class="line">            &amp;&amp; assignedReplicas.map(_.brokerId).contains(replicaId)</span><br><span class="line">            &amp;&amp; replica.logEndOffset.offsetDiff(leaderHW) &gt;= <span class="number">0</span></span><br><span class="line">            &amp;&amp; leaderEpochStartOffsetOpt.exists(fetchOffset &gt;= _)) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 添加到集合</span></span><br><span class="line">            val newInSyncReplicas = inSyncReplicas + replica</span><br><span class="line">  </span><br><span class="line">            <span class="comment">// update ISR in ZK and cache</span></span><br><span class="line">            <span class="comment">// 新的Isr更新到zk的state节点，并更新到本地缓存isrChangeSet中</span></span><br><span class="line">            updateIsr(newInSyncReplicas)</span><br><span class="line">            <span class="comment">// metrics</span></span><br><span class="line">            replicaManager.isrExpandRate.mark()</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// 尝试增加leader的HW，因为有follower进入到ISR了</span></span><br><span class="line">          <span class="comment">// check if the HW of the partition can now be incremented</span></span><br><span class="line">          <span class="comment">// since the replica may already be in the ISR and its LEO has just incremented</span></span><br><span class="line">          maybeIncrementLeaderHW(leaderReplica, logReadResult.fetchTimeMs)</span><br><span class="line">        <span class="keyword">case</span> None =&gt; <span class="keyword">false</span> <span class="comment">// nothing to do if no longer leader</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>leader端的处理结束了，再看看follower副本对fetch请求响应的处理</p>
<h1 id="follower副本端处理响应"><a href="#follower副本端处理响应" class="headerlink" title="follower副本端处理响应"></a>follower副本端处理响应</h1><p>重新回到processFetchRequest方法，该方法通过fetch方法发送请求，在上面已经讲过了leader端是如何处理follower的fetch的，下面看看follower如何处理fetch请求的响应</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 篇幅原因，仅保留核心代码</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">processFetchRequest</span><span class="params">(fetchRequest: REQ)</span> </span>&#123;</span><br><span class="line">    val partitionsWithError = mutable.Set[TopicPartition]()</span><br><span class="line">    var responseData: Seq[(TopicPartition, PD)] = Seq.empty</span><br><span class="line">   </span><br><span class="line">    responseData = fetch(fetchRequest)</span><br><span class="line">    </span><br><span class="line">    fetcherStats.requestRate.mark()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (responseData.nonEmpty) &#123;</span><br><span class="line"></span><br><span class="line">      inLock(partitionMapLock) &#123;</span><br><span class="line"></span><br><span class="line">        responseData.foreach &#123; <span class="keyword">case</span> (topicPartition, partitionData) =&gt;</span><br><span class="line">          val topic = topicPartition.topic</span><br><span class="line">          val partitionId = topicPartition.partition</span><br><span class="line">          Option(partitionStates.stateValue(topicPartition)).foreach(currentPartitionFetchState =&gt;</span><br><span class="line">            <span class="comment">// It's possible that a partition is removed and re-added or truncated when there is a pending fetch request.</span></span><br><span class="line">            <span class="comment">// In this case, we only want to process the fetch response if the partition state is ready for fetch and the current offset is the same as the offset requested.</span></span><br><span class="line">            <span class="keyword">if</span> (fetchRequest.offset(topicPartition) == currentPartitionFetchState.fetchOffset &amp;&amp;</span><br><span class="line">                currentPartitionFetchState.isReadyForFetch) &#123;</span><br><span class="line">              partitionData.error match &#123;</span><br><span class="line">                <span class="keyword">case</span> Errors.NONE =&gt;</span><br><span class="line">                  <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// ===================== 核心部分 =============================</span></span><br><span class="line">                    val records = partitionData.toRecords</span><br><span class="line">                    <span class="comment">// 获取最后一个消息的nextOffset，作为下次新的fetchOffset，没有则依然以当前的为准</span></span><br><span class="line">                    val newOffset = records.batches.asScala.lastOption.map(_.nextOffset).getOrElse(</span><br><span class="line">                      currentPartitionFetchState.fetchOffset)</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// 更新metric lag(FetcherLagStats)，如果lag&lt;=0，说明是inSync的；   HW-lastOffset</span></span><br><span class="line">                    fetcherLagStats.getAndMaybePut(topic, partitionId).lag = Math.max(<span class="number">0L</span>, partitionData.highWatermark - newOffset)</span><br><span class="line">                    <span class="comment">// Once we hand off the partition data to the subclass, we can't mess with it any more in this thread</span></span><br><span class="line">                    <span class="comment">// 参数解释：分区，拉取时的fetchOffset，拉取的结果数据</span></span><br><span class="line">                    processPartitionData(topicPartition, currentPartitionFetchState.fetchOffset, partitionData)</span><br><span class="line"></span><br><span class="line">                    val validBytes = records.validBytes</span><br><span class="line">                    <span class="comment">// ReplicaDirAlterThread may have removed topicPartition from the partitionStates after processing the partition data</span></span><br><span class="line">                    <span class="keyword">if</span> (validBytes &gt; <span class="number">0</span> &amp;&amp; partitionStates.contains(topicPartition)) &#123;</span><br><span class="line">                      <span class="comment">// 更新分区的PartitionState(newOffset, 0, false)</span></span><br><span class="line">                      <span class="comment">// Update partitionStates only if there is no exception during processPartitionData</span></span><br><span class="line">                      partitionStates.updateAndMoveToEnd(topicPartition, <span class="keyword">new</span> PartitionFetchState(newOffset))</span><br><span class="line">                      <span class="comment">// metrics ...</span></span><br><span class="line">                      fetcherStats.byteRate.mark(validBytes)</span><br><span class="line">                    &#125;</span><br><span class="line">                  &#125; </span><br><span class="line">                &#125; </span><br><span class="line">            &#125;)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>核心代码的逻辑是：</p>
<ol>
<li>将拉取到的消息的最一条的offset，作为下一次拉取的fetchOffset参数，保存在partitionStates中</li>
<li></li>
</ol>
<p>processPartitionData除去校验和限流相关代码，主要做了2件事：</p>
<ol>
<li>将消息追加到本地副本中(appendRecordsToFollowerOrFutureReplica)</li>
<li>取本地follower副本的LEO(append之后已更新)和响应中leader HW的较小值，作为follower的HW</li>
<li>根据leader的logStartOffset来判断是否需要截断自己的leader epoch startOffset，此处暂不用关心</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">processPartitionData</span><span class="params">(topicPartition: TopicPartition, fetchOffset: Long, partitionData: PartitionData)</span> </span>&#123;</span><br><span class="line">    val replica = replicaMgr.getReplicaOrException(topicPartition)</span><br><span class="line">    val partition = replicaMgr.getPartition(topicPartition).get</span><br><span class="line">    val records = partitionData.toRecords</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 老版本没有第一条消息大于replica.fetch.max.bytes时，至少取一条的处理，目前fetchRequestVersion=8,不用关心</span></span><br><span class="line">    maybeWarnIfOversizedRecords(records, topicPartition)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 说明请求的fetchOffset就是当前的LEO</span></span><br><span class="line">    <span class="keyword">if</span> (fetchOffset != replica.logEndOffset.messageOffset)</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Offset mismatch for partition %s: fetched offset = %d, log end offset = %d."</span>.format(</span><br><span class="line">        topicPartition, fetchOffset, replica.logEndOffset.messageOffset))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Append the leader's messages to the log</span></span><br><span class="line">    <span class="comment">// 就是Log append 不过调用的是Log#appendAsFollower</span></span><br><span class="line">    partition.appendRecordsToFollowerOrFutureReplica(records, isFuture = <span class="keyword">false</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 取本地follower副本的LEO(append之后已更新) 和响应中leader HW的较小值，作为follower的HW</span></span><br><span class="line">    val followerHighWatermark = replica.logEndOffset.messageOffset.min(partitionData.highWatermark)</span><br><span class="line">    replica.highWatermark = <span class="keyword">new</span> LogOffsetMetadata(followerHighWatermark)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// for the follower replica, we do not need to keep</span></span><br><span class="line">    <span class="comment">// its segment base offset the physical position,</span></span><br><span class="line">    <span class="comment">// these values will be computed upon making the leader</span></span><br><span class="line">    val leaderLogStartOffset = partitionData.logStartOffset</span><br><span class="line">    replica.maybeIncrementLogStartOffset(leaderLogStartOffset)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Traffic from both in-sync and out of sync replicas are accounted for in replication quota to ensure total replication</span></span><br><span class="line">    <span class="comment">// traffic doesn't exceed quota.</span></span><br><span class="line">    <span class="keyword">if</span> (quota.isThrottled(topicPartition))</span><br><span class="line">      quota.record(records.sizeInBytes)</span><br><span class="line">    replicaMgr.brokerTopicStats.updateReplicationBytesIn(records.sizeInBytes)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>至此，副本同步的过程结果，相关流程用以下一张图解释<br><img src="副本同步流程" alt="https://pic.downk.cc/item/5eb52e32c2a9a83be58b2424.png"></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">紫夜</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://greedypirate.github.io/2020/03/08/kafka-server端源码分析之副本同步/">https://greedypirate.github.io/2020/03/08/kafka-server端源码分析之副本同步/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/kafka/">kafka</a><a class="post-meta__tags" href="/tags/中间件/">中间件</a><a class="post-meta__tags" href="/tags/消息/">消息</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="https://ae01.alicdn.com/kf/H50b5d4d79e454447974210dae2d054435.png"><div class="post-qr-code__desc">支付宝打赏</div></div><div class="post-qr-code-item"><img class="post-qr-code__img" src="https://ae01.alicdn.com/kf/H45f5b133580045879faaa5fcbe9b598fu.png"><div class="post-qr-code__desc">微信打赏</div></div></div><div class="addthis_inline_share_toolbox pull-right"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5b6532776de86c85" async></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2020/03/10/Kafka消费者-源码分析(上)/"><i class="fa fa-chevron-left">  </i><span>Kafka消费者-源码分析(上)</span></a></div><div class="next-post pull-right"><a href="/2020/03/07/kafka-server端源码分析之获取leader副本的epoch及startOffset/"><span>kafka server端源码分析之获取leader副本的epoch及startOffset</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '0349a7a18b86f2a653e3',
  clientSecret: '567ba8cefbe2ecffbbc04e676652ae4b43e7f952',
  repo: 'GreedyPirate.github.io',
  owner: 'GreedyPirate',
  admin: 'GreedyPirate',
  id: md5(decodeURI(location.pathname)),
  language: ''
})
gitalk.render('gitalk-container')</script></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2018 - 2020 By 紫夜</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://GreedyPirate.github.io">blog</a>!</div><div class="busuanzi"><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.5.6"></script><script src="/js/fancybox.js?version=1.5.6"></script><script src="/js/sidebar.js?version=1.5.6"></script><script src="/js/copy.js?version=1.5.6"></script><script src="/js/fireworks.js?version=1.5.6"></script><script src="/js/transition.js?version=1.5.6"></script><script src="/js/scroll.js?version=1.5.6"></script><script src="/js/head.js?version=1.5.6"></script><script src="/js/search/local-search.js"></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>