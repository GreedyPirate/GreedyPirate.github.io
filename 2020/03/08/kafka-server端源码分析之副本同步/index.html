<!DOCTYPE html><html><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="kafka server端源码分析之副本同步"><meta name="keywords" content="kafka,中间件,消息"><meta name="author" content="紫夜,undefined"><meta name="copyright" content="紫夜"><title>kafka server端源码分析之副本同步 | 紫夜の博客</title><link rel="shortcut icon" href="/my-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.5.6"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css?version=1.5.6"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/gh/upupming/gitalk@36368e5dffd049e956cdbbd751ff96c28d8255cf/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="dns-prefetch" href="https://hm.baidu.com"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6ba54465c1ff0c31b169e7a89d3dbe37";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#正文"><span class="toc-number">2.</span> <span class="toc-text">正文</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#副本拉取管理器"><span class="toc-number">2.1.</span> <span class="toc-text">副本拉取管理器</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#副本同步"><span class="toc-number">3.</span> <span class="toc-text">副本同步</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#何时同步"><span class="toc-number">3.1.</span> <span class="toc-text">何时同步</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#同步线程doWork"><span class="toc-number">3.2.</span> <span class="toc-text">同步线程doWork</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://ae01.alicdn.com/kf/He0f82cbc452e4e99b7da670575752df0l.png"></div><div class="author-info__name text-center">紫夜</div><div class="author-info__description text-center">stay hungry, stay foolish</div><div class="follow-button"><a href="https://github.com/GreedyPirate" target="_blank">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">59</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">23</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">11</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" href="https://blog.csdn.net/yj7758423" target="_blank">我的CSDN</a><a class="author-info-links__name text-center" href="https://segmentfault.com/blog/code-craft" target="_blank">膜拜大神</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://ae01.alicdn.com/kf/H6e9ae455bca04f4098243e3f73a85c4fb.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">紫夜の博客</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">kafka server端源码分析之副本同步</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-03-08</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Kafka-Tutorial/">Kafka Tutorial</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">1,016</span><span class="post-meta__separator">|</span><span>Reading time: 4 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>为什么我现在才写副本同步的解析呢，因为它太复杂了，仅仅是什么时候触发的副本同步，就涉及到KafkaController，LeaderAndIsr请求等，经过前面文章的梳理，现在时机正好</p>
<h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><p>通常我们会为了提高系统并发能力、可伸缩性，为topic设置多个分区，每个分区副本数通常设置为3个，其中1个为leader副本，其余2个follower副本为冗余备份使用。在producer端为了保证消息不丢失，通常设置ack=-1，并搭配失败重试机制</p>
<p>本文主要讨论broker端写入leader副本后，follower副本如何同步消息，以及如何更新HighWatermark，并使Purgatory延迟队列中的PRODUCE请求完成(complete)，响应客户端</p>
<h2 id="副本拉取管理器"><a href="#副本拉取管理器" class="headerlink" title="副本拉取管理器"></a>副本拉取管理器</h2><p>在启动Kafka时，会初始化ReplicaManager副本管理器，同时该类中有一行初始化语句<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val replicaFetcherManager = createReplicaFetcherManager(metrics, time, threadNamePrefix, quotaManagers.follower)</span><br></pre></td></tr></table></figure></p>
<p>其实就是new了一个ReplicaFetcherManager对象，该对象的功能十分简单，就是创建和关闭Fetch线程</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class ReplicaFetcherManager(brokerConfig: KafkaConfig, protected val replicaManager: ReplicaManager, metrics: Metrics,</span><br><span class="line">                            time: Time, threadNamePrefix: Option[String] = None, quotaManager: ReplicationQuotaManager)</span><br><span class="line">      <span class="function">extends <span class="title">AbstractFetcherManager</span><span class="params">(<span class="string">"ReplicaFetcherManager on broker "</span> + brokerConfig.brokerId,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="string">"Replica"</span>, brokerConfig.numReplicaFetchers)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">override def <span class="title">createFetcherThread</span><span class="params">(fetcherId: Int, sourceBroker: BrokerEndPoint)</span>: AbstractFetcherThread </span>= &#123;</span><br><span class="line">    val prefix = threadNamePrefix.map(tp =&gt; s<span class="string">"$&#123;tp&#125;:"</span>).getOrElse(<span class="string">""</span>)</span><br><span class="line">    val threadName = s<span class="string">"$&#123;prefix&#125;ReplicaFetcherThread-$fetcherId-$&#123;sourceBroker.id&#125;"</span></span><br><span class="line">    <span class="keyword">new</span> ReplicaFetcherThread(threadName, fetcherId, sourceBroker, brokerConfig, replicaManager, metrics, time, quotaManager)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">shutdown</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    info(<span class="string">"shutting down"</span>)</span><br><span class="line">    closeAllFetchers()</span><br><span class="line">    info(<span class="string">"shutdown completed"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="副本同步"><a href="#副本同步" class="headerlink" title="副本同步"></a>副本同步</h1><p>在分析副本同步过程之前，我们先想一想什么时候开始同步，也就是上面的createFetcherThread什么时候创建并启动的</p>
<h2 id="何时同步"><a href="#何时同步" class="headerlink" title="何时同步"></a>何时同步</h2><p>这里就要回顾<a href="">KafkaController源码分析之LeaderAndIsr请求</a>一文了，这也是我先写LeaderAndIsr，然后才分析副本同步的原因</p>
<p>在前文中，提到了becomeLeaderOrFollower方法会将分区添加到副本同步线程中，具体实现就在addFetcherForPartitions方法中</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">addFetcherForPartitions</span><span class="params">(partitionAndOffsets: Map[TopicPartition, BrokerAndInitialOffset])</span> </span>&#123;</span><br><span class="line">    lock <span class="keyword">synchronized</span> &#123;</span><br><span class="line">      <span class="comment">// partitionsPerFetcher = Map[BrokerAndFetcherId, Map[TopicPartition, BrokerAndInitialOffset]]</span></span><br><span class="line">      <span class="comment">// 分组的key是目标broker+同步线程，也就是同一个fetcher线程向同一个broker同步 为一组</span></span><br><span class="line">      val partitionsPerFetcher = partitionAndOffsets.groupBy &#123; <span class="keyword">case</span>(topicPartition, brokerAndInitialFetchOffset) =&gt;</span><br><span class="line">        BrokerAndFetcherId(brokerAndInitialFetchOffset.broker, getFetcherId(topicPartition.topic, topicPartition.partition))&#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 事先定义好创建并启动的方法</span></span><br><span class="line">      <span class="function">def <span class="title">addAndStartFetcherThread</span><span class="params">(brokerAndFetcherId: BrokerAndFetcherId, brokerIdAndFetcherId: BrokerIdAndFetcherId)</span> </span>&#123;</span><br><span class="line">        val fetcherThread = createFetcherThread(brokerAndFetcherId.fetcherId, brokerAndFetcherId.broker)</span><br><span class="line">        fetcherThreadMap.put(brokerIdAndFetcherId, fetcherThread)</span><br><span class="line">        fetcherThread.start</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> ((brokerAndFetcherId, initialFetchOffsets) &lt;- partitionsPerFetcher) &#123;</span><br><span class="line">        val brokerIdAndFetcherId = BrokerIdAndFetcherId(brokerAndFetcherId.broker.id, brokerAndFetcherId.fetcherId)</span><br><span class="line">        <span class="comment">// fetcherThreadMap: Map[BrokerIdAndFetcherId, AbstractFetcherThread]</span></span><br><span class="line">        <span class="comment">// 这里的逻辑还是很清晰的</span></span><br><span class="line">        fetcherThreadMap.get(brokerIdAndFetcherId) match &#123;</span><br><span class="line">            <span class="comment">// 已存在对应的Thread，并且线程的broker和分区要同步的broker相同，直接复用就行了</span></span><br><span class="line">          <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(f)</span> <span class="keyword">if</span> f.sourceBroker.host </span>== brokerAndFetcherId.broker.host &amp;&amp; f.sourceBroker.port == brokerAndFetcherId.broker.port =&gt;</span><br><span class="line">            <span class="comment">// reuse the fetcher thread</span></span><br><span class="line">          <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(f)</span> </span>=&gt;</span><br><span class="line">            <span class="comment">// 如果前面的if不成立，就需要关闭，重新添加并启动</span></span><br><span class="line">            f.shutdown()</span><br><span class="line">            addAndStartFetcherThread(brokerAndFetcherId, brokerIdAndFetcherId)</span><br><span class="line">          <span class="keyword">case</span> None =&gt;</span><br><span class="line">            <span class="comment">// 没有就创建</span></span><br><span class="line">            addAndStartFetcherThread(brokerAndFetcherId, brokerIdAndFetcherId)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        fetcherThreadMap(brokerIdAndFetcherId).addPartitions(initialFetchOffsets.map &#123; <span class="keyword">case</span> (tp, brokerAndInitOffset) =&gt;</span><br><span class="line">          tp -&gt; brokerAndInitOffset.initOffset</span><br><span class="line">        &#125;)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到Fetcher线程的启动是通过addAndStartFetcherThread方法实现的，createFetcherThread刚好调用了前面的ReplicaFetcherManager</p>
<p>同时我们注意一下createFetcherThread方法的第二个参数传入的是broker，那么我们可以得出以下结论</p>
<ol>
<li>一个fetcher线程只会向一个broker同步</li>
<li>一个fetcher线程管理了本地broker多个分区的同步，它和消费者一样都是发送的FETCH请求，此时我们就把它看做一个消费者，我们的业务代码中就是一个消费者线程可以拉取多个分区的消息</li>
</ol>
<p>ReplicaFetcherThread的类图如下，执行的主体在它的父类AbstractFetcherThread的doWork方法中，具体的fetch逻辑由子类实现，典型的模板模式<br><img src="https://pic.downk.cc/item/5e96a9c6c2a9a83be5876153.png" alt="fetch-thread"></p>
<h2 id="同步线程doWork"><a href="#同步线程doWork" class="headerlink" title="同步线程doWork"></a>同步线程doWork</h2><p>AbstractFetcherThread的doWork方法是副本同步的入口，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">override def <span class="title">doWork</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  maybeTruncate()</span><br><span class="line">  <span class="comment">// 构建fetch请求</span></span><br><span class="line">  val fetchRequest = inLock(partitionMapLock) &#123;</span><br><span class="line">    <span class="function">val <span class="title">ResultWithPartitions</span><span class="params">(fetchRequest, partitionsWithError)</span> </span>= buildFetchRequest(states)</span><br><span class="line">    <span class="keyword">if</span> (fetchRequest.isEmpty) &#123;</span><br><span class="line">      trace(s<span class="string">"There are no active partitions. Back off for $fetchBackOffMs ms before sending a fetch request"</span>)</span><br><span class="line">      <span class="comment">// replica.fetch.backoff.ms</span></span><br><span class="line">      partitionMapCond.await(fetchBackOffMs, TimeUnit.MILLISECONDS)</span><br><span class="line">    &#125;</span><br><span class="line">    handlePartitionsWithErrors(partitionsWithError)</span><br><span class="line">    fetchRequest</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!fetchRequest.isEmpty)</span><br><span class="line">    processFetchRequest(fetchRequest)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">紫夜</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://greedypirate.github.io/2020/03/08/kafka-server端源码分析之副本同步/">https://greedypirate.github.io/2020/03/08/kafka-server端源码分析之副本同步/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/kafka/">kafka</a><a class="post-meta__tags" href="/tags/中间件/">中间件</a><a class="post-meta__tags" href="/tags/消息/">消息</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="https://ae01.alicdn.com/kf/H50b5d4d79e454447974210dae2d054435.png"><div class="post-qr-code__desc">支付宝打赏</div></div><div class="post-qr-code-item"><img class="post-qr-code__img" src="https://ae01.alicdn.com/kf/H45f5b133580045879faaa5fcbe9b598fu.png"><div class="post-qr-code__desc">微信打赏</div></div></div><div class="addthis_inline_share_toolbox pull-right"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5b6532776de86c85" async></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2020/04/14/线程池源码分析及动态更新大小实现/"><i class="fa fa-chevron-left">  </i><span>线程池源码分析及动态更新大小实现</span></a></div><div class="next-post pull-right"><a href="/2020/03/07/kafka-server端源码分析之获取leader副本的epoch及startOffset/"><span>kafka server端源码分析之获取leader副本的epoch及startOffset</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '0349a7a18b86f2a653e3',
  clientSecret: '567ba8cefbe2ecffbbc04e676652ae4b43e7f952',
  repo: 'GreedyPirate.github.io',
  owner: 'GreedyPirate',
  admin: 'GreedyPirate',
  id: md5(decodeURI(location.pathname)),
  language: ''
})
gitalk.render('gitalk-container')</script></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2018 - 2020 By 紫夜</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://GreedyPirate.github.io">blog</a>!</div><div class="busuanzi"><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.5.6"></script><script src="/js/fancybox.js?version=1.5.6"></script><script src="/js/sidebar.js?version=1.5.6"></script><script src="/js/copy.js?version=1.5.6"></script><script src="/js/fireworks.js?version=1.5.6"></script><script src="/js/transition.js?version=1.5.6"></script><script src="/js/scroll.js?version=1.5.6"></script><script src="/js/head.js?version=1.5.6"></script><script src="/js/search/local-search.js"></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>