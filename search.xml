<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>源码类文章阅读导航【置顶】</title>
      <link href="/2021/04/25/%E6%BA%90%E7%A0%81%E7%B1%BB%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%E5%AF%BC%E8%88%AA%E3%80%90%E7%BD%AE%E9%A1%B6%E3%80%91/"/>
      <url>/2021/04/25/%E6%BA%90%E7%A0%81%E7%B1%BB%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%E5%AF%BC%E8%88%AA%E3%80%90%E7%BD%AE%E9%A1%B6%E3%80%91/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>为了方便大家阅读，单独用一篇文章罗列出各个技术源码的阅读目录，目前主要分为以下几个方向:</p><p>Kafka、JDK、Spring、Spring Boot、Spring Cloud</p><h1 id="版本信息"><a href="#版本信息" class="headerlink" title="版本信息"></a>版本信息</h1><p>项目源码因版本不同会有较大的差异，尤其是kafka，请尽量找相似或相同的版本号作为参考</p><table><thead><tr><th>名称</th><th>版本</th><th>github源码阅读项目地址</th></tr></thead><tbody><tr><td>kafka</td><td>2.0.1</td><td><a href="https://github.com/GreedyPirate/kafka" target="_blank" rel="noopener">https://github.com/GreedyPirate/kafka</a></td></tr><tr><td>Spring-framework</td><td>5.2.4.RELEASE</td><td><a href="https://github.com/GreedyPirate/spring-framework" target="_blank" rel="noopener">https://github.com/GreedyPirate/spring-framework</a></td></tr><tr><td>JDK</td><td>java8</td><td><a href="https://github.com/GreedyPirate/jdk-source" target="_blank" rel="noopener">https://github.com/GreedyPirate/jdk-source</a></td></tr></tbody></table><h1 id="Kafka阅读顺序解读"><a href="#Kafka阅读顺序解读" class="headerlink" title="Kafka阅读顺序解读"></a>Kafka阅读顺序解读</h1><p>以消息的流向为顺序，分为生产者，broker，消费者</p><h2 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h2><p>生产者相关源码文章如下</p><p>基础学习：<a href="">ByteBuffer浅显易懂的图解原理</a></p><p><a href="">Kafka生产者源码浅析(一)</a><br><a href="">Kafka生产者源码浅析(二)</a><br><a href="">Kafka生产者源码浅析(三)</a></p><h2 id="broker"><a href="#broker" class="headerlink" title="broker"></a>broker</h2><p>broker端较为复杂，我建议从以下顺序开始阅读</p><p>语法与环境</p><p><a href="">快速学习scala语言及常用语法汇总</a><br><a href="">kafka源码环境搭建</a><br><a href="">kafka本地启动后不打印日志问题</a></p><p>网络模型与请求处理</p><p><a href="">kafka网络请求处理模型</a><br><a href="">kafka server端源码分析之接收消息</a><br><a href="">kafka-server端源码分析之拉取消息</a></p><p>ZooKeeper模块与Controller模块</p><p><a href="">kafka-server端源码分析之Zookeeper初始化与Watcher监听事件分发</a><br><a href="">KafkaController源码分析之Controller选举与初始化</a><br><a href="">KafkaController源码分析之副本状态机与分区状态机的启动</a><br><a href="">KafkaController源码分析之分区副本重分配(PartitionReassignment)与Preferred leader副本选举</a><br><a href="">KafkaController源码分析之LeaderAndIsr请求</a><br><a href="">KafkaController源码分析之Broker的上线与下线</a><br><a href="">kafka server端源码分析之副本同步</a></p><h2 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h2><p><a href="">Kafka消费者-源码分析(上)</a><br><a href="">kafka消费者-获取Coordinator</a><br><a href="">kafka-rebalance之JoinGroup</a><br><a href="">kafka-rebalance之SyncGroup</a><br><a href="">Kafka消费者-OffsetFetch请求</a><br><a href="">Kafka消费者-ListOffsets请求</a><br><a href="">Kafka消费者-源码分析(下)</a></p><h1 id="Spring"><a href="#Spring" class="headerlink" title="Spring"></a>Spring</h1><h2 id="Spring-framework"><a href="#Spring-framework" class="headerlink" title="Spring-framework"></a>Spring-framework</h2><p>IOC容器相关<br><a href="">Spring IOC容器启动之初始化上下文</a><br><a href="">Spring IOC容器之refresh流程(一)</a><br><a href="">Spring IOC容器之解析并注册BeanDefinition</a></p><h2 id="Spring-MVC"><a href="#Spring-MVC" class="headerlink" title="Spring MVC"></a>Spring MVC</h2><p><a href="">SpringMVC源码分析</a></p><h2 id="Spring-boot"><a href="#Spring-boot" class="headerlink" title="Spring boot"></a>Spring boot</h2><p><a href="">spring-boot原理之@EnableXxx注解的实现</a></p><h1 id="JDK"><a href="#JDK" class="headerlink" title="JDK"></a>JDK</h1><p><a href="">线程池源码分析及动态更新大小实现</a></p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>线程池源码分析及动态更新大小实现</title>
      <link href="/2020/04/14/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%8F%8A%E5%8A%A8%E6%80%81%E6%9B%B4%E6%96%B0%E5%A4%A7%E5%B0%8F%E5%AE%9E%E7%8E%B0/"/>
      <url>/2020/04/14/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%8F%8A%E5%8A%A8%E6%80%81%E6%9B%B4%E6%96%B0%E5%A4%A7%E5%B0%8F%E5%AE%9E%E7%8E%B0/</url>
      <content type="html"><![CDATA[<blockquote><p>本文主要聊聊java线程池ThreadPoolExecutor的源码实现，以及如何通过Apollo配置中心来达到动态调整线程池大小</p></blockquote><h1 id="任务执行过程简述"><a href="#任务执行过程简述" class="headerlink" title="任务执行过程简述"></a>任务执行过程简述</h1><p>首先我还是用图文来说明一下线程池执行任务的大致原理，防止大家一看代码就晕圈</p><p>线程池中的每一个线程我们称之为worker线程，因为源码中就是一个继承了AQS，实现了Runnable的Worker类，线程池分为2个部分：core线程，超出coreSize到maxSize之间的非core线程</p><p>线程池初始化时，里面是没有线程的，当然你也可以调用prestartCoreThread/prestartAllCoreThreads方法来启动一个或所有core线程，也就是所谓的预热，这样当第一个任务添加到线程池时不至于等待线程的创建，也就是说在一定程度上提高了响应速度</p><p>线程池中的每一个worker线程(即所有线程)在创建时，都可以传入一个任务(firstTask)，之后worker线程启动，就会执行这个任务，但是不能每次来一个任务就创建一个worker线程，这失去了池化的意义，这时就有一个缓冲队列(workQueue)，它和worker线程的关系可以用MQ中的消费者循环从broker拉取消息来类比，其实就是最简单的生产者消费者模式，生产者就是我们的应用程序，我们既可以在创建worker线程时，传入任务并执行，也可以在core线程数达到上限时，暂时将任务放入workQueue中，等待core worker线程轮询获取，并执行</p><p>线程池里所有的线程都有一个存活时间，由keepAliveTime参数控制，它默认只针对非core线程，如果想对core线程也设置存活时间，需要设置allowCoreThreadTimeOut为true</p><p>那么非core线程什么时候创建呢？</p><p>超出coreSize的线程会在workQueue达到容量上限之后，才会创建，那么思考一个问题，假设我的队列很大，可以容纳1000个任务，亦或者是LinkedBlockingQueue这种无界队列，里面的任务在未达到workQueue最大容量之前，又由于core线程处理之前的任务过慢，那么队列尾部的任务只有等待，如果这是一个处理http请求的任务，那么很容易造成接口超时</p><p>workQueue的大小也取决于业务特性，要求响应速度快的应该设置小，极端情况你可以用SynchronousQueue，如果业务讲求吞吐量，对延迟要求并不严苛，可以稍微设置大一些</p><p>如果workQueue满了，线程数也达到了maxSize了，会出现什么情况？</p><p>此时才是拒绝(reject)策略执行的时候，也就是RejectedExecutionHandler会处理这种情况，默认是AbortPolicy，它会抛出一个RejectedExecutionException，其它实现还有CallerRunsPolicy让我们自己定义处理方式的策略</p><p>什么时候情况下容易会出现reject</p><p>首先就是我们的maxPoolSize设置的太小了，反映在真实的业务上就是对业务流量的评估不足，亦或者是不可预料的突发流量(微博明星出轨算一个)</p><p>任务执行的流程图大致是这个样子的，这里需要说明的：因为需要执行任务而创建线程，那么这个任务对于该线程而言就是第一个任务(firstTask)，那么执行完后，线程不会销毁，它会一直轮回阻塞队列，从中获取任务</p><p><img src="https://pic.downk.cc/item/5eabec47c2a9a83be559ec32.png" alt=""></p><p>下面对源码的分析主要都是依据上述图文</p><h1 id="业务实践"><a href="#业务实践" class="headerlink" title="业务实践"></a>业务实践</h1><h2 id="延迟与吞吐量"><a href="#延迟与吞吐量" class="headerlink" title="延迟与吞吐量"></a>延迟与吞吐量</h2><p>延迟与吞吐量总是成反比的，根据不同的业务特性要做出取舍，比如要求响应速度快的业务，它就要去延迟低，比如app加载首页，而一些吞吐量大的业务，它并不需要多快的响应速度，典型的场景如报表<br>那么针对这些业务场景，如何去调整线程池参数呢？</p><p>侧重响应速度的业务，它需要执行的任务可能很多，但是都比较快，我们应该用更多的线程去执行任务，而等待队列就不能太大，否则任务积压会导致延迟增高，甚至超时<br>侧重吞吐量的业务，例如报表，离线计算，并不需要在很快的时间内完成，而是需要保证在单位时间内尽可能的执行更多的任务，也就是追求吞吐量，那么可以在保证有充分的线程数情况下，尽可能的用等待队列去缓存任务</p><h1 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h1><p>经过上面的讲解是希望大家不要害怕线程池的原理，它并不难，甚至比一些复杂的业务代码简单多了</p><h2 id="使用案例"><a href="#使用案例" class="headerlink" title="使用案例"></a>使用案例</h2><p>下面是一个ThreadPoolExecutor的使用案例，没有什么难点，我这里只是记录了RejectedExecutionException的发生数，因为在生产环境中我们是需要对线程池监控的，比如把该错误发生至falcon监控，并报警给研发负责人</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> AtomicInteger order = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> AtomicInteger rejectCounter = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> BlockingQueue&lt;Runnable&gt; blockingDeque = <span class="keyword">new</span> ArrayBlockingQueue&lt;Runnable&gt;(<span class="number">10</span>);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    ThreadPoolExecutor executor = <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">10</span>, <span class="number">20</span>, <span class="number">10</span>, TimeUnit.SECONDS, blockingDeque,</span><br><span class="line">                (r) -&gt; &#123;</span><br><span class="line">                    Thread t = <span class="keyword">new</span> Thread(r,<span class="string">"thread-pool-demo-"</span> + order.getAndIncrement());</span><br><span class="line">                    <span class="keyword">return</span> t;</span><br><span class="line">                &#125;,</span><br><span class="line">                (r, e) -&gt; &#123;</span><br><span class="line">                    rejectCounter.getAndIncrement();</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> RejectedExecutionException(<span class="string">"Task "</span> + r.toString() +</span><br><span class="line">                            <span class="string">" rejected from "</span> +</span><br><span class="line">                            e.toString());</span><br><span class="line">            &#125;);</span><br><span class="line"></span><br><span class="line">    executor.allowCoreThreadTimeOut(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">    executor.submit(() -&gt; &#123;</span><br><span class="line">        System.out.println(<span class="string">"executing ..."</span>);</span><br><span class="line">        sleep(<span class="number">3</span>);</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="线程的状态"><a href="#线程的状态" class="headerlink" title="线程的状态"></a>线程的状态</h2><p>int类型占4个字节，共32位，这里用前3位表示线程池的状态(rs)，后29位表示线程的个数(wc)<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> AtomicInteger ctl = <span class="keyword">new</span> AtomicInteger(ctlOf(RUNNING, <span class="number">0</span>));</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> COUNT_BITS = Integer.SIZE - <span class="number">3</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> CAPACITY   = (<span class="number">1</span> &lt;&lt; COUNT_BITS) - <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// runState is stored in the high-order bits</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> RUNNING    = -<span class="number">1</span> &lt;&lt; COUNT_BITS;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> SHUTDOWN   =  <span class="number">0</span> &lt;&lt; COUNT_BITS;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> STOP       =  <span class="number">1</span> &lt;&lt; COUNT_BITS;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TIDYING    =  <span class="number">2</span> &lt;&lt; COUNT_BITS;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TERMINATED =  <span class="number">3</span> &lt;&lt; COUNT_BITS;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Packing and unpacking ctl</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">runStateOf</span><span class="params">(<span class="keyword">int</span> c)</span>     </span>&#123; <span class="keyword">return</span> c &amp; ~CAPACITY; &#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">workerCountOf</span><span class="params">(<span class="keyword">int</span> c)</span>  </span>&#123; <span class="keyword">return</span> c &amp; CAPACITY; &#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">ctlOf</span><span class="params">(<span class="keyword">int</span> rs, <span class="keyword">int</span> wc)</span> </span>&#123; <span class="keyword">return</span> rs | wc; &#125;</span><br></pre></td></tr></table></figure></p><p>线程池的状态流转如下：</p><p><img src="https://pic.downk.cc/item/5e95843dc2a9a83be5bb07dc.png" alt="线程池状态"></p><h2 id="任务的执行"><a href="#任务的执行" class="headerlink" title="任务的执行"></a>任务的执行</h2><p>我们通常调用submit方法传入任务，submit源码很简单，封装成RunnableFuture之后，调用execute方法执行</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Future&lt;?&gt; submit(Runnable task) &#123;</span><br><span class="line">    <span class="keyword">if</span> (task == <span class="keyword">null</span>) <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, <span class="keyword">null</span>);</span><br><span class="line">    execute(ftask);</span><br><span class="line">    <span class="keyword">return</span> ftask;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Runnable command)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (command == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> c = ctl.get();</span><br><span class="line">    <span class="keyword">if</span> (workerCountOf(c) &lt; corePoolSize) &#123;</span><br><span class="line">        <span class="comment">// 新增一个core线程，任务作为该线程的firstTask，并启动了worker线程去执行任务</span></span><br><span class="line">        <span class="keyword">if</span> (addWorker(command, <span class="keyword">true</span>))</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        c = ctl.get();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// core满了，添加到workQueue</span></span><br><span class="line">    <span class="keyword">if</span> (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123;</span><br><span class="line">        <span class="keyword">int</span> recheck = ctl.get();</span><br><span class="line">        <span class="comment">// 注意上面的状态是isRunning，现在没有运行了，就删除任务</span></span><br><span class="line">        <span class="keyword">if</span> (! isRunning(recheck) &amp;&amp; remove(command))</span><br><span class="line">            reject(command); <span class="comment">// reject任务</span></span><br><span class="line">        <span class="comment">// worker线程数为0，我理解这里可能是core有超时回收的设置</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (workerCountOf(recheck) == <span class="number">0</span>)</span><br><span class="line">            addWorker(<span class="keyword">null</span>, <span class="keyword">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// workQueue添加失败了(满了)，才创建非core的worker线程，注意第二个参数是false</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (!addWorker(command, <span class="keyword">false</span>))</span><br><span class="line">        <span class="comment">// 创建非core worker线程失败了，就reject任务</span></span><br><span class="line">        reject(command);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>配合我前面的文字解释及下面的注释，过程十分简单，我们用一个流程图来描述下</p><p><img src="https://ae01.alicdn.com/kf/H407ec59847164875a994690240fd48b8U.png" alt="execute方法详情"></p><p>创建worker线程并执行任务的逻辑在addWorker方法中</p><h2 id="创建worker"><a href="#创建worker" class="headerlink" title="创建worker"></a>创建worker</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">addWorker</span><span class="params">(Runnable firstTask, <span class="keyword">boolean</span> core)</span> </span>&#123;</span><br><span class="line">    retry:</span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        <span class="keyword">int</span> c = ctl.get();<span class="keyword">int</span> rs = runStateOf(c);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// Check if queue empty only if necessary.</span></span><br><span class="line">        <span class="comment">// SHUTDOWN，STOP，TIDYING，TERMINATED四种状态返回失败</span></span><br><span class="line">        <span class="keyword">if</span> (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == <span class="keyword">null</span> &amp;&amp; ! workQueue.isEmpty()))</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">            <span class="keyword">int</span> wc = workerCountOf(c);</span><br><span class="line">            <span class="comment">// &gt;corePoolSize需要放入workQueue，&gt;maximumPoolSize也会返回false</span></span><br><span class="line">            <span class="keyword">if</span> (wc &gt;= CAPACITY ||</span><br><span class="line">                wc &gt;= (core ? corePoolSize : maximumPoolSize))</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment">// cas (rs,wc) + 1，rs在高位，这里是wc+1</span></span><br><span class="line">            <span class="keyword">if</span> (compareAndIncrementWorkerCount(c))</span><br><span class="line">                <span class="keyword">break</span> retry;</span><br><span class="line">            c = ctl.get();  <span class="comment">// Re-read ctl</span></span><br><span class="line">            <span class="comment">// 如果状态变了，需要重新循环</span></span><br><span class="line">            <span class="keyword">if</span> (runStateOf(c) != rs)</span><br><span class="line">                <span class="keyword">continue</span> retry;</span><br><span class="line">            <span class="comment">// else CAS failed due to workerCount change; retry inner loop</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">boolean</span> workerStarted = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">boolean</span> workerAdded = <span class="keyword">false</span>;</span><br><span class="line">    Worker w = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 创建一个worker</span></span><br><span class="line">        w = <span class="keyword">new</span> Worker(firstTask);</span><br><span class="line">        <span class="comment">// 被代理的线程</span></span><br><span class="line">        <span class="keyword">final</span> Thread t = w.thread;</span><br><span class="line">        <span class="keyword">if</span> (t != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 该锁主要针对 HashSet&lt;Worker&gt; workers</span></span><br><span class="line">            <span class="keyword">final</span> ReentrantLock mainLock = <span class="keyword">this</span>.mainLock;</span><br><span class="line">            mainLock.lock();</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">// Recheck while holding lock.</span></span><br><span class="line">                <span class="comment">// Back out on ThreadFactory failure or if</span></span><br><span class="line">                <span class="comment">// shut down before lock acquired.</span></span><br><span class="line">                <span class="keyword">int</span> rs = runStateOf(ctl.get());</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (rs &lt; SHUTDOWN ||</span><br><span class="line">                    (rs == SHUTDOWN &amp;&amp; firstTask == <span class="keyword">null</span>)) &#123;</span><br><span class="line">                    <span class="comment">// 线程已经启动过了</span></span><br><span class="line">                    <span class="keyword">if</span> (t.isAlive()) <span class="comment">// precheck that t is startable</span></span><br><span class="line">                        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalThreadStateException();</span><br><span class="line">                    <span class="comment">// 添加到Set&lt;Worker&gt;</span></span><br><span class="line">                    workers.add(w);</span><br><span class="line">                    <span class="keyword">int</span> s = workers.size();</span><br><span class="line">                    <span class="keyword">if</span> (s &gt; largestPoolSize)</span><br><span class="line">                        largestPoolSize = s;</span><br><span class="line">                    workerAdded = <span class="keyword">true</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                mainLock.unlock();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (workerAdded) &#123;</span><br><span class="line">                <span class="comment">// 启动线程</span></span><br><span class="line">                t.start();</span><br><span class="line">                workerStarted = <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (! workerStarted)</span><br><span class="line">            addWorkerFailed(w);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> workerStarted;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里核心逻辑也就是创建了work线程并传入任务:new Worker(firstTask)，之后启动了线程t，那么线程t与worker的关系又是什么呢？</p><p>Worker继承AQS，同时实现了Runnable，构造方法中可以看到获取到了我们传入的ThreadFactory()，创建了Thread线程对象，同时传入当前worker对象，即new Thread(new Runnable)的形式</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Worker</span> <span class="keyword">extends</span> <span class="title">AbstractQueuedSynchronizer</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">Worker(Runnable firstTask) &#123;</span><br><span class="line">    setState(-<span class="number">1</span>); <span class="comment">// inhibit interrupts until runWorker</span></span><br><span class="line">    <span class="keyword">this</span>.firstTask = firstTask;</span><br><span class="line">    <span class="keyword">this</span>.thread = getThreadFactory().newThread(<span class="keyword">this</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的addWorker方法已经启动了线程: t.start(), 那么剩下来的就很简单了，看Worker的run方法即可</p><h2 id="获取并执行任务"><a href="#获取并执行任务" class="headerlink" title="获取并执行任务"></a>获取并执行任务</h2><p>runWorker方法主要就是获取task并执行，逻辑十分简单</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    runWorker(<span class="keyword">this</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">runWorker</span><span class="params">(Worker w)</span> </span>&#123;</span><br><span class="line">    Thread wt = Thread.currentThread();</span><br><span class="line">    Runnable task = w.firstTask;</span><br><span class="line">    <span class="comment">// 获取完立马置为null，下面的while之后的task就为null了，就会从workQueue中获取</span></span><br><span class="line">    w.firstTask = <span class="keyword">null</span>;</span><br><span class="line">    w.unlock(); <span class="comment">// allow interrupts</span></span><br><span class="line">    <span class="keyword">boolean</span> completedAbruptly = <span class="keyword">true</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 任务从2个地方获取</span></span><br><span class="line">        <span class="comment">// 1. 创建线程时，它的firstTask</span></span><br><span class="line">        <span class="comment">// 2. 从workQueue中获取，getTask方法，返回null说明rs&gt;=Stop或者队列为空</span></span><br><span class="line">        <span class="keyword">while</span> (task != <span class="keyword">null</span> || (task = getTask()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">            w.lock();</span><br><span class="line">            <span class="comment">// If pool is stopping, ensure thread is interrupted;</span></span><br><span class="line">            <span class="comment">// if not, ensure thread is not interrupted.  This</span></span><br><span class="line">            <span class="comment">// requires a recheck in second case to deal with</span></span><br><span class="line">            <span class="comment">// shutdownNow race while clearing interrupt</span></span><br><span class="line">            <span class="keyword">if</span> ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP)))  &amp;&amp; !wt.isInterrupted())</span><br><span class="line">                wt.interrupt();</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                beforeExecute(wt, task);<span class="comment">// 啥也没做</span></span><br><span class="line"></span><br><span class="line">                Throwable thrown = <span class="keyword">null</span>;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">// 执行我们的任务</span></span><br><span class="line">                    task.run();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (RuntimeException x) &#123;</span><br><span class="line">                    thrown = x; <span class="keyword">throw</span> x;</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Error x) &#123;</span><br><span class="line">                    thrown = x; <span class="keyword">throw</span> x;</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Throwable x) &#123;</span><br><span class="line">                    thrown = x; <span class="keyword">throw</span> <span class="keyword">new</span> Error(x);</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    afterExecute(task, thrown);<span class="comment">// 啥也没做</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                task = <span class="keyword">null</span>;</span><br><span class="line">                <span class="comment">// 已执行的任务数加1</span></span><br><span class="line">                w.completedTasks++;</span><br><span class="line">                w.unlock();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        completedAbruptly = <span class="keyword">false</span>;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        processWorkerExit(w, completedAbruptly);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>getTask方法是从workQueue中获取任务，此处也可以看出keepAliveTime就是从队列中获取的超时时间</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Runnable <span class="title">getTask</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">boolean</span> timedOut = <span class="keyword">false</span>; <span class="comment">// Did the last poll() time out?</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        <span class="keyword">int</span> c = ctl.get();</span><br><span class="line">        <span class="keyword">int</span> rs = runStateOf(c);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Check if queue empty only if necessary.</span></span><br><span class="line">        <span class="keyword">if</span> (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123;</span><br><span class="line">            decrementWorkerCount();</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> wc = workerCountOf(c);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Are workers subject to culling?</span></span><br><span class="line">        <span class="comment">// worker需不需要淘汰，core，或者非core都有空闲时间淘汰策略</span></span><br><span class="line">        <span class="keyword">boolean</span> timed = allowCoreThreadTimeOut || wc &gt; corePoolSize;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut))</span><br><span class="line">            &amp;&amp; (wc &gt; <span class="number">1</span> || workQueue.isEmpty())) &#123;</span><br><span class="line">            <span class="keyword">if</span> (compareAndDecrementWorkerCount(c))</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// timed 表示core在设置了allowCoreThreadTimeOut会被淘汰，非core之外的也会被淘汰</span></span><br><span class="line">            <span class="comment">// 空闲时间=worker从workQueue里获取任务超时的时间</span></span><br><span class="line">            Runnable r = timed ?</span><br><span class="line">                workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :</span><br><span class="line">                workQueue.take(); <span class="comment">// 不需要淘汰只会是core线程没有设置超时的情况，这里用take会一直等待</span></span><br><span class="line">            <span class="comment">// 返回获取到的任务</span></span><br><span class="line">            <span class="keyword">if</span> (r != <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">return</span> r;</span><br><span class="line">            timedOut = <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException retry) &#123;</span><br><span class="line">            timedOut = <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="关于线程池的常见问题"><a href="#关于线程池的常见问题" class="headerlink" title="关于线程池的常见问题"></a>关于线程池的常见问题</h1><h2 id="队列太长导致超时"><a href="#队列太长导致超时" class="headerlink" title="队列太长导致超时"></a>队列太长导致超时</h2><p>假设A服务在接收到上游服务的一个请求后用线程池处理，但是队列设置的太大，假设某一个处理环境速度变慢，比如数据库处理了异常，导致大量任务积压，那么上游服务就会调用A服务超时</p><h2 id="maxSize线程数太小"><a href="#maxSize线程数太小" class="headerlink" title="maxSize线程数太小"></a>maxSize线程数太小</h2><p>maxSize太小，同时等待队列也不大，在任务堆积满了之后，就会reject任务，有可能抛出大量的RejectedExecutionException</p><h2 id="父子任务同用一个线程池"><a href="#父子任务同用一个线程池" class="headerlink" title="父子任务同用一个线程池"></a>父子任务同用一个线程池</h2><p>这种问题很隐蔽，假设任务的执行分为3步,step2需要执行的逻辑较为复杂，或者某一时刻，redis/mysql等出现了阻塞，那么就会hang在step2，就会导致父任务一直占用线程，得不到释放，正确的做法是把step2单独作为一个子任务放入到另一个线程池</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Task&#123;</span><br><span class="line">    step1();</span><br><span class="line">    step2();</span><br><span class="line">    step3();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="动态调整线程池大小"><a href="#动态调整线程池大小" class="headerlink" title="动态调整线程池大小"></a>动态调整线程池大小</h1><p>线程池大小的设定，根据CPU密集型和IO密集型划分，但是理论毕竟是理论，它受限于以下环境：一台服务器上只有一个应用，一个应用也只有一个线程池，同时业务的流量一直都是平稳的，没有突发性<br>但实际应用中一台服务器上一般都有日志收集，sidecar等各类agent，一个应用中也有多个线程池，业务流量在上下班，用餐时间段高也是很正常的事</p><p>那么动态调整线程池大小就很有必要了，基于Apollo可以很轻松的实现以下方案</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ApolloConfigChangeListener</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">listen</span><span class="params">(ConfigChangeEvent event)</span> </span>&#123;</span><br><span class="line">    log.info(<span class="string">"changing thread pool info ..."</span>);</span><br><span class="line"></span><br><span class="line">    Set&lt;String&gt; changeKeys = event.changedKeys();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(changeKeys.contains(CORE_SIZE) || changeKeys.contains(MAX_SIZE)) &#123;</span><br><span class="line">        <span class="keyword">if</span>(coreSize &gt; maxSize) &#123;</span><br><span class="line">            log.warn(<span class="string">"core size must less or equals max size"</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 必须都重新设置一遍</span></span><br><span class="line">        threadPoolTaskExecutor.setCorePoolSize(coreSize);</span><br><span class="line">        threadPoolTaskExecutor.setMaxPoolSize(maxSize);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么原理是怎样的呢？</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCorePoolSize</span><span class="params">(<span class="keyword">int</span> corePoolSize)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (corePoolSize &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException();</span><br><span class="line">    <span class="comment">// 差值</span></span><br><span class="line">    <span class="keyword">int</span> delta = corePoolSize - <span class="keyword">this</span>.corePoolSize;</span><br><span class="line">    <span class="comment">// 重新复制</span></span><br><span class="line">    <span class="keyword">this</span>.corePoolSize = corePoolSize;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 如果原来的线程数大于新的线程数，则会终止</span></span><br><span class="line">    <span class="keyword">if</span> (workerCountOf(ctl.get()) &gt; corePoolSize)</span><br><span class="line">        interruptIdleWorkers();</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (delta &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// We don't really know how many new threads are "needed".</span></span><br><span class="line">        <span class="comment">// As a heuristic, prestart enough new workers (up to new</span></span><br><span class="line">        <span class="comment">// core size) to handle the current number of tasks in</span></span><br><span class="line">        <span class="comment">// queue, but stop if queue becomes empty while doing so.</span></span><br><span class="line">        <span class="keyword">int</span> k = Math.min(delta, workQueue.size());</span><br><span class="line">        <span class="comment">// 创建线程</span></span><br><span class="line">        <span class="keyword">while</span> (k-- &gt; <span class="number">0</span> &amp;&amp; addWorker(<span class="keyword">null</span>, <span class="keyword">true</span>)) &#123;</span><br><span class="line">            <span class="comment">// workQueue为空就先停止创建，毕竟没必要</span></span><br><span class="line">            <span class="keyword">if</span> (workQueue.isEmpty())</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setMaximumPoolSize</span><span class="params">(<span class="keyword">int</span> maximumPoolSize)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (maximumPoolSize &lt;= <span class="number">0</span> || maximumPoolSize &lt; corePoolSize)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException();</span><br><span class="line">    <span class="keyword">this</span>.maximumPoolSize = maximumPoolSize;</span><br><span class="line">    <span class="keyword">if</span> (workerCountOf(ctl.get()) &gt; maximumPoolSize)</span><br><span class="line">        interruptIdleWorkers();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>至于workQueue的大小动态调整可以复制一下LinkedBlockingQueue实现一个ResizeableQueue，去掉capacity的final修饰符并提供set方法即可</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>ThreadPoolExecutor线程池重要的是worker线程的创建，以及任务的获取，总的来说就是先创建core线程，core满了就放入workQueue，workQueue也满了就创建worker线程至maxSize，如果超出了maxSize就执行reject</p><p>引用：<a href="https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html" target="_blank" rel="noopener">Java线程池实现原理及其在美团业务中的实践</a></p>]]></content>
      
      <categories>
          
          <category> 技术积累 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 积累 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka消费者-ListOffsets请求</title>
      <link href="/2020/03/15/Kafka%E6%B6%88%E8%B4%B9%E8%80%85-ListOffsets%E8%AF%B7%E6%B1%82/"/>
      <url>/2020/03/15/Kafka%E6%B6%88%E8%B4%B9%E8%80%85-ListOffsets%E8%AF%B7%E6%B1%82/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本文聊聊消费者拉取消息时向kafka server发送LIST_OFFSETS的请求，这个请求的功能一言以蔽之:根据请求参数中的timeStamp获取消费者(或副本)能够fetch的位移</p><p>主要应用场景为消费者第一次拉取消息时，不知道从哪个offset拉取，这个拉取策略可以消费者通过auto.offset.reset指定，请求时翻译成timeStamp(ListOffsetRequest类常量)，<br>server端处理时从日志(LogSegment)中查找应该被fetch的offset(TimestampOffset)</p><p>在消费者之后的拉取中，记录了上次拉取的位置(TopicPartitionState@position)</p><h1 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h1><p>之前的文章中说过，server端通过KafkaApis#handle方法处理所有网络请求，LIST_OFFSETS请求如下</p><h2 id="handleListOffsetRequest"><a href="#handleListOffsetRequest" class="headerlink" title="handleListOffsetRequest"></a>handleListOffsetRequest</h2><p>忽略认证，校验等代码，仅关注handleListOffsetRequestV1AndAbove方法, 它返回了每个TP对应的fetch offset</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">handleListOffsetRequestV1AndAbove</span><span class="params">(request : RequestChannel.Request)</span>: Map[TopicPartition, ListOffsetResponse.PartitionData] </span>= &#123;</span><br><span class="line">    val correlationId = request.header.correlationId</span><br><span class="line">    val clientId = request.header.clientId</span><br><span class="line">    val offsetRequest = request.body[ListOffsetRequest]</span><br><span class="line"></span><br><span class="line">    val (authorizedRequestInfo, unauthorizedRequestInfo) = offsetRequest.partitionTimestamps.asScala.partition &#123;</span><br><span class="line">      <span class="keyword">case</span> (topicPartition, _) =&gt; authorize(request.session, Describe, Resource(Topic, topicPartition.topic, LITERAL))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    val unauthorizedResponseStatus = unauthorizedRequestInfo.mapValues(_ =&gt; &#123;</span><br><span class="line">      <span class="keyword">new</span> ListOffsetResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,</span><br><span class="line">                                           ListOffsetResponse.UNKNOWN_TIMESTAMP,</span><br><span class="line">                                           ListOffsetResponse.UNKNOWN_OFFSET)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    val responseMap = authorizedRequestInfo.map &#123; <span class="keyword">case</span> (topicPartition, timestamp) =&gt;</span><br><span class="line"><span class="comment">// 获取leader</span></span><br><span class="line">val localReplica = replicaManager.getLeaderReplicaIfLocal(topicPartition)</span><br><span class="line"></span><br><span class="line"><span class="comment">// -1表示consumer</span></span><br><span class="line">val fromConsumer = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID</span><br><span class="line"></span><br><span class="line">val found = <span class="keyword">if</span> (fromConsumer) &#123;</span><br><span class="line"><span class="comment">// 根据事务隔离级别，获取可拉取的位移</span></span><br><span class="line">val lastFetchableOffset = offsetRequest.isolationLevel match &#123;</span><br><span class="line">  <span class="keyword">case</span> IsolationLevel.READ_COMMITTED =&gt; localReplica.lastStableOffset.messageOffset</span><br><span class="line">    <span class="comment">// 默认没使用事务，返回的是highWatermark</span></span><br><span class="line">  <span class="keyword">case</span> IsolationLevel.READ_UNCOMMITTED =&gt; localReplica.highWatermark.messageOffset</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这里的if...else...就是if (fromConsumer)的返回值</span></span><br><span class="line"><span class="comment">// reset到最新的</span></span><br><span class="line"><span class="keyword">if</span> (timestamp == ListOffsetRequest.LATEST_TIMESTAMP)</span><br><span class="line">  <span class="comment">// TimestampOffset，case class： -1 和 highWatermark</span></span><br><span class="line">  TimestampOffset(RecordBatch.NO_TIMESTAMP, lastFetchableOffset)</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="comment">// 过滤函数：从log里查找出来的offset一定要比lastFetchableOffset小 或者是earliest</span></span><br><span class="line">  <span class="function">def <span class="title">allowed</span><span class="params">(timestampOffset: TimestampOffset)</span>: Boolean </span>=</span><br><span class="line">    timestamp == ListOffsetRequest.EARLIEST_TIMESTAMP || timestampOffset.offset &lt; lastFetchableOffset</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 获取offset</span></span><br><span class="line">  fetchOffsetForTimestamp(topicPartition, timestamp)</span><br><span class="line">    .filter(allowed).getOrElse(TimestampOffset.Unknown)</span><br><span class="line">&#125;</span><br><span class="line">&#125; </span><br><span class="line"><span class="comment">// 不是consumer的先不看</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 这是map方法的返回，也就是在循环内</span></span><br><span class="line">(topicPartition, <span class="keyword">new</span> ListOffsetResponse.PartitionData(Errors.NONE, found.timestamp, found.offset))</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 和未认证的TP并集，返回给客户端</span></span><br><span class="line">    responseMap ++ unauthorizedResponseStatus</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Segment中获取"><a href="#Segment中获取" class="headerlink" title="Segment中获取"></a>Segment中获取</h2><p>该方法就是根据客户端的reset policy(TimeStamp)来返回offset</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">fetchOffsetForTimestamp</span><span class="params">(topicPartition: TopicPartition, timestamp: Long)</span>: Option[TimestampOffset] </span>= &#123;</span><br><span class="line">    replicaManager.getLog(topicPartition) match &#123;</span><br><span class="line">      <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(log)</span> </span>=&gt;</span><br><span class="line">        <span class="comment">// 从Log的所有Segment里，根据timestamp找offset</span></span><br><span class="line">        log.fetchOffsetsByTimestamp(timestamp)</span><br><span class="line">      <span class="keyword">case</span> None =&gt;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> UnknownTopicOrPartitionException(s<span class="string">"$topicPartition does not exist on the broker."</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">def <span class="title">fetchOffsetsByTimestamp</span><span class="params">(targetTimestamp: Long)</span>: Option[TimestampOffset] </span>= &#123;</span><br><span class="line">    maybeHandleIOException(s<span class="string">"Error while fetching offset by timestamp for $topicPartition in dir $&#123;dir.getParent&#125;"</span>) &#123;</span><br><span class="line">    </span><br><span class="line">      <span class="comment">// 所有LogSegment的副本，共享变私有，避免锁竞争</span></span><br><span class="line">      val segmentsCopy = logSegments.toBuffer</span><br><span class="line">      <span class="comment">// For the earliest and latest, we do not need to return the timestamp.</span></span><br><span class="line">      <span class="keyword">if</span> (targetTimestamp == ListOffsetRequest.EARLIEST_TIMESTAMP)</span><br><span class="line">        <span class="comment">// earliest返回logStartOffset：当前TP在日志自动清理后，目前最小的offset</span></span><br><span class="line">        <span class="keyword">return</span> Some(TimestampOffset(RecordBatch.NO_TIMESTAMP, logStartOffset))</span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (targetTimestamp == ListOffsetRequest.LATEST_TIMESTAMP)</span><br><span class="line">        <span class="comment">// latest返回LEO 但是为什么返回LEO呢，万一一直没提交呢，返回HW不是更稳妥吗</span></span><br><span class="line">        <span class="keyword">return</span> Some(TimestampOffset(RecordBatch.NO_TIMESTAMP, logEndOffset))</span><br><span class="line"></span><br><span class="line">      <span class="comment">// earliest，latest之外的类型：Timestamp表示具体的时间戳，-1，-2只是表示了2个特殊的offset</span></span><br><span class="line">      val targetSeg = &#123;</span><br><span class="line">        <span class="comment">// Get all the segments whose largest timestamp is smaller than target timestamp</span></span><br><span class="line">        <span class="comment">// 先找segments，找第一个Segment的最大Timestamp大于请求中的Timestamp，可以看下takeWhile源码</span></span><br><span class="line">        val earlierSegs = segmentsCopy.takeWhile(_.largestTimestamp &lt; targetTimestamp) <span class="comment">// takeWhile牛逼啊，一直循环，只要不满足表示式停止</span></span><br><span class="line">        <span class="comment">// We need to search the first segment whose largest timestamp is greater than the target timestamp if there is one.</span></span><br><span class="line">        <span class="comment">// 再找offset</span></span><br><span class="line">        <span class="keyword">if</span> (earlierSegs.length &lt; segmentsCopy.length)</span><br><span class="line">          Some(segmentsCopy(earlierSegs.length))</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">          None</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      targetSeg.flatMap(_.findOffsetByTimestamp(targetTimestamp, logStartOffset))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该方法实现了根据时间戳查找offset，想必大家都很好奇实现过程，它的原理分为3步：</p><ol><li>先找到segment，每个segment都有自己的largestTimestamp，循环查找即可</li><li>我们知道segment和时间索引，位移索引的文件名是一样的，接下就可以从时间索引(timeIndex)文件中找到相应的offset</li><li>通过第2步的offset，在位移索引文件中查找到position</li></ol><p>以上过程我在<a href="">kafka消息格式与日志存储原理分析</a>一文中也已单独做了分析，包括消息的二分查找算法实现，想要深入理解的同学可以看看</p><p>具体的实现在findOffsetByTimestamp方法中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">findOffsetByTimestamp</span><span class="params">(timestamp: Long, startingOffset: Long = baseOffset)</span>: Option[TimestampOffset] </span>= &#123;</span><br><span class="line">  <span class="comment">// Get the index entry with a timestamp less than or equal to the target timestamp</span></span><br><span class="line"></span><br><span class="line">  val timestampOffset = timeIndex.lookup(timestamp)</span><br><span class="line">  val position = offsetIndex.lookup(math.max(timestampOffset.offset, startingOffset)).position</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Search the timestamp</span></span><br><span class="line">  Option(log.searchForTimestamp(timestamp, position, startingOffset)).map &#123; timestampAndOffset =&gt;</span><br><span class="line">    TimestampOffset(timestampAndOffset.timestamp, timestampAndOffset.offset)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文详细描述的LIST_OFFSETS请求的处理过程，在<a href="">Kafka消费者-源码分析(上)</a>一文中也知道了什么情况下会发送该请求，简单说这个请求是为auto.offset.reset参数服务的</p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka消费者-OffsetFetch请求</title>
      <link href="/2020/03/13/Kafka%E6%B6%88%E8%B4%B9%E8%80%85-OffsetFetch%E8%AF%B7%E6%B1%82/"/>
      <url>/2020/03/13/Kafka%E6%B6%88%E8%B4%B9%E8%80%85-OffsetFetch%E8%AF%B7%E6%B1%82/</url>
      <content type="html"><![CDATA[]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>kafka-rebalance之SyncGroup</title>
      <link href="/2020/03/12/kafka-rebalance%E4%B9%8BSyncGroup/"/>
      <url>/2020/03/12/kafka-rebalance%E4%B9%8BSyncGroup/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>衔接上文<a href="">kafka-rebalance之JoinGroup</a>, 我们已经知道在JoinGroup请求的响应中，leader consumer会计算分区分配方案，并发起SyncGroup请求，本文讲解SyncGroup请求的处理过程</p><p>同样的思路，我们还是从请求发起看起</p><h1 id="发送请求"><a href="#发送请求" class="headerlink" title="发送请求"></a>发送请求</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> RequestFuture&lt;ByteBuffer&gt; <span class="title">onJoinLeader</span><span class="params">(JoinGroupResponse joinResponse)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// perform the leader synchronization and send back the assignment for the group</span></span><br><span class="line">        Map&lt;String, ByteBuffer&gt; groupAssignment = performAssignment(joinResponse.leaderId(), joinResponse.groupProtocol(),</span><br><span class="line">                joinResponse.members());</span><br><span class="line"></span><br><span class="line">        SyncGroupRequest.Builder requestBuilder =</span><br><span class="line">                <span class="keyword">new</span> SyncGroupRequest.Builder(groupId, generation.generationId, generation.memberId, groupAssignment);</span><br><span class="line">        <span class="keyword">return</span> sendSyncGroupRequest(requestBuilder);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (RuntimeException e) &#123;</span><br><span class="line">        <span class="keyword">return</span> RequestFuture.failure(e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该请求的参数多用ByteBuffer表示，这里也是我通过源码反推出来的部分结构，不敢保证100%正确，但也相差不远，核心参数是每个consumer的分配方案</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"groupId"</span>: <span class="string">"test-group"</span>,</span><br><span class="line"><span class="attr">"generationId"</span>: <span class="number">1</span>,</span><br><span class="line"><span class="attr">"memberId"</span>: <span class="string">"client-A625830A-86C6-4E10-809F-296297328FCA"</span>,</span><br><span class="line"><span class="attr">"groupAssignment"</span>: [</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"memberId"</span>: <span class="string">"client-FB86B927-DA68-4271-BB0C-2AA69879325D"</span>,</span><br><span class="line"><span class="attr">"topic_partitions"</span>: &#123;</span><br><span class="line"><span class="attr">"topic"</span>: <span class="string">"test"</span>,</span><br><span class="line"><span class="attr">"partitions"</span>: [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">&#125;,</span><br><span class="line"><span class="attr">"userData"</span>: <span class="literal">null</span></span><br><span class="line">&#125;</span><br><span class="line">// 其他member ... </span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="GoupCoordinator处理请求"><a href="#GoupCoordinator处理请求" class="headerlink" title="GoupCoordinator处理请求"></a>GoupCoordinator处理请求</h1><p>broker端处理入口同样的三步走：定义回调函数，认证(已省略)，处理，那么核心逻辑在GroupCoordinator的handleSyncGroup方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">handleSyncGroupRequest</span><span class="params">(request: RequestChannel.Request)</span> </span>&#123;</span><br><span class="line">    val syncGroupRequest = request.body[SyncGroupRequest]</span><br><span class="line"></span><br><span class="line">    <span class="function">def <span class="title">sendResponseCallback</span><span class="params">(memberState: Array[Byte], error: Errors)</span> </span>&#123;</span><br><span class="line">      sendResponseMaybeThrottle(request, requestThrottleMs =&gt;</span><br><span class="line">        <span class="keyword">new</span> SyncGroupResponse(requestThrottleMs, error, ByteBuffer.wrap(memberState)))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 省略认证代码</span></span><br><span class="line">groupCoordinator.handleSyncGroup(</span><br><span class="line">  syncGroupRequest.groupId,</span><br><span class="line">  syncGroupRequest.generationId,</span><br><span class="line">  syncGroupRequest.memberId,</span><br><span class="line">  syncGroupRequest.groupAssignment().asScala.mapValues(Utils.toArray),</span><br><span class="line">  sendResponseCallback</span><br><span class="line">)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="handleSyncGroup"><a href="#handleSyncGroup" class="headerlink" title="handleSyncGroup"></a>handleSyncGroup</h2><p>同样省略了大部分异常处理逻辑，可以看到直接调用了doSyncGroup<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">handleSyncGroup</span><span class="params">(groupId: String,</span></span></span><br><span class="line"><span class="function"><span class="params">                      generation: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                      memberId: String,</span></span></span><br><span class="line"><span class="function"><span class="params">                      groupAssignment: Map[String, Array[Byte]],</span></span></span><br><span class="line"><span class="function"><span class="params">                      responseCallback: SyncCallback)</span>: Unit </span>= &#123;</span><br><span class="line"></span><br><span class="line">    groupManager.getGroup(groupId) match &#123;</span><br><span class="line">      <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(group)</span> </span>=&gt; doSyncGroup(group, generation, memberId, groupAssignment, responseCallback)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="doSyncGroup"><a href="#doSyncGroup" class="headerlink" title="doSyncGroup"></a>doSyncGroup</h2><p>通过<a href="">kafka-rebalance之JoinGroup</a>我们一已知当前消费者组处于CompletingRebalance状态，这里的分支我们只用看它即可</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">doSyncGroup</span><span class="params">(group: GroupMetadata,</span></span></span><br><span class="line"><span class="function"><span class="params">                          generationId: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                          memberId: String,</span></span></span><br><span class="line"><span class="function"><span class="params">                          groupAssignment: Map[String, Array[Byte]],</span></span></span><br><span class="line"><span class="function"><span class="params">                          responseCallback: SyncCallback)</span> </span>&#123;</span><br><span class="line">    group.inLock &#123;</span><br><span class="line">        group.currentState match &#123;</span><br><span class="line">          <span class="keyword">case</span> Empty | Dead =&gt; <span class="comment">// 省略 ...</span></span><br><span class="line">          <span class="keyword">case</span> PreparingRebalance =&gt; <span class="comment">// 省略 ...</span></span><br><span class="line">          <span class="keyword">case</span> CompletingRebalance =&gt;</span><br><span class="line">          <span class="comment">// 同样的暂存回调，在延迟任务完成时触发</span></span><br><span class="line">            group.get(memberId).awaitingSyncCallback = responseCallback</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 只处理leader consumer</span></span><br><span class="line">            <span class="keyword">if</span> (group.isLeader(memberId)) &#123;</span><br><span class="line">              <span class="comment">// fill any missing members with an empty assignment</span></span><br><span class="line">              val missing = group.allMembers -- groupAssignment.keySet</span><br><span class="line">              val assignment = groupAssignment ++ missing.map(_ -&gt; Array.empty[Byte]).toMap</span><br><span class="line"></span><br><span class="line">              <span class="comment">// 持久化保存到__consumer_offset</span></span><br><span class="line">              groupManager.storeGroup(group, assignment, (error: Errors) =&gt; &#123;</span><br><span class="line">                group.inLock &#123;</span><br><span class="line">                  <span class="comment">// another member may have joined the group while we were awaiting this callback,</span></span><br><span class="line">                  <span class="comment">// so we must ensure we are still in the CompletingRebalance state and the same generation</span></span><br><span class="line">                  <span class="comment">// when it gets invoked. if we have transitioned to another state, then do nothing</span></span><br><span class="line">                  <span class="keyword">if</span> (group.is(CompletingRebalance) &amp;&amp; generationId == group.generationId) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (error != Errors.NONE) &#123;</span><br><span class="line">                      resetAndPropagateAssignmentError(group, error)</span><br><span class="line">                      maybePrepareRebalance(group)</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                      <span class="comment">// 正常的逻辑</span></span><br><span class="line">                      setAndPropagateAssignment(group, assignment)</span><br><span class="line">                      group.transitionTo(Stable)</span><br><span class="line">                    &#125;</span><br><span class="line">                  &#125;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;)</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">          <span class="keyword">case</span> Stable =&gt;</span><br><span class="line">            <span class="comment">// if the group is stable, we just return the current assignment</span></span><br><span class="line">            val memberMetadata = group.get(memberId)</span><br><span class="line">            responseCallback(memberMetadata.assignment, Errors.NONE)</span><br><span class="line">            completeAndScheduleNextHeartbeatExpiration(group, group.get(memberId))</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到该方法只处理leader consumer的SyncGroupRequest，并将元数据存入了__consumer_offsets中，之后关键的处理在setAndPropagateAssignment方法，处理完成后将组状态转换为Stable</p><h2 id="setAndPropagateAssignment"><a href="#setAndPropagateAssignment" class="headerlink" title="setAndPropagateAssignment"></a>setAndPropagateAssignment</h2><p>该方法首先校验了状态，然后将每个member的分配方案保存到了allMemberMetadata，之后调用了propagateAssignment<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">setAndPropagateAssignment</span><span class="params">(group: GroupMetadata, assignment: Map[String, Array[Byte]])</span> </span>&#123;</span><br><span class="line"><span class="keyword">assert</span>(group.is(CompletingRebalance))</span><br><span class="line">group.allMemberMetadata.foreach(member =&gt; member.assignment = assignment(member.memberId))</span><br><span class="line">propagateAssignment(group, Errors.NONE)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="响应客户端"><a href="#响应客户端" class="headerlink" title="响应客户端"></a>响应客户端</h2><p>该方法的处理逻辑也十分简单：调用回调响应每个客户端，响应的内容是每个consumer的assignment(分配方案)，并在之后开始执行定时任务监控member的心跳</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">propagateAssignment</span><span class="params">(group: GroupMetadata, error: Errors)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (member &lt;- group.allMemberMetadata) &#123;</span><br><span class="line">      <span class="keyword">if</span> (member.awaitingSyncCallback != <span class="keyword">null</span>) &#123;</span><br><span class="line">        member.awaitingSyncCallback(member.assignment, error)</span><br><span class="line">        member.awaitingSyncCallback = <span class="keyword">null</span></span><br><span class="line"></span><br><span class="line">        completeAndScheduleNextHeartbeatExpiration(group, member)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>响应的回调函数比较简单，可以回到最上面看handleSyncGroupRequest方法，就是把member的分配方案返回，而completeAndScheduleNextHeartbeatExpiration的作用是记录一次成功的心跳，并将下一次心跳的延迟任务放入Purgatory，同样的我们把它理解为延迟队列即可</p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>kafka-rebalance之JoinGroup</title>
      <link href="/2020/03/12/kafka-rebalance%E4%B9%8BJoinGroup/"/>
      <url>/2020/03/12/kafka-rebalance%E4%B9%8BJoinGroup/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在AbstractCoordinator的initiateJoinGroup方法中，通过判断joinFuture为null，发起了JoinGroupRequest请求，本文主要讲解GroupCoordinator对该请求的处理。同样的，源码分为客户端发起请求时的参数，broker端的处理过程，以及consumer对响应的处理</p><h1 id="发起请求"><a href="#发起请求" class="headerlink" title="发起请求"></a>发起请求</h1><p>请求的发送代码在AbstractCoordinator的sendJoinGroupRequest方法在，方法比较简单，这里说点简单之外的事情</p><ol><li>首先确保已知coordinator节点，才能向它发起请求</li><li>generation.memberId初始化时为””</li><li>protocolType=”consumer”</li><li>rebalanceTimeoutMs就是max.poll.interval.ms，这个结论可以从KafkaConsumer初始化ConsumerCoordinator得到</li><li>4中的rebalanceTimeoutMs也是不最终客户端请求的超时时间，这里源码作者额外增加了5s</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 省略部分代码</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> RequestFuture&lt;ByteBuffer&gt; <span class="title">initiateJoinGroup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (joinFuture == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">        joinFuture = sendJoinGroupRequest();</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> joinFuture;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">RequestFuture&lt;ByteBuffer&gt; <span class="title">sendJoinGroupRequest</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// 确保已知coordinator节点</span></span><br><span class="line">    <span class="keyword">if</span> (coordinatorUnknown())</span><br><span class="line">        <span class="keyword">return</span> RequestFuture.coordinatorNotAvailable();</span><br><span class="line"></span><br><span class="line">    JoinGroupRequest.Builder requestBuilder = <span class="keyword">new</span> JoinGroupRequest.Builder(</span><br><span class="line">            groupId,</span><br><span class="line">            <span class="keyword">this</span>.sessionTimeoutMs,</span><br><span class="line">            <span class="keyword">this</span>.generation.memberId,</span><br><span class="line">            protocolType(), <span class="comment">// consumer</span></span><br><span class="line">            metadata()).setRebalanceTimeout(<span class="keyword">this</span>.rebalanceTimeoutMs);</span><br><span class="line"></span><br><span class="line">    log.debug(<span class="string">"Sending JoinGroup (&#123;&#125;) to coordinator &#123;&#125;"</span>, requestBuilder, <span class="keyword">this</span>.coordinator);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Note that we override the request timeout using the rebalance timeout since that is the</span></span><br><span class="line">    <span class="comment">// maximum time that it may block on the coordinator. We add an extra 5 seconds for small delays.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> joinGroupTimeoutMs = Math.max(rebalanceTimeoutMs, rebalanceTimeoutMs + <span class="number">5000</span>);</span><br><span class="line">    <span class="keyword">return</span> client.send(coordinator, requestBuilder, joinGroupTimeoutMs)</span><br><span class="line">            .compose(<span class="keyword">new</span> JoinGroupResponseHandler());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>请求的格式的json形式如下：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"groupId"</span>: <span class="string">"test-group"</span>,</span><br><span class="line"><span class="attr">"sessionTimeout"</span>: <span class="number">30000</span>,</span><br><span class="line"><span class="attr">"memberId"</span>: <span class="string">""</span>,</span><br><span class="line"><span class="attr">"protocolType"</span>: <span class="string">"consumer"</span>,</span><br><span class="line"><span class="attr">"groupProtocols"</span>: [</span><br><span class="line">&#123;</span><br><span class="line">"name": "range", // PartitionAssignor的name</span><br><span class="line">"metadata": &#123;</span><br><span class="line">"version": 0,</span><br><span class="line">"topic": "foo,bar", // 订阅的topic</span><br><span class="line">"user_data": null // 通常为null</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">],</span><br><span class="line">"rebalanceTimeout": 10000</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="GoupCoordinator处理请求"><a href="#GoupCoordinator处理请求" class="headerlink" title="GoupCoordinator处理请求"></a>GoupCoordinator处理请求</h1><p>JoinGroupRequest由GoupCoordinator所在的broker处理，入口方法为handleJoinGroupRequest，下面的源码省略了认证相关，可以看出该方法做了2件事：定义响应回调，调用handleJoinGroup方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">handleJoinGroupRequest</span><span class="params">(request: RequestChannel.Request)</span> </span>&#123;</span><br><span class="line">    val joinGroupRequest = request.body[JoinGroupRequest]</span><br><span class="line"></span><br><span class="line">    <span class="comment">// the callback for sending a join-group response</span></span><br><span class="line">    <span class="function">def <span class="title">sendResponseCallback</span><span class="params">(joinResult: JoinGroupResult)</span> </span>&#123;</span><br><span class="line">      val members = joinResult.members map &#123; <span class="keyword">case</span> (memberId, metadataArray) =&gt; (memberId, ByteBuffer.wrap(metadataArray)) &#125;</span><br><span class="line">      <span class="function">def <span class="title">createResponse</span><span class="params">(requestThrottleMs: Int)</span>: AbstractResponse </span>= &#123;</span><br><span class="line">        val responseBody = <span class="keyword">new</span> JoinGroupResponse(requestThrottleMs, joinResult.error, joinResult.generationId,</span><br><span class="line">          joinResult.subProtocol, joinResult.memberId, joinResult.leaderId, members.asJava)</span><br><span class="line"></span><br><span class="line">        trace(<span class="string">"Sending join group response %s for correlation id %d to client %s."</span></span><br><span class="line">          .format(responseBody, request.header.correlationId, request.header.clientId))</span><br><span class="line">        responseBody</span><br><span class="line">      &#125;</span><br><span class="line">      sendResponseMaybeThrottle(request, createResponse)</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="comment">// let the coordinator handle join-group</span></span><br><span class="line">  val protocols = joinGroupRequest.groupProtocols().asScala.map(protocol =&gt;</span><br><span class="line">    (protocol.name, Utils.toArray(protocol.metadata))).toList</span><br><span class="line">  groupCoordinator.handleJoinGroup(</span><br><span class="line">    joinGroupRequest.groupId,</span><br><span class="line">    joinGroupRequest.memberId,</span><br><span class="line">    request.header.clientId,</span><br><span class="line">    request.session.clientAddress.toString,</span><br><span class="line">    joinGroupRequest.rebalanceTimeout,</span><br><span class="line">    joinGroupRequest.sessionTimeout,</span><br><span class="line">    joinGroupRequest.protocolType, <span class="comment">// consumer</span></span><br><span class="line">    protocols,</span><br><span class="line">    sendResponseCallback)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="handleJoinGroup"><a href="#handleJoinGroup" class="headerlink" title="handleJoinGroup"></a>handleJoinGroup</h2><p>handleJoinGroup的核心逻辑是校验和调用doJoinGroup，关于校验这里说2点</p><ol><li>groupId不能为null，也不能是””</li><li>sessionTimeoutMs默认必须在6000-300000 即6s-5min之间，当然你也可以修改group.min.session.timeout.ms，group.max.session.timeout.ms来调整区间</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">handleJoinGroup</span><span class="params">(groupId: String,</span></span></span><br><span class="line"><span class="function"><span class="params">                      memberId: String,</span></span></span><br><span class="line"><span class="function"><span class="params">                      clientId: String,</span></span></span><br><span class="line"><span class="function"><span class="params">                      clientHost: String,</span></span></span><br><span class="line"><span class="function"><span class="params">                      rebalanceTimeoutMs: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                      sessionTimeoutMs: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                      protocolType: String,</span></span></span><br><span class="line"><span class="function"><span class="params">                      protocols: List[(String, Array[Byte])</span>],</span></span><br><span class="line"><span class="function">                      responseCallback: JoinCallback): Unit </span>= &#123;</span><br><span class="line">    validateGroupStatus(groupId, ApiKeys.JOIN_GROUP).foreach &#123; error =&gt;</span><br><span class="line">      responseCallback(joinError(memberId, error))</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// sessionTimeoutMs默认必须在6000-300000 即6s-5min之间</span></span><br><span class="line">    <span class="keyword">if</span> (sessionTimeoutMs &lt; groupConfig.groupMinSessionTimeoutMs ||</span><br><span class="line">      sessionTimeoutMs &gt; groupConfig.groupMaxSessionTimeoutMs) &#123;</span><br><span class="line">      responseCallback(joinError(memberId, Errors.INVALID_SESSION_TIMEOUT))</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 第一个组消费者来这 group不存在并且member id=""，那么会创建group，然后调用doJoinGroup</span></span><br><span class="line">      <span class="comment">// 之后的组消费者之间走doJoinGroup</span></span><br><span class="line">      groupManager.getGroup(groupId) match &#123;</span><br><span class="line">        <span class="keyword">case</span> None =&gt;</span><br><span class="line">          <span class="comment">// memberId已存在，group为空，只能说明是错误的请求</span></span><br><span class="line">          <span class="keyword">if</span> (memberId != JoinGroupRequest.UNKNOWN_MEMBER_ID) &#123;</span><br><span class="line">            responseCallback(joinError(memberId, Errors.UNKNOWN_MEMBER_ID))</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 如果是新的group，新建一个GroupMetadata，并且GroupState为Empty，之后添加到groupManager的groupMetadataCache</span></span><br><span class="line">            val group = groupManager.addGroup(<span class="keyword">new</span> GroupMetadata(groupId, initialState = Empty))</span><br><span class="line">            doJoinGroup(group, memberId, clientId, clientHost, rebalanceTimeoutMs, sessionTimeoutMs, protocolType, protocols, responseCallback)</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(group)</span> </span>=&gt;</span><br><span class="line">          doJoinGroup(group, memberId, clientId, clientHost, rebalanceTimeoutMs, sessionTimeoutMs, protocolType, protocols, responseCallback)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="doJoinGroup"><a href="#doJoinGroup" class="headerlink" title="doJoinGroup"></a>doJoinGroup</h2><p>核心方法都在doJoinGroup方法中，此处省略了许多校验的代码，而group的状态此时为Empty，我们直接看该条件分支即可<br>此时memberId为空，也就是JoinGroupRequest.UNKNOWN_MEMBER_ID，因此这里仅调用addMemberAndRebalance方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">doJoinGroup</span><span class="params">(group: GroupMetadata,</span></span></span><br><span class="line"><span class="function"><span class="params">                          memberId: String,</span></span></span><br><span class="line"><span class="function"><span class="params">                          clientId: String,</span></span></span><br><span class="line"><span class="function"><span class="params">                          clientHost: String,</span></span></span><br><span class="line"><span class="function"><span class="params">                          rebalanceTimeoutMs: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                          sessionTimeoutMs: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                          protocolType: String,</span></span></span><br><span class="line"><span class="function"><span class="params">                          protocols: List[(String, Array[Byte])</span>],</span></span><br><span class="line"><span class="function">                          responseCallback: JoinCallback) </span>&#123;</span><br><span class="line">    </span><br><span class="line">    group.currentState match &#123;</span><br><span class="line">      <span class="keyword">case</span> Dead =&gt;</span><br><span class="line">        responseCallback(joinError(memberId, Errors.UNKNOWN_MEMBER_ID))</span><br><span class="line">      <span class="keyword">case</span> PreparingRebalance =&gt;</span><br><span class="line">       <span class="comment">// 省略...</span></span><br><span class="line">      <span class="keyword">case</span> CompletingRebalance =&gt;</span><br><span class="line">        <span class="comment">// 省略...</span></span><br><span class="line">      <span class="keyword">case</span> Empty | Stable =&gt;</span><br><span class="line">        <span class="keyword">if</span> (memberId == JoinGroupRequest.UNKNOWN_MEMBER_ID) &#123;</span><br><span class="line">          <span class="comment">// if the member id is unknown, register the member to the group</span></span><br><span class="line">          addMemberAndRebalance(rebalanceTimeoutMs, sessionTimeoutMs, clientId, clientHost, protocolType,</span><br><span class="line">            protocols, group, responseCallback)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          val member = group.get(memberId)</span><br><span class="line">          <span class="keyword">if</span> (group.isLeader(memberId) || !member.matches(protocols)) &#123;</span><br><span class="line">            updateMemberAndRebalance(group, member, protocols, responseCallback)</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">            responseCallback(JoinGroupResult(</span><br><span class="line">              members = Map.empty,</span><br><span class="line">              memberId = memberId,</span><br><span class="line">              generationId = group.generationId,</span><br><span class="line">              subProtocol = group.protocolOrNull,</span><br><span class="line">              leaderId = group.leaderOrNull,</span><br><span class="line">              error = Errors.NONE))</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (group.is(PreparingRebalance))</span><br><span class="line">      joinPurgatory.checkAndComplete(GroupKey(group.groupId))</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="addMemberAndRebalance"><a href="#addMemberAndRebalance" class="headerlink" title="addMemberAndRebalance"></a>addMemberAndRebalance</h2><p>addMemberAndRebalance首先初始化了memberId，可以看到是clientId拼接一个UUID，然后封装成了一个MemberMetadata对象，这是组成员的元信息对象，之后添加到GroupMetadata中<br>注意这里的回调函数传给了awaitingJoinCallback变量，rebalance的处理在maybePrepareRebalance中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">addMemberAndRebalance</span><span class="params">(rebalanceTimeoutMs: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                                    sessionTimeoutMs: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                                    clientId: String,</span></span></span><br><span class="line"><span class="function"><span class="params">                                    clientHost: String,</span></span></span><br><span class="line"><span class="function"><span class="params">                                    protocolType: String,</span></span></span><br><span class="line"><span class="function"><span class="params">                                    protocols: List[(String, Array[Byte])</span>],</span></span><br><span class="line"><span class="function">                                    group: GroupMetadata,</span></span><br><span class="line"><span class="function">                                    callback: JoinCallback) </span>= &#123;</span><br><span class="line">    <span class="comment">// memberId = clientId-UUID</span></span><br><span class="line">    val memberId = clientId + <span class="string">"-"</span> + group.generateMemberIdSuffix</span><br><span class="line">    <span class="comment">// 组成员的元信息</span></span><br><span class="line">    val member = <span class="keyword">new</span> MemberMetadata(memberId, group.groupId, clientId, clientHost, rebalanceTimeoutMs,</span><br><span class="line">      sessionTimeoutMs, protocolType, protocols)</span><br><span class="line">    member.awaitingJoinCallback = callback</span><br><span class="line">    <span class="comment">// update the newMemberAdded flag to indicate that the join group can be further delayed</span></span><br><span class="line">    <span class="keyword">if</span> (group.is(PreparingRebalance) &amp;&amp; group.generationId == <span class="number">0</span>)</span><br><span class="line">      group.newMemberAdded = <span class="keyword">true</span></span><br><span class="line"></span><br><span class="line">    group.add(member)</span><br><span class="line">    maybePrepareRebalance(group)</span><br><span class="line">    member</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>add方法很简单，但要关注leaderId的赋值，它表示第一个consumer就是消费者组的leader，也就是第一个consumer为消费者组的leader member<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">add</span><span class="params">(member: MemberMetadata)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (members.isEmpty)</span><br><span class="line">  <span class="keyword">this</span>.protocolType = Some(member.protocolType)</span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span>(groupId == member.groupId)</span><br><span class="line"><span class="keyword">assert</span>(<span class="keyword">this</span>.protocolType.orNull == member.protocolType)</span><br><span class="line"><span class="keyword">assert</span>(supportsProtocols(member.protocols))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (leaderId.isEmpty)</span><br><span class="line">  leaderId = Some(member.memberId)   <span class="comment">// 来的第一个就是leader ...</span></span><br><span class="line">members.put(member.memberId, member) <span class="comment">// memberId为key MemberMetadata为value</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="maybePrepareRebalance"><a href="#maybePrepareRebalance" class="headerlink" title="maybePrepareRebalance"></a>maybePrepareRebalance</h2><p>maybePrepareRebalance仅仅是做了一个判断：当前组状态是Stable, CompletingRebalance, Empty其中之一，才可以开始rebalance，满足条件就调用prepareRebalance</p><p>prepareRebalance方法在第一个consumer入组时创建一个InitialDelayedJoin，它会等待group.initial.rebalance.delay.ms<br>这个参数也是为消费者启动时的rebalance优化，因为每启动一个consumer都相当于加入一个组成员，需要进行一次rebalance，这无疑很浪费，这里等待一段时间再开始PreparingRebalance<br>之后的消费者创建的是DelayedJoin，到期时间就是rebalanceTimeoutMs，即max.poll.interval.ms</p><p>此时group的状态由Empty转换为了PreparingRebalance</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">maybePrepareRebalance</span><span class="params">(group: GroupMetadata)</span> </span>&#123;</span><br><span class="line">    group.inLock &#123;</span><br><span class="line">      <span class="keyword">if</span> (group.canRebalance)</span><br><span class="line">        prepareRebalance(group)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">prepareRebalance</span><span class="params">(group: GroupMetadata)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// if any members are awaiting sync, cancel their request and have them rejoin</span></span><br><span class="line">    <span class="keyword">if</span> (group.is(CompletingRebalance))</span><br><span class="line">      resetAndPropagateAssignmentError(group, Errors.REBALANCE_IN_PROGRESS)</span><br><span class="line"></span><br><span class="line">    val delayedRebalance = <span class="keyword">if</span> (group.is(Empty))</span><br><span class="line">      <span class="keyword">new</span> InitialDelayedJoin(<span class="keyword">this</span>,</span><br><span class="line">        joinPurgatory,</span><br><span class="line">        group,</span><br><span class="line">        groupConfig.groupInitialRebalanceDelayMs,</span><br><span class="line">        groupConfig.groupInitialRebalanceDelayMs,</span><br><span class="line">        max(group.rebalanceTimeoutMs - groupConfig.groupInitialRebalanceDelayMs, <span class="number">0</span>))</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      <span class="keyword">new</span> DelayedJoin(<span class="keyword">this</span>, group, group.rebalanceTimeoutMs)</span><br><span class="line">    <span class="comment">// 从Empty转变为PreparingRebalance</span></span><br><span class="line">    group.transitionTo(PreparingRebalance)</span><br><span class="line"></span><br><span class="line">    val groupKey = GroupKey(group.groupId)</span><br><span class="line">    joinPurgatory.tryCompleteElseWatch(delayedRebalance, Seq(groupKey))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="延迟join"><a href="#延迟join" class="headerlink" title="延迟join"></a>延迟join</h2><p>joinPurgatory可以理解为一个延迟队列，那么直接看InitialDelayedJoin的onComplete方法，大概意思就是在group.initial.rebalance.delay.ms时间内，它会一直等待消费者入组，超时后后调用父类的onComplete，而InitialDelayedJoin的父类是DelayedJoin，它的onComplete会调用GroupCoordinator的onCompleteJoin方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">private[group] class InitialDelayedJoin(coordinator: GroupCoordinator,</span><br><span class="line">                                        purgatory: DelayedOperationPurgatory[DelayedJoin],</span><br><span class="line">                                        group: GroupMetadata,</span><br><span class="line">                                        configuredRebalanceDelay: Int,</span><br><span class="line">                                        delayMs: Int,</span><br><span class="line">                                        remainingMs: Int) <span class="function">extends <span class="title">DelayedJoin</span><span class="params">(coordinator, group, delayMs)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">override def <span class="title">tryComplete</span><span class="params">()</span>: Boolean </span>= <span class="keyword">false</span></span><br><span class="line"></span><br><span class="line">  <span class="function">override def <span class="title">onComplete</span><span class="params">()</span>: Unit </span>= &#123;</span><br><span class="line">    group.inLock  &#123;</span><br><span class="line">      <span class="comment">// 是继续等待还是直接结束DelayedJoin</span></span><br><span class="line">      <span class="keyword">if</span> (group.newMemberAdded &amp;&amp; remainingMs != <span class="number">0</span>) &#123;</span><br><span class="line">        group.newMemberAdded = <span class="keyword">false</span></span><br><span class="line">        val delay = min(configuredRebalanceDelay, remainingMs)</span><br><span class="line">        val remaining = max(remainingMs - delayMs, <span class="number">0</span>)</span><br><span class="line">        purgatory.tryCompleteElseWatch(<span class="keyword">new</span> InitialDelayedJoin(coordinator,</span><br><span class="line">          purgatory,</span><br><span class="line">          group,</span><br><span class="line">          configuredRebalanceDelay,</span><br><span class="line">          delay,</span><br><span class="line">          remaining</span><br><span class="line">        ), Seq(GroupKey(group.groupId)))</span><br><span class="line">      &#125; <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">super</span>.onComplete()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private[group] class DelayedJoin(coordinator: GroupCoordinator,</span><br><span class="line">                                 group: GroupMetadata,</span><br><span class="line">                                 rebalanceTimeout: Long) <span class="function">extends <span class="title">DelayedOperation</span><span class="params">(rebalanceTimeout, Some(group.lock)</span>) </span>&#123;</span><br><span class="line">  <span class="function">override def <span class="title">tryComplete</span><span class="params">()</span>: Boolean </span>= coordinator.tryCompleteJoin(group, forceComplete _)</span><br><span class="line">  <span class="function">override def <span class="title">onExpiration</span><span class="params">()</span> </span>= coordinator.onExpireJoin()</span><br><span class="line">  <span class="function">override def <span class="title">onComplete</span><span class="params">()</span> </span>= coordinator.onCompleteJoin(group)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="延迟任务完成处理"><a href="#延迟任务完成处理" class="headerlink" title="延迟任务完成处理"></a>延迟任务完成处理</h3><p>GroupCoordinator的onCompleteJoin方法源码如下，它的大概意思是响应每一个consumer的请求，这里主要关注JoinGroupResult的第一个参数：leader member的元信息，是leader时才返回currentMemberMetadata(所有组成员的元信息)，也就是说GroupCoordinator只告诉了leader consumer组成员的元信息，原因在下文会揭晓<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">onCompleteJoin</span><span class="params">(group: GroupMetadata)</span> </span>&#123;</span><br><span class="line">    group.inLock &#123;</span><br><span class="line">      <span class="comment">// remove any members who haven't joined the group yet</span></span><br><span class="line">      group.notYetRejoinedMembers.foreach &#123; failedMember =&gt;</span><br><span class="line">        removeHeartbeatForLeavingMember(group, failedMember)</span><br><span class="line">        group.remove(failedMember.memberId)</span><br><span class="line">        <span class="comment">// <span class="doctag">TODO:</span> cut the socket connection to the client</span></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (!group.is(Dead)) &#123;</span><br><span class="line">        group.initNextGeneration()</span><br><span class="line">        <span class="keyword">if</span> (group.is(Empty)) &#123;</span><br><span class="line">          info(s<span class="string">"Group $&#123;group.groupId&#125; with generation $&#123;group.generationId&#125; is now empty "</span> +</span><br><span class="line">            s<span class="string">"($&#123;Topic.GROUP_METADATA_TOPIC_NAME&#125;-$&#123;partitionFor(group.groupId)&#125;)"</span>)</span><br><span class="line"></span><br><span class="line">          groupManager.storeGroup(group, Map.empty, error =&gt; &#123;</span><br><span class="line">            <span class="keyword">if</span> (error != Errors.NONE) &#123;</span><br><span class="line">              warn(s<span class="string">"Failed to write empty metadata for group $&#123;group.groupId&#125;: $&#123;error.message&#125;"</span>)</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          info(s<span class="string">"Stabilized group $&#123;group.groupId&#125; generation $&#123;group.generationId&#125; "</span> +</span><br><span class="line">            s<span class="string">"($&#123;Topic.GROUP_METADATA_TOPIC_NAME&#125;-$&#123;partitionFor(group.groupId)&#125;)"</span>)</span><br><span class="line"></span><br><span class="line">          <span class="keyword">for</span> (member &lt;- group.allMemberMetadata) &#123;</span><br><span class="line">            <span class="keyword">assert</span>(member.awaitingJoinCallback != <span class="keyword">null</span>)</span><br><span class="line">            val joinResult = JoinGroupResult(</span><br><span class="line">              members = <span class="keyword">if</span> (group.isLeader(member.memberId)) &#123;</span><br><span class="line">                group.currentMemberMetadata</span><br><span class="line">              &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                Map.empty</span><br><span class="line">              &#125;,</span><br><span class="line">              memberId = member.memberId,</span><br><span class="line">              generationId = group.generationId,</span><br><span class="line">              subProtocol = group.protocolOrNull,</span><br><span class="line">              leaderId = group.leaderOrNull,</span><br><span class="line">              error = Errors.NONE)</span><br><span class="line"></span><br><span class="line">            member.awaitingJoinCallback(joinResult)</span><br><span class="line">            member.awaitingJoinCallback = <span class="keyword">null</span></span><br><span class="line">            completeAndScheduleNextHeartbeatExpiration(group, member)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这里还要关注一下initNextGeneration方法，generationId+1好理解，selectProtocol是因为每个consumer的分配策略可能不一样，selectProtocol用于投票选举一个PartitionAssignor<br>最后要关注的一点是组状态由PreparingRebalance转变为了CompletingRebalance，也就是所有消费者都进入组内了，等待GroupCoordinator分配分区</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">initNextGeneration</span><span class="params">()</span> </span>= &#123;</span><br><span class="line">    <span class="keyword">assert</span>(notYetRejoinedMembers == List.empty[MemberMetadata])</span><br><span class="line">    <span class="keyword">if</span> (members.nonEmpty) &#123;</span><br><span class="line">      generationId += <span class="number">1</span></span><br><span class="line">      protocol = Some(selectProtocol)</span><br><span class="line">      transitionTo(CompletingRebalance)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      generationId += <span class="number">1</span></span><br><span class="line">      protocol = None</span><br><span class="line">      transitionTo(Empty)</span><br><span class="line">    &#125;</span><br><span class="line">    receivedConsumerOffsetCommits = <span class="keyword">false</span></span><br><span class="line">    receivedTransactionalOffsetCommits = <span class="keyword">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="调用回调函数"><a href="#调用回调函数" class="headerlink" title="调用回调函数"></a>调用回调函数</h2><p>上面调用的awaitingJoinCallback，其实就是sendResponseCallback，最终的响应返回值JoinGroupResponse如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">sendResponseCallback</span><span class="params">(joinResult: JoinGroupResult)</span> </span>&#123;</span><br><span class="line">  val members = joinResult.members map &#123; <span class="keyword">case</span> (memberId, metadataArray) =&gt; (memberId, ByteBuffer.wrap(metadataArray)) &#125;</span><br><span class="line">  <span class="function">def <span class="title">createResponse</span><span class="params">(requestThrottleMs: Int)</span>: AbstractResponse </span>= &#123;</span><br><span class="line">    val responseBody = <span class="keyword">new</span> JoinGroupResponse(requestThrottleMs, joinResult.error, joinResult.generationId,</span><br><span class="line">      joinResult.subProtocol, joinResult.memberId, joinResult.leaderId, members.asJava)</span><br><span class="line">    responseBody</span><br><span class="line">  &#125;</span><br><span class="line">  sendResponseMaybeThrottle(request, createResponse)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="客户端Consumer处理响应"><a href="#客户端Consumer处理响应" class="headerlink" title="客户端Consumer处理响应"></a>客户端Consumer处理响应</h1><p>consumer端处理响应的原理：在最开始的sendJoinGroupRequest方法中，除了发送请求，还定义了响应的处理器，我们只关注Errors为NONE的情况，主要做了2件事</p><ol><li>初始化了generation，它可以理解为rebalance的次数，版本号</li><li>根据server返回的leader memberId判断，如果当前consumer就是leader，调用onJoinLeader，否则调用onJoinFollower</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">JoinGroupResponseHandler</span> <span class="keyword">extends</span> <span class="title">CoordinatorResponseHandler</span>&lt;<span class="title">JoinGroupResponse</span>, <span class="title">ByteBuffer</span>&gt; </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(JoinGroupResponse joinResponse, RequestFuture&lt;ByteBuffer&gt; future)</span> </span>&#123;</span><br><span class="line">        Errors error = joinResponse.error();</span><br><span class="line">        <span class="keyword">if</span> (error == Errors.NONE) &#123;</span><br><span class="line">            sensors.joinLatency.record(response.requestLatencyMs());</span><br><span class="line"></span><br><span class="line">            <span class="keyword">synchronized</span> (AbstractCoordinator.<span class="keyword">this</span>) &#123;</span><br><span class="line">                <span class="keyword">if</span> (state != MemberState.REBALANCING) &#123;</span><br><span class="line">                    <span class="comment">// if the consumer was woken up before a rebalance completes, we may have already left</span></span><br><span class="line">                    <span class="comment">// the group. In this case, we do not want to continue with the sync group.</span></span><br><span class="line">                    future.raise(<span class="keyword">new</span> UnjoinedGroupException());</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    AbstractCoordinator.<span class="keyword">this</span>.generation = <span class="keyword">new</span> Generation(joinResponse.generationId(),</span><br><span class="line">                            joinResponse.memberId(), joinResponse.groupProtocol());</span><br><span class="line">                    <span class="keyword">if</span> (joinResponse.isLeader()) &#123;</span><br><span class="line">                        onJoinLeader(joinResponse).chain(future);</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        onJoinFollower().chain(future);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == xxx) &#123;</span><br><span class="line">        <span class="comment">// 其他错误处理</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>onJoinLeader和onJoinFollower都是发送了一个SyncGroupRequest请求，唯一的区别是，onJoinLeader会计算分配方案，传给SyncGroupRequest请求，而onJoinFollower传入的是一个emptyMap</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> RequestFuture&lt;ByteBuffer&gt; <span class="title">onJoinLeader</span><span class="params">(JoinGroupResponse joinResponse)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// perform the leader synchronization and send back the assignment for the group</span></span><br><span class="line">        Map&lt;String, ByteBuffer&gt; groupAssignment = performAssignment(joinResponse.leaderId(), joinResponse.groupProtocol(),</span><br><span class="line">                joinResponse.members());</span><br><span class="line"></span><br><span class="line">        SyncGroupRequest.Builder requestBuilder =</span><br><span class="line">                <span class="keyword">new</span> SyncGroupRequest.Builder(groupId, generation.generationId, generation.memberId, groupAssignment);</span><br><span class="line">        log.debug(<span class="string">"Sending leader SyncGroup to coordinator &#123;&#125;: &#123;&#125;"</span>, <span class="keyword">this</span>.coordinator, requestBuilder);</span><br><span class="line">        <span class="keyword">return</span> sendSyncGroupRequest(requestBuilder);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (RuntimeException e) &#123;</span><br><span class="line">        <span class="keyword">return</span> RequestFuture.failure(e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> RequestFuture&lt;ByteBuffer&gt; <span class="title">onJoinFollower</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// send follower's sync group with an empty assignment</span></span><br><span class="line">    SyncGroupRequest.Builder requestBuilder =</span><br><span class="line">            <span class="keyword">new</span> SyncGroupRequest.Builder(groupId, generation.generationId, generation.memberId,</span><br><span class="line">                    Collections.&lt;String, ByteBuffer&gt;emptyMap());</span><br><span class="line">    log.debug(<span class="string">"Sending follower SyncGroup to coordinator &#123;&#125;: &#123;&#125;"</span>, <span class="keyword">this</span>.coordinator, requestBuilder);</span><br><span class="line">    <span class="keyword">return</span> sendSyncGroupRequest(requestBuilder);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="过程分析"><a href="#过程分析" class="headerlink" title="过程分析"></a>过程分析</h2><p>消费者发送JoinGroupRequest请求的主要作用是向GoupCoordinator上报的订阅信息，而GoupCoordinator处理的核心逻辑就是addMemberAndRebalance，具体是封装消费者组成员的信息为MemberMetadata，将其添加到GroupMetadata中，<br>并在此时确定第一个消费者为leader，之后的操作可以理解为将rebalance操作封装成一个DelayedJoin任务，放入延迟队列中，此时消费者组状态由Empty转变为PreparingRebalance，在延迟任务完成时，才返回给客户响应，响应的主要内容主要是leader member的元信息，消费者组的元信息。<br>客户端(consumer)接收到响应后，主要查看broker返回的leader memberId是不是就是自己，如果是，调用onJoinLeader，它会按分区分配算法计算每个消费者的分区，并再次发送一个SyncGroupRequest请求；相反，如果自己不是leader member，调用的是onJoinFollower，虽然它也发送了SyncGroupRequest请求，但是它的分配方案是空的。</p><p>那么为什么要发送一个空的SyncGroupRequest呢？ 这是因为GoupCoordinator只认可leader member的分配方案，其他consumer发送空的SyncGroupRequest只是为了让GoupCoordinator返回leader member的分配方案，即对非leader member的consumer来说，空的SyncGroupRequest不是重点，该请求的响应里包含的分区分配才是重点</p><h2 id="难点分析"><a href="#难点分析" class="headerlink" title="难点分析"></a>难点分析</h2><p>JoinGroupRequest最难理解的地方是对InitialDelayedJoin和DelayedJoin的理解，InitialDelayedJoin在早期的kafka源码并不存在，是后来考虑到项目启动时会触发多次rebalance，因此在kafka的server.properties配置文件中最后一行配置：group.initial.rebalance.delay.ms，设置一定的延迟时间是有意义的，而在改时间超时后，会触发父类DelayedJoin的onComplete，它会调用GroupCoordinator的onCompleteJoin，这里面才会返回给所有consumer JoinGroupRequest请求的响应</p><h2 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h2><p><img src="https://pic.downk.cc/item/5ea294a8c2a9a83be5578794.png" alt="join_group"></p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>kafka消费者-获取Coordinator</title>
      <link href="/2020/03/11/kafka%E6%B6%88%E8%B4%B9%E8%80%85-%E8%8E%B7%E5%8F%96Coordinator/"/>
      <url>/2020/03/11/kafka%E6%B6%88%E8%B4%B9%E8%80%85-%E8%8E%B7%E5%8F%96Coordinator/</url>
      <content type="html"><![CDATA[<blockquote><p>本文主要介绍Consumer在第一次拉取消息前，获取Coordinator的过程，衔接<a href="">Kafka消费者-源码分析</a>一文</p></blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在ConsumerCoordinator的poll方法中，我们聊到第一次poll时，consumer需要加入消费者组，此时coordinator未知，需要向broker获取<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">poll</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> timeoutMs)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 省略大部分源码.....</span></span><br><span class="line">  <span class="keyword">if</span> (coordinatorUnknown()) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (!ensureCoordinatorReady(remainingTimeAtLeastZero(timeoutMs, elapsed))) &#123;</span><br><span class="line">          <span class="comment">// 直接返回了false</span></span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>ensureCoordinatorReady方法也很简单，主要是lookupCoordinator方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">boolean</span> <span class="title">ensureCoordinatorReady</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> timeoutMs)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 循环直至coordinator可用</span></span><br><span class="line">    <span class="keyword">while</span> (coordinatorUnknown()) &#123;</span><br><span class="line">        <span class="comment">// 发送查找coordinator请求</span></span><br><span class="line">        <span class="keyword">final</span> RequestFuture&lt;Void&gt; future = lookupCoordinator();</span><br><span class="line">        <span class="comment">// 等待future返回结果</span></span><br><span class="line">        client.poll(future, remainingTimeAtLeastZero(timeoutMs, elapsedTime));</span><br><span class="line">        <span class="keyword">if</span> (!future.isDone()) &#123;</span><br><span class="line">            <span class="comment">// 时间用完了还没结束(没拿到响应)</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 失败重试或抛异常</span></span><br><span class="line">        <span class="keyword">if</span> (future.failed()) &#123;</span><br><span class="line">          <span class="comment">// ...</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> !coordinatorUnknown();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>lookupCoordinator主要是调用了sendFindCoordinatorRequest来发起FindCoordinator请求</p><h1 id="请求"><a href="#请求" class="headerlink" title="请求"></a>请求</h1><p>FindCoordinatorRequest的主要参数是groupId，参数名为coordinatorKey，以下是Consumer发送FindCoordinatorRequest请求的源码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> RequestFuture&lt;Void&gt; <span class="title">sendFindCoordinatorRequest</span><span class="params">(Node node)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// initiate the group metadata request</span></span><br><span class="line">    log.debug(<span class="string">"Sending FindCoordinator request to broker &#123;&#125;"</span>, node);</span><br><span class="line">    FindCoordinatorRequest.Builder requestBuilder =</span><br><span class="line">            <span class="keyword">new</span> FindCoordinatorRequest.Builder(FindCoordinatorRequest.CoordinatorType.GROUP, <span class="keyword">this</span>.groupId);</span><br><span class="line">    <span class="keyword">return</span> client.send(node, requestBuilder)</span><br><span class="line">                 .compose(<span class="keyword">new</span> FindCoordinatorResponseHandler());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>json请求体如下：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"coordinatorKey"</span>: <span class="string">"your group id"</span>,</span><br><span class="line">"coordinatorType": 0, // 表示group</span><br><span class="line">"minVersion": 0, // group时为0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="server端处理"><a href="#server端处理" class="headerlink" title="server端处理"></a>server端处理</h1><p>server获取Coordinator的过程大致分为以下3个步骤</p><ol><li>计算分区，groupId的hashcode%50，50是__consumer_offsets的分区个数</li><li>获取__consumer_offsets所有分区的元信息</li><li>从第2步所有分区的元数据里，过滤出用第1步计算好的分区的元数据</li></ol><p>这里没有直接用第一步计算的分区去获取，是因为调用的方法具有通用性，个人认为这里优化下也不难</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">handleFindCoordinatorRequest</span><span class="params">(request: RequestChannel.Request)</span> </span>&#123;</span><br><span class="line">    val findCoordinatorRequest = request.body[FindCoordinatorRequest]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (认证失败...) &#123;</span><br><span class="line">    <span class="comment">// 省略...</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// get metadata (and create the topic if necessary)</span></span><br><span class="line">      val (partition, topicMetadata) = findCoordinatorRequest.coordinatorType match &#123;</span><br><span class="line">        <span class="keyword">case</span> FindCoordinatorRequest.CoordinatorType.GROUP =&gt;</span><br><span class="line">          <span class="comment">// 计算分区</span></span><br><span class="line">          val partition = groupCoordinator.partitionFor(findCoordinatorRequest.coordinatorKey)</span><br><span class="line">          <span class="comment">// 这里拿到的是topic所有分区的元数据</span></span><br><span class="line">          val metadata = getOrCreateInternalTopic(GROUP_METADATA_TOPIC_NAME, request.context.listenerName)</span><br><span class="line">          (partition, metadata)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">case</span> 如果是__transaction_state =&gt;</span><br><span class="line">          <span class="comment">// 处理 ...</span></span><br><span class="line">        <span class="keyword">case</span> _ =&gt;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> InvalidRequestException(<span class="string">"Unknown coordinator type in FindCoordinator request"</span>)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="function">def <span class="title">createResponse</span><span class="params">(requestThrottleMs: Int)</span>: AbstractResponse </span>= &#123;</span><br><span class="line">        val responseBody = <span class="keyword">if</span> (topicMetadata.error != Errors.NONE) &#123;</span><br><span class="line">          <span class="keyword">new</span> FindCoordinatorResponse(requestThrottleMs, Errors.COORDINATOR_NOT_AVAILABLE, Node.noNode)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// 获取消费者坐在分区的leader所在的node</span></span><br><span class="line">          val coordinatorEndpoint = topicMetadata.partitionMetadata.asScala</span><br><span class="line">            .find(_.partition == partition)</span><br><span class="line">            .map(_.leader)</span><br><span class="line">            .flatMap(p =&gt; Option(p))</span><br><span class="line"></span><br><span class="line">          <span class="comment">// 有则返回，没有报错</span></span><br><span class="line">          coordinatorEndpoint match &#123;</span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(endpoint)</span> <span class="keyword">if</span> !endpoint.isEmpty </span>=&gt;</span><br><span class="line">              <span class="keyword">new</span> FindCoordinatorResponse(requestThrottleMs, Errors.NONE, endpoint)</span><br><span class="line">            <span class="keyword">case</span> _ =&gt;</span><br><span class="line">              <span class="keyword">new</span> FindCoordinatorResponse(requestThrottleMs, Errors.COORDINATOR_NOT_AVAILABLE, Node.noNode)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        responseBody</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 响应</span></span><br><span class="line">      sendResponseMaybeThrottle(request, createResponse)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里返回给客户端的FindCoordinatorResponse对象，大致结构如下，主要是错误信息和Coordinator所在的节点信息<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">"error": &#123;...&#125;,</span><br><span class="line">"node": &#123;</span><br><span class="line">"id": 0,</span><br><span class="line">"host": "127.0.0.1",</span><br><span class="line">"port": "9092",</span><br><span class="line">"rack": "-1"</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="获取topic分区元数据"><a href="#获取topic分区元数据" class="headerlink" title="获取topic分区元数据"></a>获取topic分区元数据</h2><p>经过getOrCreateInternalTopic方法调用，getPartitionMetadata用于获取topic所有分区的元数据，即上面的第2步</p><p>该方法大部分都是对maybeLeader异常的判断，直接看最后一行代码即可</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">getOrCreateInternalTopic</span><span class="params">(topic: String, listenerName: ListenerName)</span>: MetadataResponse.TopicMetadata </span>= &#123;</span><br><span class="line">    val topicMetadata = metadataCache.getTopicMetadata(Set(topic), listenerName)</span><br><span class="line">    <span class="comment">// 取集合第一个，因为getTopicMetadata是批量的，Set(topic)</span></span><br><span class="line">    topicMetadata.headOption.getOrElse(createInternalTopic(topic))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">def <span class="title">getTopicMetadata</span><span class="params">(topics: Set[String], listenerName: ListenerName, errorUnavailableEndpoints: Boolean = <span class="keyword">false</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                       errorUnavailableListeners: Boolean = <span class="keyword">false</span>)</span>: Seq[MetadataResponse.TopicMetadata] </span>= &#123;</span><br><span class="line">    topics.toSeq.flatMap &#123; topic =&gt;</span><br><span class="line">        getPartitionMetadata(topic, listenerName, errorUnavailableEndpoints, errorUnavailableListeners).map &#123; partitionMetadata =&gt;</span><br><span class="line">          <span class="keyword">new</span> MetadataResponse.TopicMetadata(Errors.NONE, topic, Topic.isInternal(topic), partitionMetadata.toBuffer.asJava)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">getPartitionMetadata</span><span class="params">(topic: String, listenerName: ListenerName, errorUnavailableEndpoints: Boolean,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   errorUnavailableListeners: Boolean)</span>: Option[Iterable[MetadataResponse.PartitionMetadata]] </span>= &#123;</span><br><span class="line">    cache.get(topic).map &#123; partitions =&gt;</span><br><span class="line">      partitions.map &#123; <span class="keyword">case</span> (partitionId, partitionState) =&gt;</span><br><span class="line">        val topicPartition = TopicAndPartition(topic, partitionId)</span><br><span class="line">        val leaderBrokerId = partitionState.basePartitionState.leader</span><br><span class="line">        val maybeLeader = getAliveEndpoint(leaderBrokerId, listenerName) <span class="comment">// 可能为空</span></span><br><span class="line">        val replicas = partitionState.basePartitionState.replicas.asScala.map(_.toInt)</span><br><span class="line">        val replicaInfo = getEndpoints(replicas, listenerName, errorUnavailableEndpoints) <span class="comment">// 副本所在的Node</span></span><br><span class="line">        <span class="comment">// 离线副本的Node信息</span></span><br><span class="line">        val offlineReplicaInfo = getEndpoints(partitionState.offlineReplicas.asScala.map(_.toInt), listenerName, errorUnavailableEndpoints)</span><br><span class="line"></span><br><span class="line">        maybeLeader match &#123;</span><br><span class="line">          <span class="keyword">case</span> None =&gt;</span><br><span class="line">            val error = <span class="keyword">if</span> (!aliveBrokers.contains(brokerId)) &#123; <span class="comment">// we are already holding the read lock</span></span><br><span class="line">              debug(s<span class="string">"Error while fetching metadata for $topicPartition: leader not available"</span>)</span><br><span class="line">              Errors.LEADER_NOT_AVAILABLE</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">              debug(s<span class="string">"Error while fetching metadata for $topicPartition: listener $listenerName not found on leader $leaderBrokerId"</span>)</span><br><span class="line">              <span class="keyword">if</span> (errorUnavailableListeners) Errors.LISTENER_NOT_FOUND <span class="keyword">else</span> Errors.LEADER_NOT_AVAILABLE</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">new</span> MetadataResponse.PartitionMetadata(error, partitionId, Node.noNode(),</span><br><span class="line">              replicaInfo.asJava, java.util.Collections.emptyList(), offlineReplicaInfo.asJava)</span><br><span class="line"></span><br><span class="line">          <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(leader)</span> </span>=&gt;</span><br><span class="line">            val isr = partitionState.basePartitionState.isr.asScala.map(_.toInt)</span><br><span class="line">            val isrInfo = getEndpoints(isr, listenerName, errorUnavailableEndpoints) <span class="comment">// isr的Node信息</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 副本信息不全</span></span><br><span class="line">            <span class="keyword">if</span> (replicaInfo.size &lt; replicas.size) &#123;</span><br><span class="line">              debug(s<span class="string">"Error while fetching metadata for $topicPartition: replica information not available for "</span> +</span><br><span class="line">                s<span class="string">"following brokers $&#123;replicas.filterNot(replicaInfo.map(_.id).contains).mkString("</span>,<span class="string">")&#125;"</span>)</span><br><span class="line"></span><br><span class="line">              <span class="keyword">new</span> MetadataResponse.PartitionMetadata(Errors.REPLICA_NOT_AVAILABLE, partitionId, leader,</span><br><span class="line">                replicaInfo.asJava, isrInfo.asJava, offlineReplicaInfo.asJava)</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (isrInfo.size &lt; isr.size) &#123;</span><br><span class="line">              <span class="comment">// isr 信息不全</span></span><br><span class="line">              debug(s<span class="string">"Error while fetching metadata for $topicPartition: in sync replica information not available for "</span> +</span><br><span class="line">                s<span class="string">"following brokers $&#123;isr.filterNot(isrInfo.map(_.id).contains).mkString("</span>,<span class="string">")&#125;"</span>)</span><br><span class="line">              <span class="keyword">new</span> MetadataResponse.PartitionMetadata(Errors.REPLICA_NOT_AVAILABLE, partitionId, leader,</span><br><span class="line">                replicaInfo.asJava, isrInfo.asJava, offlineReplicaInfo.asJava)</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">              <span class="comment">// 分区的leader，isr，replica，offline replica信息</span></span><br><span class="line">              <span class="keyword">new</span> MetadataResponse.PartitionMetadata(Errors.NONE, partitionId, leader, replicaInfo.asJava,</span><br><span class="line">                isrInfo.asJava, offlineReplicaInfo.asJava)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>FindCoordinatorRequest请求是consumer在拉取消息时的前置步骤，用于确保coordinator的存在，broker具体的做法是根据consumer的groupId确定其所在的__consumer_offsets分区，之后再获取该分区的元数据，主要的元信息为分区leader，replica，isr集合，离线副本集合</p><p>下面是在客户端角度，coordinator初始化的流程，大致归纳为：以groupId为参数，向一个负载最小(未完成请求最少)的节点发送请求，成功之后初始化coordinator<br><img src="https://ae01.alicdn.com/kf/Hcc2697b072b84bd7a8f5a749e43613c5n.png" alt="初始化流程"></p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka消费者-源码分析(上)</title>
      <link href="/2020/03/10/Kafka%E6%B6%88%E8%B4%B9%E8%80%85-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(%E4%B8%8A)/"/>
      <url>/2020/03/10/Kafka%E6%B6%88%E8%B4%B9%E8%80%85-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(%E4%B8%8A)/</url>
      <content type="html"><![CDATA[<blockquote><p>本文从消费者拉取消息开始分析消费流程，但kafka并不是单纯的在poll方法中拉取消息，鉴于消费者组的存在，以及Rebalance动作，使整个消费流程的复杂度直线上升，因此需要比生产者花费更多的章节去讲解</p></blockquote><h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p>为了方便大家阅读源码，这里先对源码中经常出现的部分做一个解释，提示大家的阅读效率</p><h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><p>elapsedTime：已用时间，在一个带有超时时间的方法中，该变量用于记录部分已完成操作的已用时间，比如超时时间60s，其中访问数据库操作用了10s，那么elapsedTime就是10s</p><h2 id="发送请求的一般模式"><a href="#发送请求的一般模式" class="headerlink" title="发送请求的一般模式"></a>发送请求的一般模式</h2><p>consumer向broker发送请求的一般模式是：</p><ol><li>sendXxxRequest表示发生一个请求，通常返回一个RequestFuture</li><li>RequestFuture有几个方法，isDone表示请求结束，即获取到了broker端的响应，相反的表示无响应；succeeded表示请求成功，failed表示失败；可以对future注册一个Listener，执行成功和失败的回调</li><li>Listen通常是一个xxxResponseHandler，常见的代码如下：<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">RequestFuture future = client.send(coordinator, requestBuilder, joinGroupTimeoutMs)</span><br><span class="line">    .compose(<span class="keyword">new</span> xxxResponseHandler());</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (future.succeeded()) &#123;</span><br><span class="line">  <span class="comment">// 成功</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 失败</span></span><br><span class="line">    <span class="keyword">if</span> (是可重试异常)</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (!future.isRetriable()) </span><br><span class="line">        <span class="keyword">throw</span> exception;</span><br><span class="line">    <span class="comment">// 重试的back off</span></span><br><span class="line">    time.sleep(retryBackoffMs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="consumer订阅"><a href="#consumer订阅" class="headerlink" title="consumer订阅"></a>consumer订阅</h2><p>consumer订阅topic有3中方式：指定topic集合，指定topic正则，手动指定分区。前2中称之为AutoAssigned，因为是coordinator自动分配给消费者的，这三种方式分别对应下面3个api<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">subscribe</span><span class="params">(Collection&lt;String&gt; topics)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">subscribe</span><span class="params">(Pattern pattern)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">assign</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span></span></span><br></pre></td></tr></table></figure></p><p>本文只讨论第一种，这也是我们开发中最常用的订阅方式</p><h1 id="poll方法"><a href="#poll方法" class="headerlink" title="poll方法"></a>poll方法</h1><p>首先说下2个参数：timeoutMs和includeMetadataInTimeout</p><ol><li>timeoutMs：整个poll调用的超时时间，第一次poll里面向broker发送了4个请求，该参数建议设置大于3s，</li><li>includeMetadataInTimeout：针对上面的超时时间，是否应该包含获取元数据的时间(向broker请求)</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ConsumerRecords&lt;K, V&gt; <span class="title">poll</span><span class="params">(<span class="keyword">final</span> Duration timeout)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> poll(timeout.toMillis(), <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> ConsumerRecords&lt;K, V&gt; <span class="title">poll</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> timeoutMs, <span class="keyword">final</span> <span class="keyword">boolean</span> includeMetadataInTimeout)</span> </span>&#123;</span><br><span class="line">    acquireAndEnsureOpen();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (timeoutMs &lt; <span class="number">0</span>) <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Timeout must not be negative"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.subscriptions.hasNoSubscriptionOrUserAssignment()) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Consumer is not subscribed to any topics or assigned any partitions"</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// poll for new data until the timeout expires</span></span><br><span class="line">        <span class="comment">// 记录消耗的时间，防止超时</span></span><br><span class="line">        <span class="keyword">long</span> elapsedTime = <span class="number">0L</span>;</span><br><span class="line">        <span class="keyword">do</span> &#123;</span><br><span class="line"></span><br><span class="line">            client.maybeTriggerWakeup();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">long</span> metadataEnd;</span><br><span class="line">            <span class="comment">// 新版本的poll是true，就是说是否要把更新Metadata的时间，也算在poll的超时时间内</span></span><br><span class="line">            <span class="keyword">if</span> (includeMetadataInTimeout) &#123;</span><br><span class="line">                <span class="keyword">final</span> <span class="keyword">long</span> metadataStart = time.milliseconds(); <span class="comment">// SystemTime</span></span><br><span class="line">                <span class="comment">/**</span></span><br><span class="line"><span class="comment">                 * 初始化Coordinator，初次rebalance，初始化每个分区的last consumed position</span></span><br><span class="line"><span class="comment">                 * 什么情况下返回false：</span></span><br><span class="line"><span class="comment">                 * 1. coordinator unknown</span></span><br><span class="line"><span class="comment">                 * 2. rebalance失败(长时间拿不到响应结果，发生不可重试的异常)</span></span><br><span class="line"><span class="comment">                 * 3. 获取不到分区的last consumed position (fetch offset)</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line">                <span class="keyword">if</span> (!updateAssignmentMetadataIfNeeded(remainingTimeAtLeastZero(timeoutMs, elapsedTime))) &#123;</span><br><span class="line">                    <span class="comment">// coordinator不可用或者...</span></span><br><span class="line">                    <span class="keyword">return</span> ConsumerRecords.empty();</span><br><span class="line">                &#125;</span><br><span class="line">                metadataEnd = time.milliseconds();</span><br><span class="line">                elapsedTime += metadataEnd - metadataStart; <span class="comment">// += (metadataEnd - metadataStart)</span></span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 老版本的超时时间？</span></span><br><span class="line">                <span class="keyword">while</span> (!updateAssignmentMetadataIfNeeded(Long.MAX_VALUE)) &#123;</span><br><span class="line">                    log.warn(<span class="string">"Still waiting for metadata"</span>);</span><br><span class="line">                &#125;</span><br><span class="line">                metadataEnd = time.milliseconds();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">final</span> Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records = pollForFetches(remainingTimeAtLeastZero(timeoutMs, elapsedTime));</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (!records.isEmpty()) &#123;</span><br><span class="line">                <span class="comment">/**</span></span><br><span class="line"><span class="comment">                 * 立即开始下一轮请求，和用户处理消息并行</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line">                <span class="keyword">if</span> (fetcher.sendFetches() &gt; <span class="number">0</span> || client.hasPendingRequests()) &#123;</span><br><span class="line">                    client.pollNoWakeup();</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 拦截器处理后的消息才交给用户</span></span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">this</span>.interceptors.onConsume(<span class="keyword">new</span> ConsumerRecords&lt;&gt;(records));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// records为空</span></span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">long</span> fetchEnd = time.milliseconds();</span><br><span class="line">            <span class="comment">// 总的消耗时间 fetchEnd - metadataEnd是真正用来发fetch请求的所消耗的时间</span></span><br><span class="line">            elapsedTime += fetchEnd - metadataEnd;</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">while</span> (elapsedTime &lt; timeoutMs);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> ConsumerRecords.empty();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        release();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不用关注太多poll方法细节，仅关注超时时间内的循环，简单理解为3步：第一步为updateAssignmentMetadataIfNeeded，然后是pollForFetches，最后将拦截器处理后的消息返回给用户，大致的流程如下：</p><p><img src="https://pic.downk.cc/item/5ea58054c2a9a83be509e638.png" alt="poll方法"></p><h2 id="updateAssignmentMetadataIfNeeded"><a href="#updateAssignmentMetadataIfNeeded" class="headerlink" title="updateAssignmentMetadataIfNeeded"></a>updateAssignmentMetadataIfNeeded</h2><p>updateAssignmentMetadataIfNeeded方法十分复杂，逻辑也很长，我这里直接说它的逻辑，让读者心里有个底。该方法主要做了3件事：</p><ol><li>初始化Coordinator，主要是节点信息(id,ip,port)</li><li>初次rebalance，consumer启动时进入消费者组</li><li>初始化每个分区的last consumed position，表示该消费者组上次消费到哪个位移了，Coordinator会缓存每个group最后消费的位移</li><li>如果第3步获取不到，则根据auto.offset.reset获取</li></ol><p>其次它的返回值是一个boolean，它在以下情况返回false：</p><ol><li>coordinator unknown</li><li>rebalance失败(长时间拿不到响应结果，发生不可重试的异常)</li><li>获取不到分区的last consumed position (fetch offset)</li></ol><p>这里再科普一些知识点，Coordinator，即消费者组协调器，每一个broker启动时都初始化了一个GroupCoordinator对象，它负责消费者组的生命周期管理，以及消费者组，消费者组成员的元数据管理<br>而每个分区的last consumed position是指消费者每次poll，准确的说应该是发起fetch请求向broker拉取数据的时候，都要传递一个fetchOffset参数，表示从哪里开始拉消息<br>但也有一些特殊情况，比如消费者组过期被删除了，新消费者组第一次拉取时，此时coordinator没有该消费者组的信息，没法返回该消费者组上次消费的分区位移，那么auto.offset.reset就起作用了，coordinator会根据该配置返回相应的offset</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">updateAssignmentMetadataIfNeeded</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> timeoutMs)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">long</span> startMs = time.milliseconds();</span><br><span class="line">    <span class="comment">// 返回false表示获取coordinator位置，初始化rebalance失败 (正则订阅暂不考虑)</span></span><br><span class="line">    <span class="keyword">if</span> (!coordinator.poll(timeoutMs)) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 返回true,更新要fetch的Position</span></span><br><span class="line">    <span class="keyword">return</span> updateFetchPositions(remainingTimeAtLeastZero(timeoutMs, time.milliseconds() - startMs));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>updateAssignmentMetadataIfNeeded分为2部分：coordinator.poll和updateFetchPositions，前者是rebalance的核心步骤，需要重点关注</p><h2 id="coordinator-poll"><a href="#coordinator-poll" class="headerlink" title="coordinator#poll"></a>coordinator#poll</h2><p>该方法位于ConsumerCoordinator类中，虽然源码看上去也不少(已删除部分)，但在消费者组已稳定(stable)的情况下，执行到下面这行代码就会返回了：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pollHeartbeat(currentTime)</span><br></pre></td></tr></table></figure></p><p>pollHeartbeat会尝试查看是否到了心跳时间，来发起心跳，同时还记录了一个lastPoll变量，它与maxPollIntervalMs参数息息相关，如果两次poll的间隔超出了maxPollIntervalMs，心跳线程会主动发起LeaveGroup请求，让consumer主动离开消费者组，触发一次rebalance，这也是大部分人看到的rebalance异常，因为业务逻辑处理的太慢，导致rebalance的原因</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">poll</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> timeoutMs)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">long</span> startTime = time.milliseconds();</span><br><span class="line">    <span class="keyword">long</span> currentTime = startTime;</span><br><span class="line">    <span class="keyword">long</span> elapsed = <span class="number">0L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 先执行队列里所有的OffsetCommitCompletion</span></span><br><span class="line">    invokeCompletedOffsetCommitCallbacks();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 是否手动制定了TP,不用看else</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (subscriptions.partitionsAutoAssigned()) &#123;</span><br><span class="line">        <span class="comment">// Always update the heartbeat last poll time so that the heartbeat thread does not leave the</span></span><br><span class="line">        <span class="comment">// group proactively due to application inactivity even if (say) the coordinator cannot be found.</span></span><br><span class="line">        <span class="comment">// 查看距离下一次心跳时间是否为0，唤醒心跳线程，发送心跳</span></span><br><span class="line">        <span class="comment">// 同时记录lastPoll，根据maxPollIntervalMs判断是否需要发起LeaveGroup请求(主动rebalance)</span></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 如果不看下面coordinatorUnknown和rejoinNeededOrPending，正常步骤到这里就结束了</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        pollHeartbeat(currentTime);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// coordinator节点为null，或不可用</span></span><br><span class="line">        <span class="comment">// 第一次poll时为null</span></span><br><span class="line">        <span class="keyword">if</span> (coordinatorUnknown()) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (!ensureCoordinatorReady(remainingTimeAtLeastZero(timeoutMs, elapsed))) &#123;</span><br><span class="line">                <span class="comment">// 直接返回了false</span></span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            currentTime = time.milliseconds();</span><br><span class="line">            <span class="comment">// elapsed 就是已用时间</span></span><br><span class="line">            elapsed = currentTime - startTime;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (rejoinNeededOrPending()) &#123;</span><br><span class="line">            <span class="comment">// due to a race condition between the initial metadata fetch and the initial rebalance,</span></span><br><span class="line">            <span class="comment">// we need to ensure that the metadata is fresh before joining initially. This ensures</span></span><br><span class="line">            <span class="comment">// that we have matched the pattern against the cluster's topics at least once before joining.</span></span><br><span class="line">            <span class="keyword">if</span> (subscriptions.hasPatternSubscription()) &#123; </span><br><span class="line">               <span class="comment">// 一般不用正则订阅，省略代码...</span></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 直接看这，里面通过JoinGroup和SyncGroup进行rebalance，来保证达到STABLE状态</span></span><br><span class="line">            <span class="keyword">if</span> (!ensureActiveGroup(remainingTimeAtLeastZero(timeoutMs, elapsed))) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            currentTime = time.milliseconds();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// ... standalone方式 省略</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// autoCommit时尝试提交</span></span><br><span class="line">    maybeAutoCommitOffsetsAsync(currentTime);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面说的是消费者组已稳定的情况，那么在消费者启动时，相当于消费者组中新加入了一个成员，必然会触发一次rebalance，我称之为初始rebalance，此时consumer并不知道coordinator是哪台broker(coordinatorUnknown)，就会发起一次FindCoordinator请求，来初始化AbstractCoordinator.coordinator，此处的源码分析在<a href="">kafka消费者-获取Coordinator</a>一文</p><p>在获取到Coordinator之后，进入下一个if，rejoinNeededOrPending方法初始化为true，接下里的ensureActiveGroup就是初始rebalance的核心步骤</p><h2 id="开始rebalance"><a href="#开始rebalance" class="headerlink" title="开始rebalance"></a>开始rebalance</h2><p>ensureActiveGroup源码如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">ensureActiveGroup</span><span class="params">(<span class="keyword">long</span> timeoutMs, <span class="keyword">long</span> startMs)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 前面已经获取到了Coordinator，这里确认一下</span></span><br><span class="line">    <span class="keyword">if</span> (!ensureCoordinatorReady(timeoutMs)) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    startHeartbeatThreadIfNeeded(); <span class="comment">// 启动心跳线程</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// join开始时间，和剩余的超时时间</span></span><br><span class="line">    <span class="keyword">long</span> joinStartMs = time.milliseconds();</span><br><span class="line">    <span class="keyword">long</span> joinTimeoutMs = remainingTimeAtLeastZero(timeoutMs, joinStartMs - startMs);</span><br><span class="line">    <span class="keyword">return</span> joinGroupIfNeeded(joinTimeoutMs, joinStartMs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>ensureActiveGroup会启动心跳线程，但并不会开始心跳，因为enabled参数默认为false,并利用线程的等待唤醒机制，让心跳线程在wait处等待<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (!enabled) &#123;</span><br><span class="line">    AbstractCoordinator.<span class="keyword">this</span>.wait();</span><br><span class="line">    <span class="keyword">continue</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>rebalance核心逻辑都在joinGroupIfNeeded方法中</p><h3 id="joinGroupIfNeeded"><a href="#joinGroupIfNeeded" class="headerlink" title="joinGroupIfNeeded"></a>joinGroupIfNeeded</h3><p>这里我们关注下onJoinPrepare，它会回调ConsumerRebalanceListener的onPartitionsRevoked方法，而之后就是典型的<a href="#发送请求的一般模式">客户端发送请求模式</a>，只需要关注initiateJoinGroup方法即可</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">joinGroupIfNeeded</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> timeoutMs, <span class="keyword">final</span> <span class="keyword">long</span> startTimeMs)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> elapsedTime = <span class="number">0L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (rejoinNeededOrPending()) &#123; <span class="comment">// 第一次为true</span></span><br><span class="line">        <span class="keyword">if</span> (!ensureCoordinatorReady(remainingTimeAtLeastZero(timeoutMs, elapsedTime))) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        elapsedTime = time.milliseconds() - startTimeMs;</span><br><span class="line">        <span class="keyword">if</span> (needsJoinPrepare) &#123; <span class="comment">// 第一次为true，generation=Generation.NO_GENERATION</span></span><br><span class="line">            <span class="comment">// 主要是触发ConsumerRebalanceListener，如果自动提交为true，尝试提交</span></span><br><span class="line">            onJoinPrepare(generation.generationId, generation.memberId);</span><br><span class="line">            needsJoinPrepare = <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 第一次加入组 future是JoinGroup请求返回的分配方案</span></span><br><span class="line">        <span class="comment">// initiateJoinGroup里面会把rejoinNeeded置为false，如果本次rebalance成功了，就会推出当前的while循环</span></span><br><span class="line">        <span class="keyword">final</span> RequestFuture&lt;ByteBuffer&gt; future = initiateJoinGroup();</span><br><span class="line">        client.poll(future, remainingTimeAtLeastZero(timeoutMs, elapsedTime));</span><br><span class="line">        <span class="comment">// 无论请求成功还是失败，都还没拿到，说明超时了啊</span></span><br><span class="line">        <span class="keyword">if</span> (!future.isDone()) &#123;</span><br><span class="line">            <span class="comment">// we ran out of time</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 请求成功</span></span><br><span class="line">        <span class="keyword">if</span> (future.succeeded()) &#123;</span><br><span class="line">            <span class="comment">// Duplicate the buffer in case `onJoinComplete` does not complete and needs to be retried.</span></span><br><span class="line">            ByteBuffer memberAssignment = future.value().duplicate();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 初始化分区消费(拉取)状态，更新缓存数据</span></span><br><span class="line">            <span class="comment">// 执行回调 PartitionAssignor#onAssignment, ConsumerRebalanceListener#onPartitionsAssigned</span></span><br><span class="line">            onJoinComplete(generation.generationId, generation.memberId, generation.protocol, memberAssignment);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// We reset the join group future only after the completion callback returns. This ensures</span></span><br><span class="line">            <span class="comment">// that if the callback is woken up, we will retry it on the next joinGroupIfNeeded.</span></span><br><span class="line">            resetJoinGroupFuture(); <span class="comment">// joinFuture重置为null</span></span><br><span class="line">            needsJoinPrepare = <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            resetJoinGroupFuture();</span><br><span class="line">            <span class="keyword">final</span> RuntimeException exception = future.exception();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 这三种异常会再次尝试rebalance</span></span><br><span class="line">            <span class="keyword">if</span> (exception <span class="keyword">instanceof</span> UnknownMemberIdException ||</span><br><span class="line">                    exception <span class="keyword">instanceof</span> RebalanceInProgressException ||</span><br><span class="line">                    exception <span class="keyword">instanceof</span> IllegalGenerationException)</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (!future.isRetriable()) <span class="comment">// 其他的抛异常</span></span><br><span class="line">                <span class="keyword">throw</span> exception;</span><br><span class="line">            <span class="comment">// 重试的back off</span></span><br><span class="line">            time.sleep(retryBackoffMs);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 计算已用时间, 正常情况下进不到if，elapsedTime也只是为了计算多次失败的耗时</span></span><br><span class="line">        <span class="keyword">if</span> (rejoinNeededOrPending()) &#123;</span><br><span class="line">            elapsedTime = time.milliseconds() - startTimeMs;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 不需要rebalance，直接返回true</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="initiateJoinGroup"><a href="#initiateJoinGroup" class="headerlink" title="initiateJoinGroup"></a>initiateJoinGroup</h3><p>initiateJoinGroup中的sendJoinGroupRequest同样是<a href="#发送请求的一般模式">客户端发送请求模式</a>的一种，可以看到在rebalance成功后，做了以下3件事</p><ol><li>MemberState置为stable</li><li>rejoinNeeded置为false，它是退出外层循环的标志位</li><li>启动心跳线程</li></ol><p>而JoinGroupRequest的详细细节，请参考我的另外2篇文章<a href="">kafka-rebalance之JoinGroup</a>和<a href="">kafka-rebalance之SyncGroup</a>，里面完整的讲述了rebalance细节<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> RequestFuture&lt;ByteBuffer&gt; <span class="title">initiateJoinGroup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (joinFuture == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 先暂停了心跳线程，其实本来就还没启动</span></span><br><span class="line">        disableHeartbeatThread();</span><br><span class="line"></span><br><span class="line">        state = MemberState.REBALANCING;</span><br><span class="line">        joinFuture = sendJoinGroupRequest();</span><br><span class="line">        joinFuture.addListener(<span class="keyword">new</span> RequestFutureListener&lt;ByteBuffer&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSuccess</span><span class="params">(ByteBuffer value)</span> </span>&#123;</span><br><span class="line">                <span class="comment">// handle join completion in the callback so that the callback will be invoked</span></span><br><span class="line">                <span class="comment">// even if the consumer is woken up before finishing the rebalance</span></span><br><span class="line">                <span class="keyword">synchronized</span> (AbstractCoordinator.<span class="keyword">this</span>) &#123;</span><br><span class="line">                    log.info(<span class="string">"Successfully joined group with generation &#123;&#125;"</span>, generation.generationId);</span><br><span class="line">                    <span class="comment">// 跟新2个很重要的</span></span><br><span class="line">                    state = MemberState.STABLE; <span class="comment">// 消费者Stable</span></span><br><span class="line">                    rejoinNeeded = <span class="keyword">false</span>; <span class="comment">// 退出外层循环的标志位</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">// 前面停止的心跳线程也重新启动了</span></span><br><span class="line">                    <span class="keyword">if</span> (heartbeatThread != <span class="keyword">null</span>)</span><br><span class="line">                        heartbeatThread.enable();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(RuntimeException e)</span> </span>&#123;</span><br><span class="line">                <span class="comment">// we handle failures below after the request finishes. if the join completes</span></span><br><span class="line">                <span class="comment">// after having been woken up, the exception is ignored and we will rejoin</span></span><br><span class="line">                <span class="keyword">synchronized</span> (AbstractCoordinator.<span class="keyword">this</span>) &#123;</span><br><span class="line">                    state = MemberState.UNJOINED;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> joinFuture;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>该方法结束后，方法会层层返回到updateAssignmentMetadataIfNeeded，此时coordinator.poll已结束，接下来是updateFetchPositions方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">updateAssignmentMetadataIfNeeded</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> timeoutMs)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">long</span> startMs = time.milliseconds();</span><br><span class="line">    <span class="comment">// 返回false表示获取coordinator位置，初始化rebalance失败 (正则订阅暂不考虑)</span></span><br><span class="line">    <span class="keyword">if</span> (!coordinator.poll(timeoutMs)) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 返回true,更新要fetch的Position</span></span><br><span class="line">    <span class="keyword">return</span> updateFetchPositions(remainingTimeAtLeastZero(timeoutMs, time.milliseconds() - startMs));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h2><p>TopicPartitionState表示consumer在消费过程中的状态，它会在每一个拉取后更新，里面的参数都比较简单，不再细说<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">TopicPartitionState &#123;</span><br><span class="line">        <span class="keyword">private</span> Long position; <span class="comment">// last consumed position</span></span><br><span class="line">        <span class="keyword">private</span> Long highWatermark; <span class="comment">// the high watermark from last fetch</span></span><br><span class="line">        <span class="keyword">private</span> Long logStartOffset; <span class="comment">// the log start offset</span></span><br><span class="line">        <span class="keyword">private</span> Long lastStableOffset;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">boolean</span> paused;  <span class="comment">// whether this partition has been paused by the user</span></span><br><span class="line">        <span class="keyword">private</span> OffsetResetStrategy resetStrategy;  <span class="comment">// the strategy to use if the offset needs resetting</span></span><br><span class="line">        <span class="keyword">private</span> Long nextAllowedRetryTimeMs;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="updateFetchPositions"><a href="#updateFetchPositions" class="headerlink" title="updateFetchPositions"></a>updateFetchPositions</h2><p>这里首先判断了所有订阅的分区是否有last consumed position，它用于下一次消息拉取，consumer要从什么位置开始拉，初始化时为null，那么就会向coordinator发起OFFSET_FETCH请求，用于初始化TopicPartitionState的position，<br>但还有coordinator没有消费者组上次消费位置元数据的情况，比如消费者组过期，被管理员删除，第一次建立时，那么该如何初始化position呢？ </p><p>答案是auto.offset.reset，根据重置offset策略，向分区leader所在的broker，注意不是coordinator，发送LIST_OFFSETS请求来初始化position，该请求的详细处理过程请参考<a href="">Kafka消费者-ListOffsets请求</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">updateFetchPositions</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> timeoutMs)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 是否所有订阅的TP都有记录的消费位移等状态，第一次poll肯定都是是null</span></span><br><span class="line">    <span class="comment">// 具体线索：ConsumerCoordinator#onJoinComplete-&gt;assignFromSubscribed-&gt;partitionToStateMap-&gt;new TopicPartitionState()</span></span><br><span class="line">    cachedSubscriptionHashAllFetchPositions = subscriptions.hasAllFetchPositions();</span><br><span class="line">    <span class="keyword">if</span> (cachedSubscriptionHashAllFetchPositions) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 向coordinator OFFSET_FETCH请求，初始化fetch offset</span></span><br><span class="line">    <span class="comment">// 这里指的是Coordinator会保存上一次提交的位移，而consumer拿到之后会作为fetch请求的fetch offset参数</span></span><br><span class="line">    <span class="keyword">if</span> (!coordinator.refreshCommittedOffsetsIfNeeded(timeoutMs)) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 有offset Rest策略的，根据reset策略重置position，比如earliest或者latest</span></span><br><span class="line">    subscriptions.resetMissingPositions();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 为没有position(last consumed)的分区发送LIST_OFFSETS请求</span></span><br><span class="line">    <span class="comment">// 这主要是group不存在的情况，消费者组过期，被删除，第一次建立</span></span><br><span class="line">    fetcher.resetOffsetsIfNeeded();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="上半部分总结"><a href="#上半部分总结" class="headerlink" title="上半部分总结"></a>上半部分总结</h1><p>本文主要从大家平时见到的poll方法开始分析，并在一开始就普及了源码中的难点，poll方法从流程图上看十分简单，主要分为：updateAssignmentMetadataIfNeeded，pollForFetches，返回消息给用户这三步，本文主要分析第一步就已花费了很多篇幅，由于内容过长，将一些核心逻辑放在单独的文章中分析:<a href="">获取Coordinator</a>， <a href="">rebalance之JoinGroup</a>， <a href="">rebalance之SyncGroup</a>， <a href="">ListOffsets请求</a>。</p><p>这些请求都是在consumer第一次拉取消息之前的准备工作，首先consumer要知道Coordinator的信息，并保证与之连接通畅。之后便开始了初次入组的rebalance，其中又可细分为入组，等待其他组员(非必需)，选举leader consumer，然后leader consumer根据分区策略制定分配方案，所有组员再次发送SyncGroup请求，由Coordinator来返回leader consumer制定的分配方案。</p><p>在有了分配方案之后，并不能立即开始拉取消息，因为consumer不知道每一个分区从哪里开始拉取，就要通过OffsetFetch请求向Coordinator获取fetchOffset，在有了fetchOffset之后理应可以拉取了，但又有2个特殊情况：当前是新消费者组，或是消费者组过期了(相关参数为offsets.retention.minutes)，此时Coordinator不知道consumer上一次消费到哪了，那么auto.offset.reset参数就起作用了，根据是它来获取最早或是最新的位移，到此，准备工作才算完成。</p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>kafka server端源码分析之副本同步</title>
      <link href="/2020/03/08/kafka-server%E7%AB%AF%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5/"/>
      <url>/2020/03/08/kafka-server%E7%AB%AF%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>为什么我现在才写副本同步的解析呢，因为它太复杂了，仅仅是什么时候触发的副本同步，就涉及到KafkaController，LeaderAndIsr请求等，经过前面文章的梳理，现在时机正好</p><h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><p>通常我们会为了提高系统并发能力、可伸缩性，为topic设置多个分区，每个分区副本数通常设置为3个，其中1个为leader副本，其余2个follower副本为冗余备份使用。在producer端为了保证消息不丢失，通常设置ack=-1，并搭配失败重试机制</p><p>本文主要讨论broker端写入leader副本后，follower副本如何同步消息，以及如何更新HighWatermark，并使Purgatory延迟队列中的PRODUCE请求完成(complete)，响应客户端</p><h2 id="副本拉取管理器"><a href="#副本拉取管理器" class="headerlink" title="副本拉取管理器"></a>副本拉取管理器</h2><p>在Kafka启动时，会初始化ReplicaManager副本管理器，同时该类中有一行初始化语句<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val replicaFetcherManager = createReplicaFetcherManager(metrics, time, threadNamePrefix, quotaManagers.follower)</span><br></pre></td></tr></table></figure></p><p>其实就是new了一个ReplicaFetcherManager对象，该对象的功能十分简单，就是创建和关闭Fetch线程</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class ReplicaFetcherManager(brokerConfig: KafkaConfig, protected val replicaManager: ReplicaManager, metrics: Metrics,</span><br><span class="line">                            time: Time, threadNamePrefix: Option[String] = None, quotaManager: ReplicationQuotaManager)</span><br><span class="line">      <span class="function">extends <span class="title">AbstractFetcherManager</span><span class="params">(<span class="string">"ReplicaFetcherManager on broker "</span> + brokerConfig.brokerId,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="string">"Replica"</span>, brokerConfig.numReplicaFetchers)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">override def <span class="title">createFetcherThread</span><span class="params">(fetcherId: Int, sourceBroker: BrokerEndPoint)</span>: AbstractFetcherThread </span>= &#123;</span><br><span class="line">    val prefix = threadNamePrefix.map(tp =&gt; s<span class="string">"$&#123;tp&#125;:"</span>).getOrElse(<span class="string">""</span>)</span><br><span class="line">    val threadName = s<span class="string">"$&#123;prefix&#125;ReplicaFetcherThread-$fetcherId-$&#123;sourceBroker.id&#125;"</span></span><br><span class="line">    <span class="keyword">new</span> ReplicaFetcherThread(threadName, fetcherId, sourceBroker, brokerConfig, replicaManager, metrics, time, quotaManager)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">shutdown</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    info(<span class="string">"shutting down"</span>)</span><br><span class="line">    closeAllFetchers()</span><br><span class="line">    info(<span class="string">"shutdown completed"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="副本同步"><a href="#副本同步" class="headerlink" title="副本同步"></a>副本同步</h1><p>在分析副本同步过程之前，我们先想一想什么时候开始同步，也就是上面的createFetcherThread什么时候创建并启动的</p><h2 id="何时同步"><a href="#何时同步" class="headerlink" title="何时同步"></a>何时同步</h2><p>这里就要回顾<a href="">KafkaController源码分析之LeaderAndIsr请求</a>一文了，这也是我先写LeaderAndIsr，然后才分析副本同步的原因</p><p>在前文中，提到了becomeLeaderOrFollower方法会将分区添加到副本同步线程中，具体实现就在addFetcherForPartitions方法中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">addFetcherForPartitions</span><span class="params">(partitionAndOffsets: Map[TopicPartition, BrokerAndInitialOffset])</span> </span>&#123;</span><br><span class="line">    lock <span class="keyword">synchronized</span> &#123;</span><br><span class="line">      <span class="comment">// partitionsPerFetcher = Map[BrokerAndFetcherId, Map[TopicPartition, BrokerAndInitialOffset]]</span></span><br><span class="line">      <span class="comment">// 分组的key是目标broker+同步线程，也就是同一个fetcher线程向同一个broker同步 为一组</span></span><br><span class="line">      val partitionsPerFetcher = partitionAndOffsets.groupBy &#123; <span class="keyword">case</span>(topicPartition, brokerAndInitialFetchOffset) =&gt;</span><br><span class="line">        BrokerAndFetcherId(brokerAndInitialFetchOffset.broker, getFetcherId(topicPartition.topic, topicPartition.partition))&#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 事先定义好创建并启动的方法</span></span><br><span class="line">      <span class="function">def <span class="title">addAndStartFetcherThread</span><span class="params">(brokerAndFetcherId: BrokerAndFetcherId, brokerIdAndFetcherId: BrokerIdAndFetcherId)</span> </span>&#123;</span><br><span class="line">        val fetcherThread = createFetcherThread(brokerAndFetcherId.fetcherId, brokerAndFetcherId.broker)</span><br><span class="line">        fetcherThreadMap.put(brokerIdAndFetcherId, fetcherThread)</span><br><span class="line">        fetcherThread.start</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> ((brokerAndFetcherId, initialFetchOffsets) &lt;- partitionsPerFetcher) &#123;</span><br><span class="line">        val brokerIdAndFetcherId = BrokerIdAndFetcherId(brokerAndFetcherId.broker.id, brokerAndFetcherId.fetcherId)</span><br><span class="line">        <span class="comment">// fetcherThreadMap: Map[BrokerIdAndFetcherId, AbstractFetcherThread]</span></span><br><span class="line">        <span class="comment">// 这里的逻辑还是很清晰的</span></span><br><span class="line">        fetcherThreadMap.get(brokerIdAndFetcherId) match &#123;</span><br><span class="line">            <span class="comment">// 已存在对应的Thread，并且线程的broker和分区要同步的broker相同，直接复用就行了</span></span><br><span class="line">          <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(f)</span> <span class="keyword">if</span> f.sourceBroker.host </span>== brokerAndFetcherId.broker.host &amp;&amp; f.sourceBroker.port == brokerAndFetcherId.broker.port =&gt;</span><br><span class="line">            <span class="comment">// reuse the fetcher thread</span></span><br><span class="line">          <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(f)</span> </span>=&gt;</span><br><span class="line">            <span class="comment">// 如果前面的if不成立，就需要关闭，重新添加并启动</span></span><br><span class="line">            f.shutdown()</span><br><span class="line">            addAndStartFetcherThread(brokerAndFetcherId, brokerIdAndFetcherId)</span><br><span class="line">          <span class="keyword">case</span> None =&gt;</span><br><span class="line">            <span class="comment">// 没有就创建</span></span><br><span class="line">            addAndStartFetcherThread(brokerAndFetcherId, brokerIdAndFetcherId)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        fetcherThreadMap(brokerIdAndFetcherId).addPartitions(initialFetchOffsets.map &#123; <span class="keyword">case</span> (tp, brokerAndInitOffset) =&gt;</span><br><span class="line">          tp -&gt; brokerAndInitOffset.initOffset</span><br><span class="line">        &#125;)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到Fetcher线程的启动是通过addAndStartFetcherThread方法实现的，createFetcherThread刚好调用了前面的ReplicaFetcherManager</p><p>同时我们注意一下createFetcherThread方法的第二个参数传入的是broker，那么我们可以得出以下结论</p><ol><li>一个fetcher线程只会向一个broker同步</li><li>一个fetcher线程管理了本地broker多个分区的同步，它和消费者一样都是发送的FETCH请求，此时我们就把它看做一个消费者，和消费者线程一样可以拉取多个分区的消息</li></ol><p>ReplicaFetcherThread的类图如下，执行的主体在它的父类AbstractFetcherThread的doWork方法中，具体的fetch逻辑由子类实现，典型的模板模式<br><img src="https://pic.downk.cc/item/5e96a9c6c2a9a83be5876153.png" alt="fetch-thread"></p><h2 id="同步过程分解"><a href="#同步过程分解" class="headerlink" title="同步过程分解"></a>同步过程分解</h2><p>副本同步表面看只是follower单向地向leader发送fetch请求，但不要忘了ISR这个概念，follower同步不及时会触发ISR的shrink，那么怎么判断follower同步是否及时能？很简单，在leader副本端维护一个时间戳，记录follower副本每次同步的时间，超出replica.lag.time.max.ms(默认10s)就代表follower副本同步太慢</p><p>那么我们在看副本同步时，就要站在更高的一个视角去看，一边是follower，一边是leader。</p><h1 id="follower副本端同步"><a href="#follower副本端同步" class="headerlink" title="follower副本端同步"></a>follower副本端同步</h1><p>通过前面的信息我们知道同步是从AbstractFetcherThread的doWork方法开始的，需要说明的是该方法是在一个while循环中一直执行，也就是说副本同步是一个不间断的操作，下面就从它的源码开始分析</p><h2 id="同步线程doWork"><a href="#同步线程doWork" class="headerlink" title="同步线程doWork"></a>同步线程doWork</h2><p>AbstractFetcherThread的doWork方法是副本同步的入口，其中maybeTruncate是0.11版本之后，副本恢复的截断协议从HW改为leader epoch方式，过程较为复杂，后续会单独分析<br>剩下的步骤就是构建fetch请求，然后调用processFetchRequest进行请求发送及响应处理<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">override def <span class="title">doWork</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  maybeTruncate()</span><br><span class="line">  <span class="comment">// 构建fetch请求</span></span><br><span class="line">  val fetchRequest = inLock(partitionMapLock) &#123;</span><br><span class="line">    <span class="function">val <span class="title">ResultWithPartitions</span><span class="params">(fetchRequest, partitionsWithError)</span> </span>= buildFetchRequest(states)</span><br><span class="line">    <span class="keyword">if</span> (fetchRequest.isEmpty) &#123;</span><br><span class="line">      trace(s<span class="string">"There are no active partitions. Back off for $fetchBackOffMs ms before sending a fetch request"</span>)</span><br><span class="line">      <span class="comment">// replica.fetch.backoff.ms</span></span><br><span class="line">      partitionMapCond.await(fetchBackOffMs, TimeUnit.MILLISECONDS)</span><br><span class="line">    &#125;</span><br><span class="line">    handlePartitionsWithErrors(partitionsWithError)</span><br><span class="line">    fetchRequest</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!fetchRequest.isEmpty)</span><br><span class="line">    processFetchRequest(fetchRequest)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="发送fetch请求"><a href="#发送fetch请求" class="headerlink" title="发送fetch请求"></a>发送fetch请求</h2><p>processFetchRequest表示follower向leader发送fetch请求，然后对响应结果处理。而在leader副本端是如何处理该请求的，在<a href="">kafka-server端源码分析之拉取消息</a>一文中已基本描述，但是留下了一个ReplicaManager的updateFollowerLogReadResults方法没有讲解，我们按照顺序，先补一下leader端的处理，看看updateFollowerLogReadResults到底做了什么</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">processFetchRequest</span><span class="params">(fetchRequest: REQ)</span> </span>&#123;</span><br><span class="line">    val partitionsWithError = mutable.Set[TopicPartition]()</span><br><span class="line">    var responseData: Seq[(TopicPartition, PD)] = Seq.empty</span><br><span class="line"></span><br><span class="line">    responseData = fetch(fetchRequest)</span><br><span class="line">    </span><br><span class="line">    fetcherStats.requestRate.mark()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 响应结果处理下文讲解 ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="leader记录follower副本的同步状态"><a href="#leader记录follower副本的同步状态" class="headerlink" title="leader记录follower副本的同步状态"></a>leader记录follower副本的同步状态</h1><p>updateFollowerLogReadResults的作用就是leader端记录follower副本的同步状态，例如上一次达到同步状态的时间点，上一次follower副本发送fetch请求的时间点等，依据这些信息，leader副本才能判断出follower副本能否在ISR列表中。<br>下面看看源码是如何实现的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">updateFollowerLogReadResults</span><span class="params">(replicaId: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                                           readResults: Seq[(TopicPartition, LogReadResult)</span>]): Seq[<span class="params">(TopicPartition, LogReadResult)</span>] </span>= &#123;</span><br><span class="line">    debug(s<span class="string">"Recording follower broker $replicaId log end offsets: $readResults"</span>)</span><br><span class="line">    readResults.map &#123; <span class="keyword">case</span> (topicPartition, readResult) =&gt;</span><br><span class="line">      var updatedReadResult = readResult</span><br><span class="line">      nonOfflinePartition(topicPartition) match &#123;</span><br><span class="line">        <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(partition)</span> </span>=&gt;</span><br><span class="line">          partition.getReplica(replicaId) match &#123;</span><br><span class="line">            <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(replica)</span> </span>=&gt;</span><br><span class="line">              partition.updateReplicaLogReadResult(replica, readResult)</span><br><span class="line">            <span class="keyword">case</span> None =&gt;</span><br><span class="line">              <span class="comment">// 如果副本不存在则不更新</span></span><br><span class="line">              updatedReadResult = readResult.withEmptyFetchInfo</span><br><span class="line">          &#125;</span><br><span class="line">        <span class="keyword">case</span> None =&gt;</span><br><span class="line">          warn(s<span class="string">"While recording the replica LEO, the partition $topicPartition hasn't been created."</span>)</span><br><span class="line">      &#125;</span><br><span class="line">      topicPartition -&gt; updatedReadResult</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>updateFollowerLogReadResults方法比较简单，但也有不少的细节。先回顾下它的两个参数:</p><ol><li>replicaId表示follower副本的id，也就是我一直强调的follower副本所在的broker id，二者等价</li><li>readResults是本次fetch请求读取的结果，和消费者一样，可以拉取多个分区</li></ol><h4 id="重点"><a href="#重点" class="headerlink" title="重点"></a>重点</h4><p>真正的调用是以下代码，表示Partition更新某一个follower的同步状态，该方法的难点在于replica参数，结合Partition类的allReplicasMap来看，此处的replica代表了在leader端，follower副本对应的Replica对象，根据后面的代码来看，leader会维护每一个follower副本的同步状态<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 成员变量</span></span><br><span class="line"><span class="keyword">private</span> val allReplicasMap = <span class="keyword">new</span> Pool[Int, Replica]</span><br><span class="line"></span><br><span class="line"><span class="comment">// updateFollowerLogReadResults里的</span></span><br><span class="line">partition.getReplica(replicaId) match &#123;</span><br><span class="line">  <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(replica)</span> </span>=&gt;</span><br><span class="line">    partition.updateReplicaLogReadResult(replica, readResult)</span><br></pre></td></tr></table></figure></p><h2 id="Partition更新同步状态"><a href="#Partition更新同步状态" class="headerlink" title="Partition更新同步状态"></a>Partition更新同步状态</h2><p>Partition对象的updateReplicaLogReadResult方法，它主要做了3件事：</p><ol><li>调用Replica对象的updateLogReadResult，更新该follower副本的同步状态</li><li>尝试扩充ISR列表</li><li>尝试完成一些延迟操作: produce,fetch,deleteRecords</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">updateReplicaLogReadResult</span><span class="params">(replica: Replica, logReadResult: LogReadResult)</span>: Boolean </span>= &#123;</span><br><span class="line">    <span class="comment">// 此处的replica就是远程的follower副本</span></span><br><span class="line">    val replicaId = replica.brokerId</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// No need to calculate low watermark if there is no delayed DeleteRecordsRequest</span></span><br><span class="line">    <span class="comment">// LW就是所有副本logStartOffset的最小值</span></span><br><span class="line">    val oldLeaderLW = <span class="keyword">if</span> (replicaManager.delayedDeleteRecordsPurgatory.delayed &gt; <span class="number">0</span>) lowWatermarkIfLeader <span class="keyword">else</span> -<span class="number">1L</span></span><br><span class="line">    <span class="comment">// 更新同步信息</span></span><br><span class="line">    replica.updateLogReadResult(logReadResult)</span><br><span class="line">    <span class="comment">// 新的LW</span></span><br><span class="line">    val newLeaderLW = <span class="keyword">if</span> (replicaManager.delayedDeleteRecordsPurgatory.delayed &gt; <span class="number">0</span>) lowWatermarkIfLeader <span class="keyword">else</span> -<span class="number">1L</span></span><br><span class="line">    <span class="comment">// check if the LW of the partition has incremented</span></span><br><span class="line">    <span class="comment">// since the replica's logStartOffset may have incremented</span></span><br><span class="line">    val leaderLWIncremented = newLeaderLW &gt; oldLeaderLW</span><br><span class="line">    <span class="comment">// check if we need to expand ISR to include this replica</span></span><br><span class="line">    <span class="comment">// if it is not in the ISR yet</span></span><br><span class="line">    <span class="comment">// 扩充ISR列表</span></span><br><span class="line">    val leaderHWIncremented = maybeExpandIsr(replicaId, logReadResult)</span><br><span class="line"></span><br><span class="line">    val result = leaderLWIncremented || leaderHWIncremented</span><br><span class="line">    <span class="comment">// some delayed operations may be unblocked after HW or LW changed</span></span><br><span class="line">    <span class="keyword">if</span> (result)</span><br><span class="line">      <span class="comment">// 尝试完成一些延迟操作:produce,fetch,deleteRecords</span></span><br><span class="line">      tryCompleteDelayedRequests()</span><br><span class="line"></span><br><span class="line">    debug(s<span class="string">"Recorded replica $replicaId log end offset (LEO) position $&#123;logReadResult.info.fetchOffsetMetadata.messageOffset&#125;."</span>)</span><br><span class="line">    result</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先看下第一步，follower同步状态的更新</p><h3 id="Replica更新同步状态"><a href="#Replica更新同步状态" class="headerlink" title="Replica更新同步状态"></a>Replica更新同步状态</h3><p>大体思路很清晰，首先更新_lastCaughtUpTimeMs，它记录的follower达到同步状态的时间，至于如何判定达到了同步状态，该方法的2个if给出了答案，<br> 而lastFetchTimeMs仅仅是leader收到fetch请求的时间<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">updateLogReadResult</span><span class="params">(logReadResult: LogReadResult)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// fetchOffsetMetadata就是fetch请求中的fetchOffset，表示从哪里开始拉取，leaderLogEndOffset就是LEO</span></span><br><span class="line">    <span class="comment">// 通过debug，大部分情况是走第一个if，二者是相等的，表示生产消息和follower同步消息的速率在一个水平线上</span></span><br><span class="line">    <span class="keyword">if</span> (logReadResult.info.fetchOffsetMetadata.messageOffset &gt;= logReadResult.leaderLogEndOffset)</span><br><span class="line">      <span class="comment">// _lastCaughtUpTimeMs更新为fetchTimeMs，表示拉取时的当前时间</span></span><br><span class="line">      _lastCaughtUpTimeMs = math.max(_lastCaughtUpTimeMs, logReadResult.fetchTimeMs)</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (logReadResult.info.fetchOffsetMetadata.messageOffset &gt;= lastFetchLeaderLogEndOffset)</span><br><span class="line">      _lastCaughtUpTimeMs = math.max(_lastCaughtUpTimeMs, lastFetchTimeMs)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// followerLogStartOffset是fetch请求中的，表示的是follower副本的LogStartOffset</span></span><br><span class="line">    <span class="comment">// 注意里面有if local的判断，这里其实更新的是follower副本的LogStartOffset</span></span><br><span class="line">    <span class="comment">// _logStartOffset = followerLogStartOffset</span></span><br><span class="line">    logStartOffset = logReadResult.followerLogStartOffset</span><br><span class="line">    <span class="comment">// 和上面一样，这个LEO表示的是follower副本的LEO</span></span><br><span class="line">    logEndOffset = logReadResult.info.fetchOffsetMetadata</span><br><span class="line">    <span class="comment">// 记录fetch时， leader的LEO</span></span><br><span class="line">    lastFetchLeaderLogEndOffset = logReadResult.leaderLogEndOffset</span><br><span class="line">    <span class="comment">// 记录fetch的时间</span></span><br><span class="line">    lastFetchTimeMs = logReadResult.fetchTimeMs</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>logStartOffset，logEndOffset表示的是_logStartOffset和_logEndOffset，即记录的是follower的logStartOffset和logEndOffset</p><p>logStartOffset变量之前的文章也经常提到，这里再解释一遍，副本对应一个Log对象，一个日志用多个Segment存储，第一个Segment的第一条消息的offset就是logStartOffset，因为kafka会定时删除日志，所以它是会变的，也就可以简单理解为目前副本的第一个消息的offset；至于logEndOffset就不再解释了<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def logStartOffset: Long =</span><br><span class="line">  <span class="keyword">if</span> (isLocal)</span><br><span class="line">    log.get.logStartOffset</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    _logStartOffset</span><br></pre></td></tr></table></figure></p><h3 id="maybeExpandIsr扩充ISR列表"><a href="#maybeExpandIsr扩充ISR列表" class="headerlink" title="maybeExpandIsr扩充ISR列表"></a>maybeExpandIsr扩充ISR列表</h3><p>在看完Partition更新同步状态的第一步后，接下来看第二步maybeExpandIsr，首先判断是否需要添加到ISR副本中，有以下4个条件</p><ol><li>follower副本目前不在ISR列表中</li><li>是已分配的副本</li><li>follower的LEO &gt; Leader的HW，从前面看follower的LEO就是本次fetch请求的fetchOffset</li><li>follower的fetchOffset至少比一个leader epoch的start offset大<br>前2个条件很好理解，第3个条件表示已达到同步，第4个条件则是确保fetchOffset的正确性，防止数据丢失</li></ol><p>更新的过程也十分简单，就是将新的Isr更新到zk的/brokers/topics/xxxTopic/partitions/0/state节点，并更新到本地缓存isrChangeSet中</p><p>最后在ISR新加入了一个副本之后，有可能触发leader副本的HW更新</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">maybeExpandIsr</span><span class="params">(replicaId: Int, logReadResult: LogReadResult)</span>: Boolean </span>= &#123;</span><br><span class="line">    inWriteLock(leaderIsrUpdateLock) &#123;</span><br><span class="line">      <span class="comment">// check if this replica needs to be added to the ISR</span></span><br><span class="line">      leaderReplicaIfLocal match &#123;</span><br><span class="line">        <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(leaderReplica)</span> </span>=&gt;</span><br><span class="line">          val replica = getReplica(replicaId).get</span><br><span class="line">          val leaderHW = leaderReplica.highWatermark</span><br><span class="line">          val fetchOffset = logReadResult.info.fetchOffsetMetadata.messageOffset</span><br><span class="line"></span><br><span class="line">          <span class="comment">// 目前不在ISR列表中 &amp;&amp; 是已分配的副本 &amp;&amp; follower的LEO &gt; Leader的HW &amp;&amp; follower的fetchOffset至少比一个leader epoch的start offset大</span></span><br><span class="line">          <span class="keyword">if</span> (!inSyncReplicas.contains(replica)</span><br><span class="line">            &amp;&amp; assignedReplicas.map(_.brokerId).contains(replicaId)</span><br><span class="line">            &amp;&amp; replica.logEndOffset.offsetDiff(leaderHW) &gt;= <span class="number">0</span></span><br><span class="line">            &amp;&amp; leaderEpochStartOffsetOpt.exists(fetchOffset &gt;= _)) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 添加到集合</span></span><br><span class="line">            val newInSyncReplicas = inSyncReplicas + replica</span><br><span class="line">  </span><br><span class="line">            <span class="comment">// update ISR in ZK and cache</span></span><br><span class="line">            <span class="comment">// 新的Isr更新到zk的state节点，并更新到本地缓存isrChangeSet中</span></span><br><span class="line">            updateIsr(newInSyncReplicas)</span><br><span class="line">            <span class="comment">// metrics</span></span><br><span class="line">            replicaManager.isrExpandRate.mark()</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// 尝试增加leader的HW，因为有follower进入到ISR了</span></span><br><span class="line">          <span class="comment">// check if the HW of the partition can now be incremented</span></span><br><span class="line">          <span class="comment">// since the replica may already be in the ISR and its LEO has just incremented</span></span><br><span class="line">          maybeIncrementLeaderHW(leaderReplica, logReadResult.fetchTimeMs)</span><br><span class="line">        <span class="keyword">case</span> None =&gt; <span class="keyword">false</span> <span class="comment">// nothing to do if no longer leader</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>leader端的处理结束了，再看看follower副本对fetch请求响应的处理</p><h1 id="follower副本端处理响应"><a href="#follower副本端处理响应" class="headerlink" title="follower副本端处理响应"></a>follower副本端处理响应</h1><p>重新回到processFetchRequest方法，该方法通过fetch方法发送请求，在上面已经讲过了leader端是如何处理follower的fetch的，下面看看follower如何处理fetch请求的响应</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 篇幅原因，仅保留核心代码</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">processFetchRequest</span><span class="params">(fetchRequest: REQ)</span> </span>&#123;</span><br><span class="line">    val partitionsWithError = mutable.Set[TopicPartition]()</span><br><span class="line">    var responseData: Seq[(TopicPartition, PD)] = Seq.empty</span><br><span class="line">   </span><br><span class="line">    responseData = fetch(fetchRequest)</span><br><span class="line">    </span><br><span class="line">    fetcherStats.requestRate.mark()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (responseData.nonEmpty) &#123;</span><br><span class="line"></span><br><span class="line">      inLock(partitionMapLock) &#123;</span><br><span class="line"></span><br><span class="line">        responseData.foreach &#123; <span class="keyword">case</span> (topicPartition, partitionData) =&gt;</span><br><span class="line">          val topic = topicPartition.topic</span><br><span class="line">          val partitionId = topicPartition.partition</span><br><span class="line">          Option(partitionStates.stateValue(topicPartition)).foreach(currentPartitionFetchState =&gt;</span><br><span class="line">            <span class="comment">// It's possible that a partition is removed and re-added or truncated when there is a pending fetch request.</span></span><br><span class="line">            <span class="comment">// In this case, we only want to process the fetch response if the partition state is ready for fetch and the current offset is the same as the offset requested.</span></span><br><span class="line">            <span class="keyword">if</span> (fetchRequest.offset(topicPartition) == currentPartitionFetchState.fetchOffset &amp;&amp;</span><br><span class="line">                currentPartitionFetchState.isReadyForFetch) &#123;</span><br><span class="line">              partitionData.error match &#123;</span><br><span class="line">                <span class="keyword">case</span> Errors.NONE =&gt;</span><br><span class="line">                  <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// ===================== 核心部分 =============================</span></span><br><span class="line">                    val records = partitionData.toRecords</span><br><span class="line">                    <span class="comment">// 获取最后一个消息的nextOffset，作为下次新的fetchOffset，没有则依然以当前的为准</span></span><br><span class="line">                    val newOffset = records.batches.asScala.lastOption.map(_.nextOffset).getOrElse(</span><br><span class="line">                      currentPartitionFetchState.fetchOffset)</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// 更新metric lag(FetcherLagStats)，如果lag&lt;=0，说明是inSync的；   HW-lastOffset</span></span><br><span class="line">                    fetcherLagStats.getAndMaybePut(topic, partitionId).lag = Math.max(<span class="number">0L</span>, partitionData.highWatermark - newOffset)</span><br><span class="line">                    <span class="comment">// Once we hand off the partition data to the subclass, we can't mess with it any more in this thread</span></span><br><span class="line">                    <span class="comment">// 参数解释：分区，拉取时的fetchOffset，拉取的结果数据</span></span><br><span class="line">                    processPartitionData(topicPartition, currentPartitionFetchState.fetchOffset, partitionData)</span><br><span class="line"></span><br><span class="line">                    val validBytes = records.validBytes</span><br><span class="line">                    <span class="comment">// ReplicaDirAlterThread may have removed topicPartition from the partitionStates after processing the partition data</span></span><br><span class="line">                    <span class="keyword">if</span> (validBytes &gt; <span class="number">0</span> &amp;&amp; partitionStates.contains(topicPartition)) &#123;</span><br><span class="line">                      <span class="comment">// 更新分区的PartitionState(newOffset, 0, false)</span></span><br><span class="line">                      <span class="comment">// Update partitionStates only if there is no exception during processPartitionData</span></span><br><span class="line">                      partitionStates.updateAndMoveToEnd(topicPartition, <span class="keyword">new</span> PartitionFetchState(newOffset))</span><br><span class="line">                      <span class="comment">// metrics ...</span></span><br><span class="line">                      fetcherStats.byteRate.mark(validBytes)</span><br><span class="line">                    &#125;</span><br><span class="line">                  &#125; </span><br><span class="line">                &#125; </span><br><span class="line">            &#125;)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>核心代码的逻辑是：</p><ol><li>将拉取到的消息的最一条的offset，作为下一次拉取的fetchOffset参数，保存在partitionStates中</li><li></li></ol><p>processPartitionData除去校验和限流相关代码，主要做了2件事：</p><ol><li>将消息追加到本地副本中(appendRecordsToFollowerOrFutureReplica)</li><li>取本地follower副本的LEO(append之后已更新)和响应中leader HW的较小值，作为follower的HW</li><li>根据leader的logStartOffset来判断是否需要截断自己的leader epoch startOffset，此处暂不用关心</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">processPartitionData</span><span class="params">(topicPartition: TopicPartition, fetchOffset: Long, partitionData: PartitionData)</span> </span>&#123;</span><br><span class="line">    val replica = replicaMgr.getReplicaOrException(topicPartition)</span><br><span class="line">    val partition = replicaMgr.getPartition(topicPartition).get</span><br><span class="line">    val records = partitionData.toRecords</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 老版本没有第一条消息大于replica.fetch.max.bytes时，至少取一条的处理，目前fetchRequestVersion=8,不用关心</span></span><br><span class="line">    maybeWarnIfOversizedRecords(records, topicPartition)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 说明请求的fetchOffset就是当前的LEO</span></span><br><span class="line">    <span class="keyword">if</span> (fetchOffset != replica.logEndOffset.messageOffset)</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Offset mismatch for partition %s: fetched offset = %d, log end offset = %d."</span>.format(</span><br><span class="line">        topicPartition, fetchOffset, replica.logEndOffset.messageOffset))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Append the leader's messages to the log</span></span><br><span class="line">    <span class="comment">// 就是Log append 不过调用的是Log#appendAsFollower</span></span><br><span class="line">    partition.appendRecordsToFollowerOrFutureReplica(records, isFuture = <span class="keyword">false</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 取本地follower副本的LEO(append之后已更新) 和响应中leader HW的较小值，作为follower的HW</span></span><br><span class="line">    val followerHighWatermark = replica.logEndOffset.messageOffset.min(partitionData.highWatermark)</span><br><span class="line">    replica.highWatermark = <span class="keyword">new</span> LogOffsetMetadata(followerHighWatermark)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// for the follower replica, we do not need to keep</span></span><br><span class="line">    <span class="comment">// its segment base offset the physical position,</span></span><br><span class="line">    <span class="comment">// these values will be computed upon making the leader</span></span><br><span class="line">    val leaderLogStartOffset = partitionData.logStartOffset</span><br><span class="line">    replica.maybeIncrementLogStartOffset(leaderLogStartOffset)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Traffic from both in-sync and out of sync replicas are accounted for in replication quota to ensure total replication</span></span><br><span class="line">    <span class="comment">// traffic doesn't exceed quota.</span></span><br><span class="line">    <span class="keyword">if</span> (quota.isThrottled(topicPartition))</span><br><span class="line">      quota.record(records.sizeInBytes)</span><br><span class="line">    replicaMgr.brokerTopicStats.updateReplicationBytesIn(records.sizeInBytes)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>至此，副本同步的过程结果，相关流程用以下一张图解释<br><img src="副本同步流程" alt="https://pic.downk.cc/item/5eb52e32c2a9a83be58b2424.png"></p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>kafka server端源码分析之获取leader副本的epoch及startOffset</title>
      <link href="/2020/03/07/kafka-server%E7%AB%AF%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E8%8E%B7%E5%8F%96leader%E5%89%AF%E6%9C%AC%E7%9A%84epoch%E5%8F%8AstartOffset/"/>
      <url>/2020/03/07/kafka-server%E7%AB%AF%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E8%8E%B7%E5%8F%96leader%E5%89%AF%E6%9C%AC%E7%9A%84epoch%E5%8F%8AstartOffset/</url>
      <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本文主要讲解follower副本发起用于同步的fetch请求之前，获取了leader副本的leader epoch及其startOffset，关于leader epoch的介绍，可以看看前面的LeaderAndIsr请求一文</p><h1 id="follower副本同步"><a href="#follower副本同步" class="headerlink" title="follower副本同步"></a>follower副本同步</h1><p>在follower副本每次发起fetch请求之前，都会调用maybeTruncate方法，根据leader副本的leader epoch及startOffset和follower自己的作比较，判断是否需要截断日志(truncate)</p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>KafkaController源码分析之LeaderAndIsr请求</title>
      <link href="/2020/03/05/KafkaController%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BLeaderAndIsr%E8%AF%B7%E6%B1%82/"/>
      <url>/2020/03/05/KafkaController%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BLeaderAndIsr%E8%AF%B7%E6%B1%82/</url>
      <content type="html"><![CDATA[<blockquote><p>在KafkaController初始化的过程中，多次遇见了LeaderAndIsr请求，这是broker之间通信的一个重要请求，它也是副本同步的关键步骤，本文主要分析KafkaApis对该请求的处理</p></blockquote><h1 id="ControllerChannelManager"><a href="#ControllerChannelManager" class="headerlink" title="ControllerChannelManager"></a>ControllerChannelManager</h1><p>在讲解LeaderAndIsr请求之前，我们先来看下ControllerChannelManager，在<a href="">kafka-server端源码分析之Controller选举与初始化</a>我曾提到过它，说它是broker之间通信的管理器，那么它是如何工作的呢？</p><h2 id="又见内存队列"><a href="#又见内存队列" class="headerlink" title="又见内存队列"></a>又见内存队列</h2><p>和ControllerEventManager一样，ControllerChannelManager也是用的异步内存队列来处理请求的发送，它只用于Controller节点和其它broker通信，它的大致原理如下：</p><ol><li>ControllerBrokerRequestBatch用3个Map分别维护了leaderAndIsrRequest，stopReplicaRequest，updateMetadataRequest三种请求的缓存</li><li>当KafkaController等组件想要发送请求时，仅仅是通过addXXXRequestForBrokers方法，将请求参数添加到缓存中，而在调用sendRequestsToBrokers方法后，它会遍历3中请求的缓存，将请求参数，回调函数等封装为QueueItem对象，放入一个类型为BlockingQueue[QueueItem]的messageQueue中</li><li>在RequestSendThread线程启动后，从messageQueue中取出请求对象，发送请求，响应后调用回调函数进行处理</li></ol><p>请求流程如下<br><img src="https://ae01.alicdn.com/kf/H46db3f4073a847b2b51715f4fc5ad88eH.png" alt="流程图"></p><h2 id="请求对象解析"><a href="#请求对象解析" class="headerlink" title="请求对象解析"></a>请求对象解析</h2><h3 id="添加LeaderAndIsr请求到缓存"><a href="#添加LeaderAndIsr请求到缓存" class="headerlink" title="添加LeaderAndIsr请求到缓存"></a>添加LeaderAndIsr请求到缓存</h3><p>虽然这个方法很简单，但我需要提2个关键点</p><ol><li>第一个参数叫brokerIds，但是调用时传的是replicaIds或者Isr，这里要加强大家对副本id即brokerId的印象</li><li>注意最后面还添加了一个UpdateMetadata请求</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@param</span> brokerIds 通常是副本id，这里也是要请求的目标broker</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@param</span> topicPartition 分区</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@param</span> leaderIsrAndControllerEpoch leader， isr，controllerEpoch</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@param</span> replicas 通常是controllerContext缓存的分区副本集合</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@param</span> isNew 新建副本，新建分区是为true</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="function">def <span class="title">addLeaderAndIsrRequestForBrokers</span><span class="params">(brokerIds: Seq[Int], topicPartition: TopicPartition,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     leaderIsrAndControllerEpoch: LeaderIsrAndControllerEpoch,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     replicas: Seq[Int], isNew: Boolean)</span> </span>&#123;</span><br><span class="line">  brokerIds.filter(_ &gt;= <span class="number">0</span>).foreach &#123; brokerId =&gt;</span><br><span class="line">    <span class="comment">// 每个broker的LeaderAndIsr请求都有一个缓存</span></span><br><span class="line">    <span class="comment">// result: Map[TopicPartition, LeaderAndIsrRequest.PartitionState]</span></span><br><span class="line">    val result = leaderAndIsrRequestMap.getOrElseUpdate(brokerId, mutable.Map.empty)</span><br><span class="line">    val alreadyNew = result.get(topicPartition).exists(_.isNew)</span><br><span class="line">    <span class="comment">// 添加到目标broker的 leaderAndIsr请求队列中</span></span><br><span class="line">    result.put(topicPartition, <span class="keyword">new</span> LeaderAndIsrRequest.PartitionState(leaderIsrAndControllerEpoch.controllerEpoch,</span><br><span class="line">      leaderIsrAndControllerEpoch.leaderAndIsr.leader,</span><br><span class="line">      leaderIsrAndControllerEpoch.leaderAndIsr.leaderEpoch,</span><br><span class="line">      leaderIsrAndControllerEpoch.leaderAndIsr.isr.map(Integer.valueOf).asJava,</span><br><span class="line">      leaderIsrAndControllerEpoch.leaderAndIsr.zkVersion,</span><br><span class="line">      replicas.map(Integer.valueOf).asJava,</span><br><span class="line">      isNew || alreadyNew))</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 同时增加了一次UpdateMetadata请求</span></span><br><span class="line">  addUpdateMetadataRequestForBrokers(controllerContext.liveOrShuttingDownBrokerIds.toSeq, Set(topicPartition))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>请求体的推理需要点篇幅，我这里直接贴出一个请求的样例json, 其中isNew只有在新分区，新副本请求时才为true,leaderEpoch在后续的副本同步会讲到，用于保证recovery时的数据一致性<br>liveLeaders表示的是上面partitionStates参数中每个分区leader所在的broker(存活的)<br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"version"</span>:<span class="number">1</span>,</span><br><span class="line">    <span class="attr">"controllerId"</span>:<span class="number">1</span>,</span><br><span class="line">    <span class="attr">"controllerEpoch"</span>:<span class="number">1</span>,</span><br><span class="line">    <span class="attr">"partitionStates"</span>:[</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"TopicPartition"</span>:<span class="string">"test-0"</span>,</span><br><span class="line">            <span class="attr">"PartitionState"</span>:&#123;</span><br><span class="line">                <span class="attr">"isNew"</span>:<span class="literal">false</span>,</span><br><span class="line">                <span class="attr">"basePartitionState"</span>:&#123;</span><br><span class="line">                    <span class="attr">"controllerEpoch"</span>:<span class="number">1</span>,</span><br><span class="line">                    <span class="attr">"leader"</span>:<span class="number">1</span>,</span><br><span class="line">                    <span class="attr">"leaderEpoch"</span>:<span class="number">1</span>,</span><br><span class="line">                    <span class="attr">"isr"</span>:[ <span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">                    <span class="attr">"zkVersion"</span>:<span class="number">1</span>,</span><br><span class="line">                    <span class="attr">"replicas"</span>:[ <span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"liveLeaders"</span>:[</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"id"</span>:<span class="number">1</span>,</span><br><span class="line">            <span class="attr">"idString"</span>:<span class="string">"1"</span>,</span><br><span class="line">            <span class="attr">"host"</span>:<span class="string">"localhost"</span>,</span><br><span class="line">            <span class="attr">"port"</span>:<span class="number">9092</span>,</span><br><span class="line">            <span class="attr">"rack"</span>:<span class="string">"rack-1"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="打破思维定式的假设"><a href="#打破思维定式的假设" class="headerlink" title="打破思维定式的假设"></a>打破思维定式的假设</h1><p>这里我主要想分享一点我的经验，不要死心眼的认为broker有3个，比如现在的情况是</p><p>15台broker，有一个叫test的topic，它有12个分区，每个分区3个副本，以第一个分区test-0为例，它目前的leader是8，即第8台broker上的test-0分区的副本是leader， ISR列表为[8,10,14], 它的replica是[8,10,14]，即所有副本都在同步列表</p><p>现在Controller是broker-0，LeaderAndISR请求需要变更<strong>一批</strong>分区的信息，其中刚好有一个要把test-0的leader变为10，因此它要向broker 8，10，14发送LeaderAndIsr请求，下面的请求讲解都以这个为例</p><table><thead><tr><th>topic分区</th><th>原leader副本</th><th>原ISR与Replica</th><th>变更后的leader副本</th><th>变更后的ISR与Replica</th><th>场景</th></tr></thead><tbody><tr><td>foo-1</td><td>9</td><td>[5,9,10]</td><td>5</td><td>[5,9,10]</td><td>Preferred选举</td></tr><tr><td>test-0</td><td>8</td><td>[8,10,14]</td><td>10</td><td>[8,10,14]</td><td>leader换选</td></tr><tr><td>bar-1</td><td>4</td><td>[4,10,12]</td><td>4</td><td>[4,7,10,16,19]</td><td>副本重分配</td></tr></tbody></table><p>注：只有15台broker，最后一个有16，19不是我写错了</p><p>可以看到这一批LeaderAndIsr请求要发送到多个broker，leaderAndIsrRequestMap的类型是Map[brokerId, Map[TopicPartition, LeaderAndIsrRequest.PartitionState]],发送的代码如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">leaderAndIsrRequestMap.foreach &#123; <span class="keyword">case</span> (broker, leaderAndIsrPartitionStates) =&gt;</span><br><span class="line">  leaderAndIsrPartitionStates.foreach &#123; <span class="keyword">case</span> (topicPartition, state) =&gt;</span><br><span class="line">    </span><br><span class="line">  val leaderIds = leaderAndIsrPartitionStates.map(_._2.basePartitionState.leader).toSet</span><br><span class="line"></span><br><span class="line">  val leaders = controllerContext.liveOrShuttingDownBrokers.filter(b =&gt; leaderIds.contains(b.id)).map &#123;</span><br><span class="line">    _.node(controller.config.interBrokerListenerName)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  val leaderAndIsrRequestBuilder = <span class="keyword">new</span> LeaderAndIsrRequest.Builder(leaderAndIsrRequestVersion, controllerId,</span><br><span class="line">    controllerEpoch, leaderAndIsrPartitionStates.asJava, leaders.asJava)</span><br><span class="line"></span><br><span class="line">  controller.sendRequest(broker, ApiKeys.LEADER_AND_ISR, leaderAndIsrRequestBuilder,</span><br><span class="line">    (r: AbstractResponse) =&gt; controller.eventManager.put(controller.LeaderAndIsrResponseReceived(r, broker)))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到kafka的本意就是积攒一批请求，然后按照brokerId分组，再发送出去，和生产者发送消息是同样的味道</p><p>再看上面的表格，变更后的ISR与Replica列表就是我们要发送的broker，我这里故意让三个分区都包含10，那么我们往broker-10发送的LeaderAndIsr请求同时包含3个分区的信息变更请求</p><h1 id="KafkaApis处理LeaderAndIsr请求"><a href="#KafkaApis处理LeaderAndIsr请求" class="headerlink" title="KafkaApis处理LeaderAndIsr请求"></a>KafkaApis处理LeaderAndIsr请求</h1><p>LeaderAndIsr请求由handleLeaderAndIsrRequest方法处理，仅做了2件事：定义回调函数，认证预处理，关键的处理在调用的becomeLeaderOrFollower方法中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">handleLeaderAndIsrRequest</span><span class="params">(request: RequestChannel.Request)</span> </span>&#123;</span><br><span class="line">  val correlationId = request.header.correlationId</span><br><span class="line">  val leaderAndIsrRequest = request.body[LeaderAndIsrRequest]</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">onLeadershipChange</span><span class="params">(updatedLeaders: Iterable[Partition], updatedFollowers: Iterable[Partition])</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 按惯例，事先定义好的回调函数先不看，扰乱我们的视线</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (authorize(request.session, ClusterAction, Resource.ClusterResource)) &#123; <span class="comment">// 认证步骤不在细究</span></span><br><span class="line">    val response = replicaManager.becomeLeaderOrFollower(correlationId, leaderAndIsrRequest, onLeadershipChange)</span><br><span class="line">    sendResponseExemptThrottle(request, response)</span><br><span class="line">  &#125; </span><br><span class="line">  <span class="comment">// 省略</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="becomeLeaderOrFollower"><a href="#becomeLeaderOrFollower" class="headerlink" title="becomeLeaderOrFollower"></a>becomeLeaderOrFollower</h2><p>该方法分为三段，前面部分只是做了下检查，中间部分是我们重点关注的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">becomeLeaderOrFollower</span><span class="params">(correlationId: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                           leaderAndIsrRequest: LeaderAndIsrRequest,</span></span></span><br><span class="line"><span class="function"><span class="params">                           onLeadershipChange: (Iterable[Partition], Iterable[Partition])</span> </span>=&gt; Unit): LeaderAndIsrResponse = &#123;</span><br><span class="line"></span><br><span class="line">  replicaStateChangeLock <span class="keyword">synchronized</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (leaderAndIsrRequest.controllerEpoch &lt; controllerEpoch) &#123;</span><br><span class="line">      <span class="comment">// Controller已换届，忽略leaderAndIsr请求，即请求过期</span></span><br><span class="line">     </span><br><span class="line">      leaderAndIsrRequest.getErrorResponse(<span class="number">0</span>, Errors.STALE_CONTROLLER_EPOCH.exception)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      val responseMap = <span class="keyword">new</span> mutable.HashMap[TopicPartition, Errors]</span><br><span class="line"></span><br><span class="line">      val controllerId = leaderAndIsrRequest.controllerId</span><br><span class="line">      <span class="comment">// 更新controllerEpoch，记录了最新一次执行LeaderAndIsr请求的controllerEpoch</span></span><br><span class="line">      <span class="comment">// controller选举必定会发生LeaderAndIsr请求</span></span><br><span class="line">      controllerEpoch = leaderAndIsrRequest.controllerEpoch</span><br><span class="line"></span><br><span class="line">      <span class="comment">// First check partition's leader epoch</span></span><br><span class="line">      val partitionState = <span class="keyword">new</span> mutable.HashMap[Partition, LeaderAndIsrRequest.PartitionState]()</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 缓存里没有的是新分区</span></span><br><span class="line">      val newPartitions = leaderAndIsrRequest.partitionStates.asScala.keys.filter(topicPartition =&gt; getPartition(topicPartition).isEmpty)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 一堆检查，省略部分代码... </span></span><br><span class="line">      leaderAndIsrRequest.partitionStates.asScala.foreach &#123; <span class="keyword">case</span> (topicPartition, stateInfo) =&gt;</span><br><span class="line">        val partition = getOrCreatePartition(topicPartition) <span class="comment">// 返回的是Partition对象,新的partition有Pool的valueFactory初始化</span></span><br><span class="line">        val partitionLeaderEpoch = partition.getLeaderEpoch</span><br><span class="line">        <span class="keyword">if</span> (partitionLeaderEpoch &lt; stateInfo.basePartitionState.leaderEpoch) &#123; </span><br><span class="line">          <span class="comment">// 本地缓存的leader epoch要比请求中的leader epoch小，因为请求里的leader epoch是加1了的</span></span><br><span class="line">          <span class="comment">// 最终想要的数据</span></span><br><span class="line">          partitionState.put(partition, stateInfo)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// ================重点关注下面的代码==================</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// 过滤出leader是当前broker的分区，*要将当前broker上的副本变为leader* 这句话最重要</span></span><br><span class="line">      val partitionsTobeLeader = partitionState.filter &#123; <span class="keyword">case</span> (_, stateInfo) =&gt;</span><br><span class="line">        stateInfo.basePartitionState.leader == localBrokerId</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 其余的副本在当前broker都是follower</span></span><br><span class="line">      val partitionsToBeFollower = partitionState -- partitionsTobeLeader.keys</span><br><span class="line"></span><br><span class="line">      val partitionsBecomeLeader = <span class="keyword">if</span> (partitionsTobeLeader.nonEmpty)</span><br><span class="line">        <span class="comment">// 标记为leader的分区</span></span><br><span class="line">        makeLeaders(controllerId, controllerEpoch, partitionsTobeLeader, correlationId, responseMap)</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        Set.empty[Partition]</span><br><span class="line"></span><br><span class="line">      val partitionsBecomeFollower = <span class="keyword">if</span> (partitionsToBeFollower.nonEmpty)</span><br><span class="line">      <span class="comment">// 标记为follower的分区</span></span><br><span class="line">        makeFollowers(controllerId, controllerEpoch, partitionsToBeFollower, correlationId, responseMap)</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        Set.empty[Partition]</span><br><span class="line"></span><br><span class="line">      <span class="comment">// ================重点关注==================</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">      <span class="comment">// 先不看 ....</span></span><br><span class="line">      leaderAndIsrRequest.partitionStates.asScala.keys.foreach(topicPartition =&gt;</span><br><span class="line">        <span class="keyword">if</span> (getReplica(topicPartition).isEmpty &amp;&amp; (allPartitions.get(topicPartition) ne ReplicaManager.OfflinePartition))</span><br><span class="line">          allPartitions.put(topicPartition, ReplicaManager.OfflinePartition)</span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (!hwThreadInitialized) &#123;</span><br><span class="line">        startHighWaterMarksCheckPointThread()</span><br><span class="line">        hwThreadInitialized = <span class="keyword">true</span></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      val newOnlineReplicas = newPartitions.flatMap(topicPartition =&gt; getReplica(topicPartition))</span><br><span class="line">      val futureReplicasAndInitialOffset = newOnlineReplicas.filter &#123; replica =&gt;</span><br><span class="line">        logManager.getLog(replica.topicPartition, isFuture = <span class="keyword">true</span>).isDefined</span><br><span class="line">      &#125;.map &#123; replica =&gt;</span><br><span class="line">        replica.topicPartition -&gt; BrokerAndInitialOffset(BrokerEndPoint(config.brokerId, <span class="string">"localhost"</span>, -<span class="number">1</span>), replica.highWatermark.messageOffset)</span><br><span class="line">      &#125;.toMap</span><br><span class="line">      futureReplicasAndInitialOffset.keys.foreach(tp =&gt; getPartition(tp).get.getOrCreateReplica(Request.FutureLocalReplicaId))</span><br><span class="line"></span><br><span class="line">      futureReplicasAndInitialOffset.keys.foreach(logManager.abortAndPauseCleaning)</span><br><span class="line">      replicaAlterLogDirsManager.addFetcherForPartitions(futureReplicasAndInitialOffset)</span><br><span class="line"></span><br><span class="line">      replicaFetcherManager.shutdownIdleFetcherThreads()</span><br><span class="line">      replicaAlterLogDirsManager.shutdownIdleFetcherThreads()</span><br><span class="line">      onLeadershipChange(partitionsBecomeLeader, partitionsBecomeFollower)</span><br><span class="line">      <span class="keyword">new</span> LeaderAndIsrResponse(Errors.NONE, responseMap.asJava)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th>topic分区</th><th>原leader副本</th><th>原ISR与Replica</th><th>变更后的leader副本</th><th>变更后的ISR与Replica</th><th>场景</th></tr></thead><tbody><tr><td>foo-1</td><td>9</td><td>[5,9,10]</td><td>5</td><td>[5,9,10]</td><td>Preferred选举</td></tr><tr><td>test-0</td><td>8</td><td>[8,10,14]</td><td>10</td><td>[8,10,14]</td><td>leader换选</td></tr><tr><td>bar-1</td><td>4</td><td>[4,10,12]</td><td>4</td><td>[4,7,10,16,19]</td><td>副本重分配</td></tr></tbody></table><p>根据前面的假设，broker-0(controller)向broker-10发送了一批分区变更需求请求，假设当前处理请求的是broker-10，先进行分组</p><p>partitionsTobeLeader: 变更后的leader是当前broker，也就是broker-10的一组，即test-0分区，用makeLeaders方法处理</p><p>partitionsBecomeLeader: 其他的分区一组，即foo-1，bar-1，用makeFollowers方法处理</p><p>我们先看makeLeaders方法，它首先停止了这些副本的同步操作，然后遍历每个分区处理<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">makeLeaders</span><span class="params">(controllerId: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                          epoch: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                          partitionState: Map[Partition, LeaderAndIsrRequest.PartitionState],</span></span></span><br><span class="line"><span class="function"><span class="params">                          correlationId: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                          responseMap: mutable.Map[TopicPartition, Errors])</span>: Set[Partition] </span>= &#123;</span><br><span class="line">  <span class="comment">// 返回结果</span></span><br><span class="line">  val partitionsToMakeLeaders = mutable.Set[Partition]()</span><br><span class="line">  <span class="comment">// 从fetch线程中移除这些分区副本的同步操作</span></span><br><span class="line">  replicaFetcherManager.removeFetcherForPartitions(partitionState.keySet.map(_.topicPartition))</span><br><span class="line">  <span class="comment">//遍历每一个分区，调用makeLeader</span></span><br><span class="line">  partitionState.foreach&#123; <span class="keyword">case</span> (partition, partitionStateInfo) =&gt;</span><br><span class="line">    <span class="keyword">if</span> (partition.makeLeader(controllerId, partitionStateInfo, correlationId)) &#123;</span><br><span class="line">      partitionsToMakeLeaders += partition</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>那么我们直接来到Partition的makeLeader方法，它是处理单个分区信息变更的方法</p><h2 id="makeLeader"><a href="#makeLeader" class="headerlink" title="makeLeader"></a>makeLeader</h2><p>看代码之前先稍微解释下leader epoch以及leader-epoch-checkpoint文件</p><p>leader epoch在分区的leader副本变更时更新，每次更新加1，相当于记录了分区leader的更新次数，也可以理解为leader的版本号<br>leader-epoch-checkpoint在每一个分区日志目录都有一个，这里以topic为test-1,分区为0的日志目录为例<br>它的内容是一个key value，key是leader epoch，value是上一代leader的LEO，我们知道LEO是即将写入的下一条消息的offset，这里也可以理解为新leader要写入的第一条消息</p><p><img src="https://ae01.alicdn.com/kf/Hd55131d904654aaf801fcca7b0cef015s.png" alt="leader-epoch-checkpoint文件位置"><br>它里面的内容一般是这样的，其他check-point文件也是同理<br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span> <span class="number">9832</span></span><br></pre></td></tr></table></figure></p><p>第一行的0表示版本号，第二行表示记录个数，第三行才是真正的数据</p><p>言归正传，继续看makeLeader方法。该方法更新了本地的一些缓存，如controllerEpoch，inSyncReplicas，leaderEpoch，leaderEpochStartOffsetOpt(上面说的value)，zkVersion。接着更新了check-point文件</p><p>最后是关于新的leader副本的处理，比如初始化它的HW</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">makeLeader</span><span class="params">(controllerId: Int, partitionStateInfo: LeaderAndIsrRequest.PartitionState, correlationId: Int)</span>: Boolean </span>= &#123;</span><br><span class="line">  val (leaderHWIncremented, isNewLeader) = inWriteLock(leaderIsrUpdateLock) &#123;</span><br><span class="line">    <span class="comment">// 请求中的AR</span></span><br><span class="line">    val newAssignedReplicas = partitionStateInfo.basePartitionState.replicas.asScala.map(_.toInt)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Partition里也有一份controllerEpoch，更新</span></span><br><span class="line">    controllerEpoch = partitionStateInfo.basePartitionState.controllerEpoch</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取isr对应的Replica</span></span><br><span class="line">    val newInSyncReplicas = partitionStateInfo.basePartitionState.isr.asScala.map(r =&gt; getOrCreateReplica(r, partitionStateInfo.isNew)).toSet</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 副本重分配场景： 该分区已有的副本-新分配的副本=controller要移除的副本，从本地缓存allReplicasMap = new Pool[Int, Replica]中删除</span></span><br><span class="line">    (assignedReplicas.map(_.brokerId) -- newAssignedReplicas).foreach(removeReplica)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 新的isr是controller传过来的,更新</span></span><br><span class="line">    inSyncReplicas = newInSyncReplicas</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取replicas对应的Replica</span></span><br><span class="line">    newAssignedReplicas.foreach(id =&gt; getOrCreateReplica(id, partitionStateInfo.isNew))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 不是说当前replica是leader副本，而是说它即将要成为leader</span></span><br><span class="line">    val leaderReplica = getReplica().get</span><br><span class="line">    <span class="comment">// 获取leader副本的LEO</span></span><br><span class="line">    val leaderEpochStartOffset = leaderReplica.logEndOffset.messageOffset</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 更新leaderEpoch，以及这一届leaderEpoch对应的StartOffset</span></span><br><span class="line">    leaderEpoch = partitionStateInfo.basePartitionState.leaderEpoch</span><br><span class="line">    leaderEpochStartOffsetOpt = Some(leaderEpochStartOffset)</span><br><span class="line">    zkVersion = partitionStateInfo.basePartitionState.zkVersion</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将leader epoch及其开始位移写入文件</span></span><br><span class="line">    leaderReplica.epochs.foreach &#123; epochCache =&gt;</span><br><span class="line">      epochCache.assign(leaderEpoch, leaderEpochStartOffset)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果分区的leader副本就是当前broker，就不用变更了</span></span><br><span class="line">    <span class="comment">// 注：看becomeLeaderOrFollower方法的星号注释</span></span><br><span class="line">    val isNewLeader = !leaderReplicaIdOpt.contains(localBrokerId)</span><br><span class="line"></span><br><span class="line">    val curLeaderLogEndOffset = leaderReplica.logEndOffset.messageOffset <span class="comment">// leader副本的LEO</span></span><br><span class="line">    val curTimeMs = time.milliseconds</span><br><span class="line">    <span class="comment">// initialize lastCaughtUpTime of replicas as well as their lastFetchTimeMs and lastFetchLeaderLogEndOffset.</span></span><br><span class="line">    <span class="comment">// 更新副本的同步时间，LEO</span></span><br><span class="line">    (assignedReplicas - leaderReplica).foreach &#123; replica =&gt;</span><br><span class="line">      val lastCaughtUpTimeMs = <span class="keyword">if</span> (inSyncReplicas.contains(replica)) curTimeMs <span class="keyword">else</span> <span class="number">0L</span></span><br><span class="line">      replica.resetLastCaughtUpTime(curLeaderLogEndOffset, curTimeMs, lastCaughtUpTimeMs)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (isNewLeader) &#123;</span><br><span class="line">      <span class="comment">// construct the high watermark metadata for the new leader replica</span></span><br><span class="line">      <span class="comment">// 初始化HW(大概率就是当前的HW)</span></span><br><span class="line">      leaderReplica.convertHWToLocalOffsetMetadata()</span><br><span class="line">      <span class="comment">// mark local replica as the leader after converting hw</span></span><br><span class="line">      leaderReplicaIdOpt = Some(localBrokerId)</span><br><span class="line">      <span class="comment">// reset log end offset for remote replicas</span></span><br><span class="line">      <span class="comment">// 初始化同步相关的一堆参数</span></span><br><span class="line">      assignedReplicas.filter(_.brokerId != localBrokerId).foreach(_.updateLogReadResult(LogReadResult.UnknownLogReadResult))</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// we may need to increment high watermark since ISR could be down to 1</span></span><br><span class="line">    (maybeIncrementLeaderHW(leaderReplica), isNewLeader)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// some delayed operations may be unblocked after HW changed</span></span><br><span class="line">  <span class="keyword">if</span> (leaderHWIncremented)</span><br><span class="line">    <span class="comment">// HW增加了，fetch请求的max.byte，produce请求的ack=-1等待副本同步就可以try complete了，</span></span><br><span class="line">    tryCompleteDelayedRequests()</span><br><span class="line">  isNewLeader</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>makeLeader的作用可以简单归纳为：</p><ol><li>更新本地缓存数据</li><li>更新leader epoch到文件</li><li>如果本地副本不是leader，那么初始化它的HW，以及同步相关的参数</li></ol><p>处理流程如下：<br><img src="https://ae01.alicdn.com/kf/H5ca87b4ad1634fd0b8a57919c132d56eh.png" alt="makeLeader流程"></p><h2 id="Follower副本处理"><a href="#Follower副本处理" class="headerlink" title="Follower副本处理"></a>Follower副本处理</h2><p>在<a href="#becomeLeaderOrFollower">becomeLeaderOrFollower</a>方法中，makeLeaders处理完leader副本后，makeFollowers方法处理follower副本<br>该方法同样是遍历每一个分区</p><p>注：该方法源码很长，但是都是打印日志，这里删除了很多源码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">makeFollowers</span><span class="params">(controllerId: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                            epoch: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                            partitionStates: Map[Partition, LeaderAndIsrRequest.PartitionState],</span></span></span><br><span class="line"><span class="function"><span class="params">                            correlationId: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                            responseMap: mutable.Map[TopicPartition, Errors])</span> : Set[Partition] </span>= &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 定义返回结果</span></span><br><span class="line">  <span class="keyword">for</span> (partition &lt;- partitionStates.keys)</span><br><span class="line">    responseMap.put(partition.topicPartition, Errors.NONE)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 记录转变为follower副本的分区</span></span><br><span class="line">  val partitionsToMakeFollower: mutable.Set[Partition] = mutable.Set()</span><br><span class="line"></span><br><span class="line">  partitionStates.foreach &#123; <span class="keyword">case</span> (partition, partitionStateInfo) =&gt;</span><br><span class="line">    val newLeaderBrokerId = partitionStateInfo.basePartitionState.leader</span><br><span class="line">      <span class="comment">// 找到leader所在的broker</span></span><br><span class="line">      metadataCache.getAliveBrokers.find(_.id == newLeaderBrokerId) match &#123;</span><br><span class="line">        <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(_)</span> </span>=&gt;</span><br><span class="line">          <span class="comment">// makeFollower做主要初始化及更新操作</span></span><br><span class="line">          <span class="keyword">if</span> (partition.makeFollower(controllerId, partitionStateInfo, correlationId))</span><br><span class="line">            partitionsToMakeFollower += partition</span><br><span class="line">        <span class="keyword">case</span> None =&gt;</span><br><span class="line">          <span class="comment">// 没有就创建，这在分区副本重分配时有用</span></span><br><span class="line">          partition.getOrCreateReplica(isNew = partitionStateInfo.isNew)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// leader要发生改变，不能再从以前的leader同步</span></span><br><span class="line">  replicaFetcherManager.removeFetcherForPartitions(partitionsToMakeFollower.map(_.topicPartition))</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 尝试完成一些延迟请求</span></span><br><span class="line">  partitionsToMakeFollower.foreach &#123; partition =&gt;</span><br><span class="line">    val topicPartitionOperationKey = <span class="keyword">new</span> TopicPartitionOperationKey(partition.topicPartition)</span><br><span class="line">    tryCompleteDelayedProduce(topicPartitionOperationKey)</span><br><span class="line">    tryCompleteDelayedFetch(topicPartitionOperationKey)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// broker在关闭了</span></span><br><span class="line">  <span class="keyword">if</span> (isShuttingDown.get()) &#123;</span><br><span class="line">    <span class="comment">// 记录日志....</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 正常处理</span></span><br><span class="line">    <span class="comment">// we do not need to check if the leader exists again since this has been done at the beginning of this process</span></span><br><span class="line">    val partitionsToMakeFollowerWithLeaderAndOffset = partitionsToMakeFollower.map(partition =&gt;</span><br><span class="line">      <span class="comment">// leader所在的broker和当前broker副本的HW作为初始同步位移</span></span><br><span class="line">      partition.topicPartition -&gt; BrokerAndInitialOffset(</span><br><span class="line">        metadataCache.getAliveBrokers.find(_.id == partition.leaderReplicaIdOpt.get).get.brokerEndPoint(config.interBrokerListenerName),</span><br><span class="line">        partition.getReplica().get.highWatermark.messageOffset)).toMap</span><br><span class="line">    <span class="comment">// 添加到副本到同步线程</span></span><br><span class="line">    replicaFetcherManager.addFetcherForPartitions(partitionsToMakeFollowerWithLeaderAndOffset)</span><br><span class="line">  &#125;</span><br><span class="line">  partitionsToMakeFollower</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面调用的makeFollower和makeLeader方法类似<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">makeFollower</span><span class="params">(controllerId: Int, partitionStateInfo: LeaderAndIsrRequest.PartitionState, correlationId: Int)</span>: Boolean </span>= &#123;</span><br><span class="line">  inWriteLock(leaderIsrUpdateLock) &#123;</span><br><span class="line">    val newAssignedReplicas = partitionStateInfo.basePartitionState.replicas.asScala.map(_.toInt)</span><br><span class="line">    val newLeaderBrokerId = partitionStateInfo.basePartitionState.leader</span><br><span class="line">    val oldLeaderEpoch = leaderEpoch</span><br><span class="line">    <span class="comment">// record the epoch of the controller that made the leadership decision. This is useful while updating the isr</span></span><br><span class="line">    <span class="comment">// to maintain the decision maker controller's epoch in the zookeeper path</span></span><br><span class="line">    controllerEpoch = partitionStateInfo.basePartitionState.controllerEpoch</span><br><span class="line">    <span class="comment">// add replicas that are new</span></span><br><span class="line">    newAssignedReplicas.foreach(r =&gt; getOrCreateReplica(r, partitionStateInfo.isNew))</span><br><span class="line">    <span class="comment">// remove assigned replicas that have been removed by the controller</span></span><br><span class="line">    <span class="comment">// 删除缓存里不要的副本了</span></span><br><span class="line">    (assignedReplicas.map(_.brokerId) -- newAssignedReplicas).foreach(removeReplica)</span><br><span class="line"></span><br><span class="line">    inSyncReplicas = Set.empty[Replica] </span><br><span class="line">    leaderEpoch = partitionStateInfo.basePartitionState.leaderEpoch</span><br><span class="line">    leaderEpochStartOffsetOpt = None</span><br><span class="line">    zkVersion = partitionStateInfo.basePartitionState.zkVersion</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// leader是否更新了</span></span><br><span class="line">    <span class="keyword">if</span> (leaderReplicaIdOpt.contains(newLeaderBrokerId) &amp;&amp; (leaderEpoch == oldLeaderEpoch || leaderEpoch == oldLeaderEpoch + <span class="number">1</span>)) &#123;</span><br><span class="line">      <span class="keyword">false</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">      leaderReplicaIdOpt = Some(newLeaderBrokerId)</span><br><span class="line">      <span class="keyword">true</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>makeFollowers主要判断分区的leader副本是否发生了改变，如果改变了，就先移除原来的同步，重新向新leader同步</p><p><img src="https://ae01.alicdn.com/kf/Hee2c2db7c82843adb80e2ccdf67f07b2j.png" alt="makeFollowers"></p><h2 id="becomeLeaderOrFollower第三部分"><a href="#becomeLeaderOrFollower第三部分" class="headerlink" title="becomeLeaderOrFollower第三部分"></a>becomeLeaderOrFollower第三部分</h2><p>becomeLeaderOrFollower在调用makeLeaders和makeFollowers之后，处理的源码如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">leaderAndIsrRequest.partitionStates.asScala.keys.foreach(topicPartition =&gt;</span><br><span class="line">  <span class="comment">// 判断离线分区</span></span><br><span class="line">  <span class="keyword">if</span> (getReplica(topicPartition).isEmpty &amp;&amp; (allPartitions.get(topicPartition) ne ReplicaManager.OfflinePartition))</span><br><span class="line">    allPartitions.put(topicPartition, ReplicaManager.OfflinePartition)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 为初始化的LeaderAndIsr请求启动hw的check线程，记录到recovery-point-offset-checkpoint文件</span></span><br><span class="line"><span class="keyword">if</span> (!hwThreadInitialized) &#123;</span><br><span class="line">  startHighWaterMarksCheckPointThread()</span><br><span class="line">  hwThreadInitialized = <span class="keyword">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">val newOnlineReplicas = newPartitions.flatMap(topicPartition =&gt; getReplica(topicPartition))</span><br><span class="line"><span class="comment">// Add future replica to partition's map</span></span><br><span class="line">val futureReplicasAndInitialOffset = newOnlineReplicas.filter &#123; replica =&gt;</span><br><span class="line">  <span class="comment">// 新副本就是isFuture副本</span></span><br><span class="line">  logManager.getLog(replica.topicPartition, isFuture = <span class="keyword">true</span>).isDefined</span><br><span class="line">&#125;.map &#123; replica =&gt;</span><br><span class="line">  replica.topicPartition -&gt; BrokerAndInitialOffset(BrokerEndPoint(config.brokerId, <span class="string">"localhost"</span>, -<span class="number">1</span>), replica.highWatermark.messageOffset)</span><br><span class="line">&#125;.toMap</span><br><span class="line">futureReplicasAndInitialOffset.keys.foreach(tp =&gt; getPartition(tp).get.getOrCreateReplica(Request.FutureLocalReplicaId))</span><br><span class="line"></span><br><span class="line"><span class="comment">// pause cleaning for partitions that are being moved and start ReplicaAlterDirThread to move replica from source dir to destination dir</span></span><br><span class="line">futureReplicasAndInitialOffset.keys.foreach(logManager.abortAndPauseCleaning)</span><br><span class="line">replicaAlterLogDirsManager.addFetcherForPartitions(futureReplicasAndInitialOffset)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 看是否有空闲的fetcher线程</span></span><br><span class="line">replicaFetcherManager.shutdownIdleFetcherThreads()</span><br><span class="line">replicaAlterLogDirsManager.shutdownIdleFetcherThreads()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用handleLeaderAndIsrRequest中的回调函数</span></span><br><span class="line">onLeadershipChange(partitionsBecomeLeader, partitionsBecomeFollower)</span><br><span class="line"><span class="keyword">new</span> LeaderAndIsrResponse(Errors.NONE, responseMap.asJava)</span><br></pre></td></tr></table></figure><p>该部分主要是对future Replica的处理，它们会同步leader副本，之后清空空闲的fetcher线程，这里大家先理解一个fetcher线程管理了多个follower的同步<br>最后调用handleLeaderAndIsrRequest中的回调函数：onLeadershipChange，下面是该方法的源码</p><h2 id="内部topic的特殊处理"><a href="#内部topic的特殊处理" class="headerlink" title="内部topic的特殊处理"></a>内部topic的特殊处理</h2><p>kafka内部的topic有2个：<code>__consumer_offsets</code>和<code>__transaction_state</code>，它们的LeaderAndIsr处理比较复杂，这里不再展开细说。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">onLeadershipChange</span><span class="params">(updatedLeaders: Iterable[Partition], updatedFollowers: Iterable[Partition])</span> </span>&#123;</span><br><span class="line">  <span class="comment">// for each new leader or follower, call coordinator to handle consumer group migration.</span></span><br><span class="line">  <span class="comment">// this callback is invoked under the replica state change lock to ensure proper order of</span></span><br><span class="line">  <span class="comment">// leadership changes</span></span><br><span class="line">  updatedLeaders.foreach &#123; partition =&gt;</span><br><span class="line">    <span class="keyword">if</span> (partition.topic == GROUP_METADATA_TOPIC_NAME)</span><br><span class="line">      groupCoordinator.handleGroupImmigration(partition.partitionId)</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (partition.topic == TRANSACTION_STATE_TOPIC_NAME)</span><br><span class="line">      txnCoordinator.handleTxnImmigration(partition.partitionId, partition.getLeaderEpoch)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  updatedFollowers.foreach &#123; partition =&gt;</span><br><span class="line">    <span class="keyword">if</span> (partition.topic == GROUP_METADATA_TOPIC_NAME)</span><br><span class="line">      groupCoordinator.handleGroupEmigration(partition.partitionId)</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (partition.topic == TRANSACTION_STATE_TOPIC_NAME)</span><br><span class="line">      txnCoordinator.handleTxnEmigration(partition.partitionId, partition.getLeaderEpoch)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>LeaderAndIsr请求是在分区leader或者副本集合发生变更时，Controller向其它broker发生的请求，broker在接收到请求后会看分区的新leader是否是当前broker的id</p><ol><li>如果是，则先暂停该分区本地副本的同步，因为它们从follower变为leader了，然后更新元数据，记录leader epoch checkpoint等，最终初始化当前副本为leader副本</li><li>如果不是，则本地broker上的副本为follower副本,同样的更新本地缓存的元数据，此时按leader是否发生了改变分为2中情况<ol><li>leader改变了，那么移除当前同步线程对这些副本的同步，重新定位leader所在broker，以当前副本的HW为起始位移加入到副本同步线程中去</li><li>leader没有变，什么都不做</li></ol></li></ol>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>KafkaController源码分析之Broker的上线与下线</title>
      <link href="/2020/02/26/KafkaController%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BBroker%E7%9A%84%E4%B8%8A%E7%BA%BF%E4%B8%8E%E4%B8%8B%E7%BA%BF/"/>
      <url>/2020/02/26/KafkaController%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BBroker%E7%9A%84%E4%B8%8A%E7%BA%BF%E4%B8%8E%E4%B8%8B%E7%BA%BF/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本文主要聊聊某一个broker上线与下线时，集群是如何感知的</p><h1 id="zk事件"><a href="#zk事件" class="headerlink" title="zk事件"></a>zk事件</h1><p>在KafkaController#onControllerFailover方法中，会向zk注册一个brokerChangeHandler，它主要监听/brokers/ids下的子节点变化事件，我们知道该节点下就是每一个broker的id，里面的数据是broker的ip端口，协议等信息<br>BrokerChangeHandler的源码如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class BrokerChangeHandler(controller: KafkaController, eventManager: ControllerEventManager) extends ZNodeChildChangeHandler &#123;</span><br><span class="line">  override val path: String = BrokerIdsZNode.path</span><br><span class="line"></span><br><span class="line">  <span class="function">override def <span class="title">handleChildChange</span><span class="params">()</span>: Unit </span>= &#123;</span><br><span class="line">    eventManager.put(controller.BrokerChange)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="处理逻辑"><a href="#处理逻辑" class="headerlink" title="处理逻辑"></a>处理逻辑</h2><p>事件的处理逻辑在BrokerChange类中，isActive之前也说过了，表示当前broker是否是Controller，这里我们要明确一点时，broker的上下线事件只能由Controller处理，其他broker虽然也会监听/brokers/ids节点，但不会做任何处理</p><p>process方法中的curBrokers表示zk中当前的broker列表信息，liveOrShuttingDownBrokerIds表示本地缓存的broker列表信息，假设liveOrShuttingDownBrokerIds是[0,1,2]，如果新增了一个broker3，curBrokers就是[0,1,2,3]；如果broker2下线了，curBrokers就是[0,1]。只需要简单的对curBrokers和liveOrShuttingDownBrokerIds做差集运算，我们就知道上线和下线的broker集合分别是什么，这也是该方法前半部分的大致思路</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> object BrokerChange extends ControllerEvent &#123;</span><br><span class="line">    override def state: ControllerState = ControllerState.BrokerChange</span><br><span class="line"></span><br><span class="line">    <span class="function">override def <span class="title">process</span><span class="params">()</span>: Unit </span>= &#123;</span><br><span class="line">      <span class="keyword">if</span> (!isActive) <span class="keyword">return</span></span><br><span class="line">      <span class="comment">// 获取zk中当前所有broker的信息</span></span><br><span class="line">      val curBrokers = zkClient.getAllBrokersInCluster.toSet</span><br><span class="line">      val curBrokerIds = curBrokers.map(_.id)</span><br><span class="line">      val liveOrShuttingDownBrokerIds = controllerContext.liveOrShuttingDownBrokerIds</span><br><span class="line">      <span class="comment">// 新增的broker</span></span><br><span class="line">      val newBrokerIds = curBrokerIds -- liveOrShuttingDownBrokerIds</span><br><span class="line"></span><br><span class="line">      val deadBrokerIds = liveOrShuttingDownBrokerIds -- curBrokerIds</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 新broker的信息</span></span><br><span class="line">      val newBrokers = curBrokers.filter(broker =&gt; newBrokerIds(broker.id))</span><br><span class="line">      <span class="comment">// 更新缓存</span></span><br><span class="line">      controllerContext.liveBrokers = curBrokers</span><br><span class="line"></span><br><span class="line">      val newBrokerIdsSorted = newBrokerIds.toSeq.sorted</span><br><span class="line">      val deadBrokerIdsSorted = deadBrokerIds.toSeq.sorted</span><br><span class="line">      val liveBrokerIdsSorted = curBrokerIds.toSeq.sorted</span><br><span class="line">      info(s<span class="string">"Newly added brokers: $&#123;newBrokerIdsSorted.mkString("</span>,<span class="string">")&#125;, "</span> +</span><br><span class="line">        s<span class="string">"deleted brokers: $&#123;deadBrokerIdsSorted.mkString("</span>,<span class="string">")&#125;, all live brokers: $&#123;liveBrokerIdsSorted.mkString("</span>,<span class="string">")&#125;"</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 建立当前broker与新增broker之间的channel</span></span><br><span class="line">      newBrokers.foreach(controllerContext.controllerChannelManager.addBroker)</span><br><span class="line">      <span class="comment">// 关闭与dead broker直接的所有资源</span></span><br><span class="line">      deadBrokerIds.foreach(controllerContext.controllerChannelManager.removeBroker)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (newBrokerIds.nonEmpty)</span><br><span class="line">        onBrokerStartup(newBrokerIdsSorted)</span><br><span class="line">      <span class="keyword">if</span> (deadBrokerIds.nonEmpty)</span><br><span class="line">        onBrokerFailure(deadBrokerIdsSorted)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在<a href="">KafkaController源码分析之LeaderAndIsr请求</a>中已经提到了ControllerChannelManager，它是Controller节点与其它broker之间网络通信管理器，在得到上线和下线的broker集合后，分别做以下处理：</p><ol><li>上线，建立网络连接，并启动请求发送线程，用于处理leaderAndIsrRequest，stopReplicaRequest，updateMetadataRequest三类请求</li><li>下线，关闭网络连接，中断(interrupt)请求发送线程，清空请求队列</li></ol><p>此处源码较为简单，篇幅有限，不再贴出源码了。最后的两个if，表示如果有新增的broker，执行onBrokerStartup方法，有下线的broker执行onBrokerFailure方法</p><h2 id="broker上线处理onBrokerStartup"><a href="#broker上线处理onBrokerStartup" class="headerlink" title="broker上线处理onBrokerStartup"></a>broker上线处理onBrokerStartup</h2><p>该方法主要做了以下5件事：</p><ol><li>发送update metadata request，Controller把最新的broker列表同步给别的broker</li><li>将新broker上的分区和副本都置为Online状态，并选举分区leader副本，注意这里面已经包含了LeaderAndIsr请求</li><li>新broker上是否有重分配的副本，有就执行</li><li>如果新broker上有需要删除的topic，开始删除</li><li>注册了一个/broker/ids/0的数据变化的监听器——BrokerModificationsHandler，个人觉得broker元信息不会改变</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">onBrokerStartup</span><span class="params">(newBrokers: Seq[Int])</span> </span>&#123;</span><br><span class="line">    info(s<span class="string">"New broker startup callback for $&#123;newBrokers.mkString("</span>,<span class="string">")&#125;"</span>)</span><br><span class="line">    newBrokers.foreach(controllerContext.replicasOnOfflineDirs.remove)</span><br><span class="line">    val newBrokersSet = newBrokers.toSet</span><br><span class="line">    <span class="comment">// send update metadata request to all live and shutting down brokers. Old brokers will get to know of the new</span></span><br><span class="line">    <span class="comment">// broker via this update.</span></span><br><span class="line">    <span class="comment">// In cases of controlled shutdown leaders will not be elected when a new broker comes up. So at least in the</span></span><br><span class="line">    <span class="comment">// common controlled shutdown case, the metadata will reach the new brokers faster</span></span><br><span class="line">    sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq)</span><br><span class="line">    <span class="comment">// the very first thing to do when a new broker comes up is send it the entire list of partitions that it is</span></span><br><span class="line">    <span class="comment">// supposed to host. Based on that the broker starts the high watermark threads for the input list of partitions</span></span><br><span class="line">    val allReplicasOnNewBrokers = controllerContext.replicasOnBrokers(newBrokersSet)</span><br><span class="line">    replicaStateMachine.handleStateChanges(allReplicasOnNewBrokers.toSeq, OnlineReplica)</span><br><span class="line">    <span class="comment">// when a new broker comes up, the controller needs to trigger leader election for all new and offline partitions</span></span><br><span class="line">    <span class="comment">// to see if these brokers can become leaders for some/all of those</span></span><br><span class="line">    partitionStateMachine.triggerOnlinePartitionStateChange()</span><br><span class="line">    <span class="comment">// check if reassignment of some partitions need to be restarted</span></span><br><span class="line">    val partitionsWithReplicasOnNewBrokers = controllerContext.partitionsBeingReassigned.filter &#123;</span><br><span class="line">      <span class="keyword">case</span> (_, reassignmentContext) =&gt; reassignmentContext.newReplicas.exists(newBrokersSet.contains)</span><br><span class="line">    &#125;</span><br><span class="line">    partitionsWithReplicasOnNewBrokers.foreach &#123; <span class="keyword">case</span> (tp, context) =&gt; onPartitionReassignment(tp, context) &#125;</span><br><span class="line">    <span class="comment">// check if topic deletion needs to be resumed. If at least one replica that belongs to the topic being deleted exists</span></span><br><span class="line">    <span class="comment">// on the newly restarted brokers, there is a chance that topic deletion can resume</span></span><br><span class="line">    val replicasForTopicsToBeDeleted = allReplicasOnNewBrokers.filter(p =&gt; topicDeletionManager.isTopicQueuedUpForDeletion(p.topic))</span><br><span class="line">    <span class="keyword">if</span> (replicasForTopicsToBeDeleted.nonEmpty) &#123;</span><br><span class="line">      info(s<span class="string">"Some replicas $&#123;replicasForTopicsToBeDeleted.mkString("</span>,<span class="string">")&#125; for topics scheduled for deletion "</span> +</span><br><span class="line">        s<span class="string">"$&#123;topicDeletionManager.topicsToBeDeleted.mkString("</span>,<span class="string">")&#125; are on the newly restarted brokers "</span> +</span><br><span class="line">        s<span class="string">"$&#123;newBrokers.mkString("</span>,<span class="string">")&#125;. Signaling restart of topic deletion for these topics"</span>)</span><br><span class="line">      topicDeletionManager.resumeDeletionForTopics(replicasForTopicsToBeDeleted.map(_.topic))</span><br><span class="line">    &#125;</span><br><span class="line">    registerBrokerModificationsHandler(newBrokers)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="broker下线处理onBrokerFailure"><a href="#broker下线处理onBrokerFailure" class="headerlink" title="broker下线处理onBrokerFailure"></a>broker下线处理onBrokerFailure</h2><p>onBrokerFailure方法首先更新了本地缓存，之后调用了onReplicasBecomeOffline来处理副本下线的情况，之后移除了BrokerModificationsHandler，对应onBrokerStartup的最后一步</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">onBrokerFailure</span><span class="params">(deadBrokers: Seq[Int])</span> </span>&#123;</span><br><span class="line">    info(s<span class="string">"Broker failure callback for $&#123;deadBrokers.mkString("</span>,<span class="string">")&#125;"</span>)</span><br><span class="line">    <span class="comment">// 移除缓存中下线的broker上的分区</span></span><br><span class="line">    deadBrokers.foreach(controllerContext.replicasOnOfflineDirs.remove)</span><br><span class="line">    val deadBrokersThatWereShuttingDown =</span><br><span class="line">      deadBrokers.filter(id =&gt; controllerContext.shuttingDownBrokerIds.remove(id))</span><br><span class="line">    info(s<span class="string">"Removed $deadBrokersThatWereShuttingDown from list of shutting down brokers."</span>)</span><br><span class="line">    <span class="comment">// 下线broker上的副本</span></span><br><span class="line">    val allReplicasOnDeadBrokers = controllerContext.replicasOnBrokers(deadBrokers.toSet)</span><br><span class="line"></span><br><span class="line">    onReplicasBecomeOffline(allReplicasOnDeadBrokers)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 移除BrokerModificationsHandler</span></span><br><span class="line">    unregisterBrokerModificationsHandler(deadBrokers)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="处理下线broker中的副本"><a href="#处理下线broker中的副本" class="headerlink" title="处理下线broker中的副本"></a>处理下线broker中的副本</h3><p>该方法看似复杂，但是逻辑很严谨，建议大家仔细看看。它主要做了以下事情：</p><ol><li>将leader副本在dead broker上的分区找出来</li><li>将这些分区置为OfflinePartition状态</li><li>用这些分区剩下的副本触发一次leader选举</li><li>将dead broker上的副本置为Offline</li><li>如果dead broker上有要删除的topic，标记为删除失败，毕竟都下线了怎么删？</li><li>如果dead broker上没有分区的leader副本，也就是第1步返回的是空，就发送UpdateMetadataRequest给剩下活着的broker</li></ol><p>总之该方法逻辑很严谨，算是一个比较重点的步骤</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">onReplicasBecomeOffline</span><span class="params">(newOfflineReplicas: Set[PartitionAndReplica])</span>: Unit </span>= &#123;</span><br><span class="line">    val (newOfflineReplicasForDeletion, newOfflineReplicasNotForDeletion) =</span><br><span class="line">      newOfflineReplicas.partition(p =&gt; topicDeletionManager.isTopicQueuedUpForDeletion(p.topic))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将leader在dead broker上的分区找出来</span></span><br><span class="line">    val partitionsWithoutLeader = controllerContext.partitionLeadershipInfo.filter(partitionAndLeader =&gt;</span><br><span class="line">      !controllerContext.isReplicaOnline(partitionAndLeader._2.leaderAndIsr.leader, partitionAndLeader._1) &amp;&amp;</span><br><span class="line">        !topicDeletionManager.isTopicQueuedUpForDeletion(partitionAndLeader._1.topic)).keySet</span><br><span class="line"></span><br><span class="line">    <span class="comment">// trigger OfflinePartition state for all partitions whose current leader is one amongst the newOfflineReplicas</span></span><br><span class="line">    <span class="comment">// 标记这些分区为OfflinePartition状态</span></span><br><span class="line">    partitionStateMachine.handleStateChanges(partitionsWithoutLeader.toSeq, OfflinePartition)</span><br><span class="line">    <span class="comment">// 用这些剩余分区剩余的副本选举leader</span></span><br><span class="line">    <span class="comment">// trigger OnlinePartition state changes for offline or new partitions</span></span><br><span class="line">    partitionStateMachine.triggerOnlinePartitionStateChange()</span><br><span class="line">    <span class="comment">// trigger OfflineReplica state change for those newly offline replicas</span></span><br><span class="line">    <span class="comment">// dead broker上的副本置为Offline</span></span><br><span class="line">    replicaStateMachine.handleStateChanges(newOfflineReplicasNotForDeletion.toSeq, OfflineReplica)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// broker已下线，删除失败</span></span><br><span class="line">    <span class="comment">// fail deletion of topics that are affected by the offline replicas</span></span><br><span class="line">    <span class="keyword">if</span> (newOfflineReplicasForDeletion.nonEmpty) &#123;</span><br><span class="line">      <span class="comment">// it is required to mark the respective replicas in TopicDeletionFailed state since the replica cannot be</span></span><br><span class="line">      <span class="comment">// deleted when its log directory is offline. This will prevent the replica from being in TopicDeletionStarted state indefinitely</span></span><br><span class="line">      <span class="comment">// since topic deletion cannot be retried until at least one replica is in TopicDeletionStarted state</span></span><br><span class="line">      topicDeletionManager.failReplicaDeletion(newOfflineReplicasForDeletion)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If replica failure did not require leader re-election, inform brokers of the offline replica</span></span><br><span class="line">    <span class="comment">// Note that during leader re-election, brokers update their metadata</span></span><br><span class="line">    <span class="comment">// 如果dead broker上没有分区的leader副本，就发送UpdateMetadataRequest给活着的broker</span></span><br><span class="line">    <span class="keyword">if</span> (partitionsWithoutLeader.isEmpty) &#123;</span><br><span class="line">      sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>KafkaController源码分析之分区副本重分配(PartitionReassignment)与Preferred leader副本选举</title>
      <link href="/2020/02/25/KafkaController%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E5%88%86%E5%8C%BA%E9%87%8D%E5%88%86%E9%85%8D-PartitionReassignment%E4%B8%8EPreferred%20leader%E5%89%AF%E6%9C%AC%E9%80%89%E4%B8%BE/"/>
      <url>/2020/02/25/KafkaController%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E5%88%86%E5%8C%BA%E9%87%8D%E5%88%86%E9%85%8D-PartitionReassignment%E4%B8%8EPreferred%20leader%E5%89%AF%E6%9C%AC%E9%80%89%E4%B8%BE/</url>
      <content type="html"><![CDATA[<p>本文继续讲解Controller初始化过程，分析副本重分配过程</p><h1 id="分区副本重分配"><a href="#分区副本重分配" class="headerlink" title="分区副本重分配"></a>分区副本重分配</h1><p>首先什么是分区副本重分配(PartitionReassignment)，以下摘自《Apache Kafka实战》一书对其做了阐释</p><blockquote><p>分区副本重分配操作通常都是由Kafka集群的管理员发起的，旨在对topic的所有分区重新分配副本所在broker的位置，以期望实现更均匀的分配效果。在该操作中管理员需要手动制定分配方案并按照指定的格式写入ZooKeeper的/admin/reassign_partitions节点下。</p></blockquote><p>具体的操作可以参考<a href="https://www.cnblogs.com/xionggeclub/p/9390037.html" target="_blank" rel="noopener">https://www.cnblogs.com/xionggeclub/p/9390037.html</a></p><p>该操作适用于集群扩容，管理员进行手动执行命令来发起</p><h2 id="分区副本重分配事件的监听与处理"><a href="#分区副本重分配事件的监听与处理" class="headerlink" title="分区副本重分配事件的监听与处理"></a>分区副本重分配事件的监听与处理</h2><p>分区副本重分配主要由/admin/reassign_partitions节点的create事件触发，该事件的处理器为partitionReassignmentHandler,在<a href="">kafka-server端源码分析之Controller选举与初始化</a>一文中的处理器表格中已有介绍<br>同时该节点是临时节点，只有发起时才会创建该节点，重分配过程结束后会删除该节点</p><h2 id="分区副本重分配-1"><a href="#分区副本重分配-1" class="headerlink" title="分区副本重分配"></a>分区副本重分配</h2><p>分区副本重分配的方法入口是maybeTriggerPartitionReassignment方法，该方法会在Controller初始化和PartitionReassignment事件处理器中调用</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// KafkaController onControllerFailover方法中的重分配</span></span><br><span class="line">maybeTriggerPartitionReassignment(controllerContext.partitionsBeingReassigned.keySet)</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> object PartitionReassignment extends ControllerEvent &#123;</span><br><span class="line">override def state: ControllerState = ControllerState.PartitionReassignment</span><br><span class="line"></span><br><span class="line"><span class="function">override def <span class="title">process</span><span class="params">()</span>: Unit </span>= &#123;</span><br><span class="line">  <span class="keyword">if</span> (!isActive) <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// We need to register the watcher if the path doesn't exist in order to detect future reassignments and we get</span></span><br><span class="line">  <span class="comment">// the `path exists` check for free</span></span><br><span class="line">  <span class="comment">// 注册 partitionReassignmentHandler</span></span><br><span class="line">  <span class="keyword">if</span> (zkClient.registerZNodeChangeHandlerAndCheckExistence(partitionReassignmentHandler)) &#123;</span><br><span class="line">    <span class="comment">// 获取重分配方案</span></span><br><span class="line">    val partitionReassignment = zkClient.getPartitionReassignment</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Populate `partitionsBeingReassigned` with all partitions being reassigned before invoking</span></span><br><span class="line">    <span class="comment">// `maybeTriggerPartitionReassignment` (see method documentation for the reason)</span></span><br><span class="line">    partitionReassignment.foreach &#123; <span class="keyword">case</span> (tp, newReplicas) =&gt;</span><br><span class="line">      <span class="comment">// 重分配引起的isr改变事件监听 </span></span><br><span class="line">      val reassignIsrChangeHandler = <span class="keyword">new</span> PartitionReassignmentIsrChangeHandler(KafkaController.<span class="keyword">this</span>, eventManager,</span><br><span class="line">        tp)</span><br><span class="line">      <span class="comment">// 重分配缓存，ReassignedPartitionsContext：重分配的新副本，isr监听处理器</span></span><br><span class="line">      controllerContext.partitionsBeingReassigned.put(tp, ReassignedPartitionsContext(newReplicas, reassignIsrChangeHandler))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    maybeTriggerPartitionReassignment(partitionReassignment.keySet)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>maybeTriggerPartitionReassignment的源码如下，更多是做准备，剔除不需要重分配的分区，真正开始重分配是调用 onPartitionReassignment方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">maybeTriggerPartitionReassignment</span><span class="params">(topicPartitions: Set[TopicPartition])</span> </span>&#123;</span><br><span class="line">val partitionsToBeRemovedFromReassignment = scala.collection.mutable.Set.empty[TopicPartition]</span><br><span class="line"></span><br><span class="line">topicPartitions.foreach &#123; tp =&gt;</span><br><span class="line">  <span class="keyword">if</span> (topicDeletionManager.isTopicQueuedUpForDeletion(tp.topic)) &#123;</span><br><span class="line">    error(s<span class="string">"Skipping reassignment of $tp since the topic is currently being deleted"</span>)</span><br><span class="line">    partitionsToBeRemovedFromReassignment.add(tp)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    val reassignedPartitionContext = controllerContext.partitionsBeingReassigned.get(tp).getOrElse &#123;</span><br><span class="line">      <span class="comment">// 防止partitionsBeingReassigned被改变(加锁不更好吗)</span></span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(s<span class="string">"Initiating reassign replicas for partition $tp not present in "</span> +</span><br><span class="line">        s<span class="string">"partitionsBeingReassigned: $&#123;controllerContext.partitionsBeingReassigned.mkString("</span>, <span class="string">")&#125;"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    val newReplicas = reassignedPartitionContext.newReplicas</span><br><span class="line">    val topic = tp.topic</span><br><span class="line">    val assignedReplicas = controllerContext.partitionReplicaAssignment(tp)</span><br><span class="line">    <span class="keyword">if</span> (assignedReplicas.nonEmpty) &#123;</span><br><span class="line">      <span class="keyword">if</span> (assignedReplicas == newReplicas) &#123;</span><br><span class="line">        info(s<span class="string">"Partition $tp to be reassigned is already assigned to replicas "</span> +</span><br><span class="line">          s<span class="string">"$&#123;newReplicas.mkString("</span>,<span class="string">")&#125;. Ignoring request for partition reassignment."</span>)</span><br><span class="line">        partitionsToBeRemovedFromReassignment.add(tp)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          info(s<span class="string">"Handling reassignment of partition $tp to new replicas $&#123;newReplicas.mkString("</span>,<span class="string">")&#125;"</span>)</span><br><span class="line">          <span class="comment">// first register ISR change listener</span></span><br><span class="line">          <span class="comment">// 注册PartitionReassignmentIsrChangeHandler</span></span><br><span class="line">          reassignedPartitionContext.registerReassignIsrChangeHandler(zkClient)</span><br><span class="line">          <span class="comment">// mark topic ineligible for deletion for the partitions being reassigned</span></span><br><span class="line">          <span class="comment">// 标记为删除失败</span></span><br><span class="line">          topicDeletionManager.markTopicIneligibleForDeletion(Set(topic))</span><br><span class="line">          <span class="comment">// 分区副本重分配</span></span><br><span class="line">          onPartitionReassignment(tp, reassignedPartitionContext)</span><br><span class="line">        &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">          <span class="keyword">case</span> e: Throwable =&gt;</span><br><span class="line">            error(s<span class="string">"Error completing reassignment of partition $tp"</span>, e)</span><br><span class="line">            <span class="comment">// remove the partition from the admin path to unblock the admin client</span></span><br><span class="line">            partitionsToBeRemovedFromReassignment.add(tp)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        error(s<span class="string">"Ignoring request to reassign partition $tp that doesn't exist."</span>)</span><br><span class="line">        partitionsToBeRemovedFromReassignment.add(tp)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">removePartitionsFromReassignedPartitions(partitionsToBeRemovedFromReassignment)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="分区副本重分配核心流程"><a href="#分区副本重分配核心流程" class="headerlink" title="分区副本重分配核心流程"></a>分区副本重分配核心流程</h2><p>onPartitionReassignment方法是完整的重分配流程，主要分为以下几个步骤</p><ol><li>先根据是否所有要分配的副本都在isr中分为2种情况</li><li>不是所有的副本都在isr里时，取原来的副本和重分配的副本的并集，更新到/brokers/topics/topic节点的数据里，发送LeaderAndIsr请求。将重分配副本中比原来多出来的副本，设置为NewReplica状态</li><li>所有的副本都在isr里时，检查重分配的副本里是否包含leader副本，不包含或者leader副本不在线时，根据ReassignPartitionLeaderElectionStrategy重新选举leader，否则仅仅是leader epoch+1更新回zk</li><li>删除老副本(没有参与到reassign里的副本)</li><li>更新缓存，并写回zk,删除/admin/reassign_partitions节点</li><li>发送元数据更新请求，更新到每一个broker</li><li>把本次reassign过程中的topic，看看有没有要删除的，进行删除</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">onPartitionReassignment</span><span class="params">(topicPartition: TopicPartition, reassignedPartitionContext: ReassignedPartitionsContext)</span> </span>&#123;</span><br><span class="line">  val reassignedReplicas = reassignedPartitionContext.newReplicas</span><br><span class="line">  <span class="comment">// 是否所有要分配的副本都在isr中</span></span><br><span class="line">  <span class="keyword">if</span> (!areReplicasInIsr(topicPartition, reassignedReplicas)) &#123; <span class="comment">// 说明不是所有的副本都在isr里</span></span><br><span class="line">    info(s<span class="string">"New replicas $&#123;reassignedReplicas.mkString("</span>,<span class="string">")&#125; for partition $topicPartition being reassigned not yet "</span> +</span><br><span class="line">      <span class="string">"caught up with the leader"</span>)</span><br><span class="line">    <span class="comment">// 即将要分配的 减去 之前已分配(缓存里)</span></span><br><span class="line">    val newReplicasNotInOldReplicaList = reassignedReplicas.toSet -- controllerContext.partitionReplicaAssignment(topicPartition).toSet</span><br><span class="line">    <span class="comment">// 新的 + 老的 (会去重) = 全部的</span></span><br><span class="line">    val newAndOldReplicas = (reassignedPartitionContext.newReplicas ++ controllerContext.partitionReplicaAssignment(topicPartition)).toSet</span><br><span class="line">    <span class="comment">//1. Update AR in ZK with OAR + RAR.</span></span><br><span class="line">    <span class="comment">//1. 更新reassign之后的全量副本到 /brokers/topics/topic节点</span></span><br><span class="line">    updateAssignedReplicasForPartition(topicPartition, newAndOldReplicas.toSeq)</span><br><span class="line">    <span class="comment">//2. Send LeaderAndIsr request to every replica in OAR + RAR (with AR as OAR + RAR).</span></span><br><span class="line">    <span class="comment">//3. 发送LeaderAndIsr请求 TODO 这里缓存里的ReplicaAssignment应该等于newAndOldReplicas的, 但是replica也是brokerId</span></span><br><span class="line">    updateLeaderEpochAndSendRequest(topicPartition, controllerContext.partitionReplicaAssignment(topicPartition),</span><br><span class="line">      newAndOldReplicas.toSeq)</span><br><span class="line">    <span class="comment">//3. replicas in RAR - OAR -&gt; NewReplica</span></span><br><span class="line">    <span class="comment">//3. 新增的副本转为NewReplica状态</span></span><br><span class="line">    startNewReplicasForReassignedPartition(topicPartition, reassignedPartitionContext, newReplicasNotInOldReplicaList)</span><br><span class="line">    info(s<span class="string">"Waiting for new replicas $&#123;reassignedReplicas.mkString("</span>,<span class="string">")&#125; for partition $&#123;topicPartition&#125; being "</span> +</span><br><span class="line">      <span class="string">"reassigned to catch up with the leader"</span>)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">//4. Wait until all replicas in RAR are in sync with the leader.</span></span><br><span class="line">    <span class="comment">// 重分配时原来就有的副本</span></span><br><span class="line">    val oldReplicas = controllerContext.partitionReplicaAssignment(topicPartition).toSet -- reassignedReplicas.toSet</span><br><span class="line">    <span class="comment">//5. replicas in RAR -&gt; OnlineReplica</span></span><br><span class="line">    <span class="comment">// reassignedReplicas副本转为OnlineReplica状态，因为它们都在ISR中</span></span><br><span class="line">    reassignedReplicas.foreach &#123; replica =&gt;</span><br><span class="line">      replicaStateMachine.handleStateChanges(Seq(<span class="keyword">new</span> PartitionAndReplica(topicPartition, replica)), OnlineReplica)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//6. Set AR to RAR in memory.</span></span><br><span class="line">    <span class="comment">//7. Send LeaderAndIsr request with a potential new leader (if current leader not in RAR) and</span></span><br><span class="line">    <span class="comment">//   a new AR (using RAR) and same isr to every broker in RAR</span></span><br><span class="line">    moveReassignedPartitionLeaderIfRequired(topicPartition, reassignedPartitionContext)</span><br><span class="line">    <span class="comment">//8. replicas in OAR - RAR -&gt; Offline (force those replicas out of isr)</span></span><br><span class="line">    <span class="comment">//9. replicas in OAR - RAR -&gt; NonExistentReplica (force those replicas to be deleted)</span></span><br><span class="line">    <span class="comment">// 删除老副本(没有参与到reassign里的副本)</span></span><br><span class="line">    stopOldReplicasOfReassignedPartition(topicPartition, reassignedPartitionContext, oldReplicas)</span><br><span class="line">    <span class="comment">//10. Update AR in ZK with RAR.</span></span><br><span class="line">    <span class="comment">// 更新缓存，并写回zk</span></span><br><span class="line">    updateAssignedReplicasForPartition(topicPartition, reassignedReplicas)</span><br><span class="line">    <span class="comment">//11. Update the /admin/reassign_partitions path in ZK to remove this partition.</span></span><br><span class="line">    <span class="comment">// 删除/admin/reassign_partitions节点</span></span><br><span class="line">    removePartitionsFromReassignedPartitions(Set(topicPartition))</span><br><span class="line">    <span class="comment">//12. After electing leader, the replicas and isr information changes, so resend the update metadata request to every broker</span></span><br><span class="line">    <span class="comment">// 更新到每一个broker</span></span><br><span class="line">    sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq, Set(topicPartition))</span><br><span class="line">    <span class="comment">// signal delete topic thread if reassignment for some partitions belonging to topics being deleted just completed</span></span><br><span class="line">    <span class="comment">// 把本次reassign过程中的topic，看看有没有要删除的，进行删除</span></span><br><span class="line">    topicDeletionManager.resumeDeletionForTopics(Set(topicPartition.topic))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>整个过程还是十分复杂的，但是我并没有按照注释用一堆RAR，OAR，AR的概念来解释，那样很容易记混，反而是看懂了代码，再去理解这些概括水到渠成<br><img src="https://ae01.alicdn.com/kf/H33d287c097124677b568b65210d808d5V.png" alt="分区副本重分配流程"></p><p>最后再聊一下ReassignPartitionLeaderElectionStrategy</p><h3 id="分区副本重分配的leader选举算法"><a href="#分区副本重分配的leader选举算法" class="headerlink" title="分区副本重分配的leader选举算法"></a>分区副本重分配的leader选举算法</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">leaderForReassign</span><span class="params">(leaderIsrAndControllerEpochs: Seq[(TopicPartition, LeaderIsrAndControllerEpoch)</span>]):</span></span><br><span class="line"><span class="function">Seq[<span class="params">(TopicPartition, Option[LeaderAndIsr], Seq[Int])</span>] </span>= &#123;</span><br><span class="line">  leaderIsrAndControllerEpochs.map &#123; <span class="keyword">case</span> (partition, leaderIsrAndControllerEpoch) =&gt;</span><br><span class="line">    <span class="comment">// 重分配的副本</span></span><br><span class="line">    val reassignment = controllerContext.partitionsBeingReassigned(partition).newReplicas</span><br><span class="line">    <span class="comment">// 存活的重分配副本</span></span><br><span class="line">    val liveReplicas = reassignment.filter(replica =&gt; controllerContext.isReplicaOnline(replica, partition))</span><br><span class="line">    <span class="comment">// isr</span></span><br><span class="line">    val isr = leaderIsrAndControllerEpoch.leaderAndIsr.isr</span><br><span class="line">    <span class="comment">// 选举算法计算leader</span></span><br><span class="line">    val leaderOpt = PartitionLeaderElectionAlgorithms.reassignPartitionLeaderElection(reassignment, isr, liveReplicas.toSet)</span><br><span class="line">    val newLeaderAndIsrOpt = leaderOpt.map(leader =&gt; leaderIsrAndControllerEpoch.leaderAndIsr.newLeader(leader))</span><br><span class="line">    (partition, newLeaderAndIsrOpt, reassignment)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@param</span> reassignment 要重分配的副本</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@param</span> isr isr副本</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@param</span> liveReplicas reassignment中存活的副本</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="function">def <span class="title">reassignPartitionLeaderElection</span><span class="params">(reassignment: Seq[Int], isr: Seq[Int], liveReplicas: Set[Int])</span>: Option[Int] </span>= &#123;</span><br><span class="line">  <span class="comment">// reassignment里 liveReplicas和isr都有的副本 (取第一个)</span></span><br><span class="line">  reassignment.find(id =&gt; liveReplicas.contains(id) &amp;&amp; isr.contains(id))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="Preferred-leader副本"><a href="#Preferred-leader副本" class="headerlink" title="Preferred leader副本"></a>Preferred leader副本</h1><p>什么是Preferred leader副本</p><blockquote><p>Kafka在给每个Partition分配副本时，它会保证分区的主副本会均匀分布在所有的broker上，这样的话只要保证第一个replica被选举为leader，读写流量就会均匀分布在所有的Broker上，但是在实际的生产环境,每个 Partition的读写流量相差可能较多，不一定可以达到该目的</p></blockquote><h2 id="zk事件监听"><a href="#zk事件监听" class="headerlink" title="zk事件监听"></a>zk事件监听</h2><p>Preferred leader副本选举由/admin/preferred_replica_election节点的创建事件触发，对应的节点handler为PreferredReplicaElectionHandler，对应的创建事件处理器为PreferredReplicaLeaderElection</p><p>PreferredReplicaLeaderElection的核心处理方法为onPreferredReplicaElection，同时该方法也会在Controller初始化的onControllerFailover中被调用，用于Preferred leader副本选举</p><h2 id="Preferred-leader副本选举"><a href="#Preferred-leader副本选举" class="headerlink" title="Preferred leader副本选举"></a>Preferred leader副本选举</h2><p>Controller的onControllerFailover方法的调用如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val pendingPreferredReplicaElections = fetchPendingPreferredReplicaElections()</span><br><span class="line">onPreferredReplicaElection(pendingPreferredReplicaElections)</span><br></pre></td></tr></table></figure></p><p>首先是通过fetchPendingPreferredReplicaElections获取要进行Preferred leader副本选举的分区</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">fetchPendingPreferredReplicaElections</span><span class="params">()</span>: Set[TopicPartition] </span>= &#123;</span><br><span class="line">    <span class="comment">// 获取/admin/preferred_replica_election节点数据</span></span><br><span class="line">    val partitionsUndergoingPreferredReplicaElection = zkClient.getPreferredReplicaElection</span><br><span class="line">    <span class="comment">// check if they are already completed or topic was deleted</span></span><br><span class="line">    <span class="comment">// 分区没有副本或者已经是Preferred Replica了</span></span><br><span class="line">    val partitionsThatCompletedPreferredReplicaElection = partitionsUndergoingPreferredReplicaElection.filter &#123; partition =&gt;</span><br><span class="line">      val replicas = controllerContext.partitionReplicaAssignment(partition)</span><br><span class="line">      val topicDeleted = replicas.isEmpty</span><br><span class="line">      val successful =</span><br><span class="line">        <span class="keyword">if</span> (!topicDeleted) controllerContext.partitionLeadershipInfo(partition).leaderAndIsr.leader == replicas.head <span class="keyword">else</span> <span class="keyword">false</span></span><br><span class="line">      successful || topicDeleted</span><br><span class="line">    &#125;</span><br><span class="line">    val pendingPreferredReplicaElectionsIgnoringTopicDeletion = partitionsUndergoingPreferredReplicaElection -- partitionsThatCompletedPreferredReplicaElection</span><br><span class="line">    val pendingPreferredReplicaElectionsSkippedFromTopicDeletion = pendingPreferredReplicaElectionsIgnoringTopicDeletion.filter(partition =&gt; topicDeletionManager.isTopicQueuedUpForDeletion(partition.topic))</span><br><span class="line">    val pendingPreferredReplicaElections = pendingPreferredReplicaElectionsIgnoringTopicDeletion -- pendingPreferredReplicaElectionsSkippedFromTopicDeletion</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 准备要preferred replica选举的分区</span></span><br><span class="line">    pendingPreferredReplicaElections</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="核心流程"><a href="#核心流程" class="headerlink" title="核心流程"></a>核心流程</h2><p>onPreferredReplicaElection方法通过分区状态机，将分区转换为OnlinePartition状态，并根据PreferredReplicaPartitionLeaderElectionStrategy选举leader，下面我们直接看相关的代码，由于在<a href="">KafkaController源码分析之副本状态机与分区状态机的启动</a>已经讲解过该方法了，我们直接看一下ReassignPartitionLeaderElectionStrategy算法的实现</p><p>取第一个即是存活的，又在isr列表中的副本<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">preferredReplicaPartitionLeaderElection</span><span class="params">(assignment: Seq[Int], isr: Seq[Int], liveReplicas: Set[Int])</span>: Option[Int] </span>= &#123;</span><br><span class="line">  assignment.headOption.filter(id =&gt; liveReplicas.contains(id) &amp;&amp; isr.contains(id))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>KafkaController源码分析之副本状态机与分区状态机的启动</title>
      <link href="/2020/02/23/KafkaController%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E5%89%AF%E6%9C%AC%E7%8A%B6%E6%80%81%E6%9C%BA%E4%B8%8E%E5%88%86%E5%8C%BA%E7%8A%B6%E6%80%81%E6%9C%BA%E7%9A%84%E5%90%AF%E5%8A%A8/"/>
      <url>/2020/02/23/KafkaController%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E5%89%AF%E6%9C%AC%E7%8A%B6%E6%80%81%E6%9C%BA%E4%B8%8E%E5%88%86%E5%8C%BA%E7%8A%B6%E6%80%81%E6%9C%BA%E7%9A%84%E5%90%AF%E5%8A%A8/</url>
      <content type="html"><![CDATA[<p>本文承接上篇<a href="">kafka-server端源码分析之Controller初始化</a>，继续讲解Controller初始化过程中副本状态机与分区状态机的启动</p><h1 id="副本状态机"><a href="#副本状态机" class="headerlink" title="副本状态机"></a>副本状态机</h1><p>kafka将副本分为7个状态，下图是状态之间的流转图</p><p><img src="https://ae01.alicdn.com/kf/H43a853d3980c475c9f6894950bb29e41v.png" alt="副本状态流转图"></p><p>副本状态用ReplicaState接口表示，需要说下validPreviousStates方法，它表示合法的开始状态，以NewReplica为例，它只能由NonExistentReplica状态转换而来<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> object NewReplica extends ReplicaState &#123;</span><br><span class="line">  val state: Byte = <span class="number">1</span></span><br><span class="line">  val validPreviousStates: Set[ReplicaState] = Set(NonExistentReplica)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>而状态之间的转换，必将涉及到大量的更新操作，ReplicaStateMachine#doHandleStateChanges方法统一处理了状态转换</p><p>回过头来说replicaStateMachine.startup()方法，它主要是将在线的副本转换为OnlineReplica状态</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">startup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 这一步简单却很重要，初始化replicaState，它保存了每个副本的状态</span></span><br><span class="line">  <span class="comment">// 为之后handleStateChanges转变为OnlineReplica做准备</span></span><br><span class="line">  initializeReplicaState()</span><br><span class="line"></span><br><span class="line">  handleStateChanges(controllerContext.allLiveReplicas().toSeq, OnlineReplica)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="初始化副本状态缓存"><a href="#初始化副本状态缓存" class="headerlink" title="初始化副本状态缓存"></a>初始化副本状态缓存</h2><p>首先看initializeReplicaState的初始化，只要理解了controllerContext没有什么难度<br>该方法主要初始化了一个replicaState缓存，记录了每一个副本的状态，根据是否在线分为OnlineReplica和ReplicaDeletionIneligible状态<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">initializeReplicaState</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  controllerContext.allPartitions.foreach &#123; partition =&gt;</span><br><span class="line">    val replicas = controllerContext.partitionReplicaAssignment(partition)</span><br><span class="line">    replicas.foreach &#123; replicaId =&gt;</span><br><span class="line">      val partitionAndReplica = PartitionAndReplica(partition, replicaId)</span><br><span class="line">      <span class="keyword">if</span> (controllerContext.isReplicaOnline(replicaId, partition))</span><br><span class="line">        replicaState.put(partitionAndReplica, OnlineReplica)</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">      <span class="comment">// mark replicas on dead brokers as failed for topic deletion, if they belong to a topic to be deleted.</span></span><br><span class="line">      <span class="comment">// This is required during controller failover since during controller failover a broker can go down,</span></span><br><span class="line">      <span class="comment">// so the replicas on that broker should be moved to ReplicaDeletionIneligible to be on the safer side.</span></span><br><span class="line">        replicaState.put(partitionAndReplica, ReplicaDeletionIneligible)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>初始化replicaState之后，handleStateChanges将所有存活的副本转换为OnlineReplica，此时正常的副本就是从OnlineReplica -&gt; OnlineReplica<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">handleStateChanges</span><span class="params">(replicas: Seq[PartitionAndReplica], targetState: ReplicaState,</span></span></span><br><span class="line"><span class="function"><span class="params">                       callbacks: Callbacks = new Callbacks()</span>): Unit </span>= &#123;</span><br><span class="line">  <span class="keyword">if</span> (replicas.nonEmpty) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      controllerBrokerRequestBatch.newBatch()</span><br><span class="line">      replicas.groupBy(_.replica).map &#123; <span class="keyword">case</span> (replicaId, replicas) =&gt;</span><br><span class="line">        val partitions = replicas.map(_.topicPartition)</span><br><span class="line">        doHandleStateChanges(replicaId, partitions, targetState, callbacks)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 发送ControllerChannelManager中积攒的请求</span></span><br><span class="line">      controllerBrokerRequestBatch.sendRequestsToBrokers(controllerContext.epoch)</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: Throwable =&gt; error(s<span class="string">"Error while moving some replicas to $targetState state"</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>doHandleStateChanges用于处理副本状态转换，此时我们只关注targetState是OnlineReplica的处理</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">doHandleStateChanges</span><span class="params">(replicaId: Int, partitions: Seq[TopicPartition], targetState: ReplicaState,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   callbacks: Callbacks)</span>: Unit </span>= &#123;</span><br><span class="line">  <span class="comment">// 这里又组成了Seq[PartitionAndReplica]</span></span><br><span class="line">  val replicas = partitions.map(partition =&gt; PartitionAndReplica(partition, replicaId))</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 查看该副本的状态，不存在Update为NonExistentReplica</span></span><br><span class="line">  replicas.foreach(replica =&gt; replicaState.getOrElseUpdate(replica, NonExistentReplica))</span><br><span class="line"></span><br><span class="line">  <span class="comment">// isValidTransition: 对转换的开始状态做合法性校验，参考前面副本状态机的介绍</span></span><br><span class="line">  <span class="comment">// 注意这里的partition方法不是分区的意思，它是一个布尔分组器</span></span><br><span class="line">  <span class="comment">// validReplicas是转换合法的副本，invalidReplicas是非合法的</span></span><br><span class="line">  val (validReplicas, invalidReplicas) = replicas.partition(replica =&gt; isValidTransition(replica, targetState))</span><br><span class="line">  <span class="comment">// 不合法主要用日志记录异常</span></span><br><span class="line">  invalidReplicas.foreach(replica =&gt; logInvalidTransition(replica, targetState))</span><br><span class="line">  <span class="comment">// 初始化Controller时，targetState=OnlineReplica</span></span><br><span class="line">  <span class="comment">//validReplicas==&gt;Seq[PartitionAndReplica]</span></span><br><span class="line">  targetState match &#123;</span><br><span class="line">    <span class="keyword">case</span> OnlineReplica =&gt; <span class="comment">// previousState: NewReplica, OnlineReplica, OfflineReplica, ReplicaDeletionIneligible</span></span><br><span class="line">        validReplicas.foreach &#123; replica =&gt;</span><br><span class="line">          val partition = replica.topicPartition</span><br><span class="line">          replicaState(replica) match &#123; <span class="comment">// 这里获取的是副本的状态</span></span><br><span class="line">            <span class="keyword">case</span> NewReplica =&gt;</span><br><span class="line">              <span class="comment">// NewReplica-&gt;OnlineReplica，本地分区副本分配缓存里如果没有该副本，就更新进去</span></span><br><span class="line">              val assignment = controllerContext.partitionReplicaAssignment(partition) <span class="comment">// 从缓存中获取分区对应的副本集合</span></span><br><span class="line">              <span class="keyword">if</span> (!assignment.contains(replicaId)) &#123;</span><br><span class="line">                controllerContext.updatePartitionReplicaAssignment(partition, assignment :+ replicaId) </span><br><span class="line">              &#125;</span><br><span class="line">            <span class="keyword">case</span> _ =&gt;</span><br><span class="line">              controllerContext.partitionLeadershipInfo.get(partition) match &#123;</span><br><span class="line">                <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(leaderIsrAndControllerEpoch)</span> </span>=&gt;</span><br><span class="line">                  <span class="comment">// 发送LeaderAndIsr请求(放入等待队列)</span></span><br><span class="line">                  controllerBrokerRequestBatch.addLeaderAndIsrRequestForBrokers(Seq(replicaId),</span><br><span class="line">                    replica.topicPartition,</span><br><span class="line">                    leaderIsrAndControllerEpoch,</span><br><span class="line">                    controllerContext.partitionReplicaAssignment(partition), isNew = <span class="keyword">false</span>)</span><br><span class="line">                <span class="keyword">case</span> None =&gt;</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          logSuccessfulTransition(replicaId, partition, replicaState(replica), OnlineReplica)</span><br><span class="line">          replicaState.put(replica, OnlineReplica)</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="comment">// 省略其他状态的处理 ......</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>NewReplica, OnlineReplica, OfflineReplica, ReplicaDeletionIneligible状态都可以转换到OnlineReplica状态<br>NewReplica会检查本地缓存，没有就更新,而其他状态需要发送LeaderAndIsr请求同步broker之间的数据</p><p>至此副本状态机的启动结束了，LeaderAndIsr请求作为kafka最核心的一个请求会在后面单独的篇章解析。</p><h1 id="分区状态机"><a href="#分区状态机" class="headerlink" title="分区状态机"></a>分区状态机</h1><p>分区状态机相比于副本状态机而言，状态个数只有4个，但是涉及到副本leader选举，状态流转的复杂度高很多</p><p><img src="https://ae01.alicdn.com/kf/Hba4113a46e4248c6bf942b6b46374ca1i.png" alt="分区状态流转图"></p><p>PartitionStateMachine的startup方法如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">startup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 初始化分区的state</span></span><br><span class="line">  initializePartitionState()</span><br><span class="line">  triggerOnlinePartitionStateChange()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="初始化分区状态缓存"><a href="#初始化分区状态缓存" class="headerlink" title="初始化分区状态缓存"></a>初始化分区状态缓存</h2><p>和副本状态机类似，initializePartitionState也是用一个partitionState初始化每个分区的状态<br>将缓存中所有分区分为3种初始化状态</p><ol><li>有leader副本，并且在线，标记为OnlinePartition状态，不在线为OfflinePartition</li><li>没有leader标记分区为NewPartition状态<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">initializePartitionState</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (topicPartition &lt;- controllerContext.allPartitions) &#123;</span><br><span class="line">    <span class="comment">// check if leader and isr path exists for partition. If not, then it is in NEW state</span></span><br><span class="line">    <span class="comment">// 获取leader和isr信息</span></span><br><span class="line">    controllerContext.partitionLeadershipInfo.get(topicPartition) match &#123;</span><br><span class="line">      <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(currentLeaderIsrAndEpoch)</span> </span>=&gt;</span><br><span class="line">        <span class="comment">// else, check if the leader for partition is alive. If yes, it is in Online state, else it is in Offline state</span></span><br><span class="line">        <span class="comment">// leader存活就是OnlinePartition状态的分区，否则就是OfflinePartition</span></span><br><span class="line">        <span class="keyword">if</span> (controllerContext.isReplicaOnline(currentLeaderIsrAndEpoch.leaderAndIsr.leader, topicPartition))</span><br><span class="line">        <span class="comment">// leader is alive</span></span><br><span class="line">          partitionState.put(topicPartition, OnlinePartition)</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">          partitionState.put(topicPartition, OfflinePartition)</span><br><span class="line">      <span class="keyword">case</span> None =&gt;</span><br><span class="line">        <span class="comment">// 没有leader为NewPartition状态</span></span><br><span class="line">        partitionState.put(topicPartition, NewPartition)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p>初始化之后partitionState，分区状态机会把OfflinePartition和NewPartition的分区转换为OnlinePartition状态，<br>broker正常运行的情况下，分区都是OnlinePartition状态，此时handleStateChanges不会执行</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">triggerOnlinePartitionStateChange</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// try to move all partitions in NewPartition or OfflinePartition state to OnlinePartition state except partitions</span></span><br><span class="line">  <span class="comment">// that belong to topics to be deleted</span></span><br><span class="line">  <span class="comment">// 正常情况下partitionsToTrigger为空的，启动kafka时所有分区都是OnlinePartition</span></span><br><span class="line">  val partitionsToTrigger = partitionState.filter &#123; <span class="keyword">case</span> (partition, partitionState) =&gt;</span><br><span class="line">    !topicDeletionManager.isTopicQueuedUpForDeletion(partition.topic) &amp;&amp;</span><br><span class="line">      (partitionState.equals(OfflinePartition) || partitionState.equals(NewPartition))</span><br><span class="line">  &#125;.keys.toSeq</span><br><span class="line">  <span class="comment">// 把所有OfflinePartition，NewPartition和非准备删除的分区 转换为OnlinePartition</span></span><br><span class="line">  handleStateChanges(partitionsToTrigger, OnlinePartition, Option(OfflinePartitionLeaderElectionStrategy))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">def <span class="title">handleStateChanges</span><span class="params">(partitions: Seq[TopicPartition], targetState: PartitionState,</span></span></span><br><span class="line"><span class="function"><span class="params">                       partitionLeaderElectionStrategyOpt: Option[PartitionLeaderElectionStrategy] = None)</span>: Unit </span>= &#123;</span><br><span class="line">  <span class="keyword">if</span> (partitions.nonEmpty) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      controllerBrokerRequestBatch.newBatch()</span><br><span class="line">      doHandleStateChanges(partitions, targetState, partitionLeaderElectionStrategyOpt)</span><br><span class="line">      <span class="comment">// 发送一次请求队列，包括了doHandleStateChanges里新增的请求</span></span><br><span class="line">      controllerBrokerRequestBatch.sendRequestsToBrokers(controllerContext.epoch)</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: Throwable =&gt; error(s<span class="string">"Error while moving some partitions to $targetState state"</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="分区leader选举"><a href="#分区leader选举" class="headerlink" title="分区leader选举"></a>分区leader选举</h2><p>doHandleStateChanges主要是选举分区的leader副本，这里现将分区分为两类：</p><ol><li>未初始化的分区(uninitializedPartitions)：状态是NewPartition的分区</li><li>准备要选举leader副本的分区(partitionsToElectLeader)：状态是OfflinePartition，OnlinePartition的分区<br>doHandleStateChanges主要是对这两类分区选举leader，并放到前面说的partitionState缓存中</li></ol><p>注：注意前面传递过来的选举策略是OfflinePartitionLeaderElectionStrategy<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">doHandleStateChanges</span><span class="params">(partitions: Seq[TopicPartition], targetState: PartitionState,</span></span></span><br><span class="line"><span class="function"><span class="params">                         partitionLeaderElectionStrategyOpt: Option[PartitionLeaderElectionStrategy])</span>: Unit </span>= &#123;</span><br><span class="line">  <span class="comment">// 这里的处理和副本状态机一样</span></span><br><span class="line">  val stateChangeLog = stateChangeLogger.withControllerEpoch(controllerContext.epoch)</span><br><span class="line">  partitions.foreach(partition =&gt; partitionState.getOrElseUpdate(partition, NonExistentPartition))</span><br><span class="line">  val (validPartitions, invalidPartitions) = partitions.partition(partition =&gt; isValidTransition(partition, targetState))</span><br><span class="line">  invalidPartitions.foreach(partition =&gt; logInvalidTransition(partition, targetState))</span><br><span class="line">  targetState match &#123;</span><br><span class="line">    <span class="keyword">case</span> OnlinePartition =&gt;</span><br><span class="line">      val uninitializedPartitions = validPartitions.filter(partition =&gt; partitionState(partition) == NewPartition) <span class="comment">// 类型：Seq[TopicPartition]</span></span><br><span class="line">      val partitionsToElectLeader = validPartitions.filter(partition =&gt; partitionState(partition) == OfflinePartition || partitionState(partition) == OnlinePartition)</span><br><span class="line">      <span class="comment">// 状态为NewPartition的分区处理</span></span><br><span class="line">      <span class="keyword">if</span> (uninitializedPartitions.nonEmpty) &#123;</span><br><span class="line">        <span class="comment">// 初始化新分区的leader</span></span><br><span class="line">        val successfulInitializations = initializeLeaderAndIsrForPartitions(uninitializedPartitions)</span><br><span class="line">        successfulInitializations.foreach &#123; partition =&gt;</span><br><span class="line">          stateChangeLog.trace(s<span class="string">"Changed partition $partition from $&#123;partitionState(partition)&#125; to $targetState with state "</span> +</span><br><span class="line">            s<span class="string">"$&#123;controllerContext.partitionLeadershipInfo(partition).leaderAndIsr&#125;"</span>)</span><br><span class="line">          partitionState.put(partition, OnlinePartition)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// OfflinePartition,OnlinePartition副本中开始选举</span></span><br><span class="line">      <span class="keyword">if</span> (partitionsToElectLeader.nonEmpty) &#123;</span><br><span class="line">        <span class="comment">// 根据选举策略(Strategy)选举leader副本</span></span><br><span class="line">        val successfulElections = electLeaderForPartitions(partitionsToElectLeader, partitionLeaderElectionStrategyOpt.get)</span><br><span class="line">        successfulElections.foreach &#123; partition =&gt;</span><br><span class="line">          stateChangeLog.trace(s<span class="string">"Changed partition $partition from $&#123;partitionState(partition)&#125; to $targetState with state "</span> +</span><br><span class="line">            s<span class="string">"$&#123;controllerContext.partitionLeadershipInfo(partition).leaderAndIsr&#125;"</span>)</span><br><span class="line">          <span class="comment">// 更新分区状态为OnlinePartition</span></span><br><span class="line">          partitionState.put(partition, OnlinePartition)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>下面说说这两类分区leader副本选举方式</p><h3 id="NewPartition状态的分区选举leader副本"><a href="#NewPartition状态的分区选举leader副本" class="headerlink" title="NewPartition状态的分区选举leader副本"></a>NewPartition状态的分区选举leader副本</h3><p>initializeLeaderAndIsrForPartitions方法是在为NewPartition状态的分区选举leader副本<br>代码看上去很长，但是一句话就可以概括：取存活副本的列表的第一个副本作为leader，写回到zk的state节点，更新本地缓存，并发送LeaderAndIsr请求同步给其他broker</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">initializeLeaderAndIsrForPartitions</span><span class="params">(partitions: Seq[TopicPartition])</span>: Seq[TopicPartition] </span>= &#123;</span><br><span class="line">    val successfulInitializations = mutable.Buffer.empty[TopicPartition]</span><br><span class="line">    <span class="comment">// 获取分区副本</span></span><br><span class="line">    val replicasPerPartition = partitions.map(partition =&gt; partition -&gt; controllerContext.partitionReplicaAssignment(partition))</span><br><span class="line">    <span class="comment">// 只要在线的副本</span></span><br><span class="line">    val liveReplicasPerPartition = replicasPerPartition.map &#123; <span class="keyword">case</span> (partition, replicas) =&gt;</span><br><span class="line">        val liveReplicasForPartition = replicas.filter(replica =&gt; controllerContext.isReplicaOnline(replica, partition))</span><br><span class="line">        partition -&gt; liveReplicasForPartition</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 分区按照是否有在线的副本</span></span><br><span class="line">    val (partitionsWithoutLiveReplicas, partitionsWithLiveReplicas) = liveReplicasPerPartition.partition &#123; <span class="keyword">case</span> (_, liveReplicas) =&gt; liveReplicas.isEmpty &#125;</span><br><span class="line">    <span class="comment">// 没有在线副本的分区处理：打日志</span></span><br><span class="line">    partitionsWithoutLiveReplicas.foreach &#123; <span class="keyword">case</span> (partition, replicas) =&gt;</span><br><span class="line">      val failMsg = s<span class="string">"Controller $controllerId epoch $&#123;controllerContext.epoch&#125; encountered error during state change of "</span> +</span><br><span class="line">        s<span class="string">"partition $partition from New to Online, assigned replicas are "</span> +</span><br><span class="line">        s<span class="string">"[$&#123;replicas.mkString("</span>,<span class="string">")&#125;], live brokers are [$&#123;controllerContext.liveBrokerIds&#125;]. No assigned "</span> +</span><br><span class="line">        <span class="string">"replica is alive."</span></span><br><span class="line">      logFailedStateChange(partition, NewPartition, OnlinePartition, <span class="keyword">new</span> StateChangeFailedException(failMsg))</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 有在线副本的分区，将在线副本的第一个leader副本，并初始化ISR列表</span></span><br><span class="line">    <span class="comment">// Map[TopicPartition, LeaderIsrAndControllerEpoch]</span></span><br><span class="line">    val leaderIsrAndControllerEpochs = partitionsWithLiveReplicas.map &#123; <span class="keyword">case</span> (partition, liveReplicas) =&gt;</span><br><span class="line">      <span class="comment">// 这里就在初始化分区的leader(在线副本的第一个)，ISR</span></span><br><span class="line">      val leaderAndIsr = LeaderAndIsr(liveReplicas.head, liveReplicas.toList)</span><br><span class="line">      val leaderIsrAndControllerEpoch = LeaderIsrAndControllerEpoch(leaderAndIsr, controllerContext.epoch) <span class="comment">// 加上Controller epoch</span></span><br><span class="line">      partition -&gt; leaderIsrAndControllerEpoch</span><br><span class="line">    &#125;.toMap</span><br><span class="line">    val createResponses = <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 创建 /topics/topic名称/partitions/分区名称/state，包含中间节点</span></span><br><span class="line">      zkClient.createTopicPartitionStatesRaw(leaderIsrAndControllerEpochs)</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: Exception =&gt;</span><br><span class="line">        partitionsWithLiveReplicas.foreach &#123; <span class="keyword">case</span> (partition,_) =&gt; logFailedStateChange(partition, partitionState(partition), NewPartition, e) &#125;</span><br><span class="line">        Seq.empty</span><br><span class="line">    &#125;</span><br><span class="line">    createResponses.foreach &#123; createResponse =&gt;</span><br><span class="line">      val code = createResponse.resultCode</span><br><span class="line">      val partition = createResponse.ctx.get.asInstanceOf[TopicPartition]</span><br><span class="line">      val leaderIsrAndControllerEpoch = leaderIsrAndControllerEpochs(partition)</span><br><span class="line">      <span class="keyword">if</span> (code == Code.OK) &#123;</span><br><span class="line">        <span class="comment">// 缓存起来分区的leader和ISR数据</span></span><br><span class="line">        controllerContext.partitionLeadershipInfo.put(partition, leaderIsrAndControllerEpoch)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// isr是在线副本所在的brokerId，这里向这些broker发送LeaderAndIsr请求</span></span><br><span class="line">        controllerBrokerRequestBatch.addLeaderAndIsrRequestForBrokers(leaderIsrAndControllerEpoch.leaderAndIsr.isr,</span><br><span class="line">          partition, leaderIsrAndControllerEpoch, controllerContext.partitionReplicaAssignment(partition), isNew = <span class="keyword">true</span>)</span><br><span class="line">        <span class="comment">// 作为成功初始化的分区返回</span></span><br><span class="line">        successfulInitializations += partition</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        logFailedStateChange(partition, NewPartition, OnlinePartition, code)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    successfulInitializations</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="OfflinePartition-OnlinePartition状态的分区选举leader副本"><a href="#OfflinePartition-OnlinePartition状态的分区选举leader副本" class="headerlink" title="OfflinePartition/OnlinePartition状态的分区选举leader副本"></a>OfflinePartition/OnlinePartition状态的分区选举leader副本</h3><p>electLeaderForPartitions方法用于OfflinePartition/OnlinePartition状态的所有分区选举leader副本<br>而每一个分区的的leader副本选举在doElectLeaderForPartitions方法实现，虽然代码很多，但核心还是选举leader副本，写回zk，更新本地缓存，并发送LeaderAndIsr请求同步给其他broker</p><p>分区leader会在不同情况下选举leader副本，因此有4种选举策略，此时根据前面传递过来的参数，选举策略为OfflinePartitionLeaderElectionStrategy<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">doElectLeaderForPartitions</span><span class="params">(partitions: Seq[TopicPartition], partitionLeaderElectionStrategy: PartitionLeaderElectionStrategy)</span>:</span></span><br><span class="line"><span class="function">  <span class="params">(Seq[TopicPartition], Seq[TopicPartition], Map[TopicPartition, Exception])</span> </span>= &#123;</span><br><span class="line">    <span class="comment">// 先批量获取zk中.../partitions/xxx/state，即每个分区的state 数据</span></span><br><span class="line">    <span class="comment">// 样例： &#123;"controller_epoch":19,"leader":0,"version":1,"leader_epoch":57,"isr":[0,1,2]&#125;</span></span><br><span class="line">    val getDataResponses = <span class="keyword">try</span> &#123;</span><br><span class="line">      zkClient.getTopicPartitionStatesRaw(partitions)</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: Exception =&gt;</span><br><span class="line">        <span class="keyword">return</span> (Seq.empty, Seq.empty, partitions.map(_ -&gt; e).toMap)</span><br><span class="line">    &#125;</span><br><span class="line">    val failedElections = mutable.Map.empty[TopicPartition, Exception]</span><br><span class="line">    val leaderIsrAndControllerEpochPerPartition = mutable.Buffer.empty[(TopicPartition, LeaderIsrAndControllerEpoch)]</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 主要是初始化leaderIsrAndControllerEpochPerPartition</span></span><br><span class="line">    getDataResponses.foreach &#123; getDataResponse =&gt;</span><br><span class="line">      <span class="comment">// context 就是请求参数里的分区</span></span><br><span class="line">      val partition = getDataResponse.ctx.get.asInstanceOf[TopicPartition]</span><br><span class="line">      val currState = partitionState(partition) <span class="comment">// 获取缓存中该分区的状态</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (getDataResponse.resultCode == Code.OK) &#123;</span><br><span class="line">        <span class="comment">// 解析成LeaderIsrAndControllerEpoch</span></span><br><span class="line">        val leaderIsrAndControllerEpochOpt = TopicPartitionStateZNode.decode(getDataResponse.data, getDataResponse.stat)</span><br><span class="line">        <span class="comment">// 没获取到leaderIsrAndControllerEpoch，添加到failedElections集合里</span></span><br><span class="line">        <span class="keyword">if</span> (leaderIsrAndControllerEpochOpt.isEmpty) &#123;</span><br><span class="line">          val exception = <span class="keyword">new</span> StateChangeFailedException(s<span class="string">"LeaderAndIsr information doesn't exist for partition $partition in $currState state"</span>)</span><br><span class="line">          failedElections.put(partition, exception)</span><br><span class="line">        &#125;</span><br><span class="line">        leaderIsrAndControllerEpochPerPartition += partition -&gt; leaderIsrAndControllerEpochOpt.get <span class="comment">// 加个括号好看些 (partition -&gt; leaderIsrAndControllerEpochOpt.get)</span></span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (getDataResponse.resultCode == Code.NONODE) &#123;</span><br><span class="line">        <span class="comment">// 节点不存在</span></span><br><span class="line">        val exception = <span class="keyword">new</span> StateChangeFailedException(s<span class="string">"LeaderAndIsr information doesn't exist for partition $partition in $currState state"</span>)</span><br><span class="line">        failedElections.put(partition, exception)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 其他zk异常</span></span><br><span class="line">        failedElections.put(partition, getDataResponse.resultException.get)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// zk里的controllerEpoch是否比 本地缓存里的controllerEpoch大，大就说明有其他Controller已经被选举了，写到了zk的partition/state里</span></span><br><span class="line">    val (invalidPartitionsForElection, validPartitionsForElection) = leaderIsrAndControllerEpochPerPartition.partition &#123; <span class="keyword">case</span> (_, leaderIsrAndControllerEpoch) =&gt;</span><br><span class="line">      leaderIsrAndControllerEpoch.controllerEpoch &gt; controllerContext.epoch</span><br><span class="line">    &#125;</span><br><span class="line">    invalidPartitionsForElection.foreach &#123; <span class="keyword">case</span> (partition, leaderIsrAndControllerEpoch) =&gt;</span><br><span class="line">      val failMsg = s<span class="string">"aborted leader election for partition $partition since the LeaderAndIsr path was "</span> +</span><br><span class="line">        s<span class="string">"already written by another controller. This probably means that the current controller $controllerId went through "</span> +</span><br><span class="line">        s<span class="string">"a soft failure and another controller was elected with epoch $&#123;leaderIsrAndControllerEpoch.controllerEpoch&#125;."</span></span><br><span class="line">      failedElections.put(partition, <span class="keyword">new</span> StateChangeFailedException(failMsg))</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 全部分区都被新Controller更新了state，直接返回failedElections</span></span><br><span class="line">    <span class="keyword">if</span> (validPartitionsForElection.isEmpty) &#123;</span><br><span class="line">      <span class="keyword">return</span> (Seq.empty, Seq.empty, failedElections.toMap)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    val shuttingDownBrokers  = controllerContext.shuttingDownBrokerIds.toSet</span><br><span class="line"></span><br><span class="line">    val (partitionsWithoutLeaders, partitionsWithLeaders) = partitionLeaderElectionStrategy match &#123;</span><br><span class="line">      <span class="keyword">case</span> OfflinePartitionLeaderElectionStrategy =&gt; <span class="comment">// 初始化是用的是OfflinePartitionLeaderElectionStrategy(追参数传递)</span></span><br><span class="line">        <span class="comment">// 注意这里的scala语法，partition是布尔分组器，并返回结果给外边的val变量</span></span><br><span class="line">        leaderForOffline(validPartitionsForElection).partition &#123; <span class="keyword">case</span> (_, newLeaderAndIsrOpt, _) =&gt; newLeaderAndIsrOpt.isEmpty &#125;</span><br><span class="line">      <span class="keyword">case</span> ReassignPartitionLeaderElectionStrategy =&gt; <span class="comment">// 分区重分配时的选举算法</span></span><br><span class="line">        leaderForReassign(validPartitionsForElection).partition &#123; <span class="keyword">case</span> (_, newLeaderAndIsrOpt, _) =&gt; newLeaderAndIsrOpt.isEmpty &#125;</span><br><span class="line">      <span class="keyword">case</span> PreferredReplicaPartitionLeaderElectionStrategy =&gt;</span><br><span class="line">        leaderForPreferredReplica(validPartitionsForElection).partition &#123; <span class="keyword">case</span> (_, newLeaderAndIsrOpt, _) =&gt; newLeaderAndIsrOpt.isEmpty &#125;</span><br><span class="line">      <span class="keyword">case</span> ControlledShutdownPartitionLeaderElectionStrategy =&gt;</span><br><span class="line">        leaderForControlledShutdown(validPartitionsForElection, shuttingDownBrokers).partition &#123; <span class="keyword">case</span> (_, newLeaderAndIsrOpt, _) =&gt; newLeaderAndIsrOpt.isEmpty &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 没选举出leader的分区</span></span><br><span class="line">    partitionsWithoutLeaders.foreach &#123; <span class="keyword">case</span> (partition, _, _) =&gt;</span><br><span class="line">      val failMsg = s<span class="string">"Failed to elect leader for partition $partition under strategy $partitionLeaderElectionStrategy"</span></span><br><span class="line">      failedElections.put(partition, <span class="keyword">new</span> StateChangeFailedException(failMsg))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 分区和存活的副本形成一个集合</span></span><br><span class="line">    val recipientsPerPartition = partitionsWithLeaders.map &#123; <span class="keyword">case</span> (partition, _, recipients) =&gt; partition -&gt; recipients &#125;.toMap</span><br><span class="line">    <span class="comment">// 分区和选举后的isr形成一个集合</span></span><br><span class="line">    val adjustedLeaderAndIsrs = partitionsWithLeaders.map &#123; <span class="keyword">case</span> (partition, leaderAndIsrOpt, _) =&gt; partition -&gt; leaderAndIsrOpt.get &#125;.toMap</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 更新每个选举成功的分区，更新leaderAndIsr，controller epoch</span></span><br><span class="line">    <span class="function">val <span class="title">UpdateLeaderAndIsrResult</span><span class="params">(successfulUpdates, updatesToRetry, failedUpdates)</span> </span>= zkClient.updateLeaderAndIsr(</span><br><span class="line">      adjustedLeaderAndIsrs, controllerContext.epoch)</span><br><span class="line">    <span class="comment">// updatesToRetry是版本冲突而更新失败的分区</span></span><br><span class="line"></span><br><span class="line">    successfulUpdates.foreach &#123; <span class="keyword">case</span> (partition, leaderAndIsr) =&gt;</span><br><span class="line">      val replicas = controllerContext.partitionReplicaAssignment(partition)</span><br><span class="line">      val leaderIsrAndControllerEpoch = LeaderIsrAndControllerEpoch(leaderAndIsr, controllerContext.epoch)</span><br><span class="line">      <span class="comment">// zk更新成功，放入本地缓存</span></span><br><span class="line">      controllerContext.partitionLeadershipInfo.put(partition, leaderIsrAndControllerEpoch)</span><br><span class="line">      <span class="comment">// 发送LeaderAndIsr请求</span></span><br><span class="line">      controllerBrokerRequestBatch.addLeaderAndIsrRequestForBrokers(recipientsPerPartition(partition), partition,</span><br><span class="line">        leaderIsrAndControllerEpoch, replicas, isNew = <span class="keyword">false</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    (successfulUpdates.keys.toSeq, updatesToRetry, failedElections.toMap ++ failedUpdates) <span class="comment">// 这里是选举失败和更新zk失败的合并</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>OfflinePartitionLeaderElectionStrategy策略的选举算法在leaderForOffline方法中实现</p><h3 id="leaderForOffline选举"><a href="#leaderForOffline选举" class="headerlink" title="leaderForOffline选举"></a>leaderForOffline选举</h3><p>在选举过程中，受unclean.leader.election.enable配置的约束，该配置可以是topic级别，线上环境一般设置为false，否则会在非isr的副本中选举leader，造成数据不一致问题</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">leaderForOffline</span><span class="params">(leaderIsrAndControllerEpochs: Seq[(TopicPartition, LeaderIsrAndControllerEpoch)</span>]):</span></span><br><span class="line"><span class="function">  Seq[<span class="params">(TopicPartition, Option[LeaderAndIsr], Seq[Int])</span>] </span>= &#123;</span><br><span class="line">    <span class="comment">// 又是布尔分区器</span></span><br><span class="line">    val (partitionsWithNoLiveInSyncReplicas, partitionsWithLiveInSyncReplicas) = leaderIsrAndControllerEpochs.partition &#123; <span class="keyword">case</span> (partition, leaderIsrAndControllerEpoch) =&gt;</span><br><span class="line">      <span class="comment">// 这是在查看zk中的ISR列表，broker本地缓存中是否存活</span></span><br><span class="line">      val liveInSyncReplicas = leaderIsrAndControllerEpoch.leaderAndIsr.isr.filter(replica =&gt; controllerContext.isReplicaOnline(replica, partition))</span><br><span class="line">      liveInSyncReplicas.isEmpty</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// partitionsWithNoLiveInSyncReplicas的含义：partition.isr.filter(replica =&gt; controllerContext.isReplicaOnline(replica, partition)).isEmpty</span></span><br><span class="line">    <span class="comment">// config.originals()就是server.properties里的配置</span></span><br><span class="line">    <span class="comment">// 获取topic的LogConfig配置对象，LogConfig(originals+overrides, overrides.keys)</span></span><br><span class="line">    val (logConfigs, failed) = zkClient.getLogConfigs(partitionsWithNoLiveInSyncReplicas.map &#123; <span class="keyword">case</span> (partition, _) =&gt; partition.topic &#125;, config.originals())</span><br><span class="line"></span><br><span class="line">    val partitionsWithUncleanLeaderElectionState = partitionsWithNoLiveInSyncReplicas.map &#123; <span class="keyword">case</span> (partition, leaderIsrAndControllerEpoch) =&gt;</span><br><span class="line">      <span class="comment">// failed: 从zk获取配置信息失败的topic</span></span><br><span class="line">      <span class="keyword">if</span> (failed.contains(partition.topic)) &#123;</span><br><span class="line">        <span class="comment">// 打日志</span></span><br><span class="line">        logFailedStateChange(partition, partitionState(partition), OnlinePartition, failed(partition.topic))</span><br><span class="line">        (partition, None, <span class="keyword">false</span>)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 返回的是一个三元组(TopicPartition, Option(LeaderIsrAndControllerEpoch, 该topic"unclean.leader.election.enable"的配置),</span></span><br><span class="line">        (partition, Option(leaderIsrAndControllerEpoch), logConfigs(partition.topic).uncleanLeaderElectionEnable.booleanValue())</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; ++ partitionsWithLiveInSyncReplicas.map &#123; <span class="keyword">case</span> (partition, leaderIsrAndControllerEpoch) =&gt; (partition, Option(leaderIsrAndControllerEpoch), <span class="keyword">false</span>) &#125;</span><br><span class="line">    <span class="comment">// partitionsWithLiveInSyncReplicas uncleanLeaderElectionEnabled默认为false，说明有isr副本有存活的，就一定从isr里选，哪怕只有1个</span></span><br><span class="line"></span><br><span class="line">    partitionsWithUncleanLeaderElectionState.map &#123; <span class="keyword">case</span> (partition, leaderIsrAndControllerEpochOpt, uncleanLeaderElectionEnabled) =&gt;</span><br><span class="line">      <span class="comment">// 获取副本集合</span></span><br><span class="line">      val assignment = controllerContext.partitionReplicaAssignment(partition)</span><br><span class="line">      <span class="comment">// 再检查本地缓存里的副本是否在线</span></span><br><span class="line">      val liveReplicas = assignment.filter(replica =&gt; controllerContext.isReplicaOnline(replica, partition))</span><br><span class="line">      <span class="keyword">if</span> (leaderIsrAndControllerEpochOpt.nonEmpty) &#123;</span><br><span class="line">        val leaderIsrAndControllerEpoch = leaderIsrAndControllerEpochOpt.get</span><br><span class="line">        val isr = leaderIsrAndControllerEpoch.leaderAndIsr.isr</span><br><span class="line">        <span class="comment">// 选举分区leader的算法</span></span><br><span class="line">        val leaderOpt = PartitionLeaderElectionAlgorithms.offlinePartitionLeaderElection(assignment, isr, liveReplicas.toSet, uncleanLeaderElectionEnabled, controllerContext)</span><br><span class="line"></span><br><span class="line">        val newLeaderAndIsrOpt = leaderOpt.map &#123; leader =&gt;</span><br><span class="line">          <span class="comment">// 如果副本是从isr里选出来的，就再过滤检查一遍isr里的副本是否在线</span></span><br><span class="line">          val newIsr = <span class="keyword">if</span> (isr.contains(leader)) isr.filter(replica =&gt; controllerContext.isReplicaOnline(replica, partition))</span><br><span class="line">          <span class="keyword">else</span> List(leader)</span><br><span class="line">          <span class="comment">// leader epoch+1,返回新的LeaderAndIsr</span></span><br><span class="line">          leaderIsrAndControllerEpoch.leaderAndIsr.newLeaderAndIsr(leader, newIsr)</span><br><span class="line">        &#125;</span><br><span class="line">        (partition, newLeaderAndIsrOpt, liveReplicas)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        (partition, None, liveReplicas)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而最终的leader选举算法在PartitionLeaderElectionAlgorithms.offlinePartitionLeaderElection方法内实现</p><h3 id="选举算法"><a href="#选举算法" class="headerlink" title="选举算法"></a>选举算法</h3><p>该选举算法也比较简单，找到第一个在isr列表，并且是存活的副本作为leader<br>如果没有，并且unclean.leader.election.enable=true，从所有副本中取第一个存活的副本作为leader</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> assignment 分区分配的副本</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> isr zk中的ISR</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> liveReplicas assignment中在线的副本</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> uncleanLeaderElectionEnabled</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> controllerContext</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"><span class="function">def <span class="title">offlinePartitionLeaderElection</span><span class="params">(assignment: Seq[Int], isr: Seq[Int], liveReplicas: Set[Int], uncleanLeaderElectionEnabled: Boolean, controllerContext: ControllerContext)</span>: Option[Int] </span>= &#123;</span><br><span class="line">  <span class="comment">// 从assignment中找第一个liveReplicas和isr都有的replica id</span></span><br><span class="line">  <span class="comment">// 找不到执行orElse逻辑</span></span><br><span class="line">  assignment.find(id =&gt; liveReplicas.contains(id) &amp;&amp; isr.contains(id)).orElse &#123;</span><br><span class="line">    <span class="keyword">if</span> (uncleanLeaderElectionEnabled) &#123; <span class="comment">// unclean elect</span></span><br><span class="line">      <span class="comment">// 从assignment找第一个Online的Replica作为leader</span></span><br><span class="line">      <span class="comment">// 也就是说不在isr里的副本也可以参与选举（uncleanLeaderElect）</span></span><br><span class="line">      val leaderOpt = assignment.find(liveReplicas.contains)</span><br><span class="line">      <span class="keyword">if</span> (!leaderOpt.isEmpty)</span><br><span class="line">        <span class="comment">// metrics</span></span><br><span class="line">        controllerContext.stats.uncleanLeaderElectionRate.mark()</span><br><span class="line">      leaderOpt</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 所有的副本都不在线</span></span><br><span class="line">      None</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>至此副本状态机和分区状态机的启动就算完成了，副本状态机与分区状态机的启动操作，都是先初始化了状态缓存，进行初始化的状态转换，里面做了更新ControllerContext，zk中的数据的操作，而分区状态机还需要为每个分区选举leader副本</p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>KafkaController源码分析之Controller选举与初始化</title>
      <link href="/2020/02/12/KafkaController%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BController%E9%80%89%E4%B8%BE%E4%B8%8E%E5%88%9D%E5%A7%8B%E5%8C%96/"/>
      <url>/2020/02/12/KafkaController%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BController%E9%80%89%E4%B8%BE%E4%B8%8E%E5%88%9D%E5%A7%8B%E5%8C%96/</url>
      <content type="html"><![CDATA[<p>本文来分析下kafka的重要模块——Controller，主要介绍Controller的选举与初始化过程</p><h1 id="KafkaController"><a href="#KafkaController" class="headerlink" title="KafkaController"></a>KafkaController</h1><p>初始化的入口依然在KafkaServer#startup方法中<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建BrokerInfo: &#123;Broker&#123;id,EndPoint,rack&#125;, apiversion, jmxport&#125;</span></span><br><span class="line">val brokerInfo = createBrokerInfo </span><br><span class="line"><span class="comment">// zk中注册 /brokers/ids/0 节点</span></span><br><span class="line">zkClient.registerBrokerInZk(brokerInfo)</span><br><span class="line"></span><br><span class="line"><span class="comment">/* start kafka controller */</span></span><br><span class="line">kafkaController = <span class="keyword">new</span> KafkaController(config, zkClient, time, metrics, brokerInfo, tokenManager, threadNamePrefix)</span><br><span class="line">kafkaController.startup()</span><br></pre></td></tr></table></figure></p><p>在讲解KafkaController#startup之前，需要说明下KafkaController中有很多成员变量，主要分为</p><ol><li>zk事件处理器(ZNodeChangeHandler，ZNodeChildChangeHandler)</li><li>StateMachine(有限状态机): 副本的状态机，分区的状态机，主要负责状态的维护及转换时的处理</li><li>ControllerContext：broker，topic，partition，replica相关的数据缓存</li><li>ControllerEventManager: zk事件管理器，详见<a href="">Zookeeper初始化与Watcher监听事件分发</a></li></ol><h1 id="KafkaController启动"><a href="#KafkaController启动" class="headerlink" title="KafkaController启动"></a>KafkaController启动</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">startup</span><span class="params">()</span> </span>= &#123;</span><br><span class="line"><span class="comment">// StateChangeHandler用于处理ZooKeeper AuthFailed事件，Zookeeper初始化与Watcher监听事件分发一文有提到</span></span><br><span class="line">zkClient.registerStateChangeHandler(<span class="keyword">new</span> StateChangeHandler &#123;</span><br><span class="line"><span class="comment">// 非核心...</span></span><br><span class="line">&#125;)</span><br><span class="line"><span class="comment">// Startup是一个ControllerEvent，ControllerEventThread会执行它的process方法</span></span><br><span class="line">eventManager.put(Startup)</span><br><span class="line"><span class="comment">// 启动了ControllerEventManager</span></span><br><span class="line">eventManager.start()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Startup类定义如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> object Startup extends ControllerEvent &#123;</span><br><span class="line">    def state = ControllerState.ControllerChange</span><br><span class="line"></span><br><span class="line">    <span class="function">override def <span class="title">process</span><span class="params">()</span>: Unit </span>= &#123;</span><br><span class="line">      <span class="comment">// 如方法名所示：注册监听/controller节点的handler, 并检查/controller节点是否存在</span></span><br><span class="line">      zkClient.registerZNodeChangeHandlerAndCheckExistence(controllerChangeHandler)</span><br><span class="line">      <span class="comment">// Controller选举</span></span><br><span class="line">      elect()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>注册的ControllerChangeHandler主要监听/controller节点的创建，删除，以及数据改变事件，此处暂且不深入研究</p><h1 id="KafkaController选举"><a href="#KafkaController选举" class="headerlink" title="KafkaController选举"></a>KafkaController选举</h1><p>接下来的elect方法是关于Controller选举的核心方法，前文说过，选举很简单，负责的是里面各种变量的初始化<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">elect</span><span class="params">()</span>: Unit </span>= &#123;</span><br><span class="line">    val timestamp = time.milliseconds</span><br><span class="line">    <span class="comment">// 获取zk /controller节点中的ControllerId，没有返回-1</span></span><br><span class="line">    activeControllerId = zkClient.getControllerId.getOrElse(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ControllerId=-1，表示当前broker已成为Controller，属于特殊场景下的防止死循环优化</span></span><br><span class="line">    <span class="keyword">if</span> (activeControllerId != -<span class="number">1</span>) &#123;</span><br><span class="line">      debug(s<span class="string">"Broker $activeControllerId has been elected as the controller, so stopping the election process."</span>)</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 尝试去创建/controller节点，如果创建失败了(已存在)，会在catch里处理NodeExistsException</span></span><br><span class="line">      zkClient.checkedEphemeralCreate(ControllerZNode.path, ControllerZNode.encode(config.brokerId, timestamp))</span><br><span class="line">      info(s<span class="string">"$&#123;config.brokerId&#125; successfully elected as the controller"</span>)</span><br><span class="line">      activeControllerId = config.brokerId</span><br><span class="line">      onControllerFailover()</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> _: NodeExistsException =&gt;</span><br><span class="line">        <span class="comment">// If someone else has written the path, then</span></span><br><span class="line">        activeControllerId = zkClient.getControllerId.getOrElse(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果/controller已存在， brokerid就不会是-1</span></span><br><span class="line">        <span class="comment">// &#123;"version":1,"brokerid":0,"timestamp":"1582610063256"&#125;</span></span><br><span class="line">        <span class="keyword">if</span> (activeControllerId != -<span class="number">1</span>)</span><br><span class="line">          debug(s<span class="string">"Broker $activeControllerId was elected as controller instead of broker $&#123;config.brokerId&#125;"</span>)</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">          <span class="comment">// 上一届controller刚下台，节点还没删除的情况</span></span><br><span class="line">          warn(<span class="string">"A controller has been elected but just resigned, this will result in another round of election"</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> e2: Throwable =&gt;</span><br><span class="line">        error(s<span class="string">"Error while electing or becoming controller on broker $&#123;config.brokerId&#125;"</span>, e2)</span><br><span class="line">        triggerControllerMove()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>整个选举过程并不复杂，选举流程如下图所示<br><img src="https://ae01.alicdn.com/kf/H9597605bc9844f07abc7848ec538840cJ.png" alt="选举过程"></p><h1 id="KafkaController初始化"><a href="#KafkaController初始化" class="headerlink" title="KafkaController初始化"></a>KafkaController初始化</h1><p>真正复杂的是broker在成为Controller之后，在onControllerFailover方法中进行的一系列初始化动作<br>下面是源码，接下来是对onControllerFailover方法的分段讲解</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">onControllerFailover</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    info(<span class="string">"Reading controller epoch from ZooKeeper"</span>)</span><br><span class="line">    readControllerEpochFromZooKeeper()</span><br><span class="line">    info(<span class="string">"Incrementing controller epoch in ZooKeeper"</span>)</span><br><span class="line">    incrementControllerEpoch()</span><br><span class="line">    info(<span class="string">"Registering handlers"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    val childChangeHandlers = Seq(brokerChangeHandler, topicChangeHandler, topicDeletionHandler, logDirEventNotificationHandler,</span><br><span class="line">      isrChangeNotificationHandler)</span><br><span class="line">    childChangeHandlers.foreach(zkClient.registerZNodeChildChangeHandler)</span><br><span class="line">    val nodeChangeHandlers = Seq(preferredReplicaElectionHandler, partitionReassignmentHandler)</span><br><span class="line">    nodeChangeHandlers.foreach(zkClient.registerZNodeChangeHandlerAndCheckExistence)</span><br><span class="line"></span><br><span class="line">    info(<span class="string">"Deleting log dir event notifications"</span>)</span><br><span class="line">    zkClient.deleteLogDirEventNotifications()</span><br><span class="line">    info(<span class="string">"Deleting isr change notifications"</span>)</span><br><span class="line">    zkClient.deleteIsrChangeNotifications()</span><br><span class="line">    info(<span class="string">"Initializing controller context"</span>)</span><br><span class="line">    initializeControllerContext()</span><br><span class="line"></span><br><span class="line">    info(<span class="string">"Fetching topic deletions in progress"</span>)</span><br><span class="line">    val (topicsToBeDeleted, topicsIneligibleForDeletion) = fetchTopicDeletionsInProgress()</span><br><span class="line">    info(<span class="string">"Initializing topic deletion manager"</span>)</span><br><span class="line">    topicDeletionManager.init(topicsToBeDeleted, topicsIneligibleForDeletion)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// We need to send UpdateMetadataRequest after the controller context is initialized and before the state machines</span></span><br><span class="line">    <span class="comment">// are started. The is because brokers need to receive the list of live brokers from UpdateMetadataRequest before</span></span><br><span class="line">    <span class="comment">// they can process the LeaderAndIsrRequests that are generated by replicaStateMachine.startup() and</span></span><br><span class="line">    <span class="comment">// partitionStateMachine.startup().</span></span><br><span class="line">    info(<span class="string">"Sending update metadata request"</span>)</span><br><span class="line">    sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq)</span><br><span class="line"></span><br><span class="line">    replicaStateMachine.startup()</span><br><span class="line">    partitionStateMachine.startup()</span><br><span class="line"></span><br><span class="line">    info(s<span class="string">"Ready to serve as the new controller with epoch $epoch"</span>)</span><br><span class="line"></span><br><span class="line">    maybeTriggerPartitionReassignment(controllerContext.partitionsBeingReassigned.keySet)</span><br><span class="line"></span><br><span class="line">    topicDeletionManager.tryTopicDeletion()</span><br><span class="line"></span><br><span class="line">    val pendingPreferredReplicaElections = fetchPendingPreferredReplicaElections()</span><br><span class="line">    onPreferredReplicaElection(pendingPreferredReplicaElections)</span><br><span class="line"></span><br><span class="line">    info(<span class="string">"Starting the controller scheduler"</span>)</span><br><span class="line">    kafkaScheduler.startup()</span><br><span class="line">    <span class="keyword">if</span> (config.autoLeaderRebalanceEnable) &#123;</span><br><span class="line">      scheduleAutoLeaderRebalanceTask(delay = <span class="number">5</span>, unit = TimeUnit.SECONDS)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (config.tokenAuthEnabled) &#123;</span><br><span class="line">      info(<span class="string">"starting the token expiry check scheduler"</span>)</span><br><span class="line">      tokenCleanScheduler.startup()</span><br><span class="line">      tokenCleanScheduler.schedule(name = <span class="string">"delete-expired-tokens"</span>,</span><br><span class="line">        fun = tokenManager.expireTokens,</span><br><span class="line">        period = config.delegationTokenExpiryCheckIntervalMs,</span><br><span class="line">        unit = TimeUnit.MILLISECONDS)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="controller-epoch"><a href="#controller-epoch" class="headerlink" title="controller.epoch"></a>controller.epoch</h2><p>controller.epoch表示Controller的版本号，初始值为0，每次产生新的Controller都会自增1<br>它的作用类似乐观锁的版本号，在Controller操作zk相关节点时，需要用它来表示节点是被哪一个Controller更新的</p><p>以下是初始化Controller时，从zk中/controller_epoch节点读取epoch的值，加1设置回zk，并更新本地缓存中的epoch<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 这一段代码就是获取controller.epoch，并自增+1设置回zk</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">info(<span class="string">"Reading controller epoch from ZooKeeper"</span>)</span><br><span class="line"><span class="comment">// 获取/controller_epoch节点数据，初始化ControllerContext的epoch和epochZkVersion字段</span></span><br><span class="line">readControllerEpochFromZooKeeper()</span><br><span class="line">info(<span class="string">"Incrementing controller epoch in ZooKeeper"</span>)</span><br><span class="line">incrementControllerEpoch()</span><br><span class="line">info(<span class="string">"Registering handlers"</span>)</span><br></pre></td></tr></table></figure></p><h2 id="注册节点监听器"><a href="#注册节点监听器" class="headerlink" title="注册节点监听器"></a>注册节点监听器</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 注册一组childrenChangeHandler，在NodeChildrenChange事件触发后，会分发给这些handler</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="comment">// before reading source of truth from zookeeper, register the listeners to get broker/topic callbacks</span></span><br><span class="line">val childChangeHandlers = Seq(brokerChangeHandler, topicChangeHandler, topicDeletionHandler, logDirEventNotificationHandler,</span><br><span class="line">  isrChangeNotificationHandler)</span><br><span class="line">childChangeHandlers.foreach(zkClient.registerZNodeChildChangeHandler)</span><br><span class="line"><span class="comment">// 注册/admin/preferred_replica_election, /admin/reassign_partitions节点事件处理</span></span><br><span class="line"><span class="comment">// 也是注册，不过要检查节点是否存在(这里不对是否存在做处理，只是保证没有异常)</span></span><br><span class="line">val nodeChangeHandlers = Seq(preferredReplicaElectionHandler, partitionReassignmentHandler)</span><br><span class="line">nodeChangeHandlers.foreach(zkClient.registerZNodeChangeHandlerAndCheckExistence)</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 删除节点：/log_dir_event_notification/log_dir_event_xxx，/isr_change_notification/isr_change_xxx节点</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">info(<span class="string">"Deleting log dir event notifications"</span>)</span><br><span class="line">zkClient.deleteLogDirEventNotifications()</span><br><span class="line">info(<span class="string">"Deleting isr change notifications"</span>)</span><br><span class="line">zkClient.deleteIsrChangeNotifications()</span><br></pre></td></tr></table></figure><p>这里注册了很多handler，先用一个表格大致介绍一下，后面会有详细讲解</p><table><thead><tr><th>handler</th><th>监听的zk节点</th><th>事件</th><th>ControllerEvent</th><th>功能</th></tr></thead><tbody><tr><td>brokerChangeHandler</td><td>/brokers/ids</td><td>childChange</td><td>BrokerChange</td><td></td></tr><tr><td>topicChangeHandler</td><td>/brokers/topics</td><td>childChange</td><td>TopicChange</td><td></td></tr><tr><td>topicDeletionHandler</td><td>/admin/delete_topics</td><td>childChange</td><td>TopicDeletion</td><td></td></tr><tr><td>logDirEventNotificationHandler</td><td>/log_dir_event_notification</td><td>childChange</td><td>LogDirEventNotification</td><td></td></tr><tr><td>isrChangeNotificationHandler</td><td>/isr_change_notification</td><td>childChange</td><td>IsrChangeNotification</td><td></td></tr><tr><td>partitionReassignmentHandler</td><td>/admin/reassign_partitions</td><td>create</td><td>PartitionReassignment</td><td>执行副本重分配</td></tr><tr><td>preferredReplicaElectionHandler</td><td>/admin/preferred_replica_election</td><td>create</td><td>PreferredReplicaLeaderElection</td><td>Preferred leader副本选举</td></tr></tbody></table><h2 id="初始化ControllerContext"><a href="#初始化ControllerContext" class="headerlink" title="初始化ControllerContext"></a>初始化ControllerContext</h2><p>首先需要说下ControllerContext是什么，以及它的功能</p><p>ControllerContext是zk中broker，topic，partition，replica等元数据的缓存对象，它主要有以下几个缓存<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// controller epoch 在kafka中epoch就相当于乐观锁的version</span></span><br><span class="line">var epoch: Int = KafkaController.InitialControllerEpoch - <span class="number">1</span></span><br><span class="line"><span class="comment">// 这是zk自带的version，通用的用于更新节点数据</span></span><br><span class="line">var epochZkVersion: Int = KafkaController.InitialControllerEpochZkVersion - <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Map[Topic, Map[Partition, Seq[Replica]]] 存储每个topic的每个分区的副本集合</span></span><br><span class="line"><span class="keyword">private</span> var partitionReplicaAssignmentUnderlying: mutable.Map[String, mutable.Map[Int, Seq[Int]]] = mutable.Map.empty</span><br><span class="line"></span><br><span class="line"><span class="comment">// LeaderIsrAndControllerEpoch: &#123;"controller_epoch":19,"leader":0,"version":1,"leader_epoch":57,"isr":[0,1,2]&#125;</span></span><br><span class="line">val partitionLeadershipInfo: mutable.Map[TopicPartition, LeaderIsrAndControllerEpoch] = mutable.Map.empty</span><br><span class="line"></span><br><span class="line"><span class="comment">// 准备要重分配副本的分区</span></span><br><span class="line">val partitionsBeingReassigned: mutable.Map[TopicPartition, ReassignedPartitionsContext] = mutable.Map.empty</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这要等到向Controller发送LeaderAndIsr请求之后，才能初始化，key是brokerId</span></span><br><span class="line">val replicasOnOfflineDirs: mutable.Map[Int, Set[TopicPartition]] = mutable.Map.empty</span><br><span class="line"></span><br><span class="line"><span class="comment">//存活的broker</span></span><br><span class="line"><span class="keyword">private</span> var liveBrokersUnderlying: Set[Broker] = Set.empty</span><br><span class="line"><span class="keyword">private</span> var liveBrokerIdsUnderlying: Set[Int] = Set.empty</span><br></pre></td></tr></table></figure></p><p>比较重要的几个变量是：</p><ol><li>partitionReplicaAssignmentUnderlying：表示topic-partition-replica之间的关系数据</li><li>partitionLeadershipInfo：每个分区对应的leader信息</li><li>LeaderIsr：表示分区的leader以及isr信息</li><li>LeaderIsrAndControllerEpoch：在LeaderIsr的基础上加上controller epoch，表示它是被哪一个Controller写入的</li><li>state节点：以test的第0个分区为例：/brokers/topics/test/partition/0/state中的样例数据为<br> {“controller_epoch”:19,”leader”:0,”version”:1,”leader_epoch”:57,”isr”:[0,1,2]}</li></ol><h3 id="initializeControllerContext"><a href="#initializeControllerContext" class="headerlink" title="initializeControllerContext"></a>initializeControllerContext</h3><p>controller选举的第三步——ControllerContext初始化，源码如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">initializeControllerContext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// update controller cache with delete topic information</span></span><br><span class="line">    <span class="comment">// 更新controllerContext缓存中的liveBrokers和allTopics信息</span></span><br><span class="line">    controllerContext.liveBrokers = zkClient.getAllBrokersInCluster.toSet  <span class="comment">// /brokers/ids 下所有的Broker信息（id，ip，port等）</span></span><br><span class="line">    controllerContext.allTopics = zkClient.getAllTopicsInCluster.toSet <span class="comment">// brokers/topics下所有的topic名</span></span><br><span class="line">    registerPartitionModificationsHandlers(controllerContext.allTopics.toSeq) <span class="comment">// 为allTopics中的每个topic注册监听处理器</span></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">      * 通过allTopics获取Map[TopicPartition, Seq[Replica]]</span></span><br><span class="line"><span class="comment">      * 再讲该map保存到controllerContext的Map[Topic, Map[partition, Seq[replicas]]] partitionReplicaAssignmentUnderlying</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">    zkClient.getReplicaAssignmentForTopics(controllerContext.allTopics.toSet).foreach &#123;</span><br><span class="line">      <span class="keyword">case</span> (topicPartition, assignedReplicas) =&gt; controllerContext.updatePartitionReplicaAssignment(topicPartition, assignedReplicas)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 初始化partitionLeadershipInfo和shuttingDownBrokerIds</span></span><br><span class="line">    controllerContext.partitionLeadershipInfo.clear()</span><br><span class="line">    controllerContext.shuttingDownBrokerIds = mutable.Set.empty[Int]</span><br><span class="line">    <span class="comment">// register broker modifications handlers</span></span><br><span class="line">    <span class="comment">// 注册监听 /brokers/ids/0节点的handler，endpoint字段变化会更新liveBrokers缓存</span></span><br><span class="line">    registerBrokerModificationsHandler(controllerContext.liveBrokers.map(_.id))</span><br><span class="line">    <span class="comment">// update the leader and isr cache for all existing partitions from Zookeeper</span></span><br><span class="line">    <span class="comment">// 获取分区节点的数据，并缓存到controllerContext.partitionLeadershipInfo对象里</span></span><br><span class="line">    updateLeaderAndIsrCache()</span><br><span class="line">    <span class="comment">// start the channel manager</span></span><br><span class="line">    <span class="comment">// 启动ControllerChannelManager中处理ControllerEvent的RequestSendThread线程</span></span><br><span class="line">    <span class="comment">// Zookeeper初始化与Watcher监听事件分发中有详细介绍</span></span><br><span class="line">    startChannelManager()</span><br><span class="line">    <span class="comment">// 看有没有要分区重分配的操作，有就加到partitionsBeingReassigned缓存里</span></span><br><span class="line">    initializePartitionReassignment()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>该方法主要是为了初始化ControllerContext的各个缓存，调用的方法也很多，下面选几个重要变量初始化的过程</p><h4 id="分区改变事件处理器"><a href="#分区改变事件处理器" class="headerlink" title="分区改变事件处理器"></a>分区改变事件处理器</h4><p>上面的registerPartitionModificationsHandlers为每一个topic新建了PartitionModificationsHandler</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">registerPartitionModificationsHandlers</span><span class="params">(topics: Seq[String])</span> </span>= &#123;</span><br><span class="line">  <span class="comment">// 每一个topic新建处理器，并且添加到partitionModificationsHandlers</span></span><br><span class="line">  topics.foreach &#123; topic =&gt;</span><br><span class="line">    val partitionModificationsHandler = <span class="keyword">new</span> PartitionModificationsHandler(<span class="keyword">this</span>, eventManager, topic)</span><br><span class="line">    partitionModificationsHandlers.put(topic, partitionModificationsHandler)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 注册到zk watcher的NodeChangeHandler里</span></span><br><span class="line">  partitionModificationsHandlers.values.foreach(zkClient.registerZNodeChangeHandler)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>PartitionModificationsHandler主要处理/brokers/topics/topicxxx节点的数据改变事件，首先看一下该节点存储的样例数据<br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"version"</span>:<span class="number">1</span>,<span class="attr">"partitions"</span>:&#123;<span class="attr">"4"</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>],<span class="attr">"5"</span>:[<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>],<span class="attr">"1"</span>:[<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>],<span class="attr">"0"</span>:[<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>],<span class="attr">"2"</span>:[<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>],<span class="attr">"3"</span>:[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]&#125;&#125;</span><br></pre></td></tr></table></figure></p><p>就是topic每一个分区的副本映射</p><h4 id="初始化分区副本分配关系"><a href="#初始化分区副本分配关系" class="headerlink" title="初始化分区副本分配关系"></a>初始化分区副本分配关系</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">zkClient.getReplicaAssignmentForTopics(controllerContext.allTopics.toSet).foreach &#123;</span><br><span class="line">  <span class="keyword">case</span> (topicPartition, assignedReplicas) =&gt; controllerContext.updatePartitionReplicaAssignment(topicPartition, assignedReplicas)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上代码是在初始化ControllerContext的partitionReplicaAssignmentUnderlying缓存，它保存的是每个topic的每个分区的副本映射，因此它是一个嵌套map类型<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Map[Topic, Map[Partition, Seq[Replica]]] partitionReplicaAssignmentUnderlying</span><br></pre></td></tr></table></figure></p><h4 id="分区leader缓存与分区reassign"><a href="#分区leader缓存与分区reassign" class="headerlink" title="分区leader缓存与分区reassign"></a>分区leader缓存与分区reassign</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">updateLeaderAndIsrCache</span><span class="params">(partitions: Seq[TopicPartition] = controllerContext.allPartitions.toSeq)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 每个分区节点的数据对象 &#123;"controller_epoch":19,"leader":0,"version":1,"leader_epoch":57,"isr":[0,1,2]&#125;</span></span><br><span class="line">  val leaderIsrAndControllerEpochs = zkClient.getTopicPartitionStates(partitions)</span><br><span class="line">  leaderIsrAndControllerEpochs.foreach &#123; <span class="keyword">case</span> (partition, leaderIsrAndControllerEpoch) =&gt;</span><br><span class="line">    <span class="comment">// Map[TopicPartition, LeaderIsrAndControllerEpoch]</span></span><br><span class="line">    controllerContext.partitionLeadershipInfo.put(partition, leaderIsrAndControllerEpoch)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>updateLeaderAndIsrCache方法会遍历controllerContext.allPartitions，获取/brokers/topics/topicxxx/partitions/xxx/state节点的数据<br>该节点的样例数据如下<br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"controller_epoch"</span>:<span class="number">19</span>,<span class="attr">"leader"</span>:<span class="number">0</span>,<span class="attr">"version"</span>:<span class="number">1</span>,<span class="attr">"leader_epoch"</span>:<span class="number">57</span>,<span class="attr">"isr"</span>:[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]&#125;</span><br></pre></td></tr></table></figure></p><p>分区reassign即分区副本重分配，相关内容后续会说到，这里仅说初始化<br>从/admin/reassign_partitions(临时节点)获取重分配方案，并复制给controllerContext.partitionsBeingReassigned<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">initializePartitionReassignment</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// read the partitions being reassigned from zookeeper path /admin/reassign_partitions</span></span><br><span class="line">  val partitionsBeingReassigned = zkClient.getPartitionReassignment</span><br><span class="line">  info(s<span class="string">"Partitions being reassigned: $partitionsBeingReassigned"</span>)</span><br><span class="line"></span><br><span class="line">  controllerContext.partitionsBeingReassigned ++= partitionsBeingReassigned.iterator.map &#123; <span class="keyword">case</span> (tp, newReplicas) =&gt;</span><br><span class="line">    val reassignIsrChangeHandler = <span class="keyword">new</span> PartitionReassignmentIsrChangeHandler(<span class="keyword">this</span>, eventManager, tp)</span><br><span class="line">    tp -&gt; <span class="keyword">new</span> ReassignedPartitionsContext(newReplicas, reassignIsrChangeHandler)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="topic删除管理器"><a href="#topic删除管理器" class="headerlink" title="topic删除管理器"></a>topic删除管理器</h3><p>初始化ControllerContext之后，接下来是topicDeletionManager——topic删除管理器的初始化<br>注：topic删除只会在delete.topic.enable为true时才能进行，而且分阶段进行删除<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 要删除的topics和删除失败的topics</span></span><br><span class="line">info(<span class="string">"Fetching topic deletions in progress"</span>)</span><br><span class="line">val (topicsToBeDeleted, topicsIneligibleForDeletion) = fetchTopicDeletionsInProgress()</span><br><span class="line"><span class="comment">// 初始化topic删除管理器</span></span><br><span class="line">info(<span class="string">"Initializing topic deletion manager"</span>)</span><br><span class="line">topicDeletionManager.init(topicsToBeDeleted, topicsIneligibleForDeletion)</span><br></pre></td></tr></table></figure></p><p>fetchTopicDeletionsInProgress的源码分析如下，init方法比较简单，这里就不说了<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">fetchTopicDeletionsInProgress</span><span class="params">()</span>: <span class="params">(Set[String], Set[String])</span> </span>= &#123;</span><br><span class="line">  <span class="comment">// 获取/admin/delete_topics 删除的topic</span></span><br><span class="line">  val topicsToBeDeleted = zkClient.getTopicDeletions.toSet</span><br><span class="line">  <span class="comment">// 存在不在线的副本的topic</span></span><br><span class="line">  val topicsWithOfflineReplicas = controllerContext.allTopics.filter &#123; topic =&gt; &#123;</span><br><span class="line">    val replicasForTopic = controllerContext.replicasForTopic(topic)</span><br><span class="line">    replicasForTopic.exists(r =&gt; !controllerContext.isReplicaOnline(r.replica, r.topicPartition))</span><br><span class="line">  &#125;&#125;</span><br><span class="line">  <span class="comment">// 要reassign的topic</span></span><br><span class="line">  val topicsForWhichPartitionReassignmentIsInProgress = controllerContext.partitionsBeingReassigned.keySet.map(_.topic)</span><br><span class="line">  <span class="comment">// 求二者并集，即有副本不在线的，和要reassign副本的topic都不能删，标记为不能删除(Ineligible)</span></span><br><span class="line">  val topicsIneligibleForDeletion = topicsWithOfflineReplicas | topicsForWhichPartitionReassignmentIsInProgress</span><br><span class="line">  (topicsToBeDeleted, topicsIneligibleForDeletion)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// We need to send UpdateMetadataRequest after the controller context is initialized and before the state machines</span></span><br><span class="line"><span class="comment">// are started. The is because brokers need to receive the list of live brokers from UpdateMetadataRequest before</span></span><br><span class="line"><span class="comment">// they can process the LeaderAndIsrRequests that are generated by replicaStateMachine.startup() and</span></span><br><span class="line"><span class="comment">// partitionStateMachine.startup().</span></span><br><span class="line"><span class="comment">// 在处理LeaderAndIsrRequest请求之前，先更新所有broker以及所有partition的元数据</span></span><br><span class="line">sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq)</span><br></pre></td></tr></table></figure></p><p>最后一行代码是为后面的副本状态机，分区状态机的启动做准备，将元数据同步给其它broker，让它们可以处理LeaderAndIsrRequest请求</p><h3 id="副本状态机与分区状态机的启动"><a href="#副本状态机与分区状态机的启动" class="headerlink" title="副本状态机与分区状态机的启动"></a>副本状态机与分区状态机的启动</h3><p>Controller初始化接下来的动作是启动副本状态机和分区状态机，二者都比较复杂，在另一篇文章中分析<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">replicaStateMachine.startup()</span><br><span class="line">partitionStateMachine.startup()</span><br></pre></td></tr></table></figure></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>Controller的初始化代码很多，后面的操作主要依赖于ControllerContext里的缓存以及与zk的交互，代码虽然很多，但却不难<br>后面的源码分析见以下文章列表</p><p><a href="">KafkaController源码分析之副本状态机与分区状态机的启动</a><br><a href="">KafkaController源码分析之分区重分配(PartitionReassignment)</a></p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring IOC容器之解析并注册BeanDefinition</title>
      <link href="/2020/02/08/Spring-IOC%E5%AE%B9%E5%99%A8%E4%B9%8B%E8%A7%A3%E6%9E%90%E5%B9%B6%E6%B3%A8%E5%86%8CBeanDefinition/"/>
      <url>/2020/02/08/Spring-IOC%E5%AE%B9%E5%99%A8%E4%B9%8B%E8%A7%A3%E6%9E%90%E5%B9%B6%E6%B3%A8%E5%86%8CBeanDefinition/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>ConfigurationClassPostProcessor作为当前唯一的BeanFactoryPostProcessor，而且还是一个特殊的BeanDefinitionRegistryPostProcessor(继承自BeanFactoryPostProcessor)。</p><p>按前文所说，先执行的是postProcessBeanDefinitionRegistry方法，后执行postProcessBeanFactory</p><h1 id="BeanDefinitionRegistry后置处理"><a href="#BeanDefinitionRegistry后置处理" class="headerlink" title="BeanDefinitionRegistry后置处理"></a>BeanDefinitionRegistry后置处理</h1><p>抛去一些判断不说，该方法主要是调用了processConfigBeanDefinitions</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postProcessBeanDefinitionRegistry</span><span class="params">(BeanDefinitionRegistry registry)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">int</span> registryId = System.identityHashCode(registry);</span><br><span class="line">   <span class="keyword">if</span> (<span class="keyword">this</span>.registriesPostProcessed.contains(registryId)) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(</span><br><span class="line">            <span class="string">"postProcessBeanDefinitionRegistry already called on this post-processor against "</span> + registry);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">if</span> (<span class="keyword">this</span>.factoriesPostProcessed.contains(registryId)) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(</span><br><span class="line">            <span class="string">"postProcessBeanFactory already called on this post-processor against "</span> + registry);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">this</span>.registriesPostProcessed.add(registryId);</span><br><span class="line"></span><br><span class="line">   processConfigBeanDefinitions(registry);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="processConfigBeanDefinitions"><a href="#processConfigBeanDefinitions" class="headerlink" title="processConfigBeanDefinitions"></a>processConfigBeanDefinitions</h2><p>该方法主要是从各个地方解析BeanDefinition，并注册到BeanDefinitionRegistry，而DefaultListableBeanFactory继承自BeanDefinitionRegistry，我们也可以理解为注册到Spring IOC容器中</p><p>首先我们要知道Spring中有哪些可以注册Bean的方式，以下进行例举</p><ol><li>xml配置文件，最原始的方式。groovy等不在讨论范围之内</li><li>通过java config，即@Configuration+@Bean结合的方式</li><li>@Component，@Service….等注解</li><li>通过@ComponentScan，@ComponentScans扫描</li><li>通过@Import引入配置类，它又可细分为3类：@Configuration，ImportSelector，ImportBeanDefinitionRegistrar</li><li>通过@ImportResource引入配置文件</li></ol><p>此处我们仅讨论java config的方式，spring的做法主要分为以下几步</p><ol><li>每个被@Configuration标注的类抽象成一个ConfigurationClass对象</li><li>将@Configuration注解的类中所有@Bean方法，解析成一个BeanMethod，然后添加到ConfigurationClass的beanMethods属性中</li><li>由于后续需要AOP增强，需要验证是否满足CGLIB的限制，比如类和方法不能是final，方法不能是private等</li><li>将ConfigurationClass中的beanMethods解析成BeanDefinition并注册</li></ol><p>前2步由ConfigurationClassParser的parse方法完成，第3步由validate方法完成，最后一步是由ConfigurationClassBeanDefinitionReader的loadBeanDefinitions方法完成</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processConfigBeanDefinitions</span><span class="params">(BeanDefinitionRegistry registry)</span> </span>&#123;</span><br><span class="line">   List&lt;BeanDefinitionHolder&gt; configCandidates = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">   String[] candidateNames = registry.getBeanDefinitionNames();</span><br><span class="line"></span><br><span class="line">   <span class="keyword">for</span> (String beanName : candidateNames) &#123;</span><br><span class="line">      BeanDefinition beanDef = registry.getBeanDefinition(beanName);</span><br><span class="line">      <span class="keyword">if</span> (beanDef.getAttribute(ConfigurationClassUtils.CONFIGURATION_CLASS_ATTRIBUTE) != <span class="keyword">null</span>) &#123;</span><br><span class="line">         <span class="keyword">if</span> (logger.isDebugEnabled()) &#123;</span><br><span class="line">            logger.debug(<span class="string">"Bean definition has already been processed as a configuration class: "</span> + beanDef);</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (ConfigurationClassUtils.checkConfigurationClassCandidate(beanDef, <span class="keyword">this</span>.metadataReaderFactory)) &#123;</span><br><span class="line">         configCandidates.add(<span class="keyword">new</span> BeanDefinitionHolder(beanDef, beanName));</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Return immediately if no @Configuration classes were found</span></span><br><span class="line">   <span class="keyword">if</span> (configCandidates.isEmpty()) &#123;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Sort by previously determined @Order value, if applicable</span></span><br><span class="line">   configCandidates.sort((bd1, bd2) -&gt; &#123;</span><br><span class="line">      <span class="keyword">int</span> i1 = ConfigurationClassUtils.getOrder(bd1.getBeanDefinition());</span><br><span class="line">      <span class="keyword">int</span> i2 = ConfigurationClassUtils.getOrder(bd2.getBeanDefinition());</span><br><span class="line">      <span class="keyword">return</span> Integer.compare(i1, i2);</span><br><span class="line">   &#125;);</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Detect any custom bean name generation strategy supplied through the enclosing application context</span></span><br><span class="line">   SingletonBeanRegistry sbr = <span class="keyword">null</span>;</span><br><span class="line">   <span class="keyword">if</span> (registry <span class="keyword">instanceof</span> SingletonBeanRegistry) &#123;</span><br><span class="line">      sbr = (SingletonBeanRegistry) registry;</span><br><span class="line">      <span class="keyword">if</span> (!<span class="keyword">this</span>.localBeanNameGeneratorSet) &#123;</span><br><span class="line">         BeanNameGenerator generator = (BeanNameGenerator) sbr.getSingleton(</span><br><span class="line">               AnnotationConfigUtils.CONFIGURATION_BEAN_NAME_GENERATOR);</span><br><span class="line">         <span class="keyword">if</span> (generator != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">this</span>.componentScanBeanNameGenerator = generator;</span><br><span class="line">            <span class="keyword">this</span>.importBeanNameGenerator = generator;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> (<span class="keyword">this</span>.environment == <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">this</span>.environment = <span class="keyword">new</span> StandardEnvironment();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Parse each @Configuration class</span></span><br><span class="line">   ConfigurationClassParser parser = <span class="keyword">new</span> ConfigurationClassParser(</span><br><span class="line">         <span class="keyword">this</span>.metadataReaderFactory, <span class="keyword">this</span>.problemReporter, <span class="keyword">this</span>.environment,</span><br><span class="line">         <span class="keyword">this</span>.resourceLoader, <span class="keyword">this</span>.componentScanBeanNameGenerator, registry);</span><br><span class="line"></span><br><span class="line">   Set&lt;BeanDefinitionHolder&gt; candidates = <span class="keyword">new</span> LinkedHashSet&lt;&gt;(configCandidates);</span><br><span class="line">   Set&lt;ConfigurationClass&gt; alreadyParsed = <span class="keyword">new</span> HashSet&lt;&gt;(configCandidates.size());</span><br><span class="line">   <span class="keyword">do</span> &#123;</span><br><span class="line">      parser.parse(candidates);</span><br><span class="line">      parser.validate();</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 是从ConfigurationClassParser中获取解析的结果：Set&lt;ConfigurationClass&gt;</span></span><br><span class="line">      Set&lt;ConfigurationClass&gt; configClasses = <span class="keyword">new</span> LinkedHashSet&lt;&gt;(parser.getConfigurationClasses());</span><br><span class="line">      configClasses.removeAll(alreadyParsed);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Read the model and create bean definitions based on its content</span></span><br><span class="line">      <span class="keyword">if</span> (<span class="keyword">this</span>.reader == <span class="keyword">null</span>) &#123;</span><br><span class="line">         <span class="keyword">this</span>.reader = <span class="keyword">new</span> ConfigurationClassBeanDefinitionReader(</span><br><span class="line">               registry, <span class="keyword">this</span>.sourceExtractor, <span class="keyword">this</span>.resourceLoader, <span class="keyword">this</span>.environment,</span><br><span class="line">               <span class="keyword">this</span>.importBeanNameGenerator, parser.getImportRegistry());</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">this</span>.reader.loadBeanDefinitions(configClasses);</span><br><span class="line">      alreadyParsed.addAll(configClasses);</span><br><span class="line"></span><br><span class="line">      candidates.clear();</span><br><span class="line">      <span class="keyword">if</span> (registry.getBeanDefinitionCount() &gt; candidateNames.length) &#123;</span><br><span class="line">         String[] newCandidateNames = registry.getBeanDefinitionNames();</span><br><span class="line">         Set&lt;String&gt; oldCandidateNames = <span class="keyword">new</span> HashSet&lt;&gt;(Arrays.asList(candidateNames));</span><br><span class="line">         Set&lt;String&gt; alreadyParsedClasses = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">         <span class="keyword">for</span> (ConfigurationClass configurationClass : alreadyParsed) &#123;</span><br><span class="line">            alreadyParsedClasses.add(configurationClass.getMetadata().getClassName());</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="keyword">for</span> (String candidateName : newCandidateNames) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!oldCandidateNames.contains(candidateName)) &#123;</span><br><span class="line">               BeanDefinition bd = registry.getBeanDefinition(candidateName);</span><br><span class="line">               <span class="keyword">if</span> (ConfigurationClassUtils.checkConfigurationClassCandidate(bd, <span class="keyword">this</span>.metadataReaderFactory) &amp;&amp;</span><br><span class="line">                     !alreadyParsedClasses.contains(bd.getBeanClassName())) &#123;</span><br><span class="line">                  candidates.add(<span class="keyword">new</span> BeanDefinitionHolder(bd, candidateName));</span><br><span class="line">               &#125;</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">         candidateNames = newCandidateNames;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">while</span> (!candidates.isEmpty()); <span class="comment">// 用alreadyParsed来保证不会重复注册</span></span><br><span class="line"></span><br><span class="line">   <span class="comment">// Register the ImportRegistry as a bean in order to support ImportAware @Configuration classes</span></span><br><span class="line">   <span class="keyword">if</span> (sbr != <span class="keyword">null</span> &amp;&amp; !sbr.containsSingleton(IMPORT_REGISTRY_BEAN_NAME)) &#123;</span><br><span class="line">      sbr.registerSingleton(IMPORT_REGISTRY_BEAN_NAME, parser.getImportRegistry());</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> (<span class="keyword">this</span>.metadataReaderFactory <span class="keyword">instanceof</span> CachingMetadataReaderFactory) &#123;</span><br><span class="line">      <span class="comment">// Clear cache in externally provided MetadataReaderFactory; this is a no-op</span></span><br><span class="line">      <span class="comment">// for a shared cache since it'll be cleared by the ApplicationContext.</span></span><br><span class="line">      ((CachingMetadataReaderFactory) <span class="keyword">this</span>.metadataReaderFactory).clearCache();</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="parse-解析"><a href="#parse-解析" class="headerlink" title="parse(解析)"></a>parse(解析)</h3><p>首先看下parse方法，此处省略了部分代码，由于我们仅关注java config的方式，所以只看AnnotatedBeanDefinition分支即可</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">parse</span><span class="params">(Set&lt;BeanDefinitionHolder&gt; configCandidates)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">for</span> (BeanDefinitionHolder holder : configCandidates) &#123;</span><br><span class="line">      BeanDefinition bd = holder.getBeanDefinition();</span><br><span class="line">      <span class="keyword">if</span> (bd <span class="keyword">instanceof</span> AnnotatedBeanDefinition) &#123;</span><br><span class="line">          parse(((AnnotatedBeanDefinition) bd).getMetadata(), holder.getBeanName());</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">this</span>.deferredImportSelectorHandler.process();</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">parse</span><span class="params">(AnnotationMetadata metadata, String beanName)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">processConfigurationClass(<span class="keyword">new</span> ConfigurationClass(metadata, beanName), DEFAULT_EXCLUSION_FILTER);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">processConfigurationClass</span><span class="params">(ConfigurationClass configClass, Predicate&lt;String&gt; filter)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">this</span>.conditionEvaluator.shouldSkip(configClass.getMetadata(), ConfigurationPhase.PARSE_CONFIGURATION)) &#123;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 没走</span></span><br><span class="line">ConfigurationClass existingClass = <span class="keyword">this</span>.configurationClasses.get(configClass);</span><br><span class="line"><span class="keyword">if</span> (existingClass != <span class="keyword">null</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> (configClass.isImported()) &#123;</span><br><span class="line"><span class="keyword">if</span> (existingClass.isImported()) &#123;</span><br><span class="line">existingClass.mergeImportedBy(configClass);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Otherwise ignore new imported config class; existing non-imported class overrides it.</span></span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line"><span class="comment">// Explicit bean definition found, probably replacing an import.</span></span><br><span class="line"><span class="comment">// Let's remove the old one and go with the new one.</span></span><br><span class="line"><span class="keyword">this</span>.configurationClasses.remove(configClass);</span><br><span class="line"><span class="keyword">this</span>.knownSuperclasses.values().removeIf(configClass::equals);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Recursively process the configuration class and its superclass hierarchy.</span></span><br><span class="line">SourceClass sourceClass = asSourceClass(configClass, filter);</span><br><span class="line"><span class="keyword">do</span> &#123;</span><br><span class="line">sourceClass = doProcessConfigurationClass(configClass, sourceClass, filter);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">while</span> (sourceClass != <span class="keyword">null</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">this</span>.configurationClasses.put(configClass, configClass);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ConfigurationClass的beanMethods属性"><a href="#ConfigurationClass的beanMethods属性" class="headerlink" title="ConfigurationClass的beanMethods属性"></a>ConfigurationClass的beanMethods属性</h3><p>经过层层调用，最终来到doProcessConfigurationClass方法，该方法是解析的核心步骤</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">final</span> SourceClass <span class="title">doProcessConfigurationClass</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">      ConfigurationClass configClass, SourceClass sourceClass, Predicate&lt;String&gt; filter)</span></span></span><br><span class="line"><span class="function">      <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">   <span class="comment">// @Configuration继承自@Component</span></span><br><span class="line">   <span class="keyword">if</span> (configClass.getMetadata().isAnnotated(Component.class.getName())) &#123;</span><br><span class="line">      <span class="comment">// 内部类处理，不用关注</span></span><br><span class="line">      <span class="comment">// Recursively process any member (nested) classes first</span></span><br><span class="line">      processMemberClasses(configClass, sourceClass, filter);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// 省略以下代码 ... </span></span><br><span class="line">   <span class="comment">// @PropertySource 注解处理</span></span><br><span class="line">   <span class="comment">// @ComponentScan 注解处理</span></span><br><span class="line">   <span class="comment">// @Import 注解处理</span></span><br><span class="line">   <span class="comment">// @ImportResource 注解处理</span></span><br><span class="line"></span><br><span class="line">   <span class="comment">// 核心逻辑，解析为BeanMethod，并添加到configClass的beanMethods属性中</span></span><br><span class="line">   <span class="comment">// Process individual @Bean methods</span></span><br><span class="line">   Set&lt;MethodMetadata&gt; beanMethods = retrieveBeanMethodMetadata(sourceClass);</span><br><span class="line">   <span class="keyword">for</span> (MethodMetadata methodMetadata : beanMethods) &#123;</span><br><span class="line">      configClass.addBeanMethod(<span class="keyword">new</span> BeanMethod(methodMetadata, configClass));</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// 如果配置类实现了接口，要执行接口里的default方法，可忽略</span></span><br><span class="line">   <span class="comment">// Process default methods on interfaces</span></span><br><span class="line">   processInterfaces(configClass, sourceClass);</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Process superclass, if any</span></span><br><span class="line">   <span class="keyword">if</span> (sourceClass.getMetadata().hasSuperClass()) &#123;</span><br><span class="line">      String superclass = sourceClass.getMetadata().getSuperClassName();</span><br><span class="line">      <span class="keyword">if</span> (superclass != <span class="keyword">null</span> &amp;&amp; !superclass.startsWith(<span class="string">"java"</span>) &amp;&amp;</span><br><span class="line">            !<span class="keyword">this</span>.knownSuperclasses.containsKey(superclass)) &#123;</span><br><span class="line">         <span class="keyword">this</span>.knownSuperclasses.put(superclass, configClass);</span><br><span class="line">         <span class="comment">// Superclass found, return its annotation metadata and recurse</span></span><br><span class="line">         <span class="keyword">return</span> sourceClass.getSuperClass();</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// No superclass -&gt; processing is complete</span></span><br><span class="line">   <span class="comment">// 结束，停止外层循环</span></span><br><span class="line">   <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>retrieveBeanMethodMetadata是解析@Bean方法的底层逻辑，这里其实就是用反射获取被@Bean注解标注的方法，但是JVM反射获取的方法列表是无序的，而Spring内部实现是需要顺序的，这里用ASM技术来获取方法列表</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Set&lt;MethodMetadata&gt; <span class="title">retrieveBeanMethodMetadata</span><span class="params">(SourceClass sourceClass)</span> </span>&#123;</span><br><span class="line">   AnnotationMetadata original = sourceClass.getMetadata();</span><br><span class="line">   <span class="comment">// 获取被@Bean标注的方法，JVM反射方式</span></span><br><span class="line">   Set&lt;MethodMetadata&gt; beanMethods = original.getAnnotatedMethods(Bean.class.getName());</span><br><span class="line">   <span class="comment">// JVM返回的方法在顺序上是随机的，这里要用ASM来获取方法声明的顺序，关于ASM的两个类：ClassReader和ClassVisitor</span></span><br><span class="line">   <span class="keyword">if</span> (beanMethods.size() &gt; <span class="number">1</span> &amp;&amp; original <span class="keyword">instanceof</span> StandardAnnotationMetadata) &#123;</span><br><span class="line">      <span class="comment">// Try reading the class file via ASM for deterministic declaration order...</span></span><br><span class="line">      <span class="comment">// Unfortunately, the JVM's standard reflection returns methods in arbitrary</span></span><br><span class="line">      <span class="comment">// order, even between different runs of the same application on the same JVM.</span></span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">         AnnotationMetadata asm =</span><br><span class="line">               <span class="keyword">this</span>.metadataReaderFactory.getMetadataReader(original.getClassName()).getAnnotationMetadata();</span><br><span class="line">         <span class="comment">// 通过ASM解析出来的方法列表</span></span><br><span class="line">         Set&lt;MethodMetadata&gt; asmMethods = asm.getAnnotatedMethods(Bean.class.getName());</span><br><span class="line">         <span class="keyword">if</span> (asmMethods.size() &gt;= beanMethods.size()) &#123;</span><br><span class="line">            <span class="comment">// 注意是LinkedHashSet</span></span><br><span class="line">            Set&lt;MethodMetadata&gt; selectedMethods = <span class="keyword">new</span> LinkedHashSet&lt;&gt;(asmMethods.size());</span><br><span class="line">            <span class="comment">// 两个for的作用：</span></span><br><span class="line">            <span class="comment">// 既是按asm方法列表的顺序添加，也保证了asm解析出来的方法一定在jvm解析的方法列表中，这样才能添加到返回结果中</span></span><br><span class="line">            <span class="keyword">for</span> (MethodMetadata asmMethod : asmMethods) &#123;</span><br><span class="line">               <span class="keyword">for</span> (MethodMetadata beanMethod : beanMethods) &#123;</span><br><span class="line">                  <span class="keyword">if</span> (beanMethod.getMethodName().equals(asmMethod.getMethodName())) &#123;</span><br><span class="line">                     selectedMethods.add(beanMethod);</span><br><span class="line">                     <span class="keyword">break</span>;</span><br><span class="line">                  &#125;</span><br><span class="line">               &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (selectedMethods.size() == beanMethods.size()) &#123;</span><br><span class="line">               <span class="comment">// All reflection-detected methods found in ASM method set -&gt; proceed</span></span><br><span class="line">               beanMethods = selectedMethods;</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">catch</span> (IOException ex) &#123;</span><br><span class="line">         logger.debug(<span class="string">"Failed to read class file via ASM for determining @Bean method order"</span>, ex);</span><br><span class="line">         <span class="comment">// No worries, let's continue with the reflection metadata we started with...</span></span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> beanMethods;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>parse相关的处理到此结束，主要就是将@Bean方法解析成BeanMethod，并添加到ConfigurationClass的beanMethods属性中</p><h3 id="验证与注册"><a href="#验证与注册" class="headerlink" title="验证与注册"></a>验证与注册</h3><p>首先还是说说为什么@Bean方法需要被增强，这是因为@Bean方法内部也可以调用别的@Bean方法，来实现bean的依赖，那么每调用一次就新增一个bean对象吗？这就会破坏bean的单例特性，因此就需要CGLIB增强来实现，这也是@Configuration的proxyBeanMethods默认为true的原因。当然如果bean没有被依赖，不被增强也是可以的，也就是Lite模式的Bean</p><p>验证的前提是proxyBeanMethods为true，步骤为：首先类不能是final的，不然无法增强，其次@Bean方法如果是静态的直接算通过，但如果不是静态的，而且是private final的，则会抛出异常</p><p>关于验证的源码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">validate</span><span class="params">(ProblemReporter problemReporter)</span> </span>&#123;</span><br><span class="line">   <span class="comment">// A configuration class may not be final (CGLIB limitation) unless it declares proxyBeanMethods=false</span></span><br><span class="line">   Map&lt;String, Object&gt; attributes = <span class="keyword">this</span>.metadata.getAnnotationAttributes(Configuration.class.getName());</span><br><span class="line">   <span class="keyword">if</span> (attributes != <span class="keyword">null</span> &amp;&amp; (Boolean) attributes.get(<span class="string">"proxyBeanMethods"</span>)) &#123;</span><br><span class="line">      <span class="keyword">if</span> (<span class="keyword">this</span>.metadata.isFinal()) &#123;</span><br><span class="line">         problemReporter.error(<span class="keyword">new</span> FinalConfigurationProblem());</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">for</span> (BeanMethod beanMethod : <span class="keyword">this</span>.beanMethods) &#123;</span><br><span class="line">         beanMethod.validate(problemReporter);</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">validate</span><span class="params">(ProblemReporter problemReporter)</span> </span>&#123;</span><br><span class="line"><span class="comment">// @Bean 方法如果是静态，直接算验证通过</span></span><br><span class="line"><span class="keyword">if</span> (getMetadata().isStatic()) &#123;</span><br><span class="line"><span class="comment">// static @Bean methods have no constraints to validate -&gt; return immediately</span></span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果是private，final的方法，无法被CGLIB重写</span></span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">this</span>.configurationClass.getMetadata().isAnnotated(Configuration.class.getName())) &#123;</span><br><span class="line"><span class="keyword">if</span> (!getMetadata().isOverridable()) &#123;</span><br><span class="line"><span class="comment">// instance @Bean methods within @Configuration classes must be overridable to accommodate CGLIB</span></span><br><span class="line">problemReporter.error(<span class="keyword">new</span> NonOverridableMethodError());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="解析并注册BeanDefinition"><a href="#解析并注册BeanDefinition" class="headerlink" title="解析并注册BeanDefinition"></a>解析并注册BeanDefinition</h4><p>验证通过之后，便是ConfigurationClassBeanDefinitionReader从ConfigurationClass的beanMethods属性中读取并解析BeanDefinition，相关源码在reader的loadBeanDefinitions—&gt;loadBeanDefinitionsForConfigurationClass方法中</p><p>该方法我们主要看最后一个for循环中的loadBeanDefinitionsForBeanMethod方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">loadBeanDefinitionsForConfigurationClass</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">      ConfigurationClass configClass, TrackedConditionEvaluator trackedConditionEvaluator)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// 用Condition来判断是否注册bean</span></span><br><span class="line">   <span class="keyword">if</span> (trackedConditionEvaluator.shouldSkip(configClass)) &#123;</span><br><span class="line">      String beanName = configClass.getBeanName();</span><br><span class="line">      <span class="comment">// 被跳过的就移除</span></span><br><span class="line">      <span class="keyword">if</span> (StringUtils.hasLength(beanName) &amp;&amp; <span class="keyword">this</span>.registry.containsBeanDefinition(beanName)) &#123;</span><br><span class="line">         <span class="keyword">this</span>.registry.removeBeanDefinition(beanName);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">this</span>.importRegistry.removeImportingClass(configClass.getMetadata().getClassName());</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> (configClass.isImported()) &#123;</span><br><span class="line">      registerBeanDefinitionForImportedConfigurationClass(configClass);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">for</span> (BeanMethod beanMethod : configClass.getBeanMethods()) &#123;</span><br><span class="line">      loadBeanDefinitionsForBeanMethod(beanMethod);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// 从@ImportResource中加载BeanDefinition</span></span><br><span class="line">   loadBeanDefinitionsFromImportedResources(configClass.getImportedResources());</span><br><span class="line">   <span class="comment">// 调用ImportBeanDefinitionRegistrar的回调函数，其中是BeanDefinition的注册</span></span><br><span class="line">   loadBeanDefinitionsFromRegistrars(configClass.getImportBeanDefinitionRegistrars());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>loadBeanDefinitionsForBeanMethod完成了最终的解析与注册功能，主要是Bean的各项属性填充，然后进行注册</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">loadBeanDefinitionsForBeanMethod</span><span class="params">(BeanMethod beanMethod)</span> </span>&#123;</span><br><span class="line">ConfigurationClass configClass = beanMethod.getConfigurationClass();</span><br><span class="line">MethodMetadata metadata = beanMethod.getMetadata();</span><br><span class="line">String methodName = metadata.getMethodName();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 关于Bean加载的条件判断，如Spring boot中的@ConditionalOnMissingBean</span></span><br><span class="line"><span class="comment">// Do we need to mark the bean as skipped by its condition?</span></span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">this</span>.conditionEvaluator.shouldSkip(metadata, ConfigurationPhase.REGISTER_BEAN)) &#123;</span><br><span class="line">configClass.skippedBeanMethods.add(methodName);</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (configClass.skippedBeanMethods.contains(methodName)) &#123;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取@Bean的元信息，包含里面各个属性值</span></span><br><span class="line">AnnotationAttributes bean = AnnotationConfigUtils.attributesFor(metadata, Bean.class);</span><br><span class="line">Assert.state(bean != <span class="keyword">null</span>, <span class="string">"No @Bean annotation attributes"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Consider name and any aliases</span></span><br><span class="line">List&lt;String&gt; names = <span class="keyword">new</span> ArrayList&lt;&gt;(Arrays.asList(bean.getStringArray(<span class="string">"name"</span>)));</span><br><span class="line"><span class="comment">// 默认用方法名作为bean name</span></span><br><span class="line">String beanName = (!names.isEmpty() ? names.remove(<span class="number">0</span>) : methodName);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Register aliases even when overridden</span></span><br><span class="line"><span class="comment">// 注册别名</span></span><br><span class="line"><span class="keyword">for</span> (String alias : names) &#123;</span><br><span class="line"><span class="keyword">this</span>.registry.registerAlias(beanName, alias);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Has this effectively been overridden before (e.g. via XML)?</span></span><br><span class="line"><span class="comment">// 是否被重复注册了</span></span><br><span class="line"><span class="keyword">if</span> (isOverriddenByExistingDefinition(beanMethod, beanName)) &#123;</span><br><span class="line"><span class="keyword">if</span> (beanName.equals(beanMethod.getConfigurationClass().getBeanName())) &#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> BeanDefinitionStoreException(beanMethod.getConfigurationClass().getResource().getDescription(),</span><br><span class="line">beanName, <span class="string">"Bean name derived from @Bean method '"</span> + beanMethod.getMetadata().getMethodName() +</span><br><span class="line"><span class="string">"' clashes with bean name for containing configuration class; please make those names unique!"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ConfigurationClassBeanDefinition beanDef = <span class="keyword">new</span> ConfigurationClassBeanDefinition(configClass, metadata);</span><br><span class="line">beanDef.setResource(configClass.getResource());</span><br><span class="line">beanDef.setSource(<span class="keyword">this</span>.sourceExtractor.extractSource(metadata, configClass.getResource()));</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (metadata.isStatic()) &#123;</span><br><span class="line"><span class="comment">// static @Bean method</span></span><br><span class="line"><span class="keyword">if</span> (configClass.getMetadata() <span class="keyword">instanceof</span> StandardAnnotationMetadata) &#123;</span><br><span class="line">beanDef.setBeanClass(((StandardAnnotationMetadata) configClass.getMetadata()).getIntrospectedClass());</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">beanDef.setBeanClassName(configClass.getMetadata().getClassName());</span><br><span class="line">&#125;</span><br><span class="line">beanDef.setUniqueFactoryMethodName(methodName);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line"><span class="comment">// instance @Bean method</span></span><br><span class="line">beanDef.setFactoryBeanName(configClass.getBeanName());</span><br><span class="line">beanDef.setUniqueFactoryMethodName(methodName);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (metadata <span class="keyword">instanceof</span> StandardMethodMetadata) &#123;</span><br><span class="line">beanDef.setResolvedFactoryMethod(((StandardMethodMetadata) metadata).getIntrospectedMethod());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">beanDef.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_CONSTRUCTOR);</span><br><span class="line">beanDef.setAttribute(org.springframework.beans.factory.annotation.RequiredAnnotationBeanPostProcessor.</span><br><span class="line">SKIP_REQUIRED_CHECK_ATTRIBUTE, Boolean.TRUE);</span><br><span class="line"></span><br><span class="line">AnnotationConfigUtils.processCommonDefinitionAnnotations(beanDef, metadata);</span><br><span class="line"></span><br><span class="line">Autowire autowire = bean.getEnum(<span class="string">"autowire"</span>);</span><br><span class="line"><span class="keyword">if</span> (autowire.isAutowire()) &#123;</span><br><span class="line">beanDef.setAutowireMode(autowire.value());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">boolean</span> autowireCandidate = bean.getBoolean(<span class="string">"autowireCandidate"</span>);</span><br><span class="line"><span class="keyword">if</span> (!autowireCandidate) &#123;</span><br><span class="line">beanDef.setAutowireCandidate(<span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">String initMethodName = bean.getString(<span class="string">"initMethod"</span>);</span><br><span class="line"><span class="keyword">if</span> (StringUtils.hasText(initMethodName)) &#123;</span><br><span class="line">beanDef.setInitMethodName(initMethodName);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">String destroyMethodName = bean.getString(<span class="string">"destroyMethod"</span>);</span><br><span class="line">beanDef.setDestroyMethodName(destroyMethodName);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Consider scoping</span></span><br><span class="line">ScopedProxyMode proxyMode = ScopedProxyMode.NO;</span><br><span class="line">AnnotationAttributes attributes = AnnotationConfigUtils.attributesFor(metadata, Scope.class);</span><br><span class="line"><span class="keyword">if</span> (attributes != <span class="keyword">null</span>) &#123;</span><br><span class="line">beanDef.setScope(attributes.getString(<span class="string">"value"</span>));</span><br><span class="line">proxyMode = attributes.getEnum(<span class="string">"proxyMode"</span>);</span><br><span class="line"><span class="keyword">if</span> (proxyMode == ScopedProxyMode.DEFAULT) &#123;</span><br><span class="line">proxyMode = ScopedProxyMode.NO;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Replace the original bean definition with the target one, if necessary</span></span><br><span class="line">BeanDefinition beanDefToRegister = beanDef;</span><br><span class="line"><span class="keyword">if</span> (proxyMode != ScopedProxyMode.NO) &#123;</span><br><span class="line">BeanDefinitionHolder proxyDef = ScopedProxyCreator.createScopedProxy(</span><br><span class="line"><span class="keyword">new</span> BeanDefinitionHolder(beanDef, beanName), <span class="keyword">this</span>.registry,</span><br><span class="line">proxyMode == ScopedProxyMode.TARGET_CLASS);</span><br><span class="line">beanDefToRegister = <span class="keyword">new</span> ConfigurationClassBeanDefinition(</span><br><span class="line">(RootBeanDefinition) proxyDef.getBeanDefinition(), configClass, metadata);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (logger.isTraceEnabled()) &#123;</span><br><span class="line">logger.trace(String.format(<span class="string">"Registering bean definition for @Bean method %s.%s()"</span>,</span><br><span class="line">configClass.getMetadata().getClassName(), beanName));</span><br><span class="line">&#125;</span><br><span class="line">    <span class="comment">// 注册BeanDefinition</span></span><br><span class="line"><span class="keyword">this</span>.registry.registerBeanDefinition(beanName, beanDefToRegister);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="postProcessBeanFactory"><a href="#postProcessBeanFactory" class="headerlink" title="postProcessBeanFactory"></a>postProcessBeanFactory</h2><p>在看完postProcessBeanDefinitionRegistry的源码后，还有一个postProcessBeanFactory方法，这是BeanFactoryPostProcessor中的方法，它晚于postProcessBeanDefinitionRegistry执行。</p><p>该方法主要做了两件事：增强ConfigurationClass，添加了一个BeanPostProcessor——ImportAwareBeanPostProcessor，注意这是bean的后置处理器，和现在讲的bean factory后置处理器不是一个东西</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postProcessBeanFactory</span><span class="params">(ConfigurableListableBeanFactory beanFactory)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">int</span> factoryId = System.identityHashCode(beanFactory);</span><br><span class="line">   <span class="keyword">if</span> (<span class="keyword">this</span>.factoriesPostProcessed.contains(factoryId)) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(</span><br><span class="line">            <span class="string">"postProcessBeanFactory already called on this post-processor against "</span> + beanFactory);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">this</span>.factoriesPostProcessed.add(factoryId);</span><br><span class="line">   <span class="keyword">if</span> (!<span class="keyword">this</span>.registriesPostProcessed.contains(factoryId)) &#123;</span><br><span class="line">      <span class="comment">// BeanDefinitionRegistryPostProcessor hook apparently not supported...</span></span><br><span class="line">      <span class="comment">// Simply call processConfigurationClasses lazily at this point then.</span></span><br><span class="line">      processConfigBeanDefinitions((BeanDefinitionRegistry) beanFactory);</span><br><span class="line">   &#125;</span><br><span class="line">   </span><br><span class="line">   enhanceConfigurationClasses(beanFactory);</span><br><span class="line">   beanFactory.addBeanPostProcessor(<span class="keyword">new</span> ImportAwareBeanPostProcessor(beanFactory));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="增强过程"><a href="#增强过程" class="headerlink" title="增强过程"></a>增强过程</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">enhanceConfigurationClasses</span><span class="params">(ConfigurableListableBeanFactory beanFactory)</span> </span>&#123;</span><br><span class="line">   Map&lt;String, AbstractBeanDefinition&gt; configBeanDefs = <span class="keyword">new</span> LinkedHashMap&lt;&gt;();</span><br><span class="line">   <span class="keyword">for</span> (String beanName : beanFactory.getBeanDefinitionNames()) &#123;</span><br><span class="line">      BeanDefinition beanDef = beanFactory.getBeanDefinition(beanName);</span><br><span class="line">      Object configClassAttr = beanDef.getAttribute(ConfigurationClassUtils.CONFIGURATION_CLASS_ATTRIBUTE);</span><br><span class="line">      MethodMetadata methodMetadata = <span class="keyword">null</span>;</span><br><span class="line">      <span class="keyword">if</span> (beanDef <span class="keyword">instanceof</span> AnnotatedBeanDefinition) &#123;</span><br><span class="line">         methodMetadata = ((AnnotatedBeanDefinition) beanDef).getFactoryMethodMetadata();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> ((configClassAttr != <span class="keyword">null</span> || methodMetadata != <span class="keyword">null</span>) &amp;&amp; beanDef <span class="keyword">instanceof</span> AbstractBeanDefinition) &#123;</span><br><span class="line">         <span class="comment">// Configuration class (full or lite) or a configuration-derived @Bean method</span></span><br><span class="line">         <span class="comment">// -&gt; resolve bean class at this point...</span></span><br><span class="line">         AbstractBeanDefinition abd = (AbstractBeanDefinition) beanDef;</span><br><span class="line">         <span class="keyword">if</span> (!abd.hasBeanClass()) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">               abd.resolveBeanClass(<span class="keyword">this</span>.beanClassLoader);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">catch</span> (Throwable ex) &#123;</span><br><span class="line">               <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(</span><br><span class="line">                     <span class="string">"Cannot load configuration class: "</span> + beanDef.getBeanClassName(), ex);</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (ConfigurationClassUtils.CONFIGURATION_CLASS_FULL.equals(configClassAttr)) &#123;</span><br><span class="line">         <span class="keyword">if</span> (!(beanDef <span class="keyword">instanceof</span> AbstractBeanDefinition)) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> BeanDefinitionStoreException(<span class="string">"Cannot enhance @Configuration bean definition '"</span> +</span><br><span class="line">                  beanName + <span class="string">"' since it is not stored in an AbstractBeanDefinition subclass"</span>);</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="keyword">else</span> <span class="keyword">if</span> (logger.isInfoEnabled() &amp;&amp; beanFactory.containsSingleton(beanName)) &#123;</span><br><span class="line">            logger.info(<span class="string">"Cannot enhance @Configuration bean definition '"</span> + beanName +</span><br><span class="line">                  <span class="string">"' since its singleton instance has been created too early. The typical cause "</span> +</span><br><span class="line">                  <span class="string">"is a non-static @Bean method with a BeanDefinitionRegistryPostProcessor "</span> +</span><br><span class="line">                  <span class="string">"return type: Consider declaring such methods as 'static'."</span>);</span><br><span class="line">         &#125;</span><br><span class="line">         configBeanDefs.put(beanName, (AbstractBeanDefinition) beanDef);</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">if</span> (configBeanDefs.isEmpty()) &#123;</span><br><span class="line">      <span class="comment">// nothing to enhance -&gt; return immediately</span></span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   ConfigurationClassEnhancer enhancer = <span class="keyword">new</span> ConfigurationClassEnhancer();</span><br><span class="line">   <span class="keyword">for</span> (Map.Entry&lt;String, AbstractBeanDefinition&gt; entry : configBeanDefs.entrySet()) &#123;</span><br><span class="line">      AbstractBeanDefinition beanDef = entry.getValue();</span><br><span class="line">      <span class="comment">// If a @Configuration class gets proxied, always proxy the target class</span></span><br><span class="line">      beanDef.setAttribute(AutoProxyUtils.PRESERVE_TARGET_CLASS_ATTRIBUTE, Boolean.TRUE);</span><br><span class="line">      <span class="comment">// Set enhanced subclass of the user-specified bean class</span></span><br><span class="line">      Class&lt;?&gt; configClass = beanDef.getBeanClass();</span><br><span class="line">      Class&lt;?&gt; enhancedClass = enhancer.enhance(configClass, <span class="keyword">this</span>.beanClassLoader);</span><br><span class="line">      <span class="keyword">if</span> (configClass != enhancedClass) &#123;</span><br><span class="line">         <span class="keyword">if</span> (logger.isTraceEnabled()) &#123;</span><br><span class="line">            logger.trace(String.format(<span class="string">"Replacing bean definition '%s' existing class '%s' with "</span> +</span><br><span class="line">                  <span class="string">"enhanced class '%s'"</span>, entry.getKey(), configClass.getName(), enhancedClass.getName()));</span><br><span class="line">         &#125;</span><br><span class="line">         beanDef.setBeanClass(enhancedClass);</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文主要分析了ConfigurationClassPostProcessor作为一个BeanDefinitionRegistryPostProcessor是如何将java config模式中的Bean解析BeanDefinition，并最终注册到容器中的，主要是以下思路：</p><p>因为ConfigurationClassPostProcessor实现的BeanDefinitionRegistryPostProcessor，因此我们要先看postProcessBeanDefinitionRegistry，再看postProcessBeanFactory，原因在前文也说了，invokeBeanFactoryPostProcessors是按此顺序执行的</p><p>之后Spring将注册BeanDefinition分为了3步：解析，验证，注册</p><ol><li>解析主要是将被@Configuration抽象成一个ConfigurationClass，将@Bean方法解析成一个BeanMethod，</li></ol><p>然后添加到ConfigurationClass的beanMethods属性中</p><ol start="2"><li>验证是在使用CGLIB代理的前提下，验证类和方法是否能满足CGLIB增强的条件，比如final，private等</li><li>注册是ConfigurationClassBeanDefinitionReader从ConfigurationClass的beanMethods属性中读取并解析成BeanDefinition，然后进行注册</li></ol><p>因此我们可以总结出BeanDefinitionRegistryPostProcessor的主要作用就是从各种配置中解析BeanDefinition，并注册到容器中。</p><h2 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h2><p><img src="/Users/admin/mine/spring-pics/bean_definition_registry.png" alt="bean_definition_registry"></p>]]></content>
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
            <tag> 源码 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>kafka-server端源码分析之Zookeeper初始化与Watcher监听事件分发</title>
      <link href="/2020/02/06/kafka-server%E7%AB%AF%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BZookeeper%E5%88%9D%E5%A7%8B%E5%8C%96%E4%B8%8EWatcher%E7%9B%91%E5%90%AC%E4%BA%8B%E4%BB%B6%E5%88%86%E5%8F%91/"/>
      <url>/2020/02/06/kafka-server%E7%AB%AF%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BZookeeper%E5%88%9D%E5%A7%8B%E5%8C%96%E4%B8%8EWatcher%E7%9B%91%E5%90%AC%E4%BA%8B%E4%BB%B6%E5%88%86%E5%8F%91/</url>
      <content type="html"><![CDATA[<p>这一篇比较简单，快速带大家过一下kafka如何连接ZooKeeper，以及kafka对节点事件监听的代码设计</p><h1 id="ZooKeeper大致介绍"><a href="#ZooKeeper大致介绍" class="headerlink" title="ZooKeeper大致介绍"></a>ZooKeeper大致介绍</h1><p>kafka主要利用ZooKeeper选举Controller，这里先大致介绍下ZooKeeper的基本用法，仅用于学习Kafka</p><h2 id="ZNode"><a href="#ZNode" class="headerlink" title="ZNode"></a>ZNode</h2><p>几乎所有的ZooKeeper教程都会告诉你ZooKeeper是一种类似文件系统目录结构的存储系统，但我不这么认为，文件系统中的目录本身无法存储数据，而ZooKeeper可以</p><p>ZooKeeper中的节点主要分为持久节点和临时节点，持久节点即使重启也会存在，因为它已经写入到磁盘文件了，而临时节点在ZooKeeper重启或是客户端会话超时后，就会消失</p><h2 id="zkVersion"><a href="#zkVersion" class="headerlink" title="zkVersion"></a>zkVersion</h2><p>简单的把它理解为乐观锁的版本号即可</p><h2 id="chroot"><a href="#chroot" class="headerlink" title="chroot"></a>chroot</h2><p>chroot的使用场景是一个zk集群管理了多套kafka集群，那么每个kafka集群需要一个根节点来区分<br>比如我们可以在kafka的sever.properties文件中这样配置: zookeeper.connect=localhost:2181/cluster_201</p><h2 id="zkCli"><a href="#zkCli" class="headerlink" title="zkCli"></a>zkCli</h2><p>在ZooKeeper的bin目录下，可以启动zkCli.sh脚本，通过”ls 节点名”的方式获取子节点，通过”get 节点名”的方式获取该节点存储的数据<br>如果你已经有ZooKeeper的可视化管理工具，如zkui，shepher，查看起来就更方便了</p><h2 id="kafka选举Controller的原理"><a href="#kafka选举Controller的原理" class="headerlink" title="kafka选举Controller的原理"></a>kafka选举Controller的原理</h2><p>kafka是如何利用ZooKeeper的临时节点，来选举Controller的呢？<br>kafka集群的每个节点会在启动时创建/controller节点，如果该节点不存在，并且创建成功，那么该broker就成为Controller<br>其它broker创建时就会发现节点已存在，放弃成为Controller</p><h1 id="初始化ZooKeeper"><a href="#初始化ZooKeeper" class="headerlink" title="初始化ZooKeeper"></a>初始化ZooKeeper</h1><p>初始化ZooKeeper主要是建立连接，注册监听器，入口代码在KafkaServer的启动方法中(startup)，该方法调用了initZkClient<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">initZkClient</span><span class="params">(time: Time)</span>: Unit </span>= &#123;</span><br><span class="line"><span class="comment">// 方法定义，先不看</span></span><br><span class="line"><span class="function">def <span class="title">createZkClient</span><span class="params">(zkConnect: String, isSecure: Boolean)</span> </span>=</span><br><span class="line">  KafkaZkClient(zkConnect, isSecure, config.zkSessionTimeoutMs, config.zkConnectionTimeoutMs,</span><br><span class="line">    config.zkMaxInFlightRequests, time)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取chroot，没有返回None</span></span><br><span class="line">val chrootIndex = config.zkConnect.indexOf(<span class="string">"/"</span>)</span><br><span class="line">val chrootOption = &#123;</span><br><span class="line">  <span class="keyword">if</span> (chrootIndex &gt; <span class="number">0</span>) Some(config.zkConnect.substring(chrootIndex))</span><br><span class="line">  <span class="keyword">else</span> None</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 安全配置相关</span></span><br><span class="line">val secureAclsEnabled = config.zkEnableSecureAcls <span class="comment">// zookeeper.set.acl</span></span><br><span class="line">val isZkSecurityEnabled = JaasUtils.isZkSecurityEnabled()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (secureAclsEnabled &amp;&amp; !isZkSecurityEnabled)</span><br><span class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> java.lang.SecurityException(s<span class="string">"$&#123;KafkaConfig.ZkEnableSecureAclsProp&#125; is true, but the verification of the JAAS login file failed."</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// make sure chroot path exists</span></span><br><span class="line"><span class="comment">// 确保chroot节点存在，没有则创建</span></span><br><span class="line">chrootOption.foreach &#123; chroot =&gt;</span><br><span class="line">  val zkConnForChrootCreation = config.zkConnect.substring(<span class="number">0</span>, chrootIndex)</span><br><span class="line">  <span class="comment">// 这里创建的是临时连接，仅为了创建chroot</span></span><br><span class="line">  val zkClient = createZkClient(zkConnForChrootCreation, secureAclsEnabled)</span><br><span class="line">  zkClient.makeSurePersistentPathExists(chroot)</span><br><span class="line">  info(s<span class="string">"Created zookeeper path $chroot"</span>)</span><br><span class="line">  zkClient.close()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用前面定义的嵌套方法，创建KafkaZkClient对象，它是kafka对zk操作的封装类</span></span><br><span class="line">_zkClient = createZkClient(config.zkConnect, secureAclsEnabled)</span><br><span class="line"><span class="comment">// 确保一些必须用到的节点存在，没有则创建，如: /brokers/ids, /brokers/topics, /config/changes等</span></span><br><span class="line">_zkClient.createTopLevelPaths()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>createZkClient初始化了KafkaZkClient对象，我们来看看它的apply初始化方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">apply</span><span class="params">(connectString: String,</span></span></span><br><span class="line"><span class="function"><span class="params">        isSecure: Boolean,</span></span></span><br><span class="line"><span class="function"><span class="params">        sessionTimeoutMs: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">        connectionTimeoutMs: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">        maxInFlightRequests: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">        time: Time,</span></span></span><br><span class="line"><span class="function"><span class="params">        metricGroup: String = <span class="string">"kafka.server"</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        metricType: String = <span class="string">"SessionExpireListener"</span>)</span> </span>= &#123;</span><br><span class="line"><span class="comment">// 创建了ZooKeeperClient对象</span></span><br><span class="line">val zooKeeperClient = <span class="keyword">new</span> ZooKeeperClient(connectString, sessionTimeoutMs, connectionTimeoutMs, maxInFlightRequests,</span><br><span class="line">  time, metricGroup, metricType)</span><br><span class="line"><span class="comment">// 封装成KafkaZkClient</span></span><br><span class="line"><span class="keyword">new</span> KafkaZkClient(zooKeeperClient, isSecure, time)</span><br></pre></td></tr></table></figure></p><p>KafkaZkClient最常用的2个方法是对zk请求的保证<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">private def retryRequestUntilConnected[Req &lt;: AsyncRequest](request: Req): Req#Response = &#123;</span><br><span class="line"><span class="comment">// 单个请求包装成集合</span></span><br><span class="line">retryRequestsUntilConnected(Seq(request)).head</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 批量请求</span></span><br><span class="line">private def retryRequestsUntilConnected[Req &lt;: AsyncRequest](requests: Seq[Req]): Seq[Req#Response] = &#123;</span><br><span class="line">val remainingRequests = ArrayBuffer(requests: _*) <span class="comment">// 待发送的请求集合</span></span><br><span class="line">val responses = new ArrayBuffer[Req#Response] // 响应集合</span><br><span class="line"><span class="keyword">while</span> (remainingRequests.nonEmpty) &#123;</span><br><span class="line">  val batchResponses = zooKeeperClient.handleRequests(remainingRequests)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// metric ...</span></span><br><span class="line">  batchResponses.foreach(response =&gt; latencyMetric.update(response.metadata.responseTimeMs))</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Only execute slow path if we find a response with CONNECTIONLOSS</span></span><br><span class="line">  <span class="comment">// 发现连接丢失错误的处理，继续</span></span><br><span class="line">  <span class="keyword">if</span> (batchResponses.exists(_.resultCode == Code.CONNECTIONLOSS)) &#123;</span><br><span class="line">    <span class="comment">// zip方法：合并集合 A(1,2,3), B(4,5,6)</span></span><br><span class="line">    <span class="comment">// 合并结果: [(1,4),(2,5),(3,6)]</span></span><br><span class="line">    val requestResponsePairs = remainingRequests.zip(batchResponses)</span><br><span class="line"></span><br><span class="line">    remainingRequests.clear()</span><br><span class="line">    requestResponsePairs.foreach &#123; <span class="keyword">case</span> (request, response) =&gt;</span><br><span class="line">      <span class="keyword">if</span> (response.resultCode == Code.CONNECTIONLOSS)</span><br><span class="line">        <span class="comment">// 相当于是重新放进请求队列了，怪不得要判断remainingRequests.nonEmpty</span></span><br><span class="line">        remainingRequests += request</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        responses += response</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (remainingRequests.nonEmpty)</span><br><span class="line">      <span class="comment">// 无限等待直到zk达到CONNECTED状态，或者在AUTH_FAILED/CLOSED状态下抛出异常</span></span><br><span class="line">      zooKeeperClient.waitUntilConnected()</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 响应结果正常的处理，返回结果</span></span><br><span class="line">    remainingRequests.clear()</span><br><span class="line">    responses ++= batchResponses</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">responses</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="ZooKeeperClient与ZooKeeperClientWatcher"><a href="#ZooKeeperClient与ZooKeeperClientWatcher" class="headerlink" title="ZooKeeperClient与ZooKeeperClientWatcher"></a>ZooKeeperClient与ZooKeeperClientWatcher</h2><p>ZooKeeperClient类中初始化了原生的ZooKeeper对象<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@volatile</span> <span class="keyword">private</span> var zooKeeper = <span class="keyword">new</span> ZooKeeper(connectString, sessionTimeoutMs, ZooKeeperClientWatcher)</span><br></pre></td></tr></table></figure></p><p>Watch永远都是ZooKeeper的核心对象<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[zookeeper] object ZooKeeperClientWatcher extends Watcher &#123;</span><br><span class="line">    <span class="function">override def <span class="title">process</span><span class="params">(event: WatchedEvent)</span>: Unit </span>= &#123;</span><br><span class="line">      Option(event.getPath) match &#123;</span><br><span class="line">        <span class="keyword">case</span> None =&gt;</span><br><span class="line">          val state = event.getState</span><br><span class="line">          stateToMeterMap.get(state).foreach(_.mark())</span><br><span class="line">          inLock(isConnectedOrExpiredLock) &#123;</span><br><span class="line">            isConnectedOrExpiredCondition.signalAll()</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">if</span> (state == KeeperState.AuthFailed) &#123;</span><br><span class="line">            error(<span class="string">"Auth failed."</span>)</span><br><span class="line">            stateChangeHandlers.values.foreach(_.onAuthFailure())</span><br><span class="line">          &#125; <span class="keyword">else</span> <span class="keyword">if</span> (state == KeeperState.Expired) &#123;</span><br><span class="line">            scheduleSessionExpiryHandler()</span><br><span class="line">          &#125;</span><br><span class="line">        <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(path)</span> </span>=&gt;</span><br><span class="line">          (event.getType: <span class="meta">@unchecked</span>) match &#123;</span><br><span class="line">            <span class="keyword">case</span> EventType.NodeChildrenChanged =&gt; zNodeChildChangeHandlers.get(path).foreach(_.handleChildChange())</span><br><span class="line">            <span class="keyword">case</span> EventType.NodeCreated =&gt; zNodeChangeHandlers.get(path).foreach(_.handleCreation())</span><br><span class="line">            <span class="keyword">case</span> EventType.NodeDeleted =&gt; zNodeChangeHandlers.get(path).foreach(_.handleDeletion())</span><br><span class="line">            <span class="keyword">case</span> EventType.NodeDataChanged =&gt; zNodeChangeHandlers.get(path).foreach(_.handleDataChange())</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p><p>和java类似的写法，没有path时kafka对AuthFailed和Expired两种情况作了处理，不是重点<br>ZooKeeper使用EventType表示节点的4种事件，kafka针对不同节点的不同事件都有一组handler去处理，这里通过path获取handler并执行</p><p>注：不要被foreach迷惑，Option类的foreach表示对象不为空，就执行传入的函数</p><p>handlers定义的Map如下，此时Map是空的，会在后续的kafka启动程序中将handler添加进来(比如Controller启动)<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> val zNodeChangeHandlers = <span class="keyword">new</span> ConcurrentHashMap[String, ZNodeChangeHandler]().asScala</span><br><span class="line"><span class="keyword">private</span> val zNodeChildChangeHandlers = <span class="keyword">new</span> ConcurrentHashMap[String, ZNodeChildChangeHandler]().asScala</span><br></pre></td></tr></table></figure></p><p>其实到现在ZooKeeper已经启动完毕了，但是事情没有这么简单，kafka对事件的处理又采用了经典的内存队列异步处理模式，这种模式在kafka中无处不在</p><h2 id="kafka内存队列异步处理zk事件"><a href="#kafka内存队列异步处理zk事件" class="headerlink" title="kafka内存队列异步处理zk事件"></a>kafka内存队列异步处理zk事件</h2><p>通过一个简单的例子来说明kafka是如何处理zk事件的</p><p>上述的ZNodeChildChangeHandler只是一个接口，我们看下其中一个实现类<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class ControllerChangeHandler(controller: KafkaController, eventManager: ControllerEventManager) extends ZNodeChangeHandler &#123;</span><br><span class="line">  override val path: String = ControllerZNode.path</span><br><span class="line"></span><br><span class="line">  <span class="function">override def <span class="title">handleCreation</span><span class="params">()</span>: Unit </span>= eventManager.put(controller.ControllerChange)</span><br><span class="line">  <span class="function">override def <span class="title">handleDeletion</span><span class="params">()</span>: Unit </span>= eventManager.put(controller.Reelect)</span><br><span class="line">  <span class="function">override def <span class="title">handleDataChange</span><span class="params">()</span>: Unit </span>= eventManager.put(controller.ControllerChange)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>zk将不同的节点事件，转换成kafka内部的事件处理器，封装成了一个ControllerEvent对象，然后放到一个内存队列里，启动一个线程轮询处理zk事件</p><p>BrokerChange的源码如下, 主要处理放到了process中<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 上面的put方法</span></span><br><span class="line">eventManager.put(controller.BrokerChange)</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> object BrokerChange extends ControllerEvent &#123;</span><br><span class="line">override def state: ControllerState = ControllerState.BrokerChange</span><br><span class="line"></span><br><span class="line"><span class="function">override def <span class="title">process</span><span class="params">()</span>: Unit </span>= &#123;</span><br><span class="line">  <span class="comment">// 省略处理代码 ...</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>那么eventManager#put做了什么呢<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> val queue = <span class="keyword">new</span> LinkedBlockingQueue[ControllerEvent]</span><br><span class="line"></span><br><span class="line"><span class="function">def <span class="title">put</span><span class="params">(event: ControllerEvent)</span>: Unit </span>= inLock(putLock) &#123;</span><br><span class="line">queue.put(event)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>把BrokerChange放入到了一个LinkedBlockingQueue中</p><p>而在后续的eventManager启动过程中，启动了ControllerEventThread线程</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> val thread = <span class="keyword">new</span> ControllerEventThread(ControllerEventManager.ControllerEventThreadName)</span><br><span class="line"><span class="function">def <span class="title">start</span><span class="params">()</span>: Unit </span>= thread.start()</span><br><span class="line"></span><br><span class="line">class ControllerEventThread(name: String) extends ShutdownableThread(name = name, isInterruptible = false) &#123;</span><br><span class="line"><span class="function">override def <span class="title">doWork</span><span class="params">()</span>: Unit </span>= &#123;</span><br><span class="line">  <span class="comment">// 从队列中取出ControllerEvent</span></span><br><span class="line">  queue.take() match &#123;</span><br><span class="line">    <span class="keyword">case</span> KafkaController.ShutdownEventThread =&gt; initiateShutdown()</span><br><span class="line">    <span class="keyword">case</span> controllerEvent =&gt;</span><br><span class="line">      _state = controllerEvent.state</span><br><span class="line"></span><br><span class="line">      eventQueueTimeHist.update(time.milliseconds() - controllerEvent.enqueueTimeMs)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        rateAndTimeMetrics(state).time &#123;</span><br><span class="line">          <span class="comment">// 调用process方法</span></span><br><span class="line">          controllerEvent.process()</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> e: Throwable =&gt; error(s<span class="string">"Error processing event $controllerEvent"</span>, e)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// metric相关的监听</span></span><br><span class="line">      <span class="function"><span class="keyword">try</span> <span class="title">eventProcessedListener</span><span class="params">(controllerEvent)</span></span></span><br><span class="line"><span class="function">      <span class="keyword">catch</span> </span>&#123;</span><br><span class="line">        <span class="keyword">case</span> e: Throwable =&gt; error(s<span class="string">"Error while invoking listener for processed event $controllerEvent"</span>, e)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      _state = ControllerState.Idle</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>从kafka的网络请求处理模型开始，就遇见了内存队列来异步处理的模型，这种模型和mq类似，不过它是本地内存中的队列，kafka有很多地方使用了这种模式，这也是我们学习源码之后的收获<br>最后用流程图总结下<br><img src="https://ae01.alicdn.com/kf/Hb9e64a8b20784f63b40228cb32fcf6adO.png" alt=""></p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring IOC容器之refresh流程(一)</title>
      <link href="/2020/02/05/Spring-IOC%E5%AE%B9%E5%99%A8%E4%B9%8Brefresh%E6%B5%81%E7%A8%8B-%E4%B8%80/"/>
      <url>/2020/02/05/Spring-IOC%E5%AE%B9%E5%99%A8%E4%B9%8Brefresh%E6%B5%81%E7%A8%8B-%E4%B8%80/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>上文讲到了AnnotationConfigApplicationContext初始化的前两步，本文开始重点讲解第三步refresh。</p><h1 id="类图"><a href="#类图" class="headerlink" title="类图"></a>类图</h1><p>AbstractApplicationContext是所有ApplicationContext实现类的抽象接口，在它的refresh方法中抽象出了绝大部分的代码，而子类只需要根据需要实现其中几个方法，用于不同子类的差异，或者为子类提供钩子函数。</p><p><img src="/Users/admin/mine/spring-pics/refresh_uml.png" alt="refresh_uml"></p><p>注意，上文提到过GenericApplicationContext会创建DefaultListableBeanFactory</p><h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><p>refresh方法源码很多，我会拆分并省略部分不重要的代码。但有一点可以事先说明的是，refresh最重要的2个方法调用是invokeBeanFactoryPostProcessors和finishBeanFactoryInitialization</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">refresh</span><span class="params">()</span> <span class="keyword">throws</span> BeansException, IllegalStateException </span>&#123;</span><br><span class="line">   <span class="keyword">synchronized</span> (<span class="keyword">this</span>.startupShutdownMonitor) &#123;</span><br><span class="line">      <span class="comment">// Prepare this context for refreshing.</span></span><br><span class="line">      prepareRefresh();</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Tell the subclass to refresh the internal bean factory.</span></span><br><span class="line">      ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Prepare the bean factory for use in this context.</span></span><br><span class="line">      prepareBeanFactory(beanFactory);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">         <span class="comment">// Allows post-processing of the bean factory in context subclasses.</span></span><br><span class="line">         postProcessBeanFactory(beanFactory);</span><br><span class="line"></span><br><span class="line">         <span class="comment">// Invoke factory processors registered as beans in the context.</span></span><br><span class="line">         invokeBeanFactoryPostProcessors(beanFactory);</span><br><span class="line"></span><br><span class="line">         <span class="comment">// Register bean processors that intercept bean creation.</span></span><br><span class="line">         registerBeanPostProcessors(beanFactory);</span><br><span class="line"></span><br><span class="line">         <span class="comment">// Initialize message source for this context.</span></span><br><span class="line">         initMessageSource();</span><br><span class="line"></span><br><span class="line">         <span class="comment">// Initialize event multicaster for this context.</span></span><br><span class="line">         initApplicationEventMulticaster();</span><br><span class="line"></span><br><span class="line">         <span class="comment">// Initialize other special beans in specific context subclasses.</span></span><br><span class="line">         onRefresh();</span><br><span class="line"></span><br><span class="line">         <span class="comment">// Check for listener beans and register them.</span></span><br><span class="line">         registerListeners();</span><br><span class="line"></span><br><span class="line">         <span class="comment">// Instantiate all remaining (non-lazy-init) singletons.</span></span><br><span class="line">         finishBeanFactoryInitialization(beanFactory);</span><br><span class="line"></span><br><span class="line">         <span class="comment">// Last step: publish corresponding event.</span></span><br><span class="line">         finishRefresh();</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">catch</span> (BeansException ex) &#123;</span><br><span class="line">        <span class="comment">// 暂时省略 ...</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">finally</span> &#123;</span><br><span class="line">          <span class="comment">// 暂时省略 ...</span></span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先就是一个对象锁，防止多线程情况下重复执行refresh，第一个方法是prepareRefresh</p><h2 id="prepareRefresh"><a href="#prepareRefresh" class="headerlink" title="prepareRefresh"></a>prepareRefresh</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">prepareRefresh</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   <span class="comment">// Switch to active.</span></span><br><span class="line">   <span class="comment">// 记录启动事件，并重置2个标志位表示容器启动 </span></span><br><span class="line">   <span class="keyword">this</span>.startupDate = System.currentTimeMillis();</span><br><span class="line">   <span class="keyword">this</span>.closed.set(<span class="keyword">false</span>);</span><br><span class="line">   <span class="keyword">this</span>.active.set(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Initialize any placeholder property sources in the context environment.</span></span><br><span class="line">   <span class="comment">// AnnotationConfigApplicationContext这条分支没有实现，不关注</span></span><br><span class="line">   initPropertySources();</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Validate that all properties marked as required are resolvable:</span></span><br><span class="line">   <span class="comment">// see ConfigurablePropertyResolver#setRequiredProperties</span></span><br><span class="line">   <span class="comment">// 校验配置，目前需要校验的参数为0，暂不关注</span></span><br><span class="line">   getEnvironment().validateRequiredProperties();</span><br><span class="line"></span><br><span class="line">   <span class="comment">// 创建需要在refresh之前就需要监听的事件及监听器集合</span></span><br><span class="line">   <span class="comment">// Store pre-refresh ApplicationListeners...</span></span><br><span class="line">   <span class="keyword">if</span> (<span class="keyword">this</span>.earlyApplicationListeners == <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">this</span>.earlyApplicationListeners = <span class="keyword">new</span> LinkedHashSet&lt;&gt;(<span class="keyword">this</span>.applicationListeners);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// Reset local application listeners to pre-refresh state.</span></span><br><span class="line">      <span class="keyword">this</span>.applicationListeners.clear();</span><br><span class="line">      <span class="keyword">this</span>.applicationListeners.addAll(<span class="keyword">this</span>.earlyApplicationListeners);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Allow for the collection of early ApplicationEvents,</span></span><br><span class="line">   <span class="comment">// to be published once the multicaster is available...</span></span><br><span class="line">   <span class="keyword">this</span>.earlyApplicationEvents = <span class="keyword">new</span> LinkedHashSet&lt;&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="obtainFreshBeanFactory"><a href="#obtainFreshBeanFactory" class="headerlink" title="obtainFreshBeanFactory"></a>obtainFreshBeanFactory</h3><p>该方法主要从子类中获取beanFactory，并刷新beanFactory。刷新由GenericApplicationContext实现，主要是设置刷新标志位，并设置序列化Id，此处的id为当前AnnotationConfigApplicationContext对象的内存地址值</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> ConfigurableListableBeanFactory <span class="title">obtainFreshBeanFactory</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    refreshBeanFactory();</span><br><span class="line">    <span class="keyword">return</span> getBeanFactory();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// GenericApplicationContext实现</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">refreshBeanFactory</span><span class="params">()</span> <span class="keyword">throws</span> IllegalStateException </span>&#123;</span><br><span class="line">   <span class="keyword">if</span> (!<span class="keyword">this</span>.refreshed.compareAndSet(<span class="keyword">false</span>, <span class="keyword">true</span>)) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(</span><br><span class="line">            <span class="string">"GenericApplicationContext does not support multiple refresh attempts: just call 'refresh' once"</span>);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">this</span>.beanFactory.setSerializationId(getId());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="prepareBeanFactory"><a href="#prepareBeanFactory" class="headerlink" title="prepareBeanFactory"></a>prepareBeanFactory</h3><p>该方法的代码很多，通过注释看，主要还是准备工作，我们需要重点关注的是注册的BeanPostProcessor，这里有3个：ApplicationContextAwareProcessor，ApplicationListenerDetector，LoadTimeWeaverAwareProcessor。分别对应我们平时用到的Aware接口，事件监听以及AOP</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">prepareBeanFactory</span><span class="params">(ConfigurableListableBeanFactory beanFactory)</span> </span>&#123;</span><br><span class="line"><span class="comment">// Tell the internal bean factory to use the context's class loader etc.</span></span><br><span class="line"><span class="comment">// 设置用于加载bean的ClassLoader，默认是当前线程的context ClassLoader</span></span><br><span class="line">beanFactory.setBeanClassLoader(getClassLoader());</span><br><span class="line">beanFactory.setBeanExpressionResolver(<span class="keyword">new</span> StandardBeanExpressionResolver(beanFactory.getBeanClassLoader()));</span><br><span class="line">beanFactory.addPropertyEditorRegistrar(<span class="keyword">new</span> ResourceEditorRegistrar(<span class="keyword">this</span>, getEnvironment()));</span><br><span class="line"></span><br><span class="line"><span class="comment">// Configure the bean factory with context callbacks.</span></span><br><span class="line"><span class="comment">// 注册了一个BeanPostProcessor，主要是为bean提供EnvironmentAware，ApplicationContextAware等接口的实现</span></span><br><span class="line">beanFactory.addBeanPostProcessor(<span class="keyword">new</span> ApplicationContextAwareProcessor(<span class="keyword">this</span>));</span><br><span class="line"><span class="comment">// 忽略依赖注入的bean，通常是容器内部用的</span></span><br><span class="line">beanFactory.ignoreDependencyInterface(EnvironmentAware.class);</span><br><span class="line">beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class);</span><br><span class="line">beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class);</span><br><span class="line">beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class);</span><br><span class="line">beanFactory.ignoreDependencyInterface(MessageSourceAware.class);</span><br><span class="line">beanFactory.ignoreDependencyInterface(ApplicationContextAware.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// BeanFactory interface not registered as resolvable type in a plain factory.</span></span><br><span class="line"><span class="comment">// MessageSource registered (and found for autowiring) as a bean.</span></span><br><span class="line">beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory);</span><br><span class="line">beanFactory.registerResolvableDependency(ResourceLoader.class, <span class="keyword">this</span>);</span><br><span class="line">beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, <span class="keyword">this</span>);</span><br><span class="line">beanFactory.registerResolvableDependency(ApplicationContext.class, <span class="keyword">this</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实现spring事件监听机制用的，ApplicationListener的BeanPostProcessor</span></span><br><span class="line"><span class="comment">// Register early post-processor for detecting inner beans as ApplicationListeners.</span></span><br><span class="line">beanFactory.addBeanPostProcessor(<span class="keyword">new</span> ApplicationListenerDetector(<span class="keyword">this</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// Detect a LoadTimeWeaver and prepare for weaving, if found.</span></span><br><span class="line"><span class="comment">// AOP相关，LTW织入的BeanPostProcessor</span></span><br><span class="line"><span class="keyword">if</span> (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123;</span><br><span class="line">beanFactory.addBeanPostProcessor(<span class="keyword">new</span> LoadTimeWeaverAwareProcessor(beanFactory));</span><br><span class="line"><span class="comment">// Set a temporary ClassLoader for type matching.</span></span><br><span class="line">beanFactory.setTempClassLoader(<span class="keyword">new</span> ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader()));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册环境相关的单例对象</span></span><br><span class="line"><span class="comment">// Register default environment beans.</span></span><br><span class="line"><span class="keyword">if</span> (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) &#123;</span><br><span class="line">beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment());</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) &#123;</span><br><span class="line">beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties());</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) &#123;</span><br><span class="line">beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>prepareBeanFactory的分析到此为止，接下来的postProcessBeanFactory方法在子类中没有重写，不用关注，直接看invokeBeanFactoryPostProcessors。</p><h3 id="invokeBeanFactoryPostProcessors"><a href="#invokeBeanFactoryPostProcessors" class="headerlink" title="invokeBeanFactoryPostProcessors"></a>invokeBeanFactoryPostProcessors</h3><p>该方法很简单，首先是调用所有的BeanFactoryPostProcessor，后面的if可以不用关注，因为在prepareBeanFactory方法已添加过了，这里不会进if</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">invokeBeanFactoryPostProcessors</span><span class="params">(ConfigurableListableBeanFactory beanFactory)</span> </span>&#123;</span><br><span class="line">   PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors());</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Detect a LoadTimeWeaver and prepare for weaving, if found in the meantime</span></span><br><span class="line">   <span class="comment">// (e.g. through an @Bean method registered by ConfigurationClassPostProcessor)</span></span><br><span class="line">   <span class="comment">// Aspectj LWT 类加载时织入</span></span><br><span class="line">   <span class="keyword">if</span> (beanFactory.getTempClassLoader() == <span class="keyword">null</span> &amp;&amp; beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123;</span><br><span class="line">      beanFactory.addBeanPostProcessor(<span class="keyword">new</span> LoadTimeWeaverAwareProcessor(beanFactory));</span><br><span class="line">      beanFactory.setTempClassLoader(<span class="keyword">new</span> ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader()));</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="PostProcessorRegistrationDelegate调用BeanFactoryPostProcessor"><a href="#PostProcessorRegistrationDelegate调用BeanFactoryPostProcessor" class="headerlink" title="PostProcessorRegistrationDelegate调用BeanFactoryPostProcessor"></a>PostProcessorRegistrationDelegate调用BeanFactoryPostProcessor</h4><p>在看该方法之前，先看看以下2个类图。</p><p>DefaultListableBeanFactory是默认的BeanFactory实现，但同时它也实现了BeanDefinitionRegistry接口；那么BeanFactoryPostProcessor对应的就有一个BeanDefinitionRegistryPostProcessor</p><p><img src="/Users/admin/mine/spring-pics/factory_processor.png" alt="factory_processor"></p><h4 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h4><p>invokeBeanFactoryPostProcessors方法的源码如下，首先我们看一下注释中的第一部分。</p><p>第一部分主要是执行BeanFactoryPostProcessor，前面我也说了，有一种特殊的BeanFactoryPostProcessor——BeanDefinitionRegistryPostProcessor，通过名字我们也知道它是具有BeanDefinition注册功能的后置处理器，</p><p>这里需要我们细心观察下，是执行了BeanDefinitionRegistryPostProcessor，但是普通的BeanFactoryPostProcessor只是添加进了regularPostProcessors</p><p>还有十分重要的一点是，绝大部分的PostProcessor都不会在这里执行，因为必须是通过AbstractApplicationContext#addBeanFactoryPostProcessor添加进来的BeanFactoryPostProcessor才会在第一分部执行，比如我们常用的Spring boot通过实现ApplicationContextInitializer接口，就是调用了addBeanFactoryPostProcessor方法添加进来的PostProcessor就会执行</p><h5 id="执行顺序"><a href="#执行顺序" class="headerlink" title="执行顺序"></a>执行顺序</h5><p>上述的BeanFactoryPostProcessor集合是方法参数里传进来的，何时添加的上面也说过了，下面的BeanFactoryPostProcessor集合则是从容器里获取的，这类BeanFactoryPostProcessor又按执行顺序分为三类：</p><ol><li>实现了PriorityOrdered的BeanDefinitionRegistryPostProcessor</li><li>实现了Ordered的BeanDefinitionRegistryPostProcessor</li><li>其它BeanFactoryPostProcessor</li></ol><p>第二部分的源码主要就是从容器中获取并按顺序执行了这三类BeanFactoryPostProcessor，也可以看出先执行的是BeanDefinitionRegistryPostProcessor的postProcessBeanDefinitionRegistry方法，最后才执行BeanFactoryPostProcessor的postProcessBeanFactory方法</p><p>注意类图中BeanDefinitionRegistryPostProcessor继承自BeanFactoryPostProcessor的关系</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">invokeBeanFactoryPostProcessors</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">      ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Invoke BeanDefinitionRegistryPostProcessors first, if any.</span></span><br><span class="line">   Set&lt;String&gt; processedBeans = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line"></span><br><span class="line">   <span class="comment">// ===================== 第一部分 ============================</span></span><br><span class="line">   <span class="comment">// DefaultListableBeanFactory继承了BeanDefinitionRegistry</span></span><br><span class="line">   <span class="keyword">if</span> (beanFactory <span class="keyword">instanceof</span> BeanDefinitionRegistry) &#123;</span><br><span class="line">      BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory;</span><br><span class="line">      List&lt;BeanFactoryPostProcessor&gt; regularPostProcessors = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">      List&lt;BeanDefinitionRegistryPostProcessor&gt; registryProcessors = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 这里调用的是通过AbstractApplicationContext#addBeanFactoryPostProcessor添加进来的BeanDefinitionRegistryPostProcessor</span></span><br><span class="line">      <span class="comment">// 例如Spring boot通过实现ApplicationContextInitializer接口添加了很多BeanDefinitionRegistryPostProcessor</span></span><br><span class="line">      <span class="keyword">for</span> (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) &#123;</span><br><span class="line">         <span class="keyword">if</span> (postProcessor <span class="keyword">instanceof</span> BeanDefinitionRegistryPostProcessor) &#123;</span><br><span class="line">            BeanDefinitionRegistryPostProcessor registryProcessor =</span><br><span class="line">                  (BeanDefinitionRegistryPostProcessor) postProcessor;</span><br><span class="line">            <span class="comment">// 执行</span></span><br><span class="line">            registryProcessor.postProcessBeanDefinitionRegistry(registry);</span><br><span class="line">            registryProcessors.add(registryProcessor);</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 这里是普通的BeanFactoryPostProcessor，仅仅添加到了集合，并没有开始执行</span></span><br><span class="line">            regularPostProcessors.add(postProcessor);</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">       <span class="comment">// ===================== 第二部分 ============================</span></span><br><span class="line">      <span class="comment">// Do not initialize FactoryBeans here: We need to leave all regular beans</span></span><br><span class="line">      <span class="comment">// uninitialized to let the bean factory post-processors apply to them!</span></span><br><span class="line">      <span class="comment">// Separate between BeanDefinitionRegistryPostProcessors that implement</span></span><br><span class="line">      <span class="comment">// PriorityOrdered, Ordered, and the rest.</span></span><br><span class="line">      List&lt;BeanDefinitionRegistryPostProcessor&gt; currentRegistryProcessors = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">      <span class="comment">// First, invoke the BeanDefinitionRegistryPostProcessors that implement PriorityOrdered.</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// 先调用的是实现了PriorityOrdered接口的BeanDefinitionRegistryPostProcessor</span></span><br><span class="line">      String[] postProcessorNames =</span><br><span class="line">            beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, <span class="keyword">true</span>, <span class="keyword">false</span>);</span><br><span class="line">      <span class="keyword">for</span> (String ppName : postProcessorNames) &#123;</span><br><span class="line">         <span class="keyword">if</span> (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123;</span><br><span class="line">            currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));</span><br><span class="line">            processedBeans.add(ppName);</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      sortPostProcessors(currentRegistryProcessors, beanFactory);</span><br><span class="line">      registryProcessors.addAll(currentRegistryProcessors);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 这里就包含了ConfigurationClassPostProcessor，它基本解决了绝大部分bean的BeanDefinition解析以及注册</span></span><br><span class="line">      invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);</span><br><span class="line">      <span class="comment">// 该阶段结束，清空一次</span></span><br><span class="line">      currentRegistryProcessors.clear();</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Next, invoke the BeanDefinitionRegistryPostProcessors that implement Ordered.</span></span><br><span class="line">      <span class="comment">// 第二批处理的是实现了Ordered的BeanDefinitionRegistryPostProcessor</span></span><br><span class="line">      postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, <span class="keyword">true</span>, <span class="keyword">false</span>);</span><br><span class="line">      <span class="keyword">for</span> (String ppName : postProcessorNames) &#123;</span><br><span class="line">         <span class="keyword">if</span> (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) &#123;</span><br><span class="line">            currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));</span><br><span class="line">            processedBeans.add(ppName);</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      sortPostProcessors(currentRegistryProcessors, beanFactory);</span><br><span class="line">      registryProcessors.addAll(currentRegistryProcessors);</span><br><span class="line">      invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);</span><br><span class="line">      currentRegistryProcessors.clear();</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Finally, invoke all other BeanDefinitionRegistryPostProcessors until no further ones appear.</span></span><br><span class="line">      <span class="keyword">boolean</span> reiterate = <span class="keyword">true</span>;</span><br><span class="line">      <span class="keyword">while</span> (reiterate) &#123;</span><br><span class="line">         reiterate = <span class="keyword">false</span>;</span><br><span class="line">         postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, <span class="keyword">true</span>, <span class="keyword">false</span>);</span><br><span class="line">         <span class="keyword">for</span> (String ppName : postProcessorNames) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!processedBeans.contains(ppName)) &#123;</span><br><span class="line">               currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));</span><br><span class="line">               processedBeans.add(ppName);</span><br><span class="line">               reiterate = <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">         sortPostProcessors(currentRegistryProcessors, beanFactory);</span><br><span class="line">         registryProcessors.addAll(currentRegistryProcessors);</span><br><span class="line">         invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);</span><br><span class="line">         currentRegistryProcessors.clear();</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Now, invoke the postProcessBeanFactory callback of all processors handled so far.</span></span><br><span class="line">      <span class="comment">// 为什么还要再执行一次BeanDefinitionRegistryPostProcessor，里面有判断，执行过的就不再执行了，所以不会重复执行</span></span><br><span class="line">      invokeBeanFactoryPostProcessors(registryProcessors, beanFactory);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 执行普通的BeanFactoryPostProcessor</span></span><br><span class="line">      invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// Invoke factory processors registered with the context instance.</span></span><br><span class="line">      <span class="comment">// 没有实现BeanDefinitionRegistry的BeanFactory，在这里调用BeanFactoryPostProcessor</span></span><br><span class="line">      invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Do not initialize FactoryBeans here: We need to leave all regular beans</span></span><br><span class="line">   <span class="comment">// uninitialized to let the bean factory post-processors apply to them!</span></span><br><span class="line">   String[] postProcessorNames =</span><br><span class="line">         beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, <span class="keyword">true</span>, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Separate between BeanFactoryPostProcessors that implement PriorityOrdered,</span></span><br><span class="line">   <span class="comment">// Ordered, and the rest.</span></span><br><span class="line">   List&lt;BeanFactoryPostProcessor&gt; priorityOrderedPostProcessors = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">   List&lt;String&gt; orderedPostProcessorNames = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">   List&lt;String&gt; nonOrderedPostProcessorNames = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">   <span class="keyword">for</span> (String ppName : postProcessorNames) &#123;</span><br><span class="line">      <span class="comment">// 这里会跳过上面已经执行的BeanFactoryPostProcessor</span></span><br><span class="line">      <span class="keyword">if</span> (processedBeans.contains(ppName)) &#123;</span><br><span class="line">         <span class="comment">// skip - already processed in first phase above</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123;</span><br><span class="line">         priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class));</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123;</span><br><span class="line">         orderedPostProcessorNames.add(ppName);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">else</span> &#123;</span><br><span class="line">         nonOrderedPostProcessorNames.add(ppName);</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// First, invoke the BeanFactoryPostProcessors that implement PriorityOrdered.</span></span><br><span class="line">   sortPostProcessors(priorityOrderedPostProcessors, beanFactory);</span><br><span class="line">   invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory);</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Next, invoke the BeanFactoryPostProcessors that implement Ordered.</span></span><br><span class="line">   List&lt;BeanFactoryPostProcessor&gt; orderedPostProcessors = <span class="keyword">new</span> ArrayList&lt;&gt;(orderedPostProcessorNames.size());</span><br><span class="line">   <span class="keyword">for</span> (String postProcessorName : orderedPostProcessorNames) &#123;</span><br><span class="line">      orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class));</span><br><span class="line">   &#125;</span><br><span class="line">   sortPostProcessors(orderedPostProcessors, beanFactory);</span><br><span class="line">   invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory);</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Finally, invoke all other BeanFactoryPostProcessors.</span></span><br><span class="line">   List&lt;BeanFactoryPostProcessor&gt; nonOrderedPostProcessors = <span class="keyword">new</span> ArrayList&lt;&gt;(nonOrderedPostProcessorNames.size());</span><br><span class="line">   <span class="keyword">for</span> (String postProcessorName : nonOrderedPostProcessorNames) &#123;</span><br><span class="line">      nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class));</span><br><span class="line">   &#125;</span><br><span class="line">   invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory);</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Clear cached merged bean definitions since the post-processors might have</span></span><br><span class="line">   <span class="comment">// modified the original metadata, e.g. replacing placeholders in values...</span></span><br><span class="line">   beanFactory.clearMetadataCache();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>invokeBeanFactoryPostProcessors方法看似代码很多，但一言以蔽之，就是执行了所有的BeanFactoryPostProcessor，在当前的测试方法中，BeanFactoryPostProcessor的实现类只有一个：ConfigurationClassPostProcessor，下文主要讲解该类</p>]]></content>
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
            <tag> 源码 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring IOC容器启动之初始化上下文</title>
      <link href="/2020/02/03/Spring-IOC%E5%AE%B9%E5%99%A8%E5%90%AF%E5%8A%A8%E4%B9%8B%E5%88%9D%E5%A7%8B%E5%8C%96%E4%B8%8A%E4%B8%8B%E6%96%87/"/>
      <url>/2020/02/03/Spring-IOC%E5%AE%B9%E5%99%A8%E5%90%AF%E5%8A%A8%E4%B9%8B%E5%88%9D%E5%A7%8B%E5%8C%96%E4%B8%8A%E4%B8%8B%E6%96%87/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本文采用AnnotationConfigApplicationContext作为上下文，如果是web容器大部分源码可用于参考，但不能保证一致。</p><p>Spring IOC容器的源码很多，分解为多篇文章来讲解，</p><h1 id="测试代码"><a href="#测试代码" class="headerlink" title="测试代码"></a>测试代码</h1><p>测试代码很简单，我这里用了spring自带的测试类ConfigForScanning和TestBean，大家也可以自己写一个</p><p>源码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConfigForScanning</span> </span>&#123;</span><br><span class="line">   <span class="meta">@Bean</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> TestBean <span class="title">testBean</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> TestBean();</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上方式也就是我们常说的java config，再写一个最常见的基于注解的上下文来测试</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testGetBean</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   ApplicationContext context = <span class="keyword">new</span> AnnotationConfigApplicationContext(ConfigForScanning.class);</span><br><span class="line">   TestBean bean = context.getBean(TestBean.class);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="初始化上下文"><a href="#初始化上下文" class="headerlink" title="初始化上下文"></a>初始化上下文</h1><p>初始化上下文指的是创建AnnotationConfigApplicationContext对象，ConfigForScanning作为参数传入</p><p>源码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">AnnotationConfigApplicationContext</span><span class="params">(Class&lt;?&gt;... componentClasses)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">this</span>();</span><br><span class="line">   register(componentClasses);</span><br><span class="line">   refresh();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以以看到只有三行代码，第一行调用了无参构造方法。</p><h2 id="无参构造方法"><a href="#无参构造方法" class="headerlink" title="无参构造方法"></a>无参构造方法</h2><p>我们知道java会在第一行隐式调用父类的无参构造方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">AnnotationConfigApplicationContext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   <span class="comment">// super();</span></span><br><span class="line">   <span class="keyword">this</span>.reader = <span class="keyword">new</span> AnnotatedBeanDefinitionReader(<span class="keyword">this</span>);</span><br><span class="line">   <span class="keyword">this</span>.scanner = <span class="keyword">new</span> ClassPathBeanDefinitionScanner(<span class="keyword">this</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>AnnotationConfigApplicationContext的父类是GenericApplicationContext，大名鼎鼎的DefaultListableBeanFactory就在此创建了</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">GenericApplicationContext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   <span class="keyword">this</span>.beanFactory = <span class="keyword">new</span> DefaultListableBeanFactory();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此时回过头看AnnotationConfigApplicationContext，它初始化了AnnotatedBeanDefinitionReader和ClassPathBeanDefinitionScanner，我们可以理解为：</p><p>AnnotatedBeanDefinitionReader可以从@Configuration中读取BeanDefinition，而ClassPathBeanDefinitionScanner会从我们给定的classPath中扫描BeanDefinition</p><p>那么ClassPathBeanDefinitionScanner什么时候用到的呢，这里给大家一个小例子供参考</p><p>假设在org.springframework.context.annotation6包下有一个ComponentForScanning类，它被标注了@Component注解</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">AnnotationConfigApplicationContext context = <span class="keyword">new</span> AnnotationConfigApplicationContext();</span><br><span class="line">context.scan(<span class="string">"org.springframework.context.annotation6"</span>);</span><br><span class="line">context.refresh();</span><br><span class="line"></span><br><span class="line">ComponentForScanning bean = context.getBean(ComponentForScanning.class);</span><br><span class="line">assertThat(bean).isNotNull();</span><br></pre></td></tr></table></figure><p>至此，我们可以理解第一步是初始化了DefaultListableBeanFactory和2个工具类</p><h2 id="注册bean的配置类"><a href="#注册bean的配置类" class="headerlink" title="注册bean的配置类"></a>注册bean的配置类</h2><p>AnnotationConfigApplicationContext构造方法的第一行代码调用了无参构造方法，第二行代码则是把用户传进来的配置类解析为BeanDefinition，也就是ConfigForScanning类，该配置类会被上面的工具类AnnotatedBeanDefinitionReader所解析</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">AnnotationConfigApplicationContext</span><span class="params">(Class&lt;?&gt;... componentClasses)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">this</span>();</span><br><span class="line">   <span class="comment">// 把@Configuration标注的类，解析为AnnotatedGenericBeanDefinition，注册到BeanDefinitionRegistry</span></span><br><span class="line">   register(componentClasses);</span><br><span class="line">   refresh();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">register</span><span class="params">(Class&lt;?&gt;... componentClasses)</span> </span>&#123;</span><br><span class="line">Assert.notEmpty(componentClasses, <span class="string">"At least one component class must be specified"</span>);</span><br><span class="line"><span class="keyword">this</span>.reader.register(componentClasses);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 省略中间调用 ...</span></span><br></pre></td></tr></table></figure><p>经过中间层层调用，来到doRegisterBean方法</p><h3 id="doRegisterBean"><a href="#doRegisterBean" class="headerlink" title="doRegisterBean"></a>doRegisterBean</h3><p>该方法是AnnotatedBeanDefinitionReader的注册配置类的具体实现，java config的bean用的是AnnotatedGenericBeanDefinition，它的类图如下</p><p><img src="/Users/admin/mine/spring-pics/Annotated-BeanDefinition.png" alt="Annotated-BeanDefinition"></p><p>源码及注释如下，比较简单，不再细说</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> &lt;T&gt; <span class="function"><span class="keyword">void</span> <span class="title">doRegisterBean</span><span class="params">(Class&lt;T&gt; beanClass, @Nullable String name,</span></span></span><br><span class="line"><span class="function"><span class="params">      @Nullable Class&lt;? extends Annotation&gt;[] qualifiers, @Nullable Supplier&lt;T&gt; supplier,</span></span></span><br><span class="line"><span class="function"><span class="params">      @Nullable BeanDefinitionCustomizer[] customizers)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">   AnnotatedGenericBeanDefinition abd = <span class="keyword">new</span> AnnotatedGenericBeanDefinition(beanClass);</span><br><span class="line">   <span class="comment">// 判断是否有Conditional注解，常见于Spring boot </span></span><br><span class="line">   <span class="keyword">if</span> (<span class="keyword">this</span>.conditionEvaluator.shouldSkip(abd.getMetadata())) &#123;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// 除了构造方法和工厂bean，还可以通过一个Supplier创建bean</span></span><br><span class="line">   abd.setInstanceSupplier(supplier);</span><br><span class="line">   <span class="comment">// 解析scope信息，singleton</span></span><br><span class="line">   abd.setScope(scopeMetadata.getScopeName());</span><br><span class="line">   <span class="comment">// 实现类是AnnotationBeanNameGenerator，获取beanName，实现过程看里面注释</span></span><br><span class="line">   String beanName = (name != <span class="keyword">null</span> ? name : <span class="keyword">this</span>.beanNameGenerator.generateBeanName(abd, <span class="keyword">this</span>.registry));</span><br><span class="line">   <span class="comment">// 填充lazy,primary,dependOn,role,description等信息</span></span><br><span class="line">   AnnotationConfigUtils.processCommonDefinitionAnnotations(abd);</span><br><span class="line">    <span class="comment">// 为null</span></span><br><span class="line">   <span class="keyword">if</span> (qualifiers != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">for</span> (Class&lt;? extends Annotation&gt; qualifier : qualifiers) &#123;</span><br><span class="line">         <span class="keyword">if</span> (Primary.class == qualifier) &#123;</span><br><span class="line">            abd.setPrimary(<span class="keyword">true</span>);</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="keyword">else</span> <span class="keyword">if</span> (Lazy.class == qualifier) &#123;</span><br><span class="line">            abd.setLazyInit(<span class="keyword">true</span>);</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="keyword">else</span> &#123;</span><br><span class="line">            abd.addQualifier(<span class="keyword">new</span> AutowireCandidateQualifier(qualifier));</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// 为null</span></span><br><span class="line">   <span class="keyword">if</span> (customizers != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">for</span> (BeanDefinitionCustomizer customizer : customizers) &#123;</span><br><span class="line">         customizer.customize(abd);</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 注册到registry</span></span><br><span class="line">   BeanDefinitionHolder definitionHolder = <span class="keyword">new</span> BeanDefinitionHolder(abd, beanName);</span><br><span class="line">   definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, <span class="keyword">this</span>.registry);</span><br><span class="line">   BeanDefinitionReaderUtils.registerBeanDefinition(definitionHolder, <span class="keyword">this</span>.registry);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>至此AnnotationConfigApplicationContext初始化的第二步结束，接下来是第三步refresh方法，它是IOC容器初始化最核心的代码，下文会单独讲解</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>AnnotationConfigApplicationContext的初始化前两步我们可以总结为以下几步</p><ol><li>创建DefaultListableBeanFactory</li><li>初始化了用于扫描BeanDefinition的2个工具类：AnnotatedBeanDefinitionReader和ClassPathBeanDefinitionScanner</li><li>将用户用@Configuration注解标注的bean配置类信息，注册到工厂中，等待初始化</li></ol>]]></content>
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
            <tag> 源码 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>kafka消息格式与日志存储原理分析</title>
      <link href="/2020/02/01/kafka%E6%B6%88%E6%81%AF%E6%A0%BC%E5%BC%8F%E4%B8%8E%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/"/>
      <url>/2020/02/01/kafka%E6%B6%88%E6%81%AF%E6%A0%BC%E5%BC%8F%E4%B8%8E%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/</url>
      <content type="html"><![CDATA[<p>kafka自0.11.0.0版本之后消息体升级到了V2版本，本文从生产者消息发送，broker消息存储，消息读取等几个部分作为切入点，来分析kafka的消息流转</p><h1 id="写入"><a href="#写入" class="headerlink" title="写入"></a>写入</h1><p>producer通过PRODUCE请求将消息发送给broker，我们来看一下发送的内容是什么</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">short</span> acks;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> timeout;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> String transactionalId;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Map&lt;TopicPartition, Integer&gt; partitionSizes;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> Map&lt;TopicPartition, MemoryRecords&gt; partitionRecords;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">boolean</span> transactional = <span class="keyword">false</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">boolean</span> idempotent = <span class="keyword">false</span>;</span><br></pre></td></tr></table></figure><p>以上代码摘取自ProduceRequest类，它是producer发送消息的请求对象，其中消息载体为：Map&lt;TopicPartition, MemoryRecords&gt; partitionRecords</p><p>该map对象表示每一个分区对应的消息，那么MemoryRecords是如何包装消息的呢</p><p>MemoryRecords中一个重要的变量是: Iterable[MutableRecordBatch] batches， 如何理解这个对象呢，有个很取巧的办法，看MemoryRecords的toString方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    StringBuilder builder = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">    builder.append(<span class="string">'['</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 自己定义的counter</span></span><br><span class="line">    <span class="keyword">int</span> batchCounter = <span class="number">0</span>, recordCounter = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    Iterator&lt;MutableRecordBatch&gt; batchIterator = batches.iterator();</span><br><span class="line">    <span class="keyword">while</span> (batchIterator.hasNext()) &#123;</span><br><span class="line">        batchCounter++;</span><br><span class="line"></span><br><span class="line">        RecordBatch batch = batchIterator.next();</span><br><span class="line">        <span class="keyword">try</span> (CloseableIterator&lt;Record&gt; recordsIterator = batch.streamingIterator(BufferSupplier.create())) &#123;</span><br><span class="line">            <span class="keyword">while</span> (recordsIterator.hasNext()) &#123;</span><br><span class="line">                recordCounter++;</span><br><span class="line">                Record record = recordsIterator.next();</span><br><span class="line">                appendRecordToStringBuilder(builder, record.toString());</span><br><span class="line">                <span class="keyword">if</span> (recordsIterator.hasNext())</span><br><span class="line">                    builder.append(<span class="string">", "</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (KafkaException e) &#123;</span><br><span class="line">            appendRecordToStringBuilder(builder, <span class="string">"CORRUPTED"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (batchIterator.hasNext())</span><br><span class="line">            builder.append(<span class="string">", "</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    builder.append(<span class="string">']'</span>);</span><br><span class="line">    builder.append(<span class="string">", batch count is "</span>).append(batchCounter).append(<span class="string">", record count is "</span>).append(recordCounter);</span><br><span class="line">    <span class="keyword">return</span> builder.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到MemoryRecords中有一个RecordBatch(MutableRecordBatch是它的子接口)集合，而一个RecordBatch中又有一个Record集合</p><p>MemoryRecords，RecordBatch，Record三者的关系如下</p><p><img src="https://ae01.alicdn.com/kf/H69850c700b184507b2b6019442356429P.png" alt="消息类图"></p><p>其中大部分都是接口，具体实现就是MemoryRecords，DefaultRecordBatch，DefaultRecord三者的关系</p><p>小结一下：producer给broker发送一批消息：Map&lt;TopicPartition, MemoryRecords&gt;，每个分区对应的消息用MemoryRecords表示，它有一个batchs变量，表示一个DefaultRecordBatch集合<br>而每一个DefaultRecordBatch表示一批消息，里面的每一条消息用DefaultRecord对象表示</p><p>但是大家也应该发现一个问题了，一批消息用一个DefaultRecordBatch表示就好了，为什么要包装一层Iterable[MutableRecordBatch] batches<br>其实在上面的toString发送中，笔者已经做了测试，该集合的大小始终为1，只需要关心DefaultRecordBatch与DefaultRecord即可</p><h2 id="消息批与消息格式"><a href="#消息批与消息格式" class="headerlink" title="消息批与消息格式"></a>消息批与消息格式</h2><p>DefaultRecordBatch与DefaultRecord的结构在各自的类注释中已写明</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">RecordBatch =&gt;</span><br><span class="line">BaseOffset =&gt; Int64</span><br><span class="line">Length =&gt; Int32</span><br><span class="line">PartitionLeaderEpoch =&gt; Int32</span><br><span class="line">Magic =&gt; Int8</span><br><span class="line">CRC =&gt; Uint32</span><br><span class="line">Attributes =&gt; Int16</span><br><span class="line">LastOffsetDelta =&gt; Int32 <span class="comment">// also serves as LastSequenceDelta</span></span><br><span class="line">FirstTimestamp =&gt; Int64</span><br><span class="line">MaxTimestamp =&gt; Int64</span><br><span class="line">ProducerId =&gt; Int64</span><br><span class="line">ProducerEpoch =&gt; Int16</span><br><span class="line">BaseSequence =&gt; Int32</span><br><span class="line">Records =&gt; [Record]</span><br><span class="line"></span><br><span class="line">Record =&gt;</span><br><span class="line">Length =&gt; Varint</span><br><span class="line">Attributes =&gt; Int8</span><br><span class="line">TimestampDelta =&gt; Varlong</span><br><span class="line">OffsetDelta =&gt; Varint</span><br><span class="line">Key =&gt; Bytes</span><br><span class="line">Value =&gt; Bytes</span><br><span class="line">Headers =&gt; [HeaderKey HeaderValue]</span><br><span class="line">HeaderKey =&gt; String</span><br><span class="line">HeaderValue =&gt; Bytes</span><br></pre></td></tr></table></figure><p>为了方便观看，截取两张书中的图片<br><img src="https://ae01.alicdn.com/kf/H9687116c6b684543acc6b46a5c217098H.png" alt="单条消息Record结构"><br><img src="https://ae01.alicdn.com/kf/Hdad2d4d8764c434a8486ee90080aecbeM.png" alt="批量消息RecordBatch结构"></p><h2 id="日志段Segment"><a href="#日志段Segment" class="headerlink" title="日志段Segment"></a>日志段Segment</h2><p>消息真正落盘到文件系统是以日志存储，每一个分区，注意是分区级别，都对应了一个日志<strong>目录</strong>，下图是一个典型的分区目录，表示topic test-1的第0个分区<br><img src="https://ae01.alicdn.com/kf/H6501d183d9804508ba634d0ef45947e8k.png" alt="分区日志目录"></p><p>而日志更细颗粒度的存储方式是一个个以.log结尾的Segment(日志段)，以下介绍几个关于日志的概念，对大家阅读源码有很大帮助</p><p>首先大家要回忆下log4j，它在线上服务器一般是这样使用的：不论何时，只有一个日志文件在写入，一到整点，就不再写入，新建下一个日志文件，继续写入，设置日志最大保留时间为30天，30天以前的日志自动删除</p><p>以上关于log4j的使用对大家理解kafka日志的运作大有帮助，二者有很多相似之处</p><ol><li>activeSegment：活动的日志段，只有该Segment写入日志</li><li>roll Segment：在kafka中，每个Segment默认为1G，由log.segment.bytes参数控制，当达到1G时(已经写不下新消息了)，就会新建下一个Segment，文件名是offset.log，同时原来的文件变为只读</li><li><p>Segment的baseOffset：baseOffset就是Segment的第一条消息的位移，这也是Segment的文件名，读取消息时，只要我们知道了第一个比消息的offset大的baseOffset，那么它的前一个Segment就是消息所在的Segment，通过这样可以很快定位到消息在哪个Segment文件，所以见到Map&lt;Long, Segment&gt;的对象大家一看就懂了</p></li><li><p>logStartOffset: 它表示<strong>第一个Segment</strong>的起始offset，也是当前所有Segment的起始offset，在上图中它的值为203000。我们知道，kafka的日志是会过期的，也就是说logStartOffset在过期的Segment被删除之后是会变的</p></li><li><p>largestTimestamp: 每个Segment中最大的时间戳，也就是最后一条消息的时间戳</p></li></ol><h2 id="导出"><a href="#导出" class="headerlink" title="导出"></a>导出</h2><p>.log文件是不能直接打开的，我们使用以下命令将其保存到本地文件中。注：Segment默认1G，不要在线上随意上使用，可先下载到内存较大的机器上执行<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 消息</span></span><br><span class="line">./kafka-run-class.sh kafka.tools.DumpLogSegments --files /Users/admin/private/kafka/data/<span class="built_in">test</span>-1-0/00000000000000203000.log --<span class="built_in">print</span>-data-log &gt; ~/message.log</span><br><span class="line"></span><br><span class="line"><span class="comment">#索引</span></span><br><span class="line">./kafka-run-class.sh kafka.tools.DumpLogSegments --files /Users/admin/private/kafka/data/<span class="built_in">test</span>-1-0/00000000000000203000.index --<span class="built_in">print</span>-data-log &gt; ~/index.log</span><br></pre></td></tr></table></figure></p><p>截取部分日志内容如下<br>日志<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Dumping /Users/admin/private/kafka/data/<span class="built_in">test</span>-1-0/00000000000000203000.log</span><br><span class="line">Starting offset: 203000</span><br><span class="line">offset: 203000 position: 0 CreateTime: 1581597478310 isvalid: <span class="literal">true</span> keysize: -1 valuesize: 21 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: -1 isTransactional: <span class="literal">false</span> headerKeys: [] payload: <span class="built_in">local</span> <span class="built_in">test</span> -------- 0</span><br><span class="line">offset: 203001 position: 0 CreateTime: 1581597478320 isvalid: <span class="literal">true</span> keysize: -1 valuesize: 21 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: -1 isTransactional: <span class="literal">false</span> headerKeys: [] payload: <span class="built_in">local</span> <span class="built_in">test</span> -------- 1</span><br><span class="line">offset: 203002 position: 0 CreateTime: 1581597478321 isvalid: <span class="literal">true</span> keysize: -1 valuesize: 21 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: -1 isTransactional: <span class="literal">false</span> headerKeys: [] payload: <span class="built_in">local</span> <span class="built_in">test</span> -------- 2</span><br><span class="line">offset: 203003 position: 0 CreateTime: 1581597478321 isvalid: <span class="literal">true</span> keysize: -1 valuesize: 21 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: -1 isTransactional: <span class="literal">false</span> headerKeys: [] payload: <span class="built_in">local</span> <span class="built_in">test</span> -------- 3</span><br><span class="line">offset: 203004 position: 0 CreateTime: 1581597478321 isvalid: <span class="literal">true</span> keysize: -1 valuesize: 21 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: -1 isTransactional: <span class="literal">false</span> headerKeys: [] payload: <span class="built_in">local</span> <span class="built_in">test</span> -------- 4</span><br></pre></td></tr></table></figure></p><p>索引<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Dumping /Users/admin/private/kafka/data/<span class="built_in">test</span>-1-0/00000000000000203000.index</span><br><span class="line">offset: 203299 position: 8738</span><br><span class="line">offset: 204657 position: 34953</span><br><span class="line">offset: 205169 position: 51314</span><br><span class="line">offset: 205681 position: 67695</span><br><span class="line">offset: 206193 position: 84076</span><br><span class="line">offset: 206705 position: 100457</span><br><span class="line">offset: 207217 position: 116838</span><br><span class="line">offset: 207729 position: 133219</span><br><span class="line">offset: 208241 position: 149600</span><br><span class="line">offset: 208753 position: 165981</span><br><span class="line">offset: 209265 position: 182362</span><br></pre></td></tr></table></figure></p><h2 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h2><p>在以上日志文件的基础上，我们来看看kafka是如何读取日志的。 假设我要们读取offset为203500的消息，查找过程如下</p><p>首先通过Segment的baseOffset确定在哪个Segment，只需要遍历segments对象，找到第一个baseOffset比206000小的Segment，也就是00000000000000203000这个Segment</p><p>这里不要狭隘的把Segment理解为.log日志文件，在新建LogSegment对象的时候，会创建.log, .index, .timeindex, .txn(事务)4个文件<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> LogSegment(</span><br><span class="line">  FileRecords.open(Log.logFile(dir, baseOffset, fileSuffix), fileAlreadyExists, initFileSize, preallocate),</span><br><span class="line">  <span class="keyword">new</span> OffsetIndex(Log.offsetIndexFile(dir, baseOffset, fileSuffix), baseOffset = baseOffset, maxIndexSize = maxIndexSize),</span><br><span class="line">  <span class="keyword">new</span> TimeIndex(Log.timeIndexFile(dir, baseOffset, fileSuffix), baseOffset = baseOffset, maxIndexSize = maxIndexSize),</span><br><span class="line">  <span class="keyword">new</span> TransactionIndex(baseOffset, Log.transactionIndexFile(dir, baseOffset, fileSuffix)),</span><br><span class="line">  baseOffset,</span><br><span class="line">  indexIntervalBytes = config.indexInterval,</span><br><span class="line">  rollJitterMs = config.randomSegmentJitter,</span><br><span class="line">  maxSegmentMs = config.segmentMs,</span><br><span class="line">  maxSegmentBytes = config.segmentSize,</span><br><span class="line">  time)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>查找Segment相关代码如下，segments类型为ConcurrentSkipListMap&lt;baseOffset, Segment&gt;，startOffset是消费时要拉取的起始offset<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var segmentEntry = segments.floorEntry(startOffset)</span><br></pre></td></tr></table></figure></p><p>通过二分法，找出第一个比203500大的offset索引是[204657, 34953], 那么在.log文件中从物理位置34953开始查找，即可找到offset为203500的消息</p><h3 id="时间索引"><a href="#时间索引" class="headerlink" title="时间索引"></a>时间索引</h3><p>时间索引为.timeindex文件，它的原理是根据要查找的时间戳(targetTimestamp)，先找到相应的Segment，但是并没有一个Map保存了时间戳和Segment的映射关系，而Segment保存了当前分段中最大的时间戳(largestTimestamp)，所以需要遍历所有的Segment，找出第一个最大时间戳比targetTimestamp大的Segment<br>找到Segment后，通过查找.timeindex索引文件，查询先找到offset，然后再去.index文件找到相应的position，最后再去.log日志文件中查找</p><p>以上过程发生在Log类的fetchOffsetsByTimestamp方法，关键部分的代码如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">fetchOffsetsByTimestamp</span><span class="params">(targetTimestamp: Long)</span>: Option[TimestampOffset] </span>= &#123;</span><br><span class="line">  val targetSeg = &#123;</span><br><span class="line">    <span class="comment">// Get all the segments whose largest timestamp is smaller than target timestamp</span></span><br><span class="line">    <span class="comment">// 先找segments，找第一个Segment的最大Timestamp大于请求中的Timestamp，可以看下takeWhile源码</span></span><br><span class="line">    val earlierSegs = segmentsCopy.takeWhile(_.largestTimestamp &lt; targetTimestamp) <span class="comment">//一直循环，只要不满足表示式停止</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  targetSeg.flatMap(_.findOffsetByTimestamp(targetTimestamp, logStartOffset))</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">def <span class="title">findOffsetByTimestamp</span><span class="params">(timestamp: Long, startingOffset: Long = baseOffset)</span>: Option[TimestampOffset] </span>= &#123;</span><br><span class="line">  <span class="comment">// Get the index entry with a timestamp less than or equal to the target timestamp</span></span><br><span class="line">  val timestampOffset = timeIndex.lookup(timestamp)</span><br><span class="line">  val position = offsetIndex.lookup(math.max(timestampOffset.offset, startingOffset)).position</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Search the timestamp</span></span><br><span class="line">  Option(log.searchForTimestamp(timestamp, position, startingOffset)).map &#123; timestampAndOffset =&gt;</span><br><span class="line">    TimestampOffset(timestampAndOffset.timestamp, timestampAndOffset.offset)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="二分查找过程"><a href="#二分查找过程" class="headerlink" title="二分查找过程"></a>二分查找过程</h4><p>先说说3个参数，分别是：索引文件，要查找的目标值，查找类型，kafka将索引文件中的每一条数据抽象成一个entry，查找类型就是指按Key还是按Value查找</p><p>查找过程是一个十分简单的二分查找算法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">indexSlotRangeFor</span><span class="params">(idx: ByteBuffer, target: Long, searchEntity: IndexSearchEntity)</span>: <span class="params">(Int, Int)</span> </span>= &#123;</span><br><span class="line">    <span class="comment">// check if the index is empty</span></span><br><span class="line">    <span class="keyword">if</span>(_entries == <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span> (-<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// check if the target offset is smaller than the least offset</span></span><br><span class="line">    <span class="keyword">if</span>(compareIndexEntry(parseEntry(idx, <span class="number">0</span>), target, searchEntity) &gt; <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span> (-<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// binary search for the entry</span></span><br><span class="line">    var lo = <span class="number">0</span></span><br><span class="line">    var hi = _entries - <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span>(lo &lt; hi) &#123;</span><br><span class="line">      val mid = ceil(hi/<span class="number">2.0</span> + lo/<span class="number">2.0</span>).toInt</span><br><span class="line">      val found = parseEntry(idx, mid)</span><br><span class="line">      val compareResult = compareIndexEntry(found, target, searchEntity)</span><br><span class="line">      <span class="keyword">if</span>(compareResult &gt; <span class="number">0</span>)</span><br><span class="line">        hi = mid - <span class="number">1</span></span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span>(compareResult &lt; <span class="number">0</span>)</span><br><span class="line">        lo = mid</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> (mid, mid)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    (lo, <span class="keyword">if</span> (lo == _entries - <span class="number">1</span>) -<span class="number">1</span> <span class="keyword">else</span> lo + <span class="number">1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>kafka本地启动后不打印日志问题</title>
      <link href="/2020/01/25/kafka%E6%9C%AC%E5%9C%B0%E5%90%AF%E5%8A%A8%E5%90%8E%E4%B8%8D%E6%89%93%E5%8D%B0%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98/"/>
      <url>/2020/01/25/kafka%E6%9C%AC%E5%9C%B0%E5%90%AF%E5%8A%A8%E5%90%8E%E4%B8%8D%E6%89%93%E5%8D%B0%E6%97%A5%E5%BF%97%E9%97%AE%E9%A2%98/</url>
      <content type="html"><![CDATA[<blockquote><p>2020年的春节新冠状病毒肆虐，只能宅在家里(天赋异禀)，闲来无事再次打开kafka项目阅读源码，但是从一开始就有个小问题困扰着我，<br>kafka本地启动后不打印日志，虽然能运行，但是心里总是很难受，今日下定决心解决之</p></blockquote><p>在<a href="https://greedypirate.github.io/2019/10/29/kafka%E6%BA%90%E7%A0%81%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/">kafka源码环境搭建</a>一文中，启动kafka之后，控制台如下<br><img src="https://ae01.alicdn.com/kf/H0dccf862d1364893ac367dce5856bc72l.png" alt=""><br>和我们用命令启动不一样，完全没有日志产生</p><p>虽然我通过百度，Stack Overflow等多个地方查找，想要解决这个问题，<br>但解决方案还是在图片中的链接里:<a href="http://www.slf4j.org/codes.html#StaticLoggerBinder" target="_blank" rel="noopener">http://www.slf4j.org/codes.html#StaticLoggerBinder</a></p><p>根据下面的提示，只需要替换这三个jar的任意一个即可<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Placing one (and only one) of slf4j-nop.jar slf4j-simple.jar, slf4j-log4j12.jar, slf4j-jdk14.jar</span><br></pre></td></tr></table></figure></p><p>剩下的就简单了，通过本人的摸索(没有学习过gradle)，kafka的依赖管理在如下位置<br><img src="https://ae01.alicdn.com/kf/He7f6efd2a0c64e20b1eaffc19ff905e8e.png" alt=""></p><p>log4j_bugfix是我新加的一个依赖，分别在dependencies.gradle的versions和libs数组的最后一行添加<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">versions += [</span><br><span class="line">...</span><br><span class="line">log4j_bugfix: &quot;1.7.30&quot;</span><br><span class="line">]</span><br><span class="line">libs += [</span><br><span class="line">... </span><br><span class="line">log4jBugFix:&quot;org.slf4j:slf4j-log4j12:$versions.log4j_bugfix&quot;</span><br><span class="line">]</span><br></pre></td></tr></table></figure></p><p>完成以上步骤后，找到根目录下的build.gradle文件，大约来543行，添加刚才新增的依赖<br><img src="https://ae01.alicdn.com/kf/Hba525c213131420088f4420f7bce7a90z.png" alt=""></p><p>最后在启动参数中加入log的目录配置:-Dkafka.logs.dir=<br><img src="https://ae01.alicdn.com/kf/Hbf9d0dee5d5246c69b2febb82458e13ap.png" alt=""></p><p>启动kafka，日志开始正常打印，大功告成<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[2020-01-25 21:34:51,570] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)</span><br><span class="line">[2020-01-25 21:34:52,824] INFO starting (kafka.server.KafkaServer)</span><br><span class="line">[2020-01-25 21:34:52,826] INFO Connecting to zookeeper on localhost:2181/cluster_201 (kafka.server.KafkaServer)</span><br><span class="line">[2020-01-25 21:34:52,920] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)</span><br><span class="line">[2020-01-25 21:34:52,971] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)</span><br><span class="line">[2020-01-25 21:34:52,971] INFO Client environment:host.name=localhost (org.apache.zookeeper.ZooKeeper)</span><br><span class="line">[2020-01-25 21:34:52,971] INFO Client environment:java.version=1.8.0_161 (org.apache.zookeeper.ZooKeeper)</span><br><span class="line">[2020-01-25 21:34:52,971] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)</span><br><span class="line">....</span><br></pre></td></tr></table></figure></p><h2 id="2020年02月19日更新"><a href="#2020年02月19日更新" class="headerlink" title="2020年02月19日更新"></a>2020年02月19日更新</h2><p>本人IDEA升级后，突然又不打印日志了，但是错误提示变为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">No appenders could be found for logger (kafka.utils.Log4jControllerRegistration$)</span><br></pre></td></tr></table></figure></p><p>首先保证log4j在classpath下，也就是在core/src/main/resources/log4j.properties下<br>然后找到File-&gt;Project Structure中的Global library，点击加号添加scala(2.11.12) sdk，Ctrl+A全选所有模块，确定后重启项目</p><p>如果还是不行，找到IDEA最右侧的gradle按钮，点击刷新按钮即可</p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>kafka-server端源码分析之拉取消息</title>
      <link href="/2019/12/17/kafka-server%E7%AB%AF%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E6%8B%89%E5%8F%96%E6%B6%88%E6%81%AF/"/>
      <url>/2019/12/17/kafka-server%E7%AB%AF%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E6%8B%89%E5%8F%96%E6%B6%88%E6%81%AF/</url>
      <content type="html"><![CDATA[<blockquote><p>发送fetch请求的对象有2类：client和follower，client拉取时有高水位线的限制，follower则没有，本文仅介绍client，<br>follower拉取时涉及到副本同步，以后单独分析</p></blockquote><h1 id="术语回顾"><a href="#术语回顾" class="headerlink" title="术语回顾"></a>术语回顾</h1><p><img src="https://ae01.alicdn.com/kf/H7a61234572984b95a98cc61ef9abf1f4C.png" alt=""><br>在kafka消息中有2个重要的术语：HW(HighWatermark)，LEO(Log End Offset)</p><p>HW会在生产者发送的消息写入后，等待follower副本同步完成后更新, HW之前的消息称之为committed(已提交的消息)，消费者只能消费HW之前的消息<br>而LEO则是在消息写入到本地leader副本后立即更新，它的值是最后一条消息的下一个位移，图中15被虚线标注，表示LEO处没有消息</p><h1 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h1><h2 id="client端发送的FETCH请求"><a href="#client端发送的FETCH请求" class="headerlink" title="client端发送的FETCH请求"></a>client端发送的FETCH请求</h2><p>截止到2.0.1版本，Fetch请求已经是V8版本了，client端发送的FetchRequest在Fetcher#sendFetches方法中初始化</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> FetchSessionHandler.FetchRequestData data = entry.getValue();</span><br><span class="line"><span class="keyword">final</span> FetchRequest.Builder request = FetchRequest.Builder</span><br><span class="line">        <span class="comment">// fetch.max.wait.ms: 拉取的等待时间</span></span><br><span class="line">        <span class="comment">// fetch.min.bytes: 至少拉取的字节数，没有达到则等待</span></span><br><span class="line">        .forConsumer(<span class="keyword">this</span>.maxWaitMs, <span class="keyword">this</span>.minBytes, data.toSend())</span><br><span class="line">        <span class="comment">// 事务隔离级别，read_uncommited</span></span><br><span class="line">        .isolationLevel(isolationLevel)</span><br><span class="line">        <span class="comment">// fetch.max.bytes: 拉取的最大字节</span></span><br><span class="line">        .setMaxBytes(<span class="keyword">this</span>.maxBytes)</span><br><span class="line">        .metadata(data.metadata())</span><br><span class="line">        .toForget(data.toForget());</span><br></pre></td></tr></table></figure><p>该请求体略微复杂，首先关注下data.toSend方法，它返回的是一个Map&lt;TopicPartition, PartitionData&gt;，表示一个消费者可以消费多个topic的多个分区<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">PartitionData</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 拉取的offset</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">long</span> fetchOffset;</span><br><span class="line">    <span class="comment">// </span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">long</span> logStartOffset;</span><br><span class="line">    <span class="comment">// max.partition.fetch.bytes：每个分区拉取的最大值</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> maxBytes;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>data.metadata方法返回的FetchMetadata主要包含epoch和sessionId两个字段，data.toForget返回的是一个分区数组<br>相信大部分参数大家都是熟悉的，而epoch，sessionId和toForget是专门用于FetchSession的实现，它是1.1.0版本新增的功能，这里我只说它出现的背景</p><h3 id="FetchSession背景"><a href="#FetchSession背景" class="headerlink" title="FetchSession背景"></a>FetchSession背景</h3><p>FetchSession出现是为了解决什么问题？<br>在kafka集群中的topic和partition达到一定规模后，会产生大量的Fetch请求，既包含消息拉取，也包含副本同步，而后者的请求量会很大。<br>假设100个topic，每个topic有3个分区，每个分区有3个副本，那么同时就有600个follower副本发送Fetch请求，再加上活动期间的业务量猛增的消费者的请求，Fetch请求的QPS将会很高<br>并且Fetch的请求体本身就很大，通常有几十KB，但是大部分参数都是不变的，比如订阅的分区，拉取参数等，因此可以将这些参数缓存在server端，client用一个session id来代替一次会话<br>这对Fetch请求的性能将是一个瓶颈，因此需要对请求体优化</p><p>其中大部分的参数大家都很熟悉，主要说2个不常见的参数：metadata和toForget<br>这两个参数是kafka 1.1.0版本之后新加的，用于FetchSession的实现，主要解决了在server端没有接收到消息时，消费者会空轮询，在topic分区较多时，FetchSession为Fetch请求体起到了瘦身的作用</p><p>想象一下每个client不止订阅一个topic，也会不止分配到一个TopicPartition，消费者在发送FETCH请求之前，要知道每个partition的leader副本在哪个broker上，然后按照broker分组，fetch请求体很大并不是空穴来风，kafka对此进行优化是很有必要的</p><p>以下是Fetch请求体格式，红框内的参数先不必关注，之后分析FetchSession相关内容<br><img src="https://ae01.alicdn.com/kf/Haf611a59880e479d953217e41e26eaf47.png" alt="FetchRequest"></p><h2 id="FETCH请求"><a href="#FETCH请求" class="headerlink" title="FETCH请求"></a>FETCH请求</h2><p>FETCH请求同样也是在KafkaApis类中处理，此处省略部分代码，如FetchSession相关，关注拉取的核心流程</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">handleFetchRequest</span><span class="params">(request: RequestChannel.Request)</span> </span>&#123;</span><br><span class="line">    val versionId = request.header.apiVersion</span><br><span class="line">    val clientId = request.header.clientId</span><br><span class="line">    val fetchRequest = request.body[FetchRequest]</span><br><span class="line"></span><br><span class="line">    <span class="comment">// FetchSession来做增量的fetch请求</span></span><br><span class="line">    val fetchContext = fetchManager.newContext(fetchRequest.metadata(),</span><br><span class="line">          fetchRequest.fetchData(),</span><br><span class="line">          fetchRequest.toForget(),</span><br><span class="line">          <span class="comment">// isFromFollower： replicaId是否大于0表示是follower</span></span><br><span class="line">          fetchRequest.isFromFollower())</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 异常响应方法：传入一个Error，返回发送异常时的Response</span></span><br><span class="line">    def errorResponse[T &gt;: MemoryRecords &lt;: BaseRecords](error: Errors): FetchResponse.PartitionData[T] = &#123;</span><br><span class="line">      <span class="keyword">new</span> FetchResponse.PartitionData[T](error, FetchResponse.INVALID_HIGHWATERMARK, FetchResponse.INVALID_LAST_STABLE_OFFSET,</span><br><span class="line">        FetchResponse.INVALID_LOG_START_OFFSET, <span class="keyword">null</span>, MemoryRecords.EMPTY)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    val erroneous = mutable.ArrayBuffer[(TopicPartition, FetchResponse.PartitionData[Records])]()</span><br><span class="line">    val interesting = mutable.ArrayBuffer[(TopicPartition, FetchRequest.PartitionData)]()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 筛选TP, 放入interesting集合中</span></span><br><span class="line">    <span class="keyword">if</span> (fetchRequest.isFromFollower()) &#123;</span><br><span class="line">    <span class="comment">// 暂不关心follower fetch</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// foreachPartition由FullFetchContext和IncrementalFetchContext实现</span></span><br><span class="line">      fetchContext.foreachPartition &#123; (topicPartition, data) =&gt;</span><br><span class="line">      <span class="comment">// consumer要有READ读权限，而且在metadata里有记录</span></span><br><span class="line">        <span class="keyword">if</span> (!authorize(request.session, Read, Resource(Topic, topicPartition.topic, LITERAL)))</span><br><span class="line">          erroneous += topicPartition -&gt; errorResponse(Errors.TOPIC_AUTHORIZATION_FAILED)</span><br><span class="line">        <span class="comment">// 元数据中要有该topicPartition</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (!metadataCache.contains(topicPartition))</span><br><span class="line">          erroneous += topicPartition -&gt; errorResponse(Errors.UNKNOWN_TOPIC_OR_PARTITION)</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">          interesting += (topicPartition -&gt; data)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 响应的回调函数，最后分析</span></span><br><span class="line">    <span class="function">def <span class="title">processResponseCallback</span><span class="params">(responsePartitionData: Seq[(TopicPartition, FetchPartitionData)</span>]): Unit </span>= &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (interesting.isEmpty)</span><br><span class="line">      processResponseCallback(Seq.empty)</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// replicaManager为入口调用</span></span><br><span class="line">      <span class="comment">// call the replica manager to fetch messages from the local replica</span></span><br><span class="line">      replicaManager.fetchMessages(</span><br><span class="line">        fetchRequest.maxWait.toLong,</span><br><span class="line">        fetchRequest.replicaId,</span><br><span class="line">        fetchRequest.minBytes,</span><br><span class="line">        fetchRequest.maxBytes,</span><br><span class="line">        versionId &lt;= <span class="number">2</span>, <span class="comment">// 从后面的代码看，version &lt;= 2时，至少返回第一条消息，哪怕它的大小超出了maxBytes</span></span><br><span class="line">        interesting,</span><br><span class="line">        replicationQuota(fetchRequest),</span><br><span class="line">        processResponseCallback,</span><br><span class="line">        fetchRequest.isolationLevel)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>handleFetchRequest方法主要是过滤请求中可用的TopicPartition作为interesting参数，最后连带响应的回调函数一起传给replicaManager的fetchMessages方法，processResponseCallback响应回调最终再分析</p><h1 id="ReplicaManager-fetchMessages"><a href="#ReplicaManager-fetchMessages" class="headerlink" title="ReplicaManager#fetchMessages"></a>ReplicaManager#fetchMessages</h1><p>fetchMessages方法中主要调用了readFromLog-&gt;readFromLocalLog方法来读取消息，readFromLocalLog返回的是一个LogReadResult对象，如果当前是follower副本发送的用于同步的fetch请求，还会调用updateFollowerLogReadResults更新同步状态，这一部分内容在<a href="">kafka server端源码分析之副本同步</a>中做了详细阐述</p><p>由于Consumer拉取消息有一系列的参数控制，如fetch.max.wait.ms，fetch.min.bytes，fetch.max.wait.ms等，让本次fetch不能立即完成，需要新建一个DelayedOption对象，放入Purgatory中，等待后续操作触发本次请求的完成(complete)。Purgatory可以简单理解为一个延迟队列</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">fetchMessages</span><span class="params">(timeout: Long,</span></span></span><br><span class="line"><span class="function"><span class="params">                    replicaId: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                    fetchMinBytes: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                    fetchMaxBytes: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                    hardMaxBytesLimit: Boolean,</span></span></span><br><span class="line"><span class="function"><span class="params">                    fetchInfos: Seq[(TopicPartition, PartitionData)</span>],</span></span><br><span class="line"><span class="function">                    quota: ReplicaQuota </span>= UnboundedQuota,</span><br><span class="line">                    responseCallback: Seq[(TopicPartition, FetchPartitionData)] =&gt; Unit,</span><br><span class="line">                    isolationLevel: IsolationLevel) &#123;</span><br><span class="line">    val isFromFollower = Request.isValidBrokerId(replicaId)</span><br><span class="line">    val fetchOnlyFromLeader = replicaId != Request.DebuggingConsumerId &amp;&amp; replicaId != Request.FutureLocalReplicaId <span class="comment">// 还有不从leader同步的？</span></span><br><span class="line">    <span class="comment">// follower fetch时没有高水位线的限制</span></span><br><span class="line">    val fetchOnlyCommitted = !isFromFollower &amp;&amp; replicaId != Request.FutureLocalReplicaId</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 先定义后调用</span></span><br><span class="line">    <span class="function">def <span class="title">readFromLog</span><span class="params">()</span>: Seq[<span class="params">(TopicPartition, LogReadResult)</span>] </span>= &#123;</span><br><span class="line">      val result = readFromLocalLog(</span><br><span class="line">        replicaId = replicaId,</span><br><span class="line">        fetchOnlyFromLeader = fetchOnlyFromLeader,</span><br><span class="line">        readOnlyCommitted = fetchOnlyCommitted,</span><br><span class="line">        fetchMaxBytes = fetchMaxBytes,</span><br><span class="line">        <span class="comment">// vision&lt;=2，目前=8，说明为false，v2版本有最大字节限制吗？</span></span><br><span class="line">        hardMaxBytesLimit = hardMaxBytesLimit,</span><br><span class="line">        <span class="comment">// fetchInfos是读取的关键，这是fetch参数，注意要读取多个分区，这是个</span></span><br><span class="line">        readPartitionInfo = fetchInfos,</span><br><span class="line">        <span class="comment">// 配额</span></span><br><span class="line">        quota = quota,</span><br><span class="line">        <span class="comment">// 事务隔离级别，默认read_uncommited</span></span><br><span class="line">        isolationLevel = isolationLevel)</span><br><span class="line">      <span class="comment">// 这里是follower的fetch结果处理</span></span><br><span class="line">      <span class="keyword">if</span> (isFromFollower) updateFollowerLogReadResults(replicaId, result)</span><br><span class="line">      <span class="keyword">else</span> result</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用并返回一个(TopicPartition, LogReadResult)集合</span></span><br><span class="line">    val logReadResults = readFromLog()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// check if this fetch request can be satisfied right away</span></span><br><span class="line">    <span class="comment">// LogReadResult集合</span></span><br><span class="line">    val logReadResultValues = logReadResults.map &#123; <span class="keyword">case</span> (_, v) =&gt; v &#125;</span><br><span class="line">    <span class="comment">// 读取的消息大小之和</span></span><br><span class="line">    val bytesReadable = logReadResultValues.map(_.info.records.sizeInBytes).sum</span><br><span class="line">    <span class="comment">// 结果中是否有错误</span></span><br><span class="line">    val errorReadingData = logReadResultValues.foldLeft(<span class="keyword">false</span>) ((errorIncurred, readResult) =&gt;</span><br><span class="line">      errorIncurred || (readResult.error != Errors.NONE))</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">      * 能够立即返回给客户端的4种情况</span></span><br><span class="line"><span class="comment">      * 1. fetch请求没有大于0的wait时间,参考fetch.max.wait.ms设置</span></span><br><span class="line"><span class="comment">      * 2. fetch请求要拉取的分区为空</span></span><br><span class="line"><span class="comment">      * 3. 根据fetch.min.bytes的设置，有足够的数据返回</span></span><br><span class="line"><span class="comment">      * 4. 出现异常</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">    <span class="keyword">if</span> (timeout &lt;= <span class="number">0</span> || fetchInfos.isEmpty || bytesReadable &gt;= fetchMinBytes || errorReadingData) &#123;</span><br><span class="line">      <span class="comment">// fetchPartitionData是一个TopicPartition -&gt; FetchPartitionData 的map集合</span></span><br><span class="line">      val fetchPartitionData = logReadResults.map &#123; <span class="keyword">case</span> (tp, result) =&gt;</span><br><span class="line">        tp -&gt; FetchPartitionData(result.error, result.highWatermark, result.leaderLogStartOffset, result.info.records,</span><br><span class="line">          result.lastStableOffset, result.info.abortedTransactions)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 调用响应回调函数</span></span><br><span class="line">      responseCallback(fetchPartitionData)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; <span class="comment">// 创建响应的DelayOption，放入purgatory中，等待完成</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// construct the fetch results from the read results</span></span><br><span class="line">      val fetchPartitionStatus = logReadResults.map &#123; <span class="keyword">case</span> (topicPartition, result) =&gt;</span><br><span class="line">        <span class="comment">// collectFirst：根据function find first element</span></span><br><span class="line">        <span class="comment">// fetchInfos是请求参数(TopicPartition, PartitionData)集合，</span></span><br><span class="line">        <span class="comment">// 意思就是从读取结果logReadResults里的TopicPartition和fetchInfos里的TopicPartition匹配</span></span><br><span class="line">        <span class="comment">// 找出该TopicPartition的PartitionData请求参数</span></span><br><span class="line">        val fetchInfo = fetchInfos.collectFirst &#123;</span><br><span class="line">          <span class="keyword">case</span> (tp, v) <span class="keyword">if</span> tp == topicPartition =&gt; v</span><br><span class="line">        &#125;.getOrElse(sys.error(s<span class="string">"Partition $topicPartition not found in fetchInfos"</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 赋值给外层的fetchPartitionStatus</span></span><br><span class="line">        (topicPartition, FetchPartitionStatus(result.info.fetchOffsetMetadata, fetchInfo))</span><br><span class="line">      &#125;</span><br><span class="line">      val fetchMetadata = FetchMetadata(fetchMinBytes, fetchMaxBytes, hardMaxBytesLimit, fetchOnlyFromLeader,</span><br><span class="line">        fetchOnlyCommitted, isFromFollower, replicaId, fetchPartitionStatus)</span><br><span class="line">      val delayedFetch = <span class="keyword">new</span> DelayedFetch(timeout, fetchMetadata, <span class="keyword">this</span>, quota, isolationLevel, responseCallback)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// create a list of (topic, partition) pairs to use as keys for this delayed fetch operation</span></span><br><span class="line">      <span class="comment">// 以分区为delay的watchKey</span></span><br><span class="line">      val delayedFetchKeys = fetchPartitionStatus.map &#123; <span class="keyword">case</span> (tp, _) =&gt; <span class="keyword">new</span> TopicPartitionOperationKey(tp) &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// try to complete the request immediately, otherwise put it into the purgatory;</span></span><br><span class="line">      <span class="comment">// this is because while the delayed fetch operation is being created, new requests</span></span><br><span class="line">      <span class="comment">// may arrive and hence make this operation completable.</span></span><br><span class="line">      <span class="comment">// 先尝试一次，不行就放入Purgatory中</span></span><br><span class="line">      delayedFetchPurgatory.tryCompleteElseWatch(delayedFetch, delayedFetchKeys)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来就从readFromLocalLog方法看看如何读取消息</p><h2 id="readFromLocalLog方法"><a href="#readFromLocalLog方法" class="headerlink" title="readFromLocalLog方法"></a>readFromLocalLog方法</h2><p>首先明确性该方法的入参和返回值，入参前文有详细注释，返回值则是一个(TopicPartition, LogReadResult)集合，前文也已提到</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Read from multiple topic partitions at the given offset up to maxSize bytes</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"><span class="function">def <span class="title">readFromLocalLog</span><span class="params">(replicaId: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                       fetchOnlyFromLeader: Boolean,</span></span></span><br><span class="line"><span class="function"><span class="params">                       readOnlyCommitted: Boolean,</span></span></span><br><span class="line"><span class="function"><span class="params">                       fetchMaxBytes: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                       hardMaxBytesLimit: Boolean,</span></span></span><br><span class="line"><span class="function"><span class="params">                       readPartitionInfo: Seq[(TopicPartition, PartitionData)</span>],</span></span><br><span class="line"><span class="function">                       quota: ReplicaQuota,</span></span><br><span class="line"><span class="function">                       isolationLevel: IsolationLevel): Seq[<span class="params">(TopicPartition, LogReadResult)</span>] </span>= &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">      * 又是先定义后调用，从后面的代码块这是在遍历请求参数中的TopicPartition集合</span></span><br><span class="line"><span class="comment">      * 作用是读取一个分区里的消息</span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> tp 要读取的分区</span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> fetchInfo 读取的参数，如从哪里开始读，读多少</span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> limitBytes fetchMaxBytes参数</span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> minOneMessage 是否至少读第一条后立即返回，即使它比fetchMaxBytes大，true</span></span><br><span class="line"><span class="comment">      * <span class="doctag">@return</span> 读取的结果</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line"><span class="function">def <span class="title">read</span><span class="params">(tp: TopicPartition, fetchInfo: PartitionData, limitBytes: Int, minOneMessage: Boolean)</span>: LogReadResult </span>= &#123;</span><br><span class="line">val offset = fetchInfo.fetchOffset <span class="comment">//从哪fetch</span></span><br><span class="line">val partitionFetchSize = fetchInfo.maxBytes <span class="comment">// fetch多少</span></span><br><span class="line">val followerLogStartOffset = fetchInfo.logStartOffset <span class="comment">// 这应该是针对follower的，consumer始终为-1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// decide whether to only fetch from leader</span></span><br><span class="line">val localReplica = <span class="keyword">if</span> (fetchOnlyFromLeader)</span><br><span class="line">  <span class="comment">//先找leader副本</span></span><br><span class="line">  getLeaderReplicaIfLocal(tp)</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">  getReplicaOrException(tp)</span><br><span class="line"></span><br><span class="line"><span class="comment">// hw</span></span><br><span class="line">val initialHighWatermark = localReplica.highWatermark.messageOffset</span><br><span class="line"><span class="comment">// 事务相关</span></span><br><span class="line">val lastStableOffset = <span class="keyword">if</span> (isolationLevel == IsolationLevel.READ_COMMITTED)</span><br><span class="line">  Some(localReplica.lastStableOffset.messageOffset)</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">  None</span><br><span class="line"></span><br><span class="line"><span class="comment">// decide whether to only fetch committed data (i.e. messages below high watermark)</span></span><br><span class="line">val maxOffsetOpt = <span class="keyword">if</span> (readOnlyCommitted)</span><br><span class="line">  <span class="comment">// 没开启事务时lastStableOffset应该为None</span></span><br><span class="line">  <span class="comment">// 这里返回的还是initialHighWatermark</span></span><br><span class="line">  Some(lastStableOffset.getOrElse(initialHighWatermark))</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">  None</span><br><span class="line">val initialLogEndOffset = localReplica.logEndOffset.messageOffset <span class="comment">// LEO</span></span><br><span class="line"><span class="comment">// 这应该是副本目前所有Segment的初始位移(第一个Segment的baseOffset),会随着日志清理改变</span></span><br><span class="line">val initialLogStartOffset = localReplica.logStartOffset</span><br><span class="line">val fetchTimeMs = time.milliseconds <span class="comment">// 当前时间</span></span><br><span class="line">val logReadInfo = localReplica.log match &#123;</span><br><span class="line">  <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(log)</span> </span>=&gt;</span><br><span class="line">    <span class="comment">// TODO 目前还没搞清楚PartitionData里的maxBytes和FetchRequest的maxBytes什么区别</span></span><br><span class="line">    <span class="comment">// limitBytes是请求参数中的maxBytes</span></span><br><span class="line">    val adjustedFetchSize = math.min(partitionFetchSize, limitBytes)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Try the read first, this tells us whether we need all of adjustedFetchSize for this partition</span></span><br><span class="line">   <span class="comment">// 从Log对象中读取</span></span><br><span class="line">    val fetch = log.read(offset, adjustedFetchSize, maxOffsetOpt, minOneMessage, isolationLevel)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If the partition is being throttled, simply return an empty set.</span></span><br><span class="line">    <span class="comment">// 超出配额(被限流)时返回一个空消息</span></span><br><span class="line">    <span class="keyword">if</span> (shouldLeaderThrottle(quota, tp, replicaId))</span><br><span class="line">      FetchDataInfo(fetch.fetchOffsetMetadata, MemoryRecords.EMPTY)</span><br><span class="line">    <span class="comment">// For FetchRequest version 3, we replace incomplete message sets with an empty one as consumers can make</span></span><br><span class="line">    <span class="comment">// progress in such cases and don't need to report a `RecordTooLargeException`</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (!hardMaxBytesLimit &amp;&amp; fetch.firstEntryIncomplete)</span><br><span class="line">      FetchDataInfo(fetch.fetchOffsetMetadata, MemoryRecords.EMPTY)</span><br><span class="line">    <span class="keyword">else</span> fetch <span class="comment">// 返回正常的结果给logReadInfo变量</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">case</span> None =&gt;</span><br><span class="line">    error(s<span class="string">"Leader for partition $tp does not have a local log"</span>)</span><br><span class="line">    FetchDataInfo(LogOffsetMetadata.UnknownOffsetMetadata, MemoryRecords.EMPTY)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回结果</span></span><br><span class="line">LogReadResult(info = logReadInfo,</span><br><span class="line">              highWatermark = initialHighWatermark,</span><br><span class="line">              leaderLogStartOffset = initialLogStartOffset,</span><br><span class="line">              leaderLogEndOffset = initialLogEndOffset,</span><br><span class="line">              followerLogStartOffset = followerLogStartOffset,</span><br><span class="line">              fetchTimeMs = fetchTimeMs,</span><br><span class="line">              readSize = partitionFetchSize,</span><br><span class="line">              lastStableOffset = lastStableOffset,</span><br><span class="line">              exception = None)</span><br><span class="line">  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">var limitBytes = fetchMaxBytes</span><br><span class="line">val result = <span class="keyword">new</span> mutable.ArrayBuffer[(TopicPartition, LogReadResult)]</span><br><span class="line">var minOneMessage = !hardMaxBytesLimit <span class="comment">// true</span></span><br><span class="line">readPartitionInfo.foreach &#123; <span class="keyword">case</span> (tp, fetchInfo) =&gt; <span class="comment">// 遍历每个tp，按照消费者的参数读取日志</span></span><br><span class="line">  val readResult = read(tp, fetchInfo, limitBytes, minOneMessage)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 拿到读取结果后，更新limitBytes，添加到result集合中</span></span><br><span class="line">  val recordBatchSize = readResult.info.records.sizeInBytes</span><br><span class="line">  <span class="comment">// Once we read from a non-empty partition, we stop ignoring request and partition level size limits</span></span><br><span class="line">  <span class="keyword">if</span> (recordBatchSize &gt; <span class="number">0</span>)</span><br><span class="line">    minOneMessage = <span class="keyword">false</span></span><br><span class="line">  <span class="comment">// fetchMaxBytes 减去 已读取的消息大小</span></span><br><span class="line">  limitBytes = math.max(<span class="number">0</span>, limitBytes - recordBatchSize)</span><br><span class="line">  result += (tp -&gt; readResult)</span><br><span class="line">&#125;</span><br><span class="line">result</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>readFromLocalLog主要是遍历请求中的分区，调用事先定义好的嵌套方法read，read方法会先找到leader副本，并且准备好读取的各种参数，最终调用Log对象的read方法</p><p>而外层的readFromLocalLog在拿到结果之后，会在循环中从fetchMaxBytes里减去已读取的消息大小</p><h2 id="Log-read"><a href="#Log-read" class="headerlink" title="Log#read"></a>Log#read</h2><p>我们知道Log只是个逻辑上的概念，本质是一个个Segment文件，每个Segment文件都有自己的起始位移(baseOffset)，<br>fetch请求要从fetchOffset处开始读取消息，我们常规的做法是先找到要读取的Segment文件，kafka为了加快寻找速度，增加了索引文件的概念，找到后根据fetchMaxBytes参数(当前在循环中，会一直变化)， 在高水位线的限制下调用Segment对象read方法读取消息，返回FetchDataInfo结果对象</p><p>以上就是该方法要做的事，Log对象的read方法源码如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Read messages from the log.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> startOffset 从哪里fetch，fetch请求中的fetchOffset参数:</span></span><br><span class="line"><span class="comment">    *                    The offset to begin reading at</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> maxLength fetch的maxBytes-已读取的消息大小:</span></span><br><span class="line"><span class="comment">    *                  The maximum number of bytes to read</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> maxOffset fetch的上限，即高水位线:</span></span><br><span class="line"><span class="comment">    *                  The offset to read up to, exclusive. (i.e. this offset NOT included in the resulting message set)</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> minOneMessage 是否至少fetch一条，即使的大小它已经超出了maxBytes:</span></span><br><span class="line"><span class="comment">    *                      If this is true, the first message will be returned even if it exceeds `maxLength` (if one exists)</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function">def <span class="title">read</span><span class="params">(startOffset: Long, maxLength: Int, maxOffset: Option[Long] = None, minOneMessage: Boolean = <span class="keyword">false</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">           isolationLevel: IsolationLevel)</span>: FetchDataInfo </span>= &#123;</span><br><span class="line">    maybeHandleIOException(s<span class="string">"Exception while reading from $topicPartition in dir $&#123;dir.getParent&#125;"</span>) &#123;</span><br><span class="line">      trace(s<span class="string">"Reading $maxLength bytes from offset $startOffset of length $size bytes"</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Because we don't use lock for reading, the synchronization is a little bit tricky.</span></span><br><span class="line">      <span class="comment">// We create the local variables to avoid race conditions with updates to the log.</span></span><br><span class="line">      <span class="comment">// 使用局部变量来避免并发锁竞争，nextOffsetMetadata.messageOffset就是LEO</span></span><br><span class="line">      val currentNextOffsetMetadata = nextOffsetMetadata</span><br><span class="line">      val next = currentNextOffsetMetadata.messageOffset</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 事务部分，先不关心</span></span><br><span class="line">      <span class="keyword">if</span> (startOffset == next) &#123;</span><br><span class="line">        val abortedTransactions =</span><br><span class="line">          <span class="keyword">if</span> (isolationLevel == IsolationLevel.READ_COMMITTED) Some(List.empty[AbortedTransaction])</span><br><span class="line">          <span class="keyword">else</span> None</span><br><span class="line">        <span class="keyword">return</span> FetchDataInfo(currentNextOffsetMetadata, MemoryRecords.EMPTY, firstEntryIncomplete = <span class="keyword">false</span>,</span><br><span class="line">          abortedTransactions = abortedTransactions)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// segments是一个跳表做的map，key为Segment的baseOffset，value是LogSegment对象</span></span><br><span class="line">      <span class="comment">// floorEntry是干嘛的？看哪个LogSegment的baseOffset &lt;= startOffset，其实就是在找要读取的LogSegment</span></span><br><span class="line">      <span class="comment">// segmentEntry是一个entry: &lt;baseOffset,LogSegment&gt;</span></span><br><span class="line">      var segmentEntry = segments.floorEntry(startOffset)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// return error on attempt to read beyond the log end offset or read below log start offset</span></span><br><span class="line">      <span class="comment">// 异常处理，大于LEO肯定不对，没找到合适的LogSegment也是不对的，至于startOffset &lt; logStartOffset感觉很多余</span></span><br><span class="line">      <span class="keyword">if</span> (startOffset &gt; next || segmentEntry == <span class="keyword">null</span> || startOffset &lt; logStartOffset)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> OffsetOutOfRangeException(s<span class="string">"Received request for offset $startOffset for partition $topicPartition, "</span> +</span><br><span class="line">          s<span class="string">"but we only have log segments in the range $logStartOffset to $next."</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 从baseOffset小于指定offset的Segment里读取消息，但如果Segment里没有消息，</span></span><br><span class="line"><span class="comment">        * 就继续往后面的Segment读,直到读取到了消息，或者到达了log的末尾</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">      <span class="comment">// Do the read on the segment with a base offset less than the target offset</span></span><br><span class="line">      <span class="comment">// but if that segment doesn't contain any messages with an offset greater than that</span></span><br><span class="line">      <span class="comment">// continue to read from successive segments until we get some messages or we reach the end of the log</span></span><br><span class="line">      <span class="keyword">while</span> (segmentEntry != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 取出LogSegment</span></span><br><span class="line">        val segment = segmentEntry.getValue</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果fetch读取了active Segment(最后一个正在写入的LogSegment)，在LEO更新前，发生了两次fetch会产生并发竞争，</span></span><br><span class="line">        <span class="comment">// 那么第二次fetch可能会发生OffsetOutOfRangeException，因此我们限制读取已暴露的位置(下面的maxPosition变量)，而不是active Segment的LEO</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// If the fetch occurs on the active segment, there might be a race condition where two fetch requests occur after</span></span><br><span class="line">        <span class="comment">// the message is appended but before the nextOffsetMetadata is updated. In that case the second fetch may</span></span><br><span class="line">        <span class="comment">// cause OffsetOutOfRangeException. To solve that, we cap the reading up to exposed position instead of the log</span></span><br><span class="line">        <span class="comment">// end of the active segment.</span></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">          * maxPosition大概是说segmentEntry如果是最后一个(active Segment)就返回LEO，</span></span><br><span class="line"><span class="comment">          * 否则返回当前Segment的大小</span></span><br><span class="line"><span class="comment">          */</span></span><br><span class="line">        val maxPosition = &#123;</span><br><span class="line">          <span class="keyword">if</span> (segmentEntry == segments.lastEntry) &#123;</span><br><span class="line">            val exposedPos = nextOffsetMetadata.relativePositionInSegment.toLong</span><br><span class="line">            <span class="comment">// 这个check again真的有用吗，为了解决bug？有点low</span></span><br><span class="line">            <span class="comment">// Check the segment again in case a new segment has just rolled out.</span></span><br><span class="line">            <span class="keyword">if</span> (segmentEntry != segments.lastEntry)</span><br><span class="line">            <span class="comment">// New log segment has rolled out, we can read up to the file end.</span></span><br><span class="line">              segment.size</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">              exposedPos</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            segment.size</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">          * 总结一下这几个入参</span></span><br><span class="line"><span class="comment">          * startOffset：从哪个位置开始读</span></span><br><span class="line"><span class="comment">          * maxOffset：读取的上限，高水位线</span></span><br><span class="line"><span class="comment">          * maxLength：读取的maxBytes</span></span><br><span class="line"><span class="comment">          * maxPosition：目前不知道什么用，LEO或者Segment的size</span></span><br><span class="line"><span class="comment">          * minOneMessage：是否至少读第一条</span></span><br><span class="line"><span class="comment">          */</span></span><br><span class="line">        val fetchInfo = segment.read(startOffset, maxOffset, maxLength, maxPosition, minOneMessage)</span><br><span class="line">        <span class="keyword">if</span> (fetchInfo == <span class="keyword">null</span>) &#123;</span><br><span class="line">          segmentEntry = segments.higherEntry(segmentEntry.getKey)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">return</span> isolationLevel match &#123;</span><br><span class="line">            <span class="comment">// 默认是READ_UNCOMMITTED，这里的fetchInfo作为返回值</span></span><br><span class="line">            <span class="keyword">case</span> IsolationLevel.READ_UNCOMMITTED =&gt; fetchInfo</span><br><span class="line">            <span class="keyword">case</span> IsolationLevel.READ_COMMITTED =&gt; addAbortedTransactions(startOffset, segmentEntry, fetchInfo)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 上面的while执行到最后一个Segment都还没return，说明我们要读取的消息都被删除了，这种情况返回空消息</span></span><br><span class="line">      <span class="comment">// okay we are beyond the end of the last segment with no data fetched although the start offset is in range,</span></span><br><span class="line">      <span class="comment">// this can happen when all messages with offset larger than start offsets have been deleted.</span></span><br><span class="line">      <span class="comment">// In this case, we will return the empty set with log end offset metadata</span></span><br><span class="line">      FetchDataInfo(nextOffsetMetadata, MemoryRecords.EMPTY)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="LogSegment-read"><a href="#LogSegment-read" class="headerlink" title="LogSegment#read"></a>LogSegment#read</h2><p>LogSegment#read属于接近底层的方法了，上一小节已经根据一个&lt;baseOffset, Segment&gt;的map找到了相应的Segment，但是要知道默认一个Segment大小为1G，想要在这么大的文件中查询数据，必须依赖索引。</p><p>kafka的读取逻辑是先根据二分法找到相应的offset和position，最终通过FileRecords.slice读取区间内的消息<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> startOffset 从哪个位置开始读：</span></span><br><span class="line"><span class="comment">    *                    A lower bound on the first offset to include in the message set we read</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> maxOffset 读取的上限，高水位线：</span></span><br><span class="line"><span class="comment">    *                  An optional maximum offset for the message set we read</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> maxSize fetch的maxBytes-已读取的消息大小：</span></span><br><span class="line"><span class="comment">    *                The maximum number of bytes to include in the message set we read</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> maxPosition 目前不知道什么用，LEO或者Segment的size：</span></span><br><span class="line"><span class="comment">    *                    The maximum position in the log segment that should be exposed for read</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> minOneMessage 是否至少读第一条：</span></span><br><span class="line"><span class="comment">    *                      If this is true, the first message will be returned even if it exceeds `maxSize` (if one exists)</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span> The fetched data and the offset metadata of the first message whose offset is &gt;= startOffset,</span></span><br><span class="line"><span class="comment">   *         or null if the startOffset is larger than the largest offset in this log</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="meta">@threadsafe</span></span><br><span class="line">  <span class="function">def <span class="title">read</span><span class="params">(startOffset: Long, maxOffset: Option[Long], maxSize: Int, maxPosition: Long = size,</span></span></span><br><span class="line"><span class="function"><span class="params">           minOneMessage: Boolean = <span class="keyword">false</span>)</span>: FetchDataInfo </span>= &#123;</span><br><span class="line">   </span><br><span class="line">    <span class="comment">// 日志文件字节数大小</span></span><br><span class="line">    val logSize = log.sizeInBytes <span class="comment">// this may change, need to save a consistent copy</span></span><br><span class="line">    <span class="comment">// 从index文件里查找offset,position</span></span><br><span class="line">    val startOffsetAndSize = translateOffset(startOffset)</span><br><span class="line"></span><br><span class="line">    val startPosition = startOffsetAndSize.position</span><br><span class="line">    val offsetMetadata = <span class="keyword">new</span> LogOffsetMetadata(startOffset, <span class="keyword">this</span>.baseOffset, startPosition)</span><br><span class="line"></span><br><span class="line">    val adjustedMaxSize =</span><br><span class="line">      <span class="keyword">if</span> (minOneMessage) math.max(maxSize, startOffsetAndSize.size)</span><br><span class="line">      <span class="keyword">else</span> maxSize</span><br><span class="line"></span><br><span class="line">    <span class="comment">// calculate the length of the message set to read based on whether or not they gave us a maxOffset</span></span><br><span class="line">    val fetchSize: Int = maxOffset match &#123;</span><br><span class="line">      <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(offset)</span> </span>=&gt;</span><br><span class="line">        val mapping = translateOffset(offset, startPosition)</span><br><span class="line">        val endPosition =</span><br><span class="line">          <span class="keyword">if</span> (mapping == <span class="keyword">null</span>)</span><br><span class="line">            logSize <span class="comment">// the max offset is off the end of the log, use the end of the file</span></span><br><span class="line">          <span class="keyword">else</span></span><br><span class="line">            mapping.position</span><br><span class="line">        min(min(maxPosition, endPosition) - startPosition, adjustedMaxSize).toInt</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// log.slice方法是在真正的获取消息</span></span><br><span class="line">    FetchDataInfo(offsetMetadata, log.slice(startPosition, fetchSize),</span><br><span class="line">      firstEntryIncomplete = adjustedMaxSize &lt; startOffsetAndSize.size)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="返回结果处理"><a href="#返回结果处理" class="headerlink" title="返回结果处理"></a>返回结果处理</h2><p>经过层层返回，回到最初的的handleFetchRequest方法中，看看processResponseCallback方法中是如何对读取结果进行处理并返回给consumer的</p><p>省略配额限流相关代码…</p><p>该方法的入参是一个(TopicPartition, FetchPartitionData)，表示每个分区对应的读取结果<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// the callback for process a fetch response, invoked before throttling</span></span><br><span class="line"><span class="function">def <span class="title">processResponseCallback</span><span class="params">(responsePartitionData: Seq[(TopicPartition, FetchPartitionData)</span>]): Unit </span>= &#123;</span><br><span class="line">  <span class="comment">// FetchPartitionData转PartitionData</span></span><br><span class="line">  val partitions = <span class="keyword">new</span> util.LinkedHashMap[TopicPartition, FetchResponse.PartitionData[Records]]</span><br><span class="line">  responsePartitionData.foreach &#123; <span class="keyword">case</span> (tp, data) =&gt;</span><br><span class="line">    val abortedTransactions = data.abortedTransactions.map(_.asJava).orNull</span><br><span class="line">    val lastStableOffset = data.lastStableOffset.getOrElse(FetchResponse.INVALID_LAST_STABLE_OFFSET)</span><br><span class="line">    partitions.put(tp, <span class="keyword">new</span> FetchResponse.PartitionData(data.error, data.highWatermark, lastStableOffset,</span><br><span class="line">      data.logStartOffset, abortedTransactions, data.records))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 错误的分区也要返回各自的错误信息</span></span><br><span class="line">  erroneous.foreach &#123; <span class="keyword">case</span> (tp, data) =&gt; partitions.put(tp, data) &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// When this callback is triggered, the remote API call has completed.</span></span><br><span class="line">  <span class="comment">// Record time before any byte-rate throttling.</span></span><br><span class="line">  request.apiRemoteCompleteTimeNanos = time.nanoseconds</span><br><span class="line"></span><br><span class="line">  var unconvertedFetchResponse: FetchResponse[Records] = <span class="keyword">null</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// follower同步的fetch</span></span><br><span class="line">  <span class="keyword">if</span> (fetchRequest.isFromFollower) &#123;</span><br><span class="line">    <span class="comment">// We've already evaluated against the quota and are good to go. Just need to record it now.</span></span><br><span class="line">    unconvertedFetchResponse = fetchContext.updateAndGenerateResponseData(partitions)</span><br><span class="line">    val responseSize = sizeOfThrottledPartitions(versionId, unconvertedFetchResponse, quotas.leader)</span><br><span class="line">    quotas.leader.record(responseSize)</span><br><span class="line">    trace(s<span class="string">"Sending Fetch response with partitions.size=$&#123;unconvertedFetchResponse.responseData().size()&#125;, "</span> +</span><br><span class="line">      s<span class="string">"metadata=$&#123;unconvertedFetchResponse.sessionId()&#125;"</span>)</span><br><span class="line">    sendResponseExemptThrottle(request, createResponse(<span class="number">0</span>), Some(updateConversionStats))</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// Fetch size used to determine throttle time is calculated before any down conversions.</span></span><br><span class="line">    <span class="comment">// This may be slightly different from the actual response size. But since down conversions</span></span><br><span class="line">    <span class="comment">// result in data being loaded into memory, we should do this only when we are not going to throttle.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Record both bandwidth and request quota-specific values and throttle by muting the channel if any of the</span></span><br><span class="line">    <span class="comment">// quotas have been violated. If both quotas have been violated, use the max throttle time between the two</span></span><br><span class="line">    <span class="comment">// quotas. When throttled, we unrecord the recorded bandwidth quota value</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 大部分都是限流先关代码，先忽略</span></span><br><span class="line">    val responseSize = fetchContext.getResponseSize(partitions, versionId)</span><br><span class="line">    val timeMs = time.milliseconds()</span><br><span class="line">    val requestThrottleTimeMs = quotas.request.maybeRecordAndGetThrottleTimeMs(request)</span><br><span class="line">    val bandwidthThrottleTimeMs = quotas.fetch.maybeRecordAndGetThrottleTimeMs(request, responseSize, timeMs)</span><br><span class="line"></span><br><span class="line">    val maxThrottleTimeMs = math.max(bandwidthThrottleTimeMs, requestThrottleTimeMs)</span><br><span class="line">    <span class="keyword">if</span> (maxThrottleTimeMs &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// Even if we need to throttle for request quota violation, we should "unrecord" the already recorded value</span></span><br><span class="line">      <span class="comment">// from the fetch quota because we are going to return an empty response.</span></span><br><span class="line">      quotas.fetch.unrecordQuotaSensor(request, responseSize, timeMs)</span><br><span class="line">      <span class="keyword">if</span> (bandwidthThrottleTimeMs &gt; requestThrottleTimeMs) &#123;</span><br><span class="line">        quotas.fetch.throttle(request, bandwidthThrottleTimeMs, sendResponse)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        quotas.request.throttle(request, requestThrottleTimeMs, sendResponse)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// If throttling is required, return an empty response.</span></span><br><span class="line">      unconvertedFetchResponse = fetchContext.getThrottledResponse(maxThrottleTimeMs)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// Get the actual response. This will update the fetch context.</span></span><br><span class="line">      <span class="comment">// 这是很关键的一行代码，创建了Response对象，全量和增量的方式有所不同，后续的FetchSession再说</span></span><br><span class="line">      unconvertedFetchResponse = fetchContext.updateAndGenerateResponseData(partitions)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Send the response immediately.</span></span><br><span class="line">    <span class="comment">// 发送响应到Processor的responseQueue中</span></span><br><span class="line">    sendResponse(request, Some(createResponse(maxThrottleTimeMs)), Some(updateConversionStats))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 很简单的一个方法，里面用maybeConvertFetchedData方法处理版本兼容引起的消息降级转换</span></span><br><span class="line"><span class="comment">    * 然后统计了下bytes out的metric，最终返回FetchResponse</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  <span class="function">def <span class="title">createResponse</span><span class="params">(throttleTimeMs: Int)</span>: FetchResponse[BaseRecords] </span>= &#123;</span><br><span class="line">    <span class="comment">// Down-convert messages for each partition if required</span></span><br><span class="line">    val convertedData = <span class="keyword">new</span> util.LinkedHashMap[TopicPartition, FetchResponse.PartitionData[BaseRecords]]</span><br><span class="line">    unconvertedFetchResponse.responseData().asScala.foreach &#123; <span class="keyword">case</span> (tp, unconvertedPartitionData) =&gt;</span><br><span class="line">      <span class="keyword">if</span> (unconvertedPartitionData.error != Errors.NONE)</span><br><span class="line">        debug(s<span class="string">"Fetch request with correlation id $&#123;request.header.correlationId&#125; from client $clientId "</span> +</span><br><span class="line">          s<span class="string">"on partition $tp failed due to $&#123;unconvertedPartitionData.error.exceptionName&#125;"</span>)</span><br><span class="line">      convertedData.put(tp, maybeConvertFetchedData(tp, unconvertedPartitionData))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Prepare fetch response from converted data</span></span><br><span class="line">    val response = <span class="keyword">new</span> FetchResponse(unconvertedFetchResponse.error(), convertedData, throttleTimeMs,</span><br><span class="line">      unconvertedFetchResponse.sessionId())</span><br><span class="line">    response.responseData.asScala.foreach &#123; <span class="keyword">case</span> (topicPartition, data) =&gt;</span><br><span class="line">      <span class="comment">// record the bytes out metrics only when the response is being sent</span></span><br><span class="line">      brokerTopicStats.updateBytesOut(topicPartition.topic, fetchRequest.isFromFollower, data.records.sizeInBytes)</span><br><span class="line">    &#125;</span><br><span class="line">    info(s<span class="string">"fetch response is $&#123;response&#125;"</span>)</span><br><span class="line">    response</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">updateConversionStats</span><span class="params">(send: Send)</span>: Unit </span>= &#123;</span><br><span class="line">    send match &#123;</span><br><span class="line">      <span class="keyword">case</span> send: MultiRecordsSend <span class="keyword">if</span> send.recordConversionStats != <span class="keyword">null</span> =&gt;</span><br><span class="line">        send.recordConversionStats.asScala.toMap.foreach &#123;</span><br><span class="line">          <span class="keyword">case</span> (tp, stats) =&gt; updateRecordConversionStats(request, tp, stats)</span><br><span class="line">        &#125;</span><br><span class="line">      <span class="keyword">case</span> _ =&gt;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>fetch请求处理流程调用的对象基本和produce请求类似，需要注意的几点是：</p><ol><li>fetch请求分为consumer和follower，server端用一个replicaId字段判断，consumer为-1</li><li>consumer读取有高水位线的限制，follower则没有</li><li>consumer受限于各种参数，不会立即响应，需要放入purgatory延迟队列中等待完成</li><li>响应回调中遇到了限流，FetchSession，消息降级等过程</li></ol><p><img src="https://ae01.alicdn.com/kf/Hfe405813f8c148df945920680455868dt.png" alt="consumer fetch流程"></p><p>部分图片引用：<br><a href="https://www.cnblogs.com/huxi2b/p/9335064.html" target="_blank" rel="noopener">https://www.cnblogs.com/huxi2b/p/9335064.html</a><br><a href="https://www.cnblogs.com/huxi2b/p/7453543.html" target="_blank" rel="noopener">https://www.cnblogs.com/huxi2b/p/7453543.html</a></p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>kafka server端源码分析之接收消息</title>
      <link href="/2019/12/10/kafka-server%E7%AB%AF%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E6%8E%A5%E6%94%B6%E6%B6%88%E6%81%AF/"/>
      <url>/2019/12/10/kafka-server%E7%AB%AF%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E6%8E%A5%E6%94%B6%E6%B6%88%E6%81%AF/</url>
      <content type="html"><![CDATA[<blockquote><p>承接上篇搭建kafka源码环境之后，本文正式开始分析</p></blockquote><h1 id="前文"><a href="#前文" class="headerlink" title="前文"></a>前文</h1><p>在前文<a href="https://greedypirate.github.io/2019/12/06/kafka%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/">kafka网络请求处理模型</a>中提到, KafkaServer#startup方法涵盖了kafka server所有模块的初始化<br>KafkaRequestHandlerPool线程池中的KafkaRequestHandler对象通过调用KafkaApis的handle方法，处理各类网络请求</p><h1 id="图文解析"><a href="#图文解析" class="headerlink" title="图文解析"></a>图文解析</h1><p><img src="https://ae01.alicdn.com/kf/H46b57c5ef8eb44fbb533c5d808b49906v.png" alt="append消息流程"></p><p>上图是kafka server追加消息到日志的整个流程，主要分为以下几步</p><ol><li>handleProduceRequest首先过滤认证失败和leader未知的分区，定义响应回调。如果ack=0直接响应，否则ReplicaManager继续处理</li><li>将生产者的相关参数，如超时时间，ack，以及第1步的响应回调函数传给ReplicaManager#appendRecords，appendRecords继续调用appendToLocalLog，完成后如果ack=-1时，第一次尝试结束请求</li><li>appendToLocalLog则遍历所有分区，获取该分区的本地leader副本Partition对象，调用它的appendRecordsToLeader方法，为每个分区追加消息</li><li>Partition#appendRecordsToLeader方法中，在校验完minIsr参数后，调用Log对象appendAsLeader-&gt;append方法，里面首先计算要追加的位移，消息CRC校验，截断无效消息等</li><li>Log#append方法之后会判断当前activeSegment是否需要roll(新建一个)，然后调用LogSegment#append-&gt;…-&gt;FileChannel#write将消息写入日志中</li><li>层层返回，调用响应回调函数中的sendResponse，和<a href="https://greedypirate.github.io/2019/12/06/kafka%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/">kafka网络请求处理模型</a>一文承上启下，将Response对象放入Processor中的responseQueue，等待Processor轮询处理</li></ol><h1 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h1><p>注: TopicPartition, 包含topic和partition的值，简称TP</p><h2 id="生产者请求处理方法"><a href="#生产者请求处理方法" class="headerlink" title="生产者请求处理方法"></a>生产者请求处理方法</h2><p>KafkaApis#handle方法根据不同类型的请求，调用不同的handleXxx方法，生产者请求在handleProduceRequest方法中</p><p>该方法除了调用ReplicaManager#appendRecords,还对日志权限，事务，限流等做了处理，并且定义好了响应回调函数，一并作为参数传给了ReplicaManager#appendRecords方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 省略部分代码</span></span><br><span class="line"><span class="function">def <span class="title">handleProduceRequest</span><span class="params">(request: RequestChannel.Request)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 转换为具体的请求对象</span></span><br><span class="line">    val produceRequest = request.body[ProduceRequest]</span><br><span class="line">    val numBytesAppended = request.header.toStruct.sizeOf + request.sizeOfBodyInBytes</span><br><span class="line"></span><br><span class="line">    val unauthorizedTopicResponses = mutable.Map[TopicPartition, PartitionResponse]()</span><br><span class="line">    val nonExistingTopicResponses = mutable.Map[TopicPartition, PartitionResponse]()</span><br><span class="line">    val authorizedRequestInfo = mutable.Map[TopicPartition, MemoryRecords]()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ((topicPartition, memoryRecords) &lt;- produceRequest.partitionRecordsOrFail.asScala) &#123;</span><br><span class="line">      <span class="comment">// 是否认证通过，是否有write权限</span></span><br><span class="line">      <span class="keyword">if</span> (!authorize(request.session, Write, Resource(Topic, topicPartition.topic, LITERAL)))</span><br><span class="line">        <span class="comment">// 忘了语法... +=是想集合添加元素，但是 -&gt;呢？ 这是map的key-&gt;value 语法</span></span><br><span class="line">        unauthorizedTopicResponses += topicPartition -&gt; <span class="keyword">new</span> PartitionResponse(Errors.TOPIC_AUTHORIZATION_FAILED)</span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (!metadataCache.contains(topicPartition))</span><br><span class="line">        <span class="comment">// 元数据缓存中是否有该tp，元数据缓存是由controller直接更新的</span></span><br><span class="line">        nonExistingTopicResponses += topicPartition -&gt; <span class="keyword">new</span> PartitionResponse(Errors.UNKNOWN_TOPIC_OR_PARTITION)</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        <span class="comment">// 剩下的都是可用的消息</span></span><br><span class="line">        authorizedRequestInfo += (topicPartition -&gt; memoryRecords)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// the callback for sending a produce response</span></span><br><span class="line">    <span class="comment">// 嵌套方法，定义响应回调，可以先不看</span></span><br><span class="line">    <span class="function">def <span class="title">sendResponseCallback</span><span class="params">(responseStatus: Map[TopicPartition, PartitionResponse])</span> </span>&#123;</span><br><span class="line">      <span class="comment">// ++表示集合合并</span></span><br><span class="line">      val mergedResponseStatus = responseStatus ++ unauthorizedTopicResponses ++ nonExistingTopicResponses</span><br><span class="line">      var errorInResponse = <span class="keyword">false</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// 先打个日志，不管</span></span><br><span class="line">      mergedResponseStatus.foreach &#123; <span class="keyword">case</span> (topicPartition, status) =&gt;</span><br><span class="line">        <span class="keyword">if</span> (status.error != Errors.NONE) &#123;</span><br><span class="line">          errorInResponse = <span class="keyword">true</span></span><br><span class="line">          debug(<span class="string">"Produce request with correlation id %d from client %s on partition %s failed due to %s"</span>.format(</span><br><span class="line">            request.header.correlationId,</span><br><span class="line">            request.header.clientId,</span><br><span class="line">            topicPartition,</span><br><span class="line">            status.error.exceptionName))</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 省略配额限流相关代码</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// Send the response immediately. In case of throttling, the channel has already been muted.</span></span><br><span class="line">      <span class="comment">// ack=0表示发到broker就返回，不关心副本是否写入</span></span><br><span class="line">      <span class="keyword">if</span> (produceRequest.acks == <span class="number">0</span>) &#123;</span><br><span class="line">          sendNoOpResponseExemptThrottle(request)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// ack为-1或1的响应</span></span><br><span class="line">        sendResponse(request, Some(<span class="keyword">new</span> ProduceResponse(mergedResponseStatus.asJava, maxThrottleTimeMs)), None)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 只有__admin_client客户端才能写入内部topic，例如__consumer_offset</span></span><br><span class="line">  val internalTopicsAllowed = request.header.clientId == AdminUtils.AdminClientId</span><br><span class="line"></span><br><span class="line">  <span class="comment">// call the replica manager to append messages to the replicas</span></span><br><span class="line">  <span class="comment">// 开始调用副本管理器追加消息</span></span><br><span class="line">  replicaManager.appendRecords(</span><br><span class="line">  <span class="comment">// 超时时间, 客户端Sender中的requestTimeoutMs，表示客户端请求超时</span></span><br><span class="line">  timeout = produceRequest.timeout.toLong,</span><br><span class="line">  <span class="comment">// ack参数</span></span><br><span class="line">  requiredAcks = produceRequest.acks,</span><br><span class="line">  <span class="comment">// 是否允许添加内部topic消息</span></span><br><span class="line">  internalTopicsAllowed = internalTopicsAllowed,</span><br><span class="line">  <span class="comment">// 是否来自client，也有可能来自别的broker</span></span><br><span class="line">  isFromClient = <span class="keyword">true</span>,</span><br><span class="line">  <span class="comment">// 消息体</span></span><br><span class="line">  entriesPerPartition = authorizedRequestInfo,</span><br><span class="line">  <span class="comment">// 响应函数</span></span><br><span class="line">  responseCallback = sendResponseCallback,</span><br><span class="line">  <span class="comment">// 状态转换函数</span></span><br><span class="line">  recordConversionStatsCallback = processingStatsCallback</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  <span class="comment">// if the request is put into the purgatory, it will have a held reference and hence cannot be garbage collected;</span></span><br><span class="line">  <span class="comment">// hence we clear its data here in order to let GC reclaim its memory since it is already appended to log</span></span><br><span class="line">  <span class="comment">// 如果需要被放入purgatory，清空引用让GC回收, 因为已经append到log了</span></span><br><span class="line">  produceRequest.clearPartitionRecords()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ProduceRequest请求参数如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProduceRequest</span> <span class="keyword">extends</span> <span class="title">AbstractRequest</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">short</span> acks;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> timeout;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String transactionalId;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;TopicPartition, Integer&gt; partitionSizes;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// This is set to null by `clearPartitionRecords` to prevent unnecessary memory retention when a produce request is</span></span><br><span class="line">    <span class="comment">// put in the purgatory (due to client throttling, it can take a while before the response is sent).</span></span><br><span class="line">    <span class="comment">// Care should be taken in methods that use this field.</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> Map&lt;TopicPartition, MemoryRecords&gt; partitionRecords; <span class="comment">// 每个分区待处理的消息</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> transactional = <span class="keyword">false</span>; <span class="comment">// 事务</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> idempotent = <span class="keyword">false</span>; <span class="comment">// 幂等性</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="ReplicaManager"><a href="#ReplicaManager" class="headerlink" title="ReplicaManager"></a>ReplicaManager</h1><p>ReplicaManager的主要功能是对分区副本层面做管理，包含日志写入，读取，ISR的变更，副本同步等。</p><p>appendRecords的方法注释如下：将消费追加到分区的leader副本，然后等待它们被follower副本复制，回调函数将会在超时或者ack条件满足时触发</p><p>该方法主要是在append消息之后，对当前请求的处理。ack=-1尝试完成当前请求，在ack=1时直接调用响应函数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">appendRecords</span><span class="params">(... )</span> </span>&#123; <span class="comment">//参数参考上面</span></span><br><span class="line">    <span class="comment">// 简单的校验ack合法性，-1，0，1才合法</span></span><br><span class="line">    <span class="keyword">if</span> (isValidRequiredAcks(requiredAcks)) &#123;</span><br><span class="line">      val sTime = time.milliseconds</span><br><span class="line">      <span class="comment">// 写入到本地broker中, 返回每个TPLogAppendResult =&gt; LogAppendInfo和异常</span></span><br><span class="line">      val localProduceResults = appendToLocalLog(internalTopicsAllowed = internalTopicsAllowed,</span><br><span class="line">        isFromClient = isFromClient, entriesPerPartition, requiredAcks)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// produceStatus类型:Map[TopicPartition, ProducePartitionStatus]</span></span><br><span class="line">      <span class="comment">// 这个map保存的是每个TopicPartition append后的状态，状态包括：LEO和结果，结果里面有是否append出现错误等</span></span><br><span class="line">      val produceStatus = localProduceResults.map &#123; <span class="keyword">case</span> (topicPartition, result) =&gt;</span><br><span class="line">        topicPartition -&gt;</span><br><span class="line">                ProducePartitionStatus(</span><br><span class="line">                  result.info.lastOffset + <span class="number">1</span>, <span class="comment">// required offset ， LEO </span></span><br><span class="line">                  <span class="keyword">new</span> PartitionResponse(result.error, result.info.firstOffset.getOrElse(-<span class="number">1</span>), result.info.logAppendTime, result.info.logStartOffset)) <span class="comment">// response status</span></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      recordConversionStatsCallback(localProduceResults.mapValues(_.info.recordConversionStats))</span><br><span class="line"></span><br><span class="line">      <span class="comment">// ack为-1时需要follower同步，需要放入延迟队列中，等待条件满足后返回</span></span><br><span class="line">      <span class="keyword">if</span> (delayedProduceRequestRequired(requiredAcks, entriesPerPartition, localProduceResults)) &#123;</span><br><span class="line">        <span class="comment">// create delayed produce operation</span></span><br><span class="line">        <span class="comment">// ack和消息append后的结果</span></span><br><span class="line">        val produceMetadata = ProduceMetadata(requiredAcks, produceStatus)</span><br><span class="line">        <span class="comment">// 注意看里面的初始化语句块</span></span><br><span class="line">        val delayedProduce = <span class="keyword">new</span> DelayedProduce(timeout, produceMetadata, <span class="keyword">this</span>, responseCallback, delayedProduceLock)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 就是TopicPartition集合</span></span><br><span class="line">        val producerRequestKeys = entriesPerPartition.keys.map(<span class="keyword">new</span> TopicPartitionOperationKey(_)).toSeq</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 第一次尝试结束处理，否则丢入purgatory中，因为下一批消息可能已经到达将这批请求结束</span></span><br><span class="line">        delayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 这是ack=1的时候，leader写入完了，就返回，之前已经处理过ack=0了</span></span><br><span class="line">        val produceResponseStatus = produceStatus.mapValues(status =&gt; status.responseStatus)</span><br><span class="line">        responseCallback(produceResponseStatus)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// ack参数无效后直接返回错误</span></span><br><span class="line">      val responseStatus = entriesPerPartition.map &#123; <span class="keyword">case</span> (topicPartition, _) =&gt;</span><br><span class="line">        topicPartition -&gt; <span class="keyword">new</span> PartitionResponse(Errors.INVALID_REQUIRED_ACKS,</span><br><span class="line">          LogAppendInfo.UnknownLogAppendInfo.firstOffset.getOrElse(-<span class="number">1</span>), RecordBatch.NO_TIMESTAMP, LogAppendInfo.UnknownLogAppendInfo.logStartOffset)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 最后调用传进来的响应回调方法</span></span><br><span class="line">      responseCallback(responseStatus)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>追加日志都在appendToLocalLog中完成，后面的代码是对追加结果的处理</p><h3 id="appendToLocalLog方法实现"><a href="#appendToLocalLog方法实现" class="headerlink" title="appendToLocalLog方法实现"></a>appendToLocalLog方法实现</h3><p>appendToLocalLog开始遍历分区消息集合Map[TopicPartition, MemoryRecords]对象，<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Append the messages to the local replica logs</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> internalTopicsAllowed 是否允许操作内部topic</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> isFromClient true，来自客户端</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> entriesPerPartition 消息体</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> requiredAcks ack参数</span></span><br><span class="line"><span class="comment">* <span class="doctag">@return</span> Map[TopicPartition, LogAppendResult]</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">appendToLocalLog</span><span class="params">(internalTopicsAllowed: Boolean,</span></span></span><br><span class="line"><span class="function"><span class="params">                           isFromClient: Boolean,</span></span></span><br><span class="line"><span class="function"><span class="params">                           entriesPerPartition: Map[TopicPartition, MemoryRecords],</span></span></span><br><span class="line"><span class="function"><span class="params">                           requiredAcks: Short)</span>: Map[TopicPartition, LogAppendResult] </span>= &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 遍历消息集合，追加消息 map里的case表示是个匿名偏函数</span></span><br><span class="line">    entriesPerPartition.map &#123; <span class="keyword">case</span> (topicPartition, records) =&gt; </span><br><span class="line">      <span class="comment">// 省略部分非核心代码</span></span><br><span class="line">      <span class="comment">// 如果是内部topic，但没有内部topic的操作权限，就报错，内部topic只有两个__consumer_offsets和__transaction_state</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// 获取当前tp的leader Partition对象</span></span><br><span class="line">      val (partition, _) = getPartitionAndLeaderReplicaIfLocal(topicPartition)</span><br><span class="line">      val info = partition.appendRecordsToLeader(records, isFromClient, requiredAcks)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 向一个tp中追加消息结束，返回结果</span></span><br><span class="line">      (topicPartition, LogAppendResult(info))    </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="Partition-appendRecordsToLeader方法实现"><a href="#Partition-appendRecordsToLeader方法实现" class="headerlink" title="Partition#appendRecordsToLeader方法实现"></a>Partition#appendRecordsToLeader方法实现</h3><p>Partition对象的appendRecordsToLeader方法中检验ack=-1时，min.insync.replicas必须大于ISR个数，否则抛出NotEnoughReplicasException<br>然后调用Log对象的appendAsLeader-&gt;append方法，追加完消息后，第二次尝试完成生产者请求</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">appendRecordsToLeader</span><span class="params">(records: MemoryRecords, isFromClient: Boolean, requiredAcks: Int = <span class="number">0</span>)</span>: LogAppendInfo </span>= &#123;</span><br><span class="line">    <span class="comment">// inReadLock是一个柯里化函数，第二个参数是一个函数，返回值是LogAppendInfo和HW是否增加的bool值</span></span><br><span class="line">    <span class="comment">// 相当于给方法加了读锁</span></span><br><span class="line">    val (info, leaderHWIncremented) = inReadLock(leaderIsrUpdateLock) &#123;</span><br><span class="line">      <span class="comment">// leaderReplicaIfLocal表示本地broker中的leader副本</span></span><br><span class="line">      leaderReplicaIfLocal match &#123;</span><br><span class="line">        <span class="comment">//如果存在的话</span></span><br><span class="line">        <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(leaderReplica)</span> </span>=&gt;</span><br><span class="line">          <span class="comment">// 获取Replica中的Log对象</span></span><br><span class="line">          val log = leaderReplica.log.get</span><br><span class="line">          <span class="comment">// min.insync.replicas参数</span></span><br><span class="line">          val minIsr = log.config.minInSyncReplicas</span><br><span class="line">          <span class="comment">// Set[Replica] ISR大小</span></span><br><span class="line">          val inSyncSize = inSyncReplicas.size</span><br><span class="line"></span><br><span class="line">          <span class="comment">// Avoid writing to leader if there are not enough insync replicas to make it safe</span></span><br><span class="line">          <span class="comment">// 如果isr的个数没有满足min.insync.replicas就报错，需要知道的是min.insync.replicas是和ack=-1一起使用的</span></span><br><span class="line">          <span class="keyword">if</span> (inSyncSize &lt; minIsr &amp;&amp; requiredAcks == -<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> NotEnoughReplicasException(<span class="string">"Number of insync replicas for partition %s is [%d], below required minimum [%d]"</span></span><br><span class="line">              .format(topicPartition, inSyncSize, minIsr))</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          <span class="comment">// 真正的消息追加交给Log对象</span></span><br><span class="line">          val info = log.appendAsLeader(records, leaderEpoch = <span class="keyword">this</span>.leaderEpoch, isFromClient)</span><br><span class="line"></span><br><span class="line">          <span class="comment">// 写入完消息，尝试触发Fetch请求，比如满足消费者的fetch.max.bytes</span></span><br><span class="line">          replicaManager.tryCompleteDelayedFetch(TopicPartitionOperationKey(<span class="keyword">this</span>.topic, <span class="keyword">this</span>.partitionId))</span><br><span class="line">          <span class="comment">// we may need to increment high watermark since ISR could be down to 1</span></span><br><span class="line">          (info, maybeIncrementLeaderHW(leaderReplica))</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// some delayed operations may be unblocked after HW changed</span></span><br><span class="line">    <span class="keyword">if</span> (leaderHWIncremented)</span><br><span class="line">      tryCompleteDelayedRequests()</span><br><span class="line"></span><br><span class="line">    info</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来是Log对象appendAsLeader的方法调用</p><h3 id="appendAsLeader-gt-append实现"><a href="#appendAsLeader-gt-append实现" class="headerlink" title="appendAsLeader-&gt;append实现"></a>appendAsLeader-&gt;append实现</h3><p>appendAsLeader方法直接调用了append方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">append</span><span class="params">(records: MemoryRecords, isFromClient: Boolean, assignOffsets: Boolean, leaderEpoch: Int)</span>: LogAppendInfo </span>= &#123;</span><br><span class="line">    maybeHandleIOException(s<span class="string">"Error while appending records to $topicPartition in dir $&#123;dir.getParent&#125;"</span>) &#123;</span><br><span class="line">      </span><br><span class="line">      val appendInfo = analyzeAndValidateRecords(records, isFromClient = isFromClient)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// return if we have no valid messages or if this is a duplicate of the last appended entry</span></span><br><span class="line">      <span class="keyword">if</span> (appendInfo.shallowCount == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> appendInfo</span><br><span class="line"></span><br><span class="line">      <span class="comment">// trim any invalid bytes or partial messages before appending it to the on-disk log</span></span><br><span class="line">      var validRecords = trimInvalidBytes(records, appendInfo)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">      lock <span class="keyword">synchronized</span> &#123;</span><br><span class="line">      <span class="comment">// assignOffsets写死为true，就不看else了</span></span><br><span class="line">        <span class="keyword">if</span> (assignOffsets) &#123;</span><br><span class="line">          <span class="comment">// assign offsets to the message set</span></span><br><span class="line">          val offset = <span class="keyword">new</span> LongRef(nextOffsetMetadata.messageOffset)</span><br><span class="line">          <span class="comment">// firstOffset又重新赋值了</span></span><br><span class="line">          appendInfo.firstOffset = Some(offset.value)</span><br><span class="line">          val now = time.milliseconds</span><br><span class="line">          <span class="comment">// 各种验证</span></span><br><span class="line">          val validateAndOffsetAssignResult = LogValidator.validateMessagesAndAssignOffsets(validRecords,</span><br><span class="line">              offset,</span><br><span class="line">              time,</span><br><span class="line">              now,</span><br><span class="line">              appendInfo.sourceCodec,</span><br><span class="line">              appendInfo.targetCodec,</span><br><span class="line">              config.compact,</span><br><span class="line">              config.messageFormatVersion.recordVersion.value,</span><br><span class="line">              config.messageTimestampType,</span><br><span class="line">              config.messageTimestampDifferenceMaxMs,</span><br><span class="line">              leaderEpoch,</span><br><span class="line">              isFromClient)</span><br><span class="line"></span><br><span class="line">          <span class="comment">// 验证通过后的消息</span></span><br><span class="line">          validRecords = validateAndOffsetAssignResult.validatedRecords</span><br><span class="line">          <span class="comment">// 根据校验结果完善appendInfo对象</span></span><br><span class="line">          appendInfo.maxTimestamp = validateAndOffsetAssignResult.maxTimestamp</span><br><span class="line">          appendInfo.offsetOfMaxTimestamp = validateAndOffsetAssignResult.shallowOffsetOfMaxTimestamp</span><br><span class="line">          appendInfo.lastOffset = offset.value - <span class="number">1</span></span><br><span class="line">          appendInfo.recordConversionStats = validateAndOffsetAssignResult.recordConversionStats</span><br><span class="line">          <span class="keyword">if</span> (config.messageTimestampType == TimestampType.LOG_APPEND_TIME)</span><br><span class="line">            appendInfo.logAppendTime = now</span><br><span class="line"></span><br><span class="line">          <span class="keyword">if</span> (validateAndOffsetAssignResult.messageSizeMaybeChanged) &#123;</span><br><span class="line">            <span class="keyword">for</span> (batch &lt;- validRecords.batches.asScala) &#123;</span><br><span class="line">              <span class="comment">// 每一批消息不能比max.message.bytes大</span></span><br><span class="line">              <span class="keyword">if</span> (batch.sizeInBytes &gt; config.maxMessageSize) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> RecordTooLargeException(s<span class="string">"Message batch size is $&#123;batch.sizeInBytes&#125; bytes in append to"</span> +</span><br><span class="line">                  s<span class="string">"partition $topicPartition which exceeds the maximum configured size of $&#123;config.maxMessageSize&#125;."</span>)</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; </span><br><span class="line"></span><br><span class="line">        <span class="comment">// update the epoch cache with the epoch stamped onto the message by the leader</span></span><br><span class="line">        validRecords.batches.asScala.foreach &#123; batch =&gt;</span><br><span class="line">          <span class="keyword">if</span> (batch.magic &gt;= RecordBatch.MAGIC_VALUE_V2)</span><br><span class="line">            _leaderEpochCache.assign(batch.partitionLeaderEpoch, batch.baseOffset)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// check messages set size may be exceed config.segmentSize</span></span><br><span class="line">        <span class="comment">// MemoryRecords总消息不能比segment.bytes大</span></span><br><span class="line">        <span class="keyword">if</span> (validRecords.sizeInBytes &gt; config.segmentSize) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> RecordBatchTooLargeException(s<span class="string">"Message batch size is $&#123;validRecords.sizeInBytes&#125; bytes in append "</span> +</span><br><span class="line">            s<span class="string">"to partition $topicPartition, which exceeds the maximum configured segment size of $&#123;config.segmentSize&#125;."</span>)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// maybe roll the log if this segment is full</span></span><br><span class="line">        <span class="comment">// 是否需要生成一个新的segment，具体判断条件见下文</span></span><br><span class="line">        val segment = maybeRoll(validRecords.sizeInBytes, appendInfo)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 保存位移的VO</span></span><br><span class="line">        val logOffsetMetadata = LogOffsetMetadata(</span><br><span class="line">          messageOffset = appendInfo.firstOrLastOffsetOfFirstBatch,</span><br><span class="line">          segmentBaseOffset = segment.baseOffset,</span><br><span class="line">          relativePositionInSegment = segment.size)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 真正append日志的是LogSegment对象</span></span><br><span class="line">        segment.append(largestOffset = appendInfo.lastOffset,</span><br><span class="line">          largestTimestamp = appendInfo.maxTimestamp,</span><br><span class="line">          shallowOffsetOfMaxTimestamp = appendInfo.offsetOfMaxTimestamp,</span><br><span class="line">          records = validRecords)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 更新LEO，lastOffset + 1</span></span><br><span class="line">        updateLogEndOffset(appendInfo.lastOffset + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (unflushedMessages &gt;= config.flushInterval)</span><br><span class="line">          flush()</span><br><span class="line"></span><br><span class="line">        appendInfo</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>这里必须要关注一下analyzeAndValidateRecords，因为它返回了LogAppendInfo对象,但是在讲解之前，需要和大家对kafka的消息结构所有了解，可以参考我之前的文章: <a href="">kafka消息格式与日志存储原理分析</a></p><h4 id="analyzeAndValidateRecords"><a href="#analyzeAndValidateRecords" class="headerlink" title="analyzeAndValidateRecords"></a>analyzeAndValidateRecords</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">analyzeAndValidateRecords</span><span class="params">(records: MemoryRecords, isFromClient: Boolean)</span>: LogAppendInfo </span>= &#123;</span><br><span class="line">  var shallowMessageCount = <span class="number">0</span></span><br><span class="line">  var validBytesCount = <span class="number">0</span></span><br><span class="line">  var firstOffset: Option[Long] = None</span><br><span class="line">  var lastOffset = -<span class="number">1L</span></span><br><span class="line">  var sourceCodec: CompressionCodec = NoCompressionCodec</span><br><span class="line">  var monotonic = <span class="keyword">true</span></span><br><span class="line">  var maxTimestamp = RecordBatch.NO_TIMESTAMP</span><br><span class="line">  var offsetOfMaxTimestamp = -<span class="number">1L</span></span><br><span class="line">  var readFirstMessage = <span class="keyword">false</span></span><br><span class="line">  var lastOffsetOfFirstBatch = -<span class="number">1L</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// MemoryRecords</span></span><br><span class="line">  info(s<span class="string">"MemoryRecords is $&#123;records&#125;"</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (batch &lt;- records.batches.asScala) &#123;</span><br><span class="line">    <span class="comment">// we only validate V2 and higher to avoid potential compatibility issues with older clients</span></span><br><span class="line">    <span class="keyword">if</span> (batch.magic &gt;= RecordBatch.MAGIC_VALUE_V2 &amp;&amp; isFromClient &amp;&amp; batch.baseOffset != <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> InvalidRecordException(s<span class="string">"The baseOffset of the record batch in the append to $topicPartition should "</span> +</span><br><span class="line">        s<span class="string">"be 0, but it is $&#123;batch.baseOffset&#125;"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// update the first offset if on the first message. For magic versions older than 2, we use the last offset</span></span><br><span class="line">    <span class="comment">// to avoid the need to decompress the data (the last offset can be obtained directly from the wrapper message).</span></span><br><span class="line">    <span class="comment">// For magic version 2, we can get the first offset directly from the batch header.</span></span><br><span class="line">    <span class="comment">// When appending to the leader, we will update LogAppendInfo.baseOffset with the correct value. In the follower</span></span><br><span class="line">    <span class="comment">// case, validation will be more lenient.</span></span><br><span class="line">    <span class="comment">// Also indicate whether we have the accurate first offset or not</span></span><br><span class="line">    <span class="comment">// readFirstMessage就是想取第一批消息的数据</span></span><br><span class="line">    <span class="keyword">if</span> (!readFirstMessage) &#123;</span><br><span class="line">      <span class="keyword">if</span> (batch.magic &gt;= RecordBatch.MAGIC_VALUE_V2)</span><br><span class="line">        firstOffset = Some(batch.baseOffset)</span><br><span class="line">      lastOffsetOfFirstBatch = batch.lastOffset</span><br><span class="line">      readFirstMessage = <span class="keyword">true</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// check that offsets are monotonically increasing</span></span><br><span class="line">    <span class="comment">// offset是否单调递增</span></span><br><span class="line">    <span class="keyword">if</span> (lastOffset &gt;= batch.lastOffset)</span><br><span class="line">      monotonic = <span class="keyword">false</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// update the last offset seen</span></span><br><span class="line">    lastOffset = batch.lastOffset</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Check if the message sizes are valid.</span></span><br><span class="line">    val batchSize = batch.sizeInBytes</span><br><span class="line">    <span class="keyword">if</span> (batchSize &gt; config.maxMessageSize) &#123;</span><br><span class="line">      brokerTopicStats.topicStats(topicPartition.topic).bytesRejectedRate.mark(records.sizeInBytes)</span><br><span class="line">      brokerTopicStats.allTopicsStats.bytesRejectedRate.mark(records.sizeInBytes)</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> RecordTooLargeException(s<span class="string">"The record batch size in the append to $topicPartition is $batchSize bytes "</span> +</span><br><span class="line">        s<span class="string">"which exceeds the maximum configured value of $&#123;config.maxMessageSize&#125;."</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// check the validity of the message by checking CRC</span></span><br><span class="line">    batch.ensureValid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (batch.maxTimestamp &gt; maxTimestamp) &#123;</span><br><span class="line">      maxTimestamp = batch.maxTimestamp</span><br><span class="line">      offsetOfMaxTimestamp = lastOffset</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    shallowMessageCount += <span class="number">1</span></span><br><span class="line">    validBytesCount += batchSize</span><br><span class="line"></span><br><span class="line">    val messageCodec = CompressionCodec.getCompressionCodec(batch.compressionType.id)</span><br><span class="line">    <span class="keyword">if</span> (messageCodec != NoCompressionCodec)</span><br><span class="line">      sourceCodec = messageCodec</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Apply broker-side compression if any</span></span><br><span class="line">  val targetCodec = BrokerCompressionCodec.getTargetCompressionCodec(config.compressionType, sourceCodec)</span><br><span class="line">   <span class="comment">/*</span></span><br><span class="line"><span class="comment">    * @param firstOffset v2版本都是0</span></span><br><span class="line"><span class="comment">    * @param lastOffset 消息集(MemoryRecords)中最后一条消息的位移</span></span><br><span class="line"><span class="comment">    * @param maxTimestamp 消息集(MemoryRecords)中最大的Timestamp，一般就是最后一条消息的时间戳</span></span><br><span class="line"><span class="comment">    * @param offsetOfMaxTimestamp 最大时间戳对应的位移</span></span><br><span class="line"><span class="comment">    * @param logAppendTime -1，RecordBatch.NO_TIMESTAMP</span></span><br><span class="line"><span class="comment">    * @param logStartOffset 这是当前所有Segment的起始位移(过期的会清楚)</span></span><br><span class="line"><span class="comment">    * @param recordConversionStats assignOffsets=false时为null，此时为EMPTY</span></span><br><span class="line"><span class="comment">    * @param sourceCodec 生产者设置的压缩</span></span><br><span class="line"><span class="comment">    * @param targetCodec broker设置的压缩</span></span><br><span class="line"><span class="comment">    * @param shallowCount 浅层message的个数，一般都是1</span></span><br><span class="line"><span class="comment">    * @param validBytes 验证过的消息字节数</span></span><br><span class="line"><span class="comment">    * @param offsetsMonotonic 消息位移是否单调递增</span></span><br><span class="line"><span class="comment">    * @param lastOffsetOfFirstBatch 第一批消息的lastOffset</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  val appendInfo = LogAppendInfo(firstOffset, lastOffset, maxTimestamp, offsetOfMaxTimestamp, RecordBatch.NO_TIMESTAMP, logStartOffset,</span><br><span class="line">    RecordConversionStats.EMPTY, sourceCodec, targetCodec, shallowMessageCount, validBytesCount, monotonic, lastOffsetOfFirstBatch)</span><br><span class="line">  info(s<span class="string">"analyzeAndValidateRecords append info is $&#123;appendInfo.toString&#125;"</span>)</span><br><span class="line">  appendInfo</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Roll-Segment-滚动日志段"><a href="#Roll-Segment-滚动日志段" class="headerlink" title="Roll Segment(滚动日志段)"></a>Roll Segment(滚动日志段)</h3><p>maybeRoll方法用于判断是否需要roll一个新Segment，什么叫做roll可以参考<a href="">kafka消息格式与日志存储原理分析</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">maybeRoll</span><span class="params">(messagesSize: Int, appendInfo: LogAppendInfo)</span>: LogSegment </span>= &#123;</span><br><span class="line">    val segment = activeSegment</span><br><span class="line">    val now = time.milliseconds</span><br><span class="line"></span><br><span class="line">    val maxTimestampInMessages = appendInfo.maxTimestamp</span><br><span class="line">    val maxOffsetInMessages = appendInfo.lastOffset</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (segment.shouldRoll(messagesSize, maxTimestampInMessages, maxOffsetInMessages, now)) &#123;</span><br><span class="line">      <span class="comment">// 省略了代码</span></span><br><span class="line">      roll(maxOffsetInMessages - Integer.MAX_VALUE)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 不需要Roll，就返回当前正在使用的Segment：activeSegment</span></span><br><span class="line">      segment</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Roll方法其实就是在新建.log, .index, .timeIndex文件，如果用了事务，还会有.txnindex文件<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">roll</span><span class="params">(expectedNextOffset: Long = <span class="number">0</span>)</span>: LogSegment </span>= &#123;</span><br><span class="line">    maybeHandleIOException(s<span class="string">"Error while rolling log segment for $topicPartition in dir $&#123;dir.getParent&#125;"</span>) &#123;</span><br><span class="line">      val start = time.hiResClockMs()</span><br><span class="line">      lock <span class="keyword">synchronized</span> &#123;</span><br><span class="line">        checkIfMemoryMappedBufferClosed()</span><br><span class="line">        val newOffset = math.max(expectedNextOffset, logEndOffset)</span><br><span class="line">        <span class="comment">// 新建.log, .index, .timeIndex文件，如果用了事务，还会有.txnindex文件</span></span><br><span class="line">        val logFile = Log.logFile(dir, newOffset)</span><br><span class="line">        val offsetIdxFile = offsetIndexFile(dir, newOffset)</span><br><span class="line">        val timeIdxFile = timeIndexFile(dir, newOffset)</span><br><span class="line">        val txnIdxFile = transactionIndexFile(dir, newOffset)</span><br><span class="line">        <span class="comment">// 检查是否已存在以上文件，存在则先删除</span></span><br><span class="line">        <span class="keyword">for</span> (file &lt;- List(logFile, offsetIdxFile, timeIdxFile, txnIdxFile) <span class="keyword">if</span> file.exists) &#123;</span><br><span class="line">          warn(s<span class="string">"Newly rolled segment file $&#123;file.getAbsolutePath&#125; already exists; deleting it first"</span>)</span><br><span class="line">          Files.delete(file.toPath)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// segments使用一个跳表构建的Map，说明Segment使用跳表组织的</span></span><br><span class="line">        <span class="comment">// key是Segment的baseOffset，value是Segment对象</span></span><br><span class="line">        Option(segments.lastEntry).foreach(_.getValue.onBecomeInactiveSegment())</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建LogSegment，添加到segments集合里</span></span><br><span class="line">        val segment = LogSegment.open(dir,</span><br><span class="line">          baseOffset = newOffset,</span><br><span class="line">          config,</span><br><span class="line">          time = time,</span><br><span class="line">          fileAlreadyExists = <span class="keyword">false</span>,</span><br><span class="line">          initFileSize = initFileSize,</span><br><span class="line">          preallocate = config.preallocate)</span><br><span class="line">        val prev = addSegment(segment)</span><br><span class="line">        <span class="comment">// 说明已存在</span></span><br><span class="line">        <span class="keyword">if</span> (prev != <span class="keyword">null</span>)</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(s<span class="string">"Trying to roll a new log segment for topic partition $topicPartition with "</span> +</span><br><span class="line">            s<span class="string">"start offset $newOffset while it already exists."</span>)</span><br><span class="line">        <span class="comment">// 更新LEO</span></span><br><span class="line">        updateLogEndOffset(nextOffsetMetadata.messageOffset)</span><br><span class="line">        <span class="comment">// 将recoveryPoint到新segment offset，也就是老的segment刷盘，包含4个文件：.log, .index, .timeIndex，.txnindex</span></span><br><span class="line">        scheduler.schedule(<span class="string">"flush-log"</span>, () =&gt; flush(newOffset), delay = <span class="number">0L</span>)</span><br><span class="line"></span><br><span class="line">        segment</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="日志文件与索引文件的写入"><a href="#日志文件与索引文件的写入" class="headerlink" title="日志文件与索引文件的写入"></a>日志文件与索引文件的写入</h3><p>Log#append方法在analyzeAndValidateRecords与maybeRoll操作之后，开始进行消息的写入，<br>Segment的append方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">append</span><span class="params">(largestOffset: Long,</span></span></span><br><span class="line"><span class="function"><span class="params">             largestTimestamp: Long,</span></span></span><br><span class="line"><span class="function"><span class="params">             shallowOffsetOfMaxTimestamp: Long,</span></span></span><br><span class="line"><span class="function"><span class="params">             records: MemoryRecords)</span>: Unit </span>= &#123;</span><br><span class="line">  <span class="keyword">if</span> (records.sizeInBytes &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    val physicalPosition = log.sizeInBytes()</span><br><span class="line">    <span class="keyword">if</span> (physicalPosition == <span class="number">0</span>)</span><br><span class="line">      rollingBasedTimestamp = Some(largestTimestamp)</span><br><span class="line"></span><br><span class="line">    ensureOffsetInRange(largestOffset)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 追加消息</span></span><br><span class="line">    val appendedBytes = log.append(records)</span><br><span class="line">    <span class="comment">// Update the in memory max timestamp and corresponding offset.</span></span><br><span class="line">    <span class="keyword">if</span> (largestTimestamp &gt; maxTimestampSoFar) &#123;</span><br><span class="line">      maxTimestampSoFar = largestTimestamp</span><br><span class="line">      offsetOfMaxTimestamp = shallowOffsetOfMaxTimestamp</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// offsetIndex和timeIndex的添加</span></span><br><span class="line">    <span class="comment">// indexIntervalBytes = index.interval.bytes， 每4KB的消息，建立一个索引</span></span><br><span class="line">    <span class="keyword">if</span> (bytesSinceLastIndexEntry &gt; indexIntervalBytes) &#123;</span><br><span class="line">      offsetIndex.append(largestOffset, physicalPosition)</span><br><span class="line">      timeIndex.maybeAppend(maxTimestampSoFar, offsetOfMaxTimestamp)</span><br><span class="line">      bytesSinceLastIndexEntry = <span class="number">0</span></span><br><span class="line">    &#125;</span><br><span class="line">    bytesSinceLastIndexEntry += records.sizeInBytes</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以下是日志的具体写入过程，可以看到就是java nio的操作了<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">append</span><span class="params">(MemoryRecords records)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> written = records.writeFullyTo(channel);</span><br><span class="line">    size.getAndAdd(written);</span><br><span class="line">    <span class="keyword">return</span> written;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">writeFullyTo</span><span class="params">(GatheringByteChannel channel)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    buffer.mark();</span><br><span class="line">    <span class="keyword">int</span> written = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (written &lt; sizeInBytes())</span><br><span class="line">        written += channel.write(buffer);</span><br><span class="line">    buffer.reset();</span><br><span class="line">    <span class="keyword">return</span> written;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>总的来说kafka在ReplicaManager,Partition,Log,LogSegment对象的层层调用来append消息。</p><p>在ack=-1时，因为follower同步之后，才算是消息提交(commit)，而在消息append过程中，并不知道什么时候follower完成同步</p><p>kafka的做法是多次尝试完成生产者请求，因此在源码中我们可以看到在append完成后，还会尝试完成生产者请求，否则放入Purgatory中监听(tryCompleteElseWatch)。</p><p>等待follower副本同步完成，再次尝试完成生产者请求(tryCompleteDelayedFetch)</p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>kafka网络请求处理模型</title>
      <link href="/2019/12/06/kafka%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/"/>
      <url>/2019/12/06/kafka%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/</url>
      <content type="html"><![CDATA[<p>众所周知，kafka是一款高性能，可伸缩的消息队列中间件，在一个庞大的kafka集群中，每秒能处理几十万条消息，那么必然存在着大量的网络请求，kafka是如何构建自己的网络请求模型的呢，答案就是Reactor</p><h1 id="Reactor模型"><a href="#Reactor模型" class="headerlink" title="Reactor模型"></a>Reactor模型</h1><p>Reactor线程模型即为Java NIO中的selector模型。最简单的Reactor模型中，有多个client向服务端发送请求，首先请求会达到Dispatcher组件，它负责将不同的请求分发到多个线程中处理<br><img src="https://ae01.alicdn.com/kf/H969ad8e2946e4fd284760f4868e91fcfD.png" alt="Reactor线程模型"></p><p>Dispatcher将变得十分轻量，因为它只负责分发，不用处理十分复杂的逻辑，而worker线程可以伸容、缩容，达到负载均衡的效果。<br>但是当处理读写任务的线程负载过高后，处理速度下降，事件会堆积，严重的会超时，可能导致客户端重新发送请求，性能越来越差</p><h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h1><p>kafka server中当Acceptor将请求分发给Processor后，Processor并不处理，而是将请求放入到一个请求队列(requestQueue)中<br>同时还有一个IO线程池(KafkaRequestHandlerPoll)，该线程池大小由num.io.threads参数控制，默认为8，其中的KafkaRequestHandler线程，循环从请求队列中取出请求，执行真正的处理。</p><p>KafkaRequestHandler背后真正负责处理的是一个叫做KafkaApis的类，它可以处理40多种请求，包含client与其它broker的请求，其中最常见的就是PRODUCE生产请求和FETCH消费拉取请求。PRODUCE将消息写入日志中；FETCH则从磁盘或页缓存中读取消息。</p><p>当IO线程处理完请求后，会将生成的响应发送到网络线程池的响应队列中，然后由对应的网络线程负责将Response返还给客户端。<br>请求队列是所有网络线程共享的，而响应队列则是每个网络线程专属的。这么设计的原因就在于，Acceptor只是用于请求分发而不负责响应回传，因此只能让每个网络线程自己发送Response给客户端，所以这些Response也就没必要放在一个公共的地方。</p><p><img src="https://ae01.alicdn.com/kf/H9d81a3a1afa14c2d945eef4dcce57ec8D.png" alt="kafka请求处理流程"></p><p>在有了上面对kafka的感性认知之后，再来看看它的源码是怎么写的</p><h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p>希望大家在看源码之前对java nio代码有一定的熟悉程度，可以事先看看博客，参考我github上的<a href="https://github.com/GreedyPirate/Spring-Cloud-Stack/tree/master/java8/src/main/java/com/net/nio" target="_blank" rel="noopener">代码</a><br>阅读源码时不要去关注边缘代码，这会影响我们的思路，大部分代码我都做了删减，只保留核心部分代码</p><h1 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h1><h2 id="Acceptor与Processor的初始化"><a href="#Acceptor与Processor的初始化" class="headerlink" title="Acceptor与Processor的初始化"></a>Acceptor与Processor的初始化</h2><p>从Kafka#main方法出发，跟踪到KafkaServer#startup方法，该方法涵盖kafka server所有模块的初始化，其中也包括了网络请求处理模块<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Create and start the socket server acceptor threads so that the bound port is known.</span></span><br><span class="line"><span class="comment">// Delay starting processors until the end of the initialization sequence to ensure</span></span><br><span class="line"><span class="comment">// that credentials have been loaded before processing authentications.</span></span><br><span class="line">socketServer = <span class="keyword">new</span> SocketServer(config, metrics, time, credentialProvider)</span><br><span class="line">socketServer.startup(startupProcessors = <span class="keyword">false</span>)</span><br></pre></td></tr></table></figure></p><h3 id="SocketServer-startup"><a href="#SocketServer-startup" class="headerlink" title="SocketServer#startup"></a>SocketServer#startup</h3><p>SocketServer核心代码如下，第一个参数numNetworkThreads，这是num.network.threads配置的值<br>第二个参数则是listeners配置的值，它是一个EndPoint集合<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SocketServer</span></span>&#123;</span><br><span class="line"><span class="function">def <span class="title">startup</span><span class="params">(startupProcessors: Boolean = <span class="keyword">true</span>)</span> </span>&#123;</span><br><span class="line">createAcceptorAndProcessors(config.numNetworkThreads, config.listeners)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="创建Acceptor与Processor"><a href="#创建Acceptor与Processor" class="headerlink" title="创建Acceptor与Processor"></a>创建Acceptor与Processor</h3><p>遍历EndPoint集合并在里面创建Acceptor，并启动Acceptor线程</p><p>Acceptor的个数和配置里listeners的个数有关，也就是一个服务用几个端口去监听网络请求</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">createAcceptorAndProcessors</span><span class="params">(processorsPerListener: Int,</span></span></span><br><span class="line"><span class="function"><span class="params">                                  endpoints: Seq[EndPoint])</span>: Unit </span>= <span class="keyword">synchronized</span> &#123;</span><br><span class="line">endpoints.foreach &#123; endpoint =&gt;</span><br><span class="line">val acceptor = <span class="keyword">new</span> Acceptor(endpoint, sendBufferSize, recvBufferSize, brokerId, connectionQuotas)</span><br><span class="line">addProcessors(acceptor, endpoint, processorsPerListener)</span><br><span class="line"></span><br><span class="line">KafkaThread.nonDaemon(s<span class="string">"kafka-socket-acceptor-$listenerName-$securityProtocol-$&#123;endpoint.port&#125;"</span>, acceptor).start()</span><br><span class="line">acceptor.awaitStartup()</span><br><span class="line">acceptors.put(endpoint, acceptor)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Acceptor类简要分析"><a href="#Acceptor类简要分析" class="headerlink" title="Acceptor类简要分析"></a>Acceptor类简要分析</h3><p>进入到Acceptor类中，下面这行代码建立了socket<br>注：scala类中，非方法的语句在初始化之前都会先执行，而java中语句只能定义在方法中</p><p>Acceptor的初始化是一个标准的nio ServerSocketChannel创建<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[kafka] <span class="class"><span class="keyword">class</span> <span class="title">Acceptor</span> <span class="keyword">extends</span> <span class="title">AbstractServerThread</span>(间接<span class="keyword">extends</span> <span class="title">Runnable</span>) </span>&#123;</span><br><span class="line"><span class="comment">// 初始化语句</span></span><br><span class="line">val serverChannel = openServerSocket(endPoint.host, endPoint.port)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 相信熟悉java nio代码的同学看到这里很熟悉</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">openServerSocket</span><span class="params">(host: String, port: Int)</span>: ServerSocketChannel </span>= &#123;</span><br><span class="line">val socketAddress =</span><br><span class="line">  <span class="keyword">if</span> (host == <span class="keyword">null</span> || host.trim.isEmpty)</span><br><span class="line">    <span class="keyword">new</span> InetSocketAddress(port)</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    <span class="keyword">new</span> InetSocketAddress(host, port)</span><br><span class="line">val serverChannel = ServerSocketChannel.open()</span><br><span class="line">serverChannel.configureBlocking(<span class="keyword">false</span>)</span><br><span class="line"></span><br><span class="line">serverChannel.socket.bind(socketAddress) </span><br><span class="line">serverChannel</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h4 id="Acceptor-run方法"><a href="#Acceptor-run方法" class="headerlink" title="Acceptor#run方法"></a>Acceptor#run方法</h4><p>Acceptor本身也是一个线程，在run方法中通过select轮询，接收请求，并将数据通过round-robin(轮询)的方式分配给不同的Processor处理<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">serverChannel.register(nioSelector, SelectionKey.OP_ACCEPT)</span><br><span class="line">var currentProcessor = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> (isRunning) &#123;</span><br><span class="line">val ready = nioSelector.select(<span class="number">500</span>)</span><br><span class="line"><span class="keyword">if</span> (ready &gt; <span class="number">0</span>) &#123;</span><br><span class="line">val keys = nioSelector.selectedKeys()</span><br><span class="line">val iter = keys.iterator()</span><br><span class="line"><span class="keyword">while</span> (iter.hasNext &amp;&amp; isRunning) &#123;</span><br><span class="line">  </span><br><span class="line">    val key = iter.next</span><br><span class="line">    iter.remove()</span><br><span class="line">    <span class="keyword">if</span> (key.isAcceptable) &#123;</span><br><span class="line">      val processor = <span class="keyword">synchronized</span> &#123;</span><br><span class="line">        currentProcessor = currentProcessor % processors.size</span><br><span class="line">        processors(currentProcessor)</span><br><span class="line">      &#125;</span><br><span class="line">      accept(key, processor)</span><br><span class="line">    &#125; <span class="keyword">else</span></span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Unrecognized key state for acceptor thread."</span>)</span><br><span class="line">    <span class="comment">// round robin to the next processor thread, mod(numProcessors) will be done later</span></span><br><span class="line">    currentProcessor = currentProcessor + <span class="number">1</span></span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br><span class="line">&#125;    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>注意accept(key, processor)这行代码是将请求保存到了Processor对象一个叫做newConnections队列对象中了，它的类型为ConcurrentLinkedQueue[SocketChannel].这为Processor后续的处理埋下了伏笔</p><h3 id="Processor初始化"><a href="#Processor初始化" class="headerlink" title="Processor初始化"></a>Processor初始化</h3><p>在初始化Acceptor之后，在创建Acceptor之后，<a href="#创建Acceptor与Processor">addProcessors</a>方法会根据num.network.threads的个数循环去创建Processor线程<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">addProcessors</span><span class="params">(acceptor: Acceptor, endpoint: EndPoint, newProcessorsPerListener: Int)</span>: Unit </span>= <span class="keyword">synchronized</span> &#123;</span><br><span class="line">  val listenerProcessors = <span class="keyword">new</span> ArrayBuffer[Processor]()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (_ &lt;- <span class="number">0</span> until newProcessorsPerListener) &#123;</span><br><span class="line">    val processor = newProcessor(nextProcessorId, connectionQuotas, listenerName, securityProtocol, memoryPool)</span><br><span class="line">    listenerProcessors += processor</span><br><span class="line">    requestChannel.addProcessor(processor)</span><br><span class="line">    nextProcessorId += <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  listenerProcessors.foreach(p =&gt; processors.put(p.id, p))</span><br><span class="line">  acceptor.addProcessors(listenerProcessors)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>其中有两行代码比较关键<br>requestChannel.addProcessor(processor)是将Processor添加到RequestChannel的缓存map中，为以后的请求处理做准备<br>acceptor.addProcessors(listenerProcessors)是为Acceptor和Processor做关系映射，说明该Processor属于该Acceptor，同时该方法内部启动了Processor线程</p><p>相关代码如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">startProcessors</span><span class="params">(processors: Seq[Processor])</span>: Unit </span>= <span class="keyword">synchronized</span> &#123;</span><br><span class="line">processors.foreach &#123; processor =&gt;</span><br><span class="line">KafkaThread.nonDaemon(<span class="string">"..."</span>,processor).start()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="Processor类简要分析"><a href="#Processor类简要分析" class="headerlink" title="Processor类简要分析"></a>Processor类简要分析</h3><p>既然Processor是一个线程，那么run方法是必须要看的, 在看run方法之前，需要知道Processor初始化了一个selector<br>虽然它叫KSelector(scala可以重命名import的类), 但熟悉kafka java客户端源码的同学应该知道，这就是kafka客户端中基于java nio Selector封装的Selector。<br>希望大家不要被绕晕了，简而言之，kafka在java nio Selector上封装了一个自己的Selector，而且是同名的<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.common.network.&#123;..., Selector =&gt; KSelector&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">protected</span>[network] <span class="function">def <span class="title">createSelector</span><span class="params">(channelBuilder: ChannelBuilder)</span>: KSelector </span>= &#123;</span><br><span class="line">    <span class="keyword">new</span> KSelector(</span><br><span class="line">      maxRequestSize,</span><br><span class="line">      connectionsMaxIdleMs,</span><br><span class="line">      metrics,</span><br><span class="line">      time,</span><br><span class="line">      <span class="string">"socket-server"</span>,</span><br><span class="line">      metricTags,</span><br><span class="line">      <span class="keyword">false</span>,</span><br><span class="line">      <span class="keyword">true</span>,</span><br><span class="line">      channelBuilder,</span><br><span class="line">      memoryPool,</span><br><span class="line">      logContext)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">override def <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">startupComplete()</span><br><span class="line"><span class="keyword">while</span> (isRunning) &#123;</span><br><span class="line"><span class="comment">// setup any new connections that have been queued up</span></span><br><span class="line">configureNewConnections()</span><br><span class="line"><span class="comment">// register any new responses for writing</span></span><br><span class="line">processNewResponses()</span><br><span class="line">poll()</span><br><span class="line">processCompletedReceives()</span><br><span class="line">processCompletedSends()</span><br><span class="line">processDisconnected()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在<a href="#Acceptor#run方法">Acceptor#run方法</a>中，kafka将SocketChannel保存到了Processor的一个ConcurrentLinkedQueue<socketchannel>队列中<br>这里依次调用的6个方法就是对队列轮询，取出SocketChannel并做处理</socketchannel></p><ol><li>configureNewConnections：向selector注册OP_READ事件</li><li>processNewResponses：处理响应</li><li>poll：将网络请求放入到List<networkreceive>集合中</networkreceive></li><li>processCompletedReceives：遍历List<networkreceive>集合，构建Request对象，放入到RequestChannel的requestQueue队列中<br>5,6省略，不是现在关心的</networkreceive></li></ol><h4 id="processCompletedReceives详细"><a href="#processCompletedReceives详细" class="headerlink" title="processCompletedReceives详细"></a>processCompletedReceives详细</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">processCompletedReceives</span><span class="params">()</span> </span>&#123;</span><br><span class="line">selector.completedReceives.asScala.foreach &#123; receive =&gt;</span><br><span class="line">    openOrClosingChannel(receive.source) match &#123;</span><br><span class="line">      <span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(channel)</span> </span>=&gt;</span><br><span class="line">      <span class="comment">// 构建Request对象</span></span><br><span class="line">        val header = RequestHeader.parse(receive.payload)</span><br><span class="line">        val connectionId = receive.source</span><br><span class="line">        val context = <span class="keyword">new</span> RequestContext(header, connectionId, channel.socketAddress,</span><br><span class="line">          channel.principal, listenerName, securityProtocol)</span><br><span class="line">        val req = <span class="keyword">new</span> RequestChannel.Request(processor = id, context = context,</span><br><span class="line">          startTimeNanos = time.nanoseconds, memoryPool, receive.payload, requestChannel.metrics)</span><br><span class="line">        <span class="comment">// 发送到RequestChannel的requestQueue队列中</span></span><br><span class="line">        requestChannel.sendRequest(req)</span><br><span class="line">    &#125;</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>至此我们已经分析完了一半的流程<br><img src="https://ae01.alicdn.com/kf/H5ba778ed69274f8380f75ff04b88d2234.png" alt="处理流程"></p><h2 id="KafkaRequestHandler"><a href="#KafkaRequestHandler" class="headerlink" title="KafkaRequestHandler"></a>KafkaRequestHandler</h2><p>KafkaRequestHandler线程run方法如下, requestChannel.receiveRequest就是从requestQueue队列中循环获取请求(300ms是超时时间)，最后交给KafkaApis#handle方法处理</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">while</span> (!stopped) &#123;</span><br><span class="line">val req = requestChannel.receiveRequest(<span class="number">300</span>)</span><br><span class="line">req match &#123;</span><br><span class="line"><span class="keyword">case</span> request: RequestChannel.Request =&gt;</span><br><span class="line">apis.handle(request)</span><br><span class="line">&#125;</span><br><span class="line">&#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="RequestChannel"><a href="#RequestChannel" class="headerlink" title="RequestChannel"></a>RequestChannel</h3><p>requestQueue是一个ArrayBlockingQueue有界队列，队列大小由queued.max.requests参数控制</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class RequestChannel(val queueSize: Int) extends KafkaMetricsGroup &#123;</span><br><span class="line"><span class="keyword">private</span> val requestQueue = <span class="keyword">new</span> ArrayBlockingQueue[BaseRequest](queueSize)</span><br><span class="line"></span><br><span class="line"><span class="function">def <span class="title">receiveRequest</span><span class="params">(timeout: Long)</span>: RequestChannel.BaseRequest </span>= </span><br><span class="line">requestQueue.poll(timeout, TimeUnit.MILLISECONDS)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="KafkaApis处理请求"><a href="#KafkaApis处理请求" class="headerlink" title="KafkaApis处理请求"></a>KafkaApis处理请求</h3><p>KafkaApis具体的请求处理流程以<a href="https://greedypirate.github.io/2019/11/02/kafka-server%E7%AB%AF%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E6%8E%A5%E6%94%B6%E6%B6%88%E6%81%AF-%E4%B8%80/">kafka server端源码分析之接收消息(一)</a>为例，在每个请求处理结束后，都会调用RequestChannel的sendResponse方法，将Response放入LinkedBlockingDeque无界队列<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> val responseQueue = <span class="keyword">new</span> LinkedBlockingDeque[RequestChannel.Response]()</span><br><span class="line"></span><br><span class="line"><span class="comment">/** Send a response back to the socket server to be sent over the network */</span></span><br><span class="line"><span class="function">def <span class="title">sendResponse</span><span class="params">(response: RequestChannel.Response)</span> </span>&#123;</span><br><span class="line">  val processor = processors.get(response.processor)</span><br><span class="line">  <span class="comment">// The processor may be null if it was shutdown. In this case, the connections</span></span><br><span class="line">  <span class="comment">// are closed, so the response is dropped.</span></span><br><span class="line">  <span class="keyword">if</span> (processor != <span class="keyword">null</span>) &#123;</span><br><span class="line">    processor.enqueueResponse(response)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 放入队列</span></span><br><span class="line"><span class="keyword">private</span>[network] <span class="function">def <span class="title">enqueueResponse</span><span class="params">(response: RequestChannel.Response)</span>: Unit </span>= &#123;</span><br><span class="line">  responseQueue.put(response)</span><br><span class="line">  wakeup()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><img src="https://ae01.alicdn.com/kf/H4e58b30e781b4d2bbdc0a9010fe240dfa.png" alt="sendResponse方法调用链"></p><h3 id="发送响应"><a href="#发送响应" class="headerlink" title="发送响应"></a>发送响应</h3><p>在<a href="#Processor类简要分析">Processor类简要分析</a>中，有6个方法，其中第2个方法用于处理新的响应，现在向responseQueue队列中放入了Response对象后，回过头来看看发送的源码<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">processNewResponses</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    var currentResponse: RequestChannel.Response = <span class="keyword">null</span></span><br><span class="line">    <span class="keyword">while</span> (&#123;currentResponse = dequeueResponse(); currentResponse != <span class="keyword">null</span>&#125;) &#123;</span><br><span class="line">      val channelId = currentResponse.request.context.connectionId</span><br><span class="line"></span><br><span class="line">      currentResponse match &#123;</span><br><span class="line">        <span class="keyword">case</span> response: SendResponse =&gt;</span><br><span class="line">          sendResponse(response, response.responseSend)</span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>处理响应的代码很清晰，通过dequeueResponse方法获取responseQueue中的Response，循环发送给客户端或其它broker<br>sendResponse方法的代码几乎只有一行，inflightResponses用于保存发送中的Response，表示还未收到客户端应答</p><p>注：带有inflight前缀的还有inflightRequest，含义也是类似的，常用于客户端请求<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">selector.send(responseSend)</span><br><span class="line">inflightResponses += (connectionId -&gt; response)</span><br></pre></td></tr></table></figure></p><p>至此整个kafka的网络请求处理流程分析结束，接下来将会分析kafka server如何处理生产者发送的消息，如何应答消费者的fetch请求，这些都是实际开发中常用的功能，必须要扎实掌握</p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ByteBuffer浅显易懂的图解原理</title>
      <link href="/2019/12/01/ByteBuffer%E6%B5%85%E6%98%BE%E6%98%93%E6%87%82%E7%9A%84%E5%9B%BE%E8%A7%A3%E5%8E%9F%E7%90%86/"/>
      <url>/2019/12/01/ByteBuffer%E6%B5%85%E6%98%BE%E6%98%93%E6%87%82%E7%9A%84%E5%9B%BE%E8%A7%A3%E5%8E%9F%E7%90%86/</url>
      <content type="html"><![CDATA[<p>本文希望通过图解的形式帮助更多新手理解ByteBuffer的使用</p><h1 id="ByteBuffer的作用"><a href="#ByteBuffer的作用" class="headerlink" title="ByteBuffer的作用"></a>ByteBuffer的作用</h1><p>我们知道在java中读写文件都是通过流操作的，那么想象一下要读取一个大文件，每次都从流中一个字节一个字节的读取，效率有多低下，缓存是必须存在的，就好比搬一堆沙子，总不能一粒一粒的搬，得要用个小推车来搬运</p><p>那么在java nio中，都是通过channel读写，ByteBuffer作为缓存</p><p>读：从channel中读取到ByteBuffer中，程序再从ByteBuffer中读取<br>写：程序先写到ByteBuffer中，然后ByteBuffer写入到channel</p><h1 id="ByteBuffer"><a href="#ByteBuffer" class="headerlink" title="ByteBuffer"></a>ByteBuffer</h1><p>ByteBuffer没有大家想象的那么复杂，即使它的方法、变量很多，大家就把它理解为一个普通的字节数组(byte[])就好了。<br>为数不多的难点是里面的4个变量：mark，position，limit，capacity</p><p>第一次看见就要理解4个变量确实比较多，精简一下，capacity就是数组的初始化长度，它是不变的，mark暂时不用看<br>剩下的position，limit是读写的关键</p><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><p>首先来说下ByteBuffer的初始化，既然它本质是一个byte[], 那么我们指定长度就可以了，常用的初始化方式如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ByteBuffer buffer = ByteBuffer.allocate(<span class="number">8</span>);</span><br></pre></td></tr></table></figure><p>或者自己初始化好一个byte[]，交给ByteBuffer用<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">byte</span>[] arr = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">8</span>];</span><br><span class="line">ByteBuffer buffer = ByteBuffer.wrap(arr);</span><br></pre></td></tr></table></figure></p><p>以上代码都是创建了一个8字节长度的缓冲, 此时内部的变量状态如下<br><img src="https://ae01.alicdn.com/kf/Hc6075479cfe345cd8f692defb2ff0dben.png" alt=""></p><p>为了方便观察，定义一个打印方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">printBuffer</span><span class="params">(ByteBuffer buffer)</span> </span>&#123;</span><br><span class="line">    System.out.println(<span class="string">"position :"</span> + buffer.position() + <span class="string">",limit :"</span> + buffer.limit() + <span class="string">",capacity"</span> + buffer.capacity());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="写入"><a href="#写入" class="headerlink" title="写入"></a>写入</h2><p>接下来我们写入一个int类型，还记得int类型在内存中占几个字节吗，4个</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ByteBuffer buffer = ByteBuffer.allocate(<span class="number">8</span>);</span><br><span class="line">buffer.putInt(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">printBuffer(buffer);</span><br></pre></td></tr></table></figure><p>此时的内部状态如下: position :4,limit :8,capacity8</p><p><img src="https://ae01.alicdn.com/kf/Ha16d3139a96049af8a7239ee1e234effJ.png" alt=""></p><h3 id="limit"><a href="#limit" class="headerlink" title="limit"></a>limit</h3><p>在写入时，position的作用就是一个指针，写入一个byte就加1，就和我们常用的List的size作用一样<br>同时我们也应该知道，写入”1”之后，ByteBuffer只剩4个字节了，如果我们再写入2个数字，就出超出ByteBuffer的容量限制(limit)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">buffer.putInt(<span class="number">2</span>);</span><br><span class="line">buffer.putInt(<span class="number">3</span>);</span><br></pre></td></tr></table></figure><p>报错：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java.nio.BufferOverflowException</span><br><span class="line">at java.nio.Buffer.nextPutIndex(Buffer.java:<span class="number">527</span>)</span><br><span class="line">at java.nio.HeapByteBuffer.putInt(HeapByteBuffer.java:<span class="number">372</span>)</span><br></pre></td></tr></table></figure><p>由此引出，limit表示在写入时position的上限</p><h2 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h2><p>首先考虑一个问题，我们读取的起始位置，结束位置是什么。承接上文，在写入数字1之后，position :4,limit :8<br>我们要做的是从0开始读取，读到4为止，ByteBuffer为我们提供了一个很方便的方法：flip，读之前要翻转，很巧妙的比喻</p><p>调用flip之后，position置为0， limit置为4，刚好是读取的区间. 而flip的源码也是按照这个思路来的<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">flip</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    limit = position;</span><br><span class="line">    position = <span class="number">0</span>;</span><br><span class="line">    mark = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>flip之后的状态如下图：</p><p><img src="https://ae01.alicdn.com/kf/Ha80a7ce86b1a4411975447fd515df539L.png" alt="flip之后的状态"></p><h3 id="读取ByteBuffer"><a href="#读取ByteBuffer" class="headerlink" title="读取ByteBuffer"></a>读取ByteBuffer</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">buffer.flip();</span><br><span class="line"><span class="keyword">while</span> (buffer.hasRemaining()) &#123;</span><br><span class="line">    <span class="keyword">int</span> anInt = buffer.getInt();</span><br><span class="line">    System.out.println(<span class="string">"anInt = "</span> + anInt);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>操作读取的代码如上，每读取一个int，position+4, limit就是读取的上限，hasRemaining方法就是为了防止越界</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>相信通过上面的图文，大家对position和limit这两个变量不在陌生了，也能理解为什么有flip方法</p><h2 id="api"><a href="#api" class="headerlink" title="api"></a>api</h2><p>ByteBuffer还有很多的api，其实都无须解释它们的作用，源码都是在操纵那4个变量</p><h3 id="clear"><a href="#clear" class="headerlink" title="clear"></a>clear</h3><p>clear方法有点类似重置，position，limit，mark都回归到了初始状态<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">clear</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    position = <span class="number">0</span>;</span><br><span class="line">    limit = capacity;</span><br><span class="line">    mark = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="rewind"><a href="#rewind" class="headerlink" title="rewind"></a>rewind</h3><p>听名字很难理解，感觉很抽象，但是源码及其简单，重置position=0<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">rewind</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    position = <span class="number">0</span>;</span><br><span class="line">    mark = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="slice"><a href="#slice" class="headerlink" title="slice"></a>slice</h3><p>就是字面意思的截取，假设长度为8的ByteBuffer，写了4个字节，目前position为4</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ByteBuffer <span class="title">slice</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> HeapByteBuffer(hb,</span><br><span class="line">                                    -<span class="number">1</span>,</span><br><span class="line">                                    <span class="number">0</span>,</span><br><span class="line">                                    <span class="keyword">this</span>.remaining(), <span class="comment">// limit - position，即要截取的字节数</span></span><br><span class="line">                                    <span class="keyword">this</span>.remaining(),</span><br><span class="line">                                    <span class="keyword">this</span>.position() + offset);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="title">HeapByteBuffer</span><span class="params">(<span class="keyword">byte</span>[] buf,</span></span></span><br><span class="line"><span class="function"><span class="params">                         <span class="keyword">int</span> mark, <span class="keyword">int</span> pos, <span class="keyword">int</span> lim, <span class="keyword">int</span> cap,</span></span></span><br><span class="line"><span class="function"><span class="params">                         <span class="keyword">int</span> off)</span></span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(mark, pos, lim, cap, buf, off);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="mark与reset"><a href="#mark与reset" class="headerlink" title="mark与reset"></a>mark与reset</h3><p>摘取kafka MemoryRecords中的一段代码, 可以看到为了重置position，先进行了mark<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">writeFullyTo</span><span class="params">(GatheringByteChannel channel)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    buffer.mark();</span><br><span class="line">    <span class="keyword">int</span> written = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (written &lt; sizeInBytes())</span><br><span class="line">        written += channel.write(buffer);</span><br><span class="line">    buffer.reset();</span><br><span class="line">    <span class="keyword">return</span> written;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="HeapByteBuffer与MappedByteBuffer"><a href="#HeapByteBuffer与MappedByteBuffer" class="headerlink" title="HeapByteBuffer与MappedByteBuffer"></a>HeapByteBuffer与MappedByteBuffer</h2><p>HeapByteBuffer与MappedByteBuffer是ByteBuffer的两个子类，二者通俗的区别在于：</p><p>HeapByteBuffer创建在jvm heap堆上，创建，回收都由jvm控制，适合需要频繁创建的情形，不适合需要大缓存的场景，毕竟jvm内存有限<br>MappedByteBuffer使用的是系统内存，也就是堆外内存，创建与回收对于jvm来说都是比较重的操作，适合申请之后不会立即回收，长时间重复利用的场景</p><p>最后我想说的是，学习ByteBuffer最快速最简单的方式就是看源码，网上很多文档对api的表述方式反而让人看得云里雾里</p>]]></content>
      
      <categories>
          
          <category> 技术积累 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nio </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>快速学习scala语言及常用语法汇总</title>
      <link href="/2019/11/27/%E5%BF%AB%E9%80%9F%E5%AD%A6%E4%B9%A0scala%E8%AF%AD%E8%A8%80%E5%8F%8A%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95%E6%B1%87%E6%80%BB/"/>
      <url>/2019/11/27/%E5%BF%AB%E9%80%9F%E5%AD%A6%E4%B9%A0scala%E8%AF%AD%E8%A8%80%E5%8F%8A%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95%E6%B1%87%E6%80%BB/</url>
      <content type="html"><![CDATA[<blockquote><p>阅读kafka源码的一大障碍就是scala语言，本文的目的是罗列kakfa源码中涉及到的基础源码知识，一些不常用的东西不会涉及，同时我也会不断总结遇到的语法特性，因为极个别语法俺也不会！</p></blockquote><h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><p>和java一样，scala也需要sdk来运行程序，scala也是jvm语言，请事先保证本机上已安装java</p><h2 id="sdk"><a href="#sdk" class="headerlink" title="sdk"></a>sdk</h2><p>scala sdk的安装我强烈推荐sdkman(mac用户)，windows用户自己百度安装即可<br>sdk安装scala命令： sdk i scala 2.12.10</p><h2 id="ide"><a href="#ide" class="headerlink" title="ide"></a>ide</h2><p>ide依然选择idea，安装scala插件即可</p><h1 id="语法基础"><a href="#语法基础" class="headerlink" title="语法基础"></a>语法基础</h1><h2 id="启动类定义"><a href="#启动类定义" class="headerlink" title="启动类定义"></a>启动类定义</h2><p>main方法只能定义在object中，object中所有的方法和变量都是静态的</p><h2 id="小知识点"><a href="#小知识点" class="headerlink" title="小知识点"></a>小知识点</h2><p>一些小知识点提前说明</p><ol><li>scala中句尾不用写分号</li><li>scala中的Unit就是java中的void</li></ol><h2 id="变量定义"><a href="#变量定义" class="headerlink" title="变量定义"></a>变量定义</h2><p>var是变量，val是常量，常量利于jvm的GC回收，因此kafka中几乎都是val</p><p>同时scala中变量是不要定义类型的，会进行自动推断<br>这种语法比较恶心的是方法调用后的返回值类型不能一眼看出，比如<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val obj = fun()</span><br></pre></td></tr></table></figure></p><p>obj的类型通常要进入fun方法定义，看它的返回值</p><h2 id="if-else对变量赋值"><a href="#if-else对变量赋值" class="headerlink" title="if/else对变量赋值"></a>if/else对变量赋值</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val result = if(size &gt; 0) true else false</span><br></pre></td></tr></table></figure><p>看到这里是不是感觉神清气爽，想想java里要如何实现这个功能，真是省了不少事</p><h2 id="打印字符串"><a href="#打印字符串" class="headerlink" title="打印字符串"></a>打印字符串</h2><p>scala中打印时拼接字符串极为方便<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">log.info(s<span class="string">"request size is: $&#123;request.size&#125;"</span>)</span><br></pre></td></tr></table></figure></p><p>s开头，后面跟字符串，打印变量，用${}包裹即可，java中几乎没有比这种方法更好的，即使String.format也很丑陋，更不要说加号拼接了</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>首先记住一点，看见def就是方法定义，它的大概形式如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">fun</span><span class="params">(参数名 :参数类型)</span> :返回值类型 </span>= &#123;</span><br><span class="line"><span class="comment">// 方法体...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>scala中的方法千变万化，但是都是以上形式，鉴于篇幅，本文只介绍kafka中常用的一些形式</p><h3 id="返回值"><a href="#返回值" class="headerlink" title="返回值"></a>返回值</h3><p>scala中方法返回值不用写return，最后一行代码就是返回值，遇到if/else,case也不要慌，慢慢看即可</p><h4 id="多个返回值"><a href="#多个返回值" class="headerlink" title="多个返回值"></a>多个返回值</h4><p>java中的方法不能有多个返回值，一直是我很耿耿于怀的地方<br>假如要返回方法中的一个List对象和一个Map对象，只能定义一个对象来保存</p><p>而scala的多返回值完全没有这种麻烦，还可以自行指定要哪个返回值<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">fun</span><span class="params">()</span>:<span class="params">(Int, Int)</span> </span>= &#123;</span><br><span class="line">(<span class="number">10</span>,<span class="number">20</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 只要fun方法的第一个返回值</span></span><br><span class="line">var result = fun()._1</span><br></pre></td></tr></table></figure></p><p>以上用法在kafka源码中也会见到</p><h3 id="省略"><a href="#省略" class="headerlink" title="省略"></a>省略</h3><p>scala中的方法有各种省略。只有一行代码可以省略{}，返回值类型用自动推断也可以省略。如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">def getSize = size</span><br></pre></td></tr></table></figure></p><h3 id="嵌套方法"><a href="#嵌套方法" class="headerlink" title="嵌套方法"></a>嵌套方法</h3><p>嵌套方法的意思是说方法里可以定义方法，常见的格式如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">handle</span><span class="params">()</span> :Unit </span>= &#123;</span><br><span class="line"><span class="function">def <span class="title">callback</span><span class="params">()</span> :Unit</span>=&#123;</span><br><span class="line"><span class="comment">//...</span></span><br><span class="line">&#125;</span><br><span class="line">read(args..., callback)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>以上例子是kafka中常见的一种用法：将回调方法先定义好，然后作为参数传给另一个方法<br>这种特性的好处也是显而易见的，配合函数传参使方法调用以及定义更优雅，想想java中要实现类似的功能，得要定义一个接口<br>坏处在于滥用该特性，嵌套多层或者定义太多嵌套方法，使代码阅读性变差</p><h3 id="柯里化函数"><a href="#柯里化函数" class="headerlink" title="柯里化函数"></a>柯里化函数</h3><p>听上去高大上的一个名字，其实既简单又实用，kafka中常见的定义如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">inLock</span><span class="params">(lock :Lock)</span><span class="params">(fun :Any)</span></span>&#123;</span><br><span class="line">lock.lock()</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      fun</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      lock.unlock()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这是kafka中的一个加锁方法的大概源码，它是一个公共方法，作用是传入一个锁和一个方法对象，然后在方法执行前后加锁和释放锁，这有些类似java中aop的思想</p><h4 id="如何调用"><a href="#如何调用" class="headerlink" title="如何调用"></a>如何调用</h4><p>以上的柯里化函数调用方式在kafka源码中也采取了一定的简化<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">inLock(readLock) &#123;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>可以看到第二个参数的方法对象，直接用花括号</p><h2 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h2><p>scala中的集合默认是不可变的，所以经常看到mutabl开头的初始化，例如</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val map = mutable.HashMap[String, Integer]</span><br></pre></td></tr></table></figure><h2 id="Option与match…case"><a href="#Option与match…case" class="headerlink" title="Option与match…case"></a>Option与match…case</h2><p>kafka源码中充斥着大量的这种结果，Option和java中的Optional类似，都是为了避免空指针而引入的<br>在scala中Option有2个子类：Some和None，就是元素是否为空的2种类型</p><p>以下是从kafka源码中复制的一段代码<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">partition.getReplica(replicaId) match &#123;</span><br><span class="line"><span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(replica)</span> </span>=&gt;</span><br><span class="line">  partition.updateReplicaLogReadResult(replica, readResult)</span><br><span class="line"><span class="keyword">case</span> None =&gt;</span><br><span class="line">  updatedReadResult = readResult.withEmptyFetchInfo</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>解释如下：</p><ol><li>partition.getReplica(replicaId)的返回值类型是Option[Replica]</li><li>match…case类似于java中的switch…case</li><li>Some(replica)中的replica变量名是可以随便起的<br>总的来说类似 if(replica != null) … else …</li></ol><h1 id="特殊语法汇总"><a href="#特殊语法汇总" class="headerlink" title="特殊语法汇总"></a>特殊语法汇总</h1><p>scala中求多个集合的并集，有3个List集合，list1，list2，list3<br>val all = list1 ++ list2 ++ list3</p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> scala </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>《快手万亿级别Kafka集群应用实践与技术演进之路》观后心得</title>
      <link href="/2019/11/21/%E3%80%8A%E5%BF%AB%E6%89%8B%E4%B8%87%E4%BA%BF%E7%BA%A7%E5%88%ABKafka%E9%9B%86%E7%BE%A4%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5%E4%B8%8E%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF%E3%80%8B%E8%A7%82%E5%90%8E%E5%BF%83%E5%BE%97/"/>
      <url>/2019/11/21/%E3%80%8A%E5%BF%AB%E6%89%8B%E4%B8%87%E4%BA%BF%E7%BA%A7%E5%88%ABKafka%E9%9B%86%E7%BE%A4%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5%E4%B8%8E%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF%E3%80%8B%E8%A7%82%E5%90%8E%E5%BF%83%E5%BE%97/</url>
      <content type="html"><![CDATA[<blockquote><p>本文用于记录观看快手万亿级别Kafka集群应用实践与技术演进之路演讲后的心得，从中确实学到了很多，快手作为kafka的重度使用者，对kafka集群从不同角度优化，其中发现问题，解决问题的思路都值得学习</p></blockquote><p>以下这张图是本次演讲的内容，分章节阐述具体内容<br><img src="https://ae01.alicdn.com/kf/Hb4200382b3f448eeb7ebbda8d380768cP.jpg" alt=""></p><h1 id="平滑扩容"><a href="#平滑扩容" class="headerlink" title="平滑扩容"></a>平滑扩容</h1><p>kafka集群节点扩容时，要做副本迁移，但kafka是从副本最开始的offset同步的，并且消息是在不断写入的，那么就要去同步的速度要大于写入的速度，才有可能同步完，要么就会产生以下问题</p><h2 id="磁盘读取"><a href="#磁盘读取" class="headerlink" title="磁盘读取"></a>磁盘读取</h2><p>从最开始的offset开始迁移，就极有可能是在磁盘上，而不是在pageCache中，迁移过程将加大磁盘的负载，影响生产者的写入效率，造成不稳定</p><p>同时kafka有消息过期机制，假设同步完成后，消息过期了，就白同步了。而在大型集群中，一次同步动辄几个小时都是有可能的</p><h2 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h2><p>对最早的offset同步产生质疑，是否有可能从最新的offset开始同步，答案是肯定的，但是这样做会有消费者丢失数据的情况。<br>假设以下情形，消费者拉取消息offset为5，高水位线为8，LEO为10，此时集群扩容，新副本从10开始同步，那么新副本成为leader后，就丢失了6-9的数据</p><p>解决这个问题也不难，快手的解决方案是同步一段时间，等所有消费者都已经消费。<br>我个人的观点是从消费者已提交的位置开始同步，保险起见可以再往前一部分offset</p><h1 id="Mirror集群"><a href="#Mirror集群" class="headerlink" title="Mirror集群"></a>Mirror集群</h1><p>MirrorMarker是用于同步多个kafka集群的工具，但它有很多缺点，不足以大规模应用</p><ol><li>无法同步消费者offset</li><li>缺乏监控</li><li>topic是静态配置的，增加topic需要重启MirrorMarker</li><li>只支持一个集群到另一个集群的同步，无法同步多个集群</li></ol><h1 id="资源隔离"><a href="#资源隔离" class="headerlink" title="资源隔离"></a>资源隔离</h1><p>在<a href="https://greedypirate.github.io/2019/12/29/kafka%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/">kafka网络请求处理模型</a>一文中，阐述了Processor是如何将请求放入requestQueue中的，<br><img src="https://ae01.alicdn.com/kf/H9d81a3a1afa14c2d945eef4dcce57ec8D.png" alt="kafka请求处理流程"><br>该队列是一个有界队列，大小由queued.max.requests参数控制，默认是500，当某一个topic出现问题时，kafka处理速度变慢，导致队列满了，后续请求被阻塞，向上导致Processor和Acceptor接收网络请求被阻塞，这是不能接受的<br>快手的策略是多队列，每个队列后面跟一个worker线程池(KafkaRequestHandlerPoll), 同时发现队列满了以后，请求被丢弃</p><h1 id="cache改造"><a href="#cache改造" class="headerlink" title="cache改造"></a>cache改造</h1><p>cache改造是我很感兴趣的一个部分，原来pageCache有很多稳定性问题，导致缓存命中率降低</p><p>在理想情况下，生产者发送的消费写入到pageCache中，消费者在缓存未失效的情况下，从pageCache中读取，整个过程是基于内存的，效率非常高<br>但是这以下两种情况下，pageCache会被污染，到时消息在pageCache中失效，需要从磁盘中读取，降低了效率</p><ol><li>线上环境消息积压是极有可能的情况，被积压的消息大概率是在磁盘中，此时消费者拉取消息就会将历史消息加载pageCache中<br>而正常topic写入的消息能够使用的pageCache就减少了，又会被写入到磁盘中，此时正常topic的消费者来消费时就要读取磁盘，降低了pageCache的命中率</li><li>follower副本从leader副本同步后，也要写入到broker磁盘中区，但是它也是要先写到pageCache中，我们都知道kafka中的follower副本是不提供读写能力的，那么它也写到pageCache中就很浪费内存了</li></ol><h2 id="解决方式-1"><a href="#解决方式-1" class="headerlink" title="解决方式"></a>解决方式</h2><p>让kafka不要重度依赖pageCache，构建kafka自己的内存cache<br><img src="https://ae01.alicdn.com/kf/H8509500f136e4f3f892e81b07e0cbd71B.png" alt="kafka-cache"></p><p>基于以上设计，consumer拉取消费时，先从cache中获取消息，没有再去pageCache中获取</p>]]></content>
      
      <categories>
          
          <category> 架构随笔录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
            <tag> 演讲 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>kafka源码环境搭建</title>
      <link href="/2019/11/18/kafka%E6%BA%90%E7%A0%81%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
      <url>/2019/11/18/kafka%E6%BA%90%E7%A0%81%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<h1 id="源码下载"><a href="#源码下载" class="headerlink" title="源码下载"></a>源码下载</h1><p>从<a href="http://kafka.apache.org/downloads" target="_blank" rel="noopener">kafka官网</a>下载源码压缩包，以2.0.1版本为例，选择-src结尾的压缩包</p><p><img src="https://ae01.alicdn.com/kf/H210e4ddd7a6e484eb1187793e785a0c1w.png" alt="kafka 2.0.1"></p><h1 id="依赖环境"><a href="#依赖环境" class="headerlink" title="依赖环境"></a>依赖环境</h1><p>kafka采用gradle构建，根据kafka的git提交记录，采用4.10.3版本构建，如果本地有别的gradle版本，可以尝试用<a href="https://sdkman.io/" target="_blank" rel="noopener">sdkman</a>这款工具来管理，一个命令即可切换版本<br>kafka使用scala语言开发，需要安装2.12版本的scala，同样的sdkman也可以快速安装<br><img src="https://ae01.alicdn.com/kf/H2d59f09399574120b822f6d7c71729090.png" alt="提交日志"></p><h1 id="修改配置及日志文件"><a href="#修改配置及日志文件" class="headerlink" title="修改配置及日志文件"></a>修改配置及日志文件</h1><p>修改config/server.properties文件相关参数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">listeners=PLAINTEXT://localhost:9092</span><br><span class="line"># 设置自己的目录路径</span><br><span class="line">log.dirs=/Users/admin/app/other-kafka/kafka-2.0.1-src/logs</span><br><span class="line"># 如果本地有别的kafka集群，设置zk的chroot</span><br><span class="line">zookeeper.connect=localhost:2181/cluster_201</span><br></pre></td></tr></table></figure></p><p>将config目录下的log4j文件复制到src/main/resources目录下，resources目录自己新建即可<br><img src="https://ae01.alicdn.com/kf/H97695e5cf22d4509b660f785e19ac77dE.png" alt="移动log4j文件"></p><h1 id="导入IDEA"><a href="#导入IDEA" class="headerlink" title="导入IDEA"></a>导入IDEA</h1><p>解压后导入IDEA中，IDEA会自动开始构建，等待IDEA下载依赖</p><h1 id="相关问题"><a href="#相关问题" class="headerlink" title="相关问题"></a>相关问题</h1><p>如果在编译的过程中出现以下错误<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">You can&apos;t map a property that does not exist: propertyName=testClassesDir</span><br></pre></td></tr></table></figure></p><p>调整build.gradle中的依赖版本为以下版本<br><img src="https://ae01.alicdn.com/kf/H86c22cdb3be04652b06db45350080181y.png" alt="调整版本"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Cause: org.jetbrains.plugins.gradle.tooling.util.ModuleComponentIdentifierIm Lorg/gradle/api/artifacts/ModuleIdentifier</span><br></pre></td></tr></table></figure><p>如果报以上错误,请检查IDEA是否配置了正确的gradle 4.10.3版本的home路径(尤其是IDEA 2018版本)</p><p>遇到下载超时的jar包，可以到maven中央仓库下载jar，通过命名手动安装</p><p>举例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn install:install-file -DgroupId=org.scala-lang -DartifactId=scala-reflect -Dversion=2.10.6 -Dpackaging=jar -Dfile=/Users/admin/scala/scala-reflect-2.10.6.jar</span><br></pre></td></tr></table></figure></p><p>然后继续等待IDEA编译，等待期间多祈祷能下载下来…</p><h1 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h1><p>首先启动Zookeeper，成功构建之后，调整kafka的启动参数<br>注：建议将jvm堆内存设置小一点，kafka默认是1G，本机机器完全没有必要 -Xmx512m -Xms512m<br><img src="https://ae01.alicdn.com/kf/H43d9e3cc1fad40fdbdba654de897c442J.png" alt="启动参数"></p><p>启动成功之后控制台如下<br><img src="https://ae01.alicdn.com/kf/H0dccf862d1364893ac367dce5856bc72l.png" alt=""><br>注：日志不打印问题见我的另一篇博客-<a href="">kafka本地启动后不打印日志问题</a></p><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>向topic中发送消息之后，logs目录产生了日志文件<br><img src="https://ae01.alicdn.com/kf/Ha8852196a2bc47c993dd79367104e549v.png" alt="lgos目录"></p><p>以上步骤已在MacOS和Windows系统上验证通过，遇到问题的同学请在评论区写下问题，我会尽量解答</p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka生产者源码浅析(三)</title>
      <link href="/2019/10/28/Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90(%E4%B8%89)/"/>
      <url>/2019/10/28/Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90(%E4%B8%89)/</url>
      <content type="html"><![CDATA[<h1 id="Kafka生产者源码浅析-三"><a href="#Kafka生产者源码浅析-三" class="headerlink" title="Kafka生产者源码浅析(三)"></a>Kafka生产者源码浅析(三)</h1><h2 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h2><p>在doSend方法中，最后几行代码是在消息添加进内存缓冲区之后，判断是否有可发送的消息，并唤醒了Sender线程</p><p>那么sender线程又是如何发送的呢</p><p>猜想：</p><ol><li>先拿到缓冲区中待发送的所有消息，找到每个partition leader所在的broker</li><li>topic的分区可能很多，按照分区的leader所在的broker id分组</li><li>和broker建立连接，发送消息</li></ol><p>为什么要按broker分组？<br>假设broker集群有3台，一批消息要发送给5个分区，那么我们可以按照broker分区，一次请求就把所有在这台broker上的分区leader的消息发送完，这样请求按broker分组合并，提升了效率。</p><p>但是kafka有一个限定，同一个client对一个broker只能一个一个发请求，不能同时发送多个请求，这也是为了缓解broker端的压力<br>为了实现该方式，必然有个先进先出的请求队列，前一个请求拿到响应之后，才能出队，进行第二个请求</p><h2 id="sender发送消息"><a href="#sender发送消息" class="headerlink" title="sender发送消息"></a>sender发送消息</h2><p>Sender类实现了Runnable接口，那么主逻辑就应该在run方法中了，关于一些判断，事务先不用管，来到Sender重载的run(long)方法，其中的两行关键代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 省略事务相关代码 ....</span></span><br><span class="line">    <span class="keyword">long</span> pollTimeout = sendProducerData(now);</span><br><span class="line">    client.poll(pollTimeout, now);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="消息分组并构建请求对象"><a href="#消息分组并构建请求对象" class="headerlink" title="消息分组并构建请求对象"></a>消息分组并构建请求对象</h2><p>sendProducerData方法用于构建PRODUCE请求对象，主要分以下三个步骤</p><ol><li>获取可发送的分区所在的broker节点集合</li><li>按照broker id对消息集合分组</li><li>构建请求对象</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">sendProducerData</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    Cluster cluster = metadata.fetch();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// get the list of partitions with data ready to send</span></span><br><span class="line">    <span class="comment">// 获取可发送的分区所在的broker节点集合</span></span><br><span class="line">    RecordAccumulator.ReadyCheckResult result = <span class="keyword">this</span>.accumulator.ready(cluster, now);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// if there are any partitions whose leaders are not known yet, force metadata update</span></span><br><span class="line">    <span class="keyword">if</span> (!result.unknownLeaderTopics.isEmpty()) &#123;</span><br><span class="line">        <span class="comment">// The set of topics with unknown leader contains topics with leader election pending as well as</span></span><br><span class="line">        <span class="comment">// topics which may have expired. Add the topic again to metadata to ensure it is included</span></span><br><span class="line">        <span class="comment">// and request metadata update, since there are messages to send to the topic.</span></span><br><span class="line">        <span class="comment">// 有分区leader未知的topic，等待下次元数据更新</span></span><br><span class="line">        <span class="keyword">for</span> (String topic : result.unknownLeaderTopics)</span><br><span class="line">            <span class="keyword">this</span>.metadata.add(topic);</span><br><span class="line"></span><br><span class="line">        log.debug(<span class="string">"Requesting metadata update due to unknown leader topics from the batched records: &#123;&#125;"</span>, result.unknownLeaderTopics);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">this</span>.metadata.requestUpdate();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// remove any nodes we aren't ready to send to</span></span><br><span class="line">    <span class="comment">// 移除网络通信异常的node</span></span><br><span class="line">    Iterator&lt;Node&gt; iter = result.readyNodes.iterator();</span><br><span class="line">    <span class="keyword">long</span> notReadyTimeout = Long.MAX_VALUE;</span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">        Node node = iter.next();</span><br><span class="line">        <span class="keyword">if</span> (!<span class="keyword">this</span>.client.ready(node, now)) &#123;</span><br><span class="line">            iter.remove();</span><br><span class="line">            notReadyTimeout = Math.min(notReadyTimeout, <span class="keyword">this</span>.client.pollDelayMs(node, now));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// create produce requests</span></span><br><span class="line">    <span class="comment">// 按照broker id分组</span></span><br><span class="line">    Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; batches = <span class="keyword">this</span>.accumulator.drain(cluster, result.readyNodes,</span><br><span class="line">            <span class="keyword">this</span>.maxRequestSize, now);</span><br><span class="line">    <span class="keyword">if</span> (guaranteeMessageOrder) &#123;</span><br><span class="line">        <span class="comment">// Mute all the partitions drained</span></span><br><span class="line">        <span class="keyword">for</span> (List&lt;ProducerBatch&gt; batchList : batches.values()) &#123;</span><br><span class="line">            <span class="keyword">for</span> (ProducerBatch batch : batchList)</span><br><span class="line">                <span class="keyword">this</span>.accumulator.mutePartition(batch.topicPartition);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 省略事务，监控相关</span></span><br><span class="line">    sendProduceRequests(batches, now);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pollTimeout;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="构建请求对象"><a href="#构建请求对象" class="headerlink" title="构建请求对象"></a>构建请求对象</h3><p>可以看到最终发送给broker的是一个Map&lt;TopicPartition, MemoryRecords&gt;对象</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">sendProduceRequest</span><span class="params">(<span class="keyword">long</span> now, <span class="keyword">int</span> destination, <span class="keyword">short</span> acks, <span class="keyword">int</span> timeout, List&lt;ProducerBatch&gt; batches)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (batches.isEmpty())</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    Map&lt;TopicPartition, MemoryRecords&gt; produceRecordsByPartition = <span class="keyword">new</span> HashMap&lt;&gt;(batches.size());</span><br><span class="line">    <span class="keyword">final</span> Map&lt;TopicPartition, ProducerBatch&gt; recordsByPartition = <span class="keyword">new</span> HashMap&lt;&gt;(batches.size());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// find the minimum magic version used when creating the record sets</span></span><br><span class="line">    <span class="keyword">byte</span> minUsedMagic = apiVersions.maxUsableProduceMagic();</span><br><span class="line">    <span class="keyword">for</span> (ProducerBatch batch : batches) &#123;</span><br><span class="line">        <span class="keyword">if</span> (batch.magic() &lt; minUsedMagic)</span><br><span class="line">            minUsedMagic = batch.magic();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (ProducerBatch batch : batches) &#123;</span><br><span class="line">        TopicPartition tp = batch.topicPartition;</span><br><span class="line">        MemoryRecords records = batch.records();</span><br><span class="line"></span><br><span class="line">        produceRecordsByPartition.put(tp, records);</span><br><span class="line">        recordsByPartition.put(tp, batch);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ProduceRequest.Builder requestBuilder = ProduceRequest.Builder.forMagic(minUsedMagic, acks, timeout,</span><br><span class="line">            produceRecordsByPartition, transactionalId);</span><br><span class="line">    RequestCompletionHandler callback = <span class="keyword">new</span> RequestCompletionHandler() &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onComplete</span><span class="params">(ClientResponse response)</span> </span>&#123;</span><br><span class="line">            handleProduceResponse(response, recordsByPartition, time.milliseconds());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    String nodeId = Integer.toString(destination);</span><br><span class="line">    ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != <span class="number">0</span>,</span><br><span class="line">            requestTimeoutMs, callback);</span><br><span class="line">    client.send(clientRequest, now);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="发送流程"><a href="#发送流程" class="headerlink" title="发送流程"></a>发送流程</h1><p>最后总结下生产者发送流程<br><img src="https://ae01.alicdn.com/kf/H85cc7061b8514ba2bcb36773714a49276.png" alt=""></p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ElasticSearch7.2 实现数据自动冷热分离</title>
      <link href="/2019/10/25/ElasticSearch7-2-Hot-warm%E4%B8%8Erollover-API%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E8%87%AA%E5%8A%A8%E5%86%B7%E7%83%AD%E5%88%86%E7%A6%BB/"/>
      <url>/2019/10/25/ElasticSearch7-2-Hot-warm%E4%B8%8Erollover-API%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E8%87%AA%E5%8A%A8%E5%86%B7%E7%83%AD%E5%88%86%E7%A6%BB/</url>
      <content type="html"><![CDATA[<h1 id="冷热分离"><a href="#冷热分离" class="headerlink" title="冷热分离"></a>冷热分离</h1><p>在基于时序数据中，我们总是关心最近产生的数据，例如查询订单通常只会查询最近三天，至多到最近一个月的，查询日志也是同样的情形，很少会去查询历史数据，也就是说类似的时序数据随着时间推移，价值在逐渐弱化。在es中经常按日或按月建立索引，我们很容易想到，历史索引被查询命中的概率越来越低，不应该占用高性能的机器资源(比如大内存，SSD)，可以将其迁移到低配置的机器上，从而实现冷热数据分离存储。</p><h1 id="分片分配规则-shard-allocation-filtering"><a href="#分片分配规则-shard-allocation-filtering" class="headerlink" title="分片分配规则(shard allocation filtering)"></a>分片分配规则(shard allocation filtering)</h1><p>假设我们有三个es节点，一台高性能机器(hot)和2个低配置机器(warm)，通常索引分片会均匀分布在集群节点中，但我们希望最新的数据由于其写入和查询频繁的特性，只能保存在hot节点上，而过期的数据保存在warm节点上。<br>实现该功能，首先要对节点人为的打个标签，然后在索引创建时指定要把分片分配给hot节点，在索引不再写入后，迁移到warm节点上</p><h2 id="节点tag"><a href="#节点tag" class="headerlink" title="节点tag"></a>节点tag</h2><p>依次启动三个节点，同时加入box_type和resource_level标签，box_type标记node1、node2为warm节点，node3为hot节点，resource_level标记机器资源的性能，分为高，中，低<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/elasticsearch -d -p pid -E node.name=node1 -E node.max_local_storage_nodes=3 -E path.data=node1_data -E path.logs=node1_logs -E node.attr.box_type=warm -E node.attr.resource_level=high</span><br><span class="line"></span><br><span class="line">bin/elasticsearch -d -p pid -E node.name=node2 -E node.max_local_storage_nodes=3 -E path.data=node2_data -E path.logs=node2_logs -E node.attr.box_type=warm -E node.attr.resource_level=mdeium</span><br><span class="line"></span><br><span class="line">bin/elasticsearch -d -p pid -E node.name=node3 -E node.max_local_storage_nodes=3 -E path.data=node3_data -E path.logs=node3_logs -E node.attr.box_type=hot -E node.attr.resource_level=high</span><br></pre></td></tr></table></figure></p><h3 id="查看属性"><a href="#查看属性" class="headerlink" title="查看属性"></a>查看属性</h3><p>kibana中输入以下命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET _cat/indices?v</span><br></pre></td></tr></table></figure></p><p>得到以下结果，可以看到box_type和resource_level标签在每个节点的值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">node  host      ip        attr              value</span><br><span class="line">node3 127.0.0.1 127.0.0.1 ml.machine_memory 17179869184</span><br><span class="line">node3 127.0.0.1 127.0.0.1 ml.max_open_jobs  20</span><br><span class="line">node3 127.0.0.1 127.0.0.1 box_type          hot</span><br><span class="line">node3 127.0.0.1 127.0.0.1 xpack.installed   true</span><br><span class="line">node3 127.0.0.1 127.0.0.1 resource_level    high</span><br><span class="line">node1 127.0.0.1 127.0.0.1 ml.machine_memory 17179869184</span><br><span class="line">node1 127.0.0.1 127.0.0.1 box_type          warm</span><br><span class="line">node1 127.0.0.1 127.0.0.1 xpack.installed   true</span><br><span class="line">node1 127.0.0.1 127.0.0.1 ml.max_open_jobs  20</span><br><span class="line">node1 127.0.0.1 127.0.0.1 resource_level    high</span><br><span class="line">node2 127.0.0.1 127.0.0.1 ml.machine_memory 17179869184</span><br><span class="line">node2 127.0.0.1 127.0.0.1 ml.max_open_jobs  20</span><br><span class="line">node2 127.0.0.1 127.0.0.1 box_type          warm</span><br><span class="line">node2 127.0.0.1 127.0.0.1 xpack.installed   true</span><br><span class="line">node2 127.0.0.1 127.0.0.1 resource_level    mdeium</span><br></pre></td></tr></table></figure></p><h2 id="建立索引"><a href="#建立索引" class="headerlink" title="建立索引"></a>建立索引</h2><p>假设当前时间为2019年9月1日，作为最新的数据存储在hot节点上，只需要在建立索引时指定allocation策略即可<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PUT api_log_2019-09-01</span><br><span class="line">&#123;</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;number_of_shards&quot;: 3, </span><br><span class="line">    &quot;number_of_replicas&quot;: 0, </span><br><span class="line">    &quot;index.routing.allocation.require.box_type&quot;: &quot;hot&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="index-routing-allocation详解"><a href="#index-routing-allocation详解" class="headerlink" title="index.routing.allocation详解"></a>index.routing.allocation详解</h3><p>该配置支持include，require，exclude三种选项，它们的值都可以是多个，用逗号分隔<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">index.routing.allocation.include.&#123;attribute&#125;：将索引分配给具有至少一个值的节点。</span><br><span class="line">index.routing.allocation.require.&#123;attribute&#125;：将索引分配给具有所有值的节点。</span><br><span class="line">index.routing.allocation.exclude.&#123;attribute&#125;：将索引分配给没有该值的节点</span><br></pre></td></tr></table></figure></p><p>es还提供了以下内置字段</p><ul><li>_name： 节点名称匹配</li><li>_host_ip：主机名ip地址匹配</li><li>_publish_ip：publish ip匹配，参考network.publish_host配置</li><li>_ip：_host_ip或者_publish_ip匹配</li><li>_host：主机名匹配</li></ul><p>假设建立索引时没有配置该选项也不要紧，动态修改即可<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PUT api_log_2019-09-01/_settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index.routing.allocation.require.box_type&quot;: &quot;hot&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="迁移索引"><a href="#迁移索引" class="headerlink" title="迁移索引"></a>迁移索引</h2><p>迁移历史索引到warm节点的方式也是采用动态修改请求的方式<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PUT api_log_2019-09-01/_settings</span><br><span class="line">&#123;</span><br><span class="line">    &quot;index.routing.allocation.require.box_type&quot;: &quot;warm&quot;,</span><br><span class="line">    &quot;index.routing.allocation.include.resource_level&quot;: &quot;mdeium&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>我们将api_log_2019-09-01迁移到了box_type为warm，resource_level为mdeium的节点，即node2<br>通过查询索引分片的分布情况<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET _cat/shards/api_log_2019-09-01?v</span><br></pre></td></tr></table></figure></p><p>结果如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">index          shard prirep state   docs store ip        node</span><br><span class="line">api_log_2019-09-01 1     p      STARTED 4711 4.1mb 127.0.0.1 node2</span><br><span class="line">api_log_2019-09-01 2     p      STARTED 4656   4mb 127.0.0.1 node2</span><br><span class="line">api_log_2019-09-01 0     p      STARTED 4707 4.1mb 127.0.0.1 node2</span><br></pre></td></tr></table></figure></p><h1 id="Rollover-API"><a href="#Rollover-API" class="headerlink" title="Rollover API"></a>Rollover API</h1><p>大家应该也注意到了，迁移索引的步骤是手动完成的，有没有更智能的方式呢，答案是肯定的，rollover API可以很好地实现这个功能</p><h2 id="rollover"><a href="#rollover" class="headerlink" title="rollover"></a>rollover</h2><p>首先为索引建立别名, 由于多个index可以对应一个alias，为了让es知道往哪个索引中写，标记其中一个索引is_write_index为true<br>同时需要注意索引名以横杠+数字结尾的形式命名，这是为了让es自动生成索引<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">POST _aliases</span><br><span class="line">&#123;</span><br><span class="line">  &quot;actions&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;remove&quot;: &#123;</span><br><span class="line">        &quot;index&quot;: &quot;api_log_2019-09-01&quot;,</span><br><span class="line">        &quot;alias&quot;: &quot;api_logs&quot;,</span><br><span class="line">        &quot;is_write_index&quot;: true</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>rollover API会根据设置的条件(conditions)来生成新的索引<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">POST api_logs/_rollover</span><br><span class="line">&#123;</span><br><span class="line">  &quot;conditions&quot;: &#123;</span><br><span class="line">    &quot;max_age&quot;: &quot;1d&quot;,</span><br><span class="line">    &quot;max_docs&quot;: 10000,</span><br><span class="line">    &quot;max_size&quot;: &quot;5gb&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>conditions的详细解释：</p><ul><li>max_age：索引是否创建大于1天</li><li>max_docs：索引文档数是否超过10000</li><li>max_size：索引大小是否超过5GB<br>max_size正在进行中的合并会产生大量的临时分片大小增长，而当合并结束后这些增长会消失掉，不稳定，max_age每个时间内不一定均衡，max_docs比较合适<br>即以上三个条件满足其一就会自动rollover</li></ul><h3 id="新索引配置"><a href="#新索引配置" class="headerlink" title="新索引配置"></a>新索引配置</h3><p>rollover也支持索引的settings设置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">POST api_logs/_rollover</span><br><span class="line">&#123;</span><br><span class="line">  &quot;conditions&quot;: &#123;</span><br><span class="line">    &quot;max_age&quot;: &quot;1d&quot;,</span><br><span class="line">    &quot;max_docs&quot;: 10000,</span><br><span class="line">    &quot;max_size&quot;: &quot;5gb&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;index.number_of_shards&quot;: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="自定义索引名称"><a href="#自定义索引名称" class="headerlink" title="自定义索引名称"></a>自定义索引名称</h3><p>生成的索引名称为api_log_2019-09-000002, 以长度为6，序号+1，左填充0的格式命名，但es支持自定义名称，只需要在_rollover端点加入名称即可<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">POST api_logs/_rollover/api_log_2019-09-02</span><br><span class="line">&#123;...&#125;</span><br></pre></td></tr></table></figure></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>shard allocation filtering赋予了索引选择节点的能力，但在迁移过程中需要手动触发，因此rollover API应运而生，它可以在索引满足一定的条件下自动迁移索引到warm节点，index lifecycle management从更高的角度定义了索引的声明周期，把每个节点定义为一个phase，在每个阶段要做的事定义为action，这个action可以让我们对索引rollover，delete等，这一系列的功能，都是为了更智能的管理时序数据，典型的场景就是每天产生的日志</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.2/getting-started-index-lifecycle-management.html#ilm-gs-apply-policy" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.2/getting-started-index-lifecycle-management.html#ilm-gs-apply-policy</a><br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.2/indices-rollover-index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.2/indices-rollover-index.html</a><br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.2/shard-allocation-filtering.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.2/shard-allocation-filtering.html</a><br><a href="https://www.elastic.co/cn/blog/managing-time-based-indices-efficiently" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/managing-time-based-indices-efficiently</a><br><a href="https://juejin.im/post/5a990cdbf265da239b40de65" target="_blank" rel="noopener">https://juejin.im/post/5a990cdbf265da239b40de65</a></p>]]></content>
      
      <categories>
          
          <category> ELK Stack </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
            <tag> X-pack </tag>
            
            <tag> kibana </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka生产者源码浅析(二)</title>
      <link href="/2019/10/16/Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90(%E4%BA%8C)/"/>
      <url>/2019/10/16/Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90(%E4%BA%8C)/</url>
      <content type="html"><![CDATA[<h1 id="Kafka生产者源码浅析-二"><a href="#Kafka生产者源码浅析-二" class="headerlink" title="Kafka生产者源码浅析(二)"></a>Kafka生产者源码浅析(二)</h1><blockquote><p>上篇文章中对Spring-kafka源码做了追踪，也对原生的KafkaProducer做了部分解析，对关键类事先说明，帮助读者理解源码，克服对源码的恐惧心理</p></blockquote><p>doSend的方法很长，我们分部拆解<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 省略部分代码，catch处理</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> Future&lt;RecordMetadata&gt; <span class="title">doSend</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>&#123;</span><br><span class="line">    TopicPartition tp = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        throwIfProducerClosed();</span><br><span class="line">        <span class="comment">// first make sure the metadata for the topic is available</span></span><br><span class="line">        ClusterAndWaitTime clusterAndWaitTime;</span><br><span class="line">        clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);</span><br><span class="line">        <span class="keyword">long</span> remainingWaitMs = Math.max(<span class="number">0</span>, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);</span><br><span class="line">        Cluster cluster = clusterAndWaitTime.cluster;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">byte</span>[] serializedKey;</span><br><span class="line">        serializedKey = keySerializer.serialize(record.topic(), record.headers(), record.key());</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">byte</span>[] serializedValue;</span><br><span class="line">        serializedValue = valueSerializer.serialize(record.topic(), record.headers(), record.value());</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">int</span> partition = partition(record, serializedKey, serializedValue, cluster);</span><br><span class="line">        tp = <span class="keyword">new</span> TopicPartition(record.topic(), partition);</span><br><span class="line"></span><br><span class="line">        setReadOnly(record.headers());</span><br><span class="line">        Header[] headers = record.headers().toArray();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> serializedSize = AbstractRecords.estimateSizeInBytesUpperBound(apiVersions.maxUsableProduceMagic(),</span><br><span class="line">                compressionType, serializedKey, serializedValue, headers);</span><br><span class="line">        ensureValidRecordSize(serializedSize);</span><br><span class="line">        <span class="keyword">long</span> timestamp = record.timestamp() == <span class="keyword">null</span> ? time.milliseconds() : record.timestamp();</span><br><span class="line">        Callback interceptCallback = <span class="keyword">new</span> InterceptorCallback&lt;&gt;(callback, <span class="keyword">this</span>.interceptors, tp);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span> &amp;&amp; transactionManager.isTransactional())</span><br><span class="line">            transactionManager.maybeAddPartitionToTransaction(tp);</span><br><span class="line"></span><br><span class="line">        RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey,</span><br><span class="line">                serializedValue, headers, interceptCallback, remainingWaitMs);</span><br><span class="line">        <span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">            <span class="keyword">this</span>.sender.wakeup();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result.future;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="Part-one"><a href="#Part-one" class="headerlink" title="Part one"></a>Part one</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">TopicPartition tp = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    throwIfProducerClosed();</span><br><span class="line">    <span class="comment">// first make sure the metadata for the topic is available</span></span><br><span class="line">    ClusterAndWaitTime clusterAndWaitTime;</span><br><span class="line">    clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);</span><br><span class="line">    <span class="keyword">long</span> remainingWaitMs = Math.max(<span class="number">0</span>, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);</span><br><span class="line">    Cluster cluster = clusterAndWaitTime.cluster;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li><p>throwIfProducerClosed做的很简单，看看Sender线程是否活着</p></li><li><p>waitOnMetadata返回一个ClusterAndWaitTime对象，里面是broker集群的元信息和获取信息的耗时，这个耗时算在了max.block.ms中，它控制这send方法的最大执行时间</p></li><li><p>waitOnMetadata通过唤醒sender线程，依靠NetworkClient.poll()方法来更新元数据</p></li></ol><p>Cluster 类信息如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Cluster</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> isBootstrapConfigured;</span><br><span class="line">    <span class="comment">// 所有的broker节点</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;Node&gt; nodes;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Set&lt;String&gt; unauthorizedTopics;</span><br><span class="line">    <span class="comment">// 内部topic，如_consumer_offset</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Set&lt;String&gt; internalTopics;</span><br><span class="line">    <span class="comment">// controller节点</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Node controller;</span><br><span class="line">    <span class="comment">// 每个分区对应的分区信息</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;TopicPartition, PartitionInfo&gt; partitionsByTopicPartition;</span><br><span class="line">    <span class="comment">// 每个topic所有分区的信息</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, List&lt;PartitionInfo&gt;&gt; partitionsByTopic;</span><br><span class="line">    <span class="comment">// topic所有可用分区的信息</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, List&lt;PartitionInfo&gt;&gt; availablePartitionsByTopic;</span><br><span class="line">    <span class="comment">// 每个broker节点的所有分区</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;Integer, List&lt;PartitionInfo&gt;&gt; partitionsByNode;</span><br><span class="line">    <span class="comment">// 按照nodeId组成map</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;Integer, Node&gt; nodesById;</span><br><span class="line">    <span class="comment">// 里面只有一个clusterId熟悉</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ClusterResource clusterResource;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>具体是如何初始化的，可以看一下Cluster构造函数的源码</p><p>上面出现的PartitionInfo, 这些信息想必大家已经很熟悉<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PartitionInfo</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 主题</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;</span><br><span class="line">    <span class="comment">// 分区</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> partition;</span><br><span class="line">    <span class="comment">// leader分区所在broker</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Node leader;</span><br><span class="line">    <span class="comment">// 副本所在broker</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Node[] replicas;</span><br><span class="line">    <span class="comment">// ISR副本所在broker</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Node[] inSyncReplicas;</span><br><span class="line">    <span class="comment">// 离线副本所在broker</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Node[] offlineReplicas;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="Part-two"><a href="#Part-two" class="headerlink" title="Part two"></a>Part two</h2><p>这一部分比较简单，对key和value序列化</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">byte</span>[] serializedKey;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    serializedKey = keySerializer.serialize(record.topic(), record.headers(), record.key());</span><br><span class="line">&#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</span><br><span class="line">   <span class="comment">// 省略...</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">byte</span>[] serializedValue;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    serializedValue = valueSerializer.serialize(record.topic(), record.headers(), record.value());</span><br><span class="line">&#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</span><br><span class="line">    <span class="comment">// 省略...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h3><p>接下来关注kafka是如何根据key为消息计算分区的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> partition = partition(record, serializedKey, serializedValue, cluster);</span><br><span class="line">tp = <span class="keyword">new</span> TopicPartition(record.topic(), partition);</span><br></pre></td></tr></table></figure><p>第二行代码是将topic和分区包装成一个TopicPartition类，重点关注第一行代码</p><p>partition方法会尝试获取消息中的partition，如果用户指定了分区，此时就不用计算了，否则使用partitioner计算分区</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(ProducerRecord&lt;K, V&gt; record, <span class="keyword">byte</span>[] serializedKey, <span class="keyword">byte</span>[] serializedValue, Cluster cluster)</span> </span>&#123;</span><br><span class="line">    Integer partition = record.partition();</span><br><span class="line">    <span class="keyword">return</span> partition != <span class="keyword">null</span> ?</span><br><span class="line">            partition :</span><br><span class="line">            partitioner.partition(</span><br><span class="line">                    record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="DefaultPartitioner"><a href="#DefaultPartitioner" class="headerlink" title="DefaultPartitioner"></a>DefaultPartitioner</h4><p>partitioner.partition的具体实现在DefaultPartitioner#partition，其源码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class="line">    List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">    <span class="keyword">int</span> numPartitions = partitions.size();</span><br><span class="line">    <span class="keyword">if</span> (keyBytes == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> nextValue = nextValue(topic);</span><br><span class="line">        List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">        <span class="keyword">if</span> (availablePartitions.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">int</span> part = Utils.toPositive(nextValue) % availablePartitions.size();</span><br><span class="line">            <span class="keyword">return</span> availablePartitions.get(part).partition();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// no partitions are available, give a non-available partition</span></span><br><span class="line">            <span class="keyword">return</span> Utils.toPositive(nextValue) % numPartitions;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// hash the keyBytes to choose a partition</span></span><br><span class="line">        <span class="keyword">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>回顾前文，Cluster封装了broker的很多信息，其中就用一个Map封装了topic的partition信息</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;String, List&lt;PartitionInfo&gt;&gt; partitionsByTopic</span><br></pre></td></tr></table></figure><p>此时要分区，首先要获取这个topic的PartitionInfo，第一行代码的作用就是这个，map.get(topic)，很简单</p><p>接下分两种情况：用户指定了key，和未指定key，我们知道旧版本的kafka在用户未指定key的情况下会默认将消息分配到某一个分区，<br>但这样会造成数据倾斜，官方后来对此作了优化，采用轮询(round-robin)的方式，简单提一下这块的代码</p><h4 id="随机分配"><a href="#随机分配" class="headerlink" title="随机分配"></a>随机分配</h4><p>kafka会初始化一个很大的伪随机数放在AtomicInteger中：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">nextValue</span><span class="params">(String topic)</span> </span>&#123;</span><br><span class="line">    AtomicInteger counter = topicCounterMap.get(topic);</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> == counter) &#123;</span><br><span class="line">        counter = <span class="keyword">new</span> AtomicInteger(ThreadLocalRandom.current().nextInt());</span><br><span class="line">        AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter);</span><br><span class="line">        <span class="keyword">if</span> (currentCounter != <span class="keyword">null</span>) &#123;</span><br><span class="line">            counter = currentCounter;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> counter.getAndIncrement();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>以topic为key保存在一个ConcurrentHashMap中，每次用完counter自增并返回，这就是nextValue方法的作用</p><p>接下来从Cluster中获取可用的分区信息，获取分区数，使用counter对其取模，然后从可用分区列表中获取一个分区，由于counter的自增，达到了轮询(round-robin)的效果。但如果没有可用的分区，则从所有分区中挑选(有种破罐子破摔的味道)</p><p>Utils.toPositive用于取绝对值，kafka选择了一个cheap way: 与运算</p><p>以上是对消息中没有key的情况下如何分配分区的分析，至于有key的情况就比较简单了：对key做<a href="https://sites.google.com/site/murmurhash/" target="_blank" rel="noopener">murmur2 hash</a>运算，然后对分区数取模</p><h3 id="自定义分区策略"><a href="#自定义分区策略" class="headerlink" title="自定义分区策略"></a>自定义分区策略</h3><p>实现Partitioner接口即可，配置方式参考拦截器，二者同理，参数名称为: partitioner.class</p><h2 id="Part-three"><a href="#Part-three" class="headerlink" title="Part three"></a>Part three</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">setReadOnly(record.headers());</span><br><span class="line">Header[] headers = record.headers().toArray();</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> serializedSize = AbstractRecords.estimateSizeInBytesUpperBound(apiVersions.maxUsableProduceMagic(),</span><br><span class="line">                    compressionType, serializedKey, serializedValue, headers);</span><br><span class="line">ensureValidRecordSize(serializedSize);</span><br><span class="line"><span class="keyword">long</span> timestamp = record.timestamp() == <span class="keyword">null</span> ? time.milliseconds() : record.timestamp();</span><br><span class="line">log.trace(<span class="string">"Sending record &#123;&#125; with callback &#123;&#125; to topic &#123;&#125; partition &#123;&#125;"</span>, record, callback, record.topic(), partition);</span><br><span class="line">Callback interceptCallback = <span class="keyword">new</span> InterceptorCallback&lt;&gt;(callback, <span class="keyword">this</span>.interceptors, tp);</span><br></pre></td></tr></table></figure><p>先把不重要的说了，这几行代码的可读性很好，设置消息头只读，然后<strong>估算</strong>消息的总大小，确保不会超出max.request.size和buffer.memory的大小，获取消息的时间戳，用户指定的优先，最后构建一个InterceptorCallback回调对象，它会先指定拦截器的onAcknowledgement回调，然后执行用户指定的Callback#onCompletion</p><h3 id="追加至缓存并发送"><a href="#追加至缓存并发送" class="headerlink" title="追加至缓存并发送"></a>追加至缓存并发送</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey,serializedValue, headers, interceptCallback, remainingWaitMs);</span><br><span class="line"><span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">    log.trace(<span class="string">"Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch"</span>, record.topic(), partition);</span><br><span class="line">    <span class="keyword">this</span>.sender.wakeup();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> result.future;</span><br></pre></td></tr></table></figure><p>首先思考下缓存区的数据结构是什么：每一个分区都有一个先进先出的队列，，而kafka真正使用的是一个双端队列</p><p>RecordAccumulator为topic的每一个分区都创建了一个ArrayDeque(thread unsafe)，里面存放的元素是ProducerBatch，它就是待批量发送的消息。<br>kafka使用一个CopyOnWriteMap保存分区和队列的关系，即只有在修改该map时把内容Copy出去形成一个新的map，然后配合volatile改变引用，这也是COW机制的常见用法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ConcurrentMap&lt;TopicPartition, Deque&lt;ProducerBatch&gt;&gt; batches = <span class="keyword">new</span> CopyOnWriteMap&lt;&gt;();</span><br></pre></td></tr></table></figure><p>该map的模型如下<br><img src="https://ae01.alicdn.com/kf/H409e050f5b184f7ebad5ecc5f12d9e41V.png" alt="模型"></p><p>append方法返回一个RecordAppendResult，它是消息在添加进内存缓冲区后的结果：Deque队列中是否有元素，是否有新的ProducerBatch创建，两个条件都可以去通知sender线程发送消息</p><p>这里的代码看似很多，其实并不难，我们还是逐步分析下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> RecordAppendResult <span class="title">append</span><span class="params">(TopicPartition tp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">long</span> timestamp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">byte</span>[] key,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">byte</span>[] value,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 Header[] headers,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 Callback callback,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">long</span> maxTimeToBlock)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    <span class="comment">// We keep track of the number of appending thread to make sure we do not miss batches in</span></span><br><span class="line">    <span class="comment">// abortIncompleteBatches().</span></span><br><span class="line">    appendsInProgress.incrementAndGet();</span><br><span class="line">    ByteBuffer buffer = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (headers == <span class="keyword">null</span>) headers = Record.EMPTY_HEADERS;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// check if we have an in-progress batch</span></span><br><span class="line">        Deque&lt;ProducerBatch&gt; dq = getOrCreateDeque(tp);</span><br><span class="line">        <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">            <span class="keyword">if</span> (closed)</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"Producer closed while send in progress"</span>);</span><br><span class="line">            RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq);</span><br><span class="line">            <span class="keyword">if</span> (appendResult != <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">return</span> appendResult;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// batch.size默认是16KB，但是即使超出也没事，通过Math.max函数取了二者最大值</span></span><br><span class="line">        <span class="comment">// we don't have an in-progress record batch try to allocate a new batch</span></span><br><span class="line">        <span class="keyword">byte</span> maxUsableMagic = apiVersions.maxUsableProduceMagic();</span><br><span class="line">        <span class="keyword">int</span> size = Math.max(<span class="keyword">this</span>.batchSize, AbstractRecords.estimateSizeInBytesUpperBound(maxUsableMagic, compression, key, value, headers));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 这里在申请ByteBuffer缓存空间了</span></span><br><span class="line">        buffer = free.allocate(size, maxTimeToBlock);</span><br><span class="line">        <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">            <span class="comment">// Need to check if producer is closed again after grabbing the dequeue lock.</span></span><br><span class="line">            <span class="comment">// 我暂时没看懂意图，大概意思是在极端情况下，检查线程在获取到dequeue锁之后，producer又关闭</span></span><br><span class="line">            <span class="keyword">if</span> (closed)</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"Producer closed while send in progress"</span>);</span><br><span class="line"></span><br><span class="line">            RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq);</span><br><span class="line">            <span class="keyword">if</span> (appendResult != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="comment">// 万一这个时候又有了可用的ProducerBatch呢，我们就不用新建了呀，唉~这就很舒服</span></span><br><span class="line">                <span class="comment">// Somebody else found us a batch, return the one we waited for! Hopefully this doesn't happen often...</span></span><br><span class="line">                <span class="keyword">return</span> appendResult;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 初始化MemoryRecordsBuilder，初始化DataOutputStream appendStream关键对象</span></span><br><span class="line">            MemoryRecordsBuilder recordsBuilder = recordsBuilder(buffer, maxUsableMagic);</span><br><span class="line">            <span class="comment">// 新建一个ProducerBatch</span></span><br><span class="line">            ProducerBatch batch = <span class="keyword">new</span> ProducerBatch(tp, recordsBuilder, time.milliseconds());</span><br><span class="line">            <span class="comment">// 写入消息到appendStream关键对象</span></span><br><span class="line">            FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, headers, callback, time.milliseconds()));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 然后添加到队列尾部</span></span><br><span class="line">            dq.addLast(batch);</span><br><span class="line">            <span class="comment">// incomplete对象就是个Set&lt;ProducerBatch&gt;, 用来保存还没有发送完成的，包括还没发送的</span></span><br><span class="line">            incomplete.add(batch);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// Don't deallocate this buffer in the finally block as it's being used in the record batch</span></span><br><span class="line">            <span class="comment">// 释放buffer资源，因为是HeapByteBuffer，等待GC回收即可</span></span><br><span class="line">            buffer = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 返回结果</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> RecordAppendResult(future, dq.size() &gt; <span class="number">1</span> || batch.isFull(), <span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (buffer != <span class="keyword">null</span>)</span><br><span class="line">            free.deallocate(buffer);</span><br><span class="line">        appendsInProgress.decrementAndGet();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面截取部分调用的代码进行讲解</p><h4 id="创建队列"><a href="#创建队列" class="headerlink" title="创建队列"></a>创建队列</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Get the deque for the given topic-partition, creating it if necessary.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> Deque&lt;ProducerBatch&gt; <span class="title">getOrCreateDeque</span><span class="params">(TopicPartition tp)</span> </span>&#123;</span><br><span class="line">    Deque&lt;ProducerBatch&gt; d = <span class="keyword">this</span>.batches.get(tp);</span><br><span class="line">    <span class="keyword">if</span> (d != <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">return</span> d;</span><br><span class="line">    d = <span class="keyword">new</span> ArrayDeque&lt;&gt;();</span><br><span class="line">    Deque&lt;ProducerBatch&gt; previous = <span class="keyword">this</span>.batches.putIfAbsent(tp, d);</span><br><span class="line">    <span class="keyword">if</span> (previous == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">return</span> d;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> previous;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从<code>ConcurrentMap&lt;TopicPartition, Deque&lt;ProducerBatch&gt;&gt; batches</code>中获取该主题分区对应的队列,如果不为空说明已经有了，直接返回，否者创建一个新的ArrayDeque，并放到map中，方便下次使用，<br>至于putIfAbsent方法，就是map中之前没有这个key，插入并返回新value，已经有了，就返回之前的value，即Deque</p><h4 id="RecordAccumulator-tryAppend方法源码："><a href="#RecordAccumulator-tryAppend方法源码：" class="headerlink" title="RecordAccumulator#tryAppend方法源码："></a>RecordAccumulator#tryAppend方法源码：</h4><p>其实文档写的很清楚了，就是把消息追加到最后一个ProducerBatch中，但要是队列中一个都没有呢？ 很简单，直接返回null，在外层方法中会判断不为null在结束，否则会分配<br>吐槽下：一开始就看岔了，好几个tryAppend，如果是我，我会写成tryAppendInternal之类的方法名<br>RecordAppendResult构造方法的最后一个参数表示是否是新建的ProducerBatch，这里返回时也确实返回了false<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *  Try to append to a ProducerBatch.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *  If it is full, we return null and a new batch is created. We also close the batch for record appends to free up</span></span><br><span class="line"><span class="comment"> *  resources like compression buffers. The batch will be fully closed (ie. the record batch headers will be written</span></span><br><span class="line"><span class="comment"> *  and memory records built) in one of the following cases (whichever comes first): right before send,</span></span><br><span class="line"><span class="comment"> *  if it is expired, or when the producer is closed.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> RecordAppendResult <span class="title">tryAppend</span><span class="params">(<span class="keyword">long</span> timestamp, <span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value, Header[] headers,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     Callback callback, Deque&lt;ProducerBatch&gt; deque)</span> </span>&#123;</span><br><span class="line">    ProducerBatch last = deque.peekLast();</span><br><span class="line">    <span class="keyword">if</span> (last != <span class="keyword">null</span>) &#123;</span><br><span class="line">        FutureRecordMetadata future = last.tryAppend(timestamp, key, value, headers, callback, time.milliseconds());</span><br><span class="line">        <span class="keyword">if</span> (future == <span class="keyword">null</span>)</span><br><span class="line">            last.closeForRecordAppends();</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> RecordAppendResult(future, deque.size() &gt; <span class="number">1</span> || last.isFull(), <span class="keyword">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="ProducerBatch-tryAppend"><a href="#ProducerBatch-tryAppend" class="headerlink" title="ProducerBatch#tryAppend"></a>ProducerBatch#tryAppend</h3><p>注：一定注意和上面的同名方法的区分</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> FutureRecordMetadata <span class="title">tryAppend</span><span class="params">(<span class="keyword">long</span> timestamp, <span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value, Header[] headers, Callback callback, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!recordsBuilder.hasRoomFor(timestamp, key, value, headers)) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        Long checksum = <span class="keyword">this</span>.recordsBuilder.append(timestamp, key, value, headers);</span><br><span class="line">        <span class="keyword">this</span>.maxRecordSize = Math.max(<span class="keyword">this</span>.maxRecordSize, AbstractRecords.estimateSizeInBytesUpperBound(magic(),</span><br><span class="line">                recordsBuilder.compressionType(), key, value, headers));</span><br><span class="line">        <span class="keyword">this</span>.lastAppendTime = now;</span><br><span class="line">        FutureRecordMetadata future = <span class="keyword">new</span> FutureRecordMetadata(<span class="keyword">this</span>.produceFuture, <span class="keyword">this</span>.recordCount,</span><br><span class="line">                                                               timestamp, checksum,</span><br><span class="line">                                                               key == <span class="keyword">null</span> ? -<span class="number">1</span> : key.length,</span><br><span class="line">                                                               value == <span class="keyword">null</span> ? -<span class="number">1</span> : value.length);</span><br><span class="line">        <span class="comment">// we have to keep every future returned to the users in case the batch needs to be</span></span><br><span class="line">        <span class="comment">// split to several new batches and resent.</span></span><br><span class="line">        thunks.add(<span class="keyword">new</span> Thunk(callback, future));</span><br><span class="line">        <span class="keyword">this</span>.recordCount++;</span><br><span class="line">        <span class="keyword">return</span> future;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="具体写入过程"><a href="#具体写入过程" class="headerlink" title="具体写入过程"></a>具体写入过程</h4><p>recordsBuilder.append的主要实现过程如下：<br>首先key，value都会包装成ByteBuffer，写入时都是先写长度，再写内容<br>key，value，headers都写入DataOutputStream appendStream流对象中，返回写入的长度</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Write the record to `out` and return its size.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">writeTo</span><span class="params">(DataOutputStream out,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">int</span> offsetDelta,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">long</span> timestampDelta,</span></span></span><br><span class="line"><span class="function"><span class="params">                          ByteBuffer key,</span></span></span><br><span class="line"><span class="function"><span class="params">                          ByteBuffer value,</span></span></span><br><span class="line"><span class="function"><span class="params">                          Header[] headers)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> sizeInBytes = sizeOfBodyInBytes(offsetDelta, timestampDelta, key, value, headers);</span><br><span class="line">    ByteUtils.writeVarint(sizeInBytes, out);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">byte</span> attributes = <span class="number">0</span>; <span class="comment">// there are no used record attributes at the moment</span></span><br><span class="line">    out.write(attributes);</span><br><span class="line"></span><br><span class="line">    ByteUtils.writeVarlong(timestampDelta, out);</span><br><span class="line">    ByteUtils.writeVarint(offsetDelta, out);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (key == <span class="keyword">null</span>) &#123;</span><br><span class="line">        ByteUtils.writeVarint(-<span class="number">1</span>, out);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">int</span> keySize = key.remaining();</span><br><span class="line">        ByteUtils.writeVarint(keySize, out);</span><br><span class="line">        Utils.writeTo(out, key, keySize);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (value == <span class="keyword">null</span>) &#123;</span><br><span class="line">        ByteUtils.writeVarint(-<span class="number">1</span>, out);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">int</span> valueSize = value.remaining();</span><br><span class="line">        ByteUtils.writeVarint(valueSize, out);</span><br><span class="line">        Utils.writeTo(out, value, valueSize);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (headers == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Headers cannot be null"</span>);</span><br><span class="line"></span><br><span class="line">    ByteUtils.writeVarint(headers.length, out);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (Header header : headers) &#123;</span><br><span class="line">        String headerKey = header.key();</span><br><span class="line">        <span class="keyword">if</span> (headerKey == <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Invalid null header key found in headers"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">byte</span>[] utf8Bytes = Utils.utf8(headerKey);</span><br><span class="line">        ByteUtils.writeVarint(utf8Bytes.length, out);</span><br><span class="line">        out.write(utf8Bytes);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">byte</span>[] headerValue = header.value();</span><br><span class="line">        <span class="keyword">if</span> (headerValue == <span class="keyword">null</span>) &#123;</span><br><span class="line">            ByteUtils.writeVarint(-<span class="number">1</span>, out);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            ByteUtils.writeVarint(headerValue.length, out);</span><br><span class="line">            out.write(headerValue);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ByteUtils.sizeOfVarint(sizeInBytes) + sizeInBytes;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="append方法小结"><a href="#append方法小结" class="headerlink" title="append方法小结"></a>append方法小结</h3><p>append方法的具体实现过程还是很复杂的，这里说下笔者对这个过程的理解：</p><ol><li>尝试获取该TopicPartition下的队列，如果没有则创建</li><li>获取队列的最后一个ProducerBatch元素，将消息添加至该ProducerBatch，该过程会对Deque加锁</li><li>如果队列里没有ProducerBatch，或是最后一个ProducerBatch已经满了，就需要新建一个ProducerBatch</li><li>分配一个ByteBuffer空间，该空间大小在batch.size和消息大小中取较大值</li><li>再重新尝试步骤2一次，万一这时候刚好又有了呢(这时候Deque已经释放锁了)</li><li>创建好ProducerBatch之后，继续尝试append，添加成功之后将future和callback放入一个Thunk对象中，并且添加到一个List<thunk>集合，这是因为一批消息需要发送之后才有回调，所以先把回调统一放入一个集合中</thunk></li><li>添加成功之后，返回future对象，将ProducerBatch添加至Deque队列，同时用一个集合IncompleteBatches持有住了ProducerBatch</li><li>清理buffer空间，封装RecordAppendResult结果：Deque队列大小，新建的ProducerBatch对象是否已满</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>kafka发送消息的步骤大致如下：</p><ol><li>获取broker上的元信息</li><li>key, value的序列化</li><li>计算分区</li><li>添加到缓存区<ol><li>获取该分区对应的队列</li><li>尝试添加</li><li>如果添加成功返回</li></ol></li></ol>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka生产者源码浅析(一)</title>
      <link href="/2019/10/16/Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90(%E4%B8%80)/"/>
      <url>/2019/10/16/Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90(%E4%B8%80)/</url>
      <content type="html"><![CDATA[<h1 id="Kafka生产者源码浅析-一"><a href="#Kafka生产者源码浅析-一" class="headerlink" title="Kafka生产者源码浅析(一)"></a>Kafka生产者源码浅析(一)</h1><blockquote><p>本文并没有直接使用原生的kafka-client，而是spring-kafka，版本为2.2.3.RELEASE。在当前以Spring-boot为首的潮流中，有必要学习Spring是如何集成kafka客户端的</p></blockquote><h1 id="send方法"><a href="#send方法" class="headerlink" title="send方法"></a>send方法</h1><p>以KafkaTemplate#send方法为入口，使用debug方式跟进源码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; send(String topic, K key, <span class="meta">@Nullable</span> V data) &#123;</span><br><span class="line">  ProducerRecord&lt;K, V&gt; producerRecord = <span class="keyword">new</span> ProducerRecord&lt;&gt;(topic, key, data);</span><br><span class="line">  <span class="keyword">return</span> doSend(producerRecord);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里将消息封装为ProducerRecord对象，这是kafka-client原生对象，接下来进行发送操作<br>在doSend方法中，有很多事务相关，日志相关的代码，我们的目的是理清楚主流程，因此省略</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 省略部分代码 ... </span></span><br><span class="line"><span class="keyword">protected</span> ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; doSend(<span class="keyword">final</span> ProducerRecord&lt;K, V&gt; producerRecord) &#123;</span><br><span class="line">  <span class="keyword">final</span> Producer&lt;K, V&gt; producer = getTheProducer();</span><br><span class="line">  <span class="keyword">final</span> SettableListenableFuture&lt;SendResult&lt;K, V&gt;&gt; future = <span class="keyword">new</span> SettableListenableFuture&lt;&gt;();</span><br><span class="line">  producer.send(producerRecord, buildCallback(producerRecord, producer, future));</span><br><span class="line">  <span class="keyword">return</span> future;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到首先通过getTheProducer获取生产者对象，那么Spring-kafka是如何创建该对象的呢？</p><h2 id="构建生产者"><a href="#构建生产者" class="headerlink" title="构建生产者"></a>构建生产者</h2><p>代码只有一行，通过DefaultKafkaProducerFactory创建生产者<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Producer&lt;K, V&gt; <span class="title">getTheProducer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 省略部分代码 ...</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.producerFactory.createProducer();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>进入到DefaultKafkaProducerFactory#createProducer</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Producer&lt;K, V&gt; <span class="title">createProducer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span>.producer == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (<span class="keyword">this</span>.producer == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">this</span>.producer = <span class="keyword">new</span> CloseSafeProducer&lt;K, V&gt;(createKafkaProducer());</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">this</span>.producer;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们知道kafka生产者是单例并且线程安全的，这里spring使用double-check构建了一个CloseSafeProducer对象，而它被volatile修饰，经典的懒汉单例模式<br>平常我们使用的都是KafkaProducer，这个CloseSafeProducer又是什么呢？<br>该类实现了Producer接口，这也是KafkaProducer的父接口，细心的同学发现了CloseSafeProducer在创建是调用了createKafkaProducer方法，该方法源码如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> Producer&lt;K, V&gt; <span class="title">createKafkaProducer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> KafkaProducer&lt;K, V&gt;(<span class="keyword">this</span>.configs, <span class="keyword">this</span>.keySerializer, <span class="keyword">this</span>.valueSerializer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>坑爹呢这是，这个不还是KafkaProducer对象吗，那么传入一个KafkaProducer是要干吗，对装饰者模式和代理模式熟悉的同学已经明白是怎么回事，spring也确实这样做的：具体功能实现都委托给KafkaProducer对象实现，spring对记录事务id等日志信息做了增强</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">CloseSafeProducer</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Producer</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Producer&lt;K, V&gt; delegate;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> BlockingQueue&lt;CloseSafeProducer&lt;K, V&gt;&gt; cache;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Consumer&lt;CloseSafeProducer&lt;K, V&gt;&gt; removeConsumerProducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> String txId;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> txFailed;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>CloseSafeProducer的分析至此结束，在获取到包装后的KafkaProducer后，便是发送流程了</p><h2 id="消息发送"><a href="#消息发送" class="headerlink" title="消息发送"></a>消息发送</h2><p>回到doSend方法，发送的代码只有两行<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 省略部分代码...</span></span><br><span class="line"><span class="keyword">protected</span> ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; doSend(<span class="keyword">final</span> ProducerRecord&lt;K, V&gt; producerRecord) &#123;</span><br><span class="line">  <span class="keyword">final</span> Producer&lt;K, V&gt; producer = getTheProducer();</span><br><span class="line">  <span class="keyword">final</span> SettableListenableFuture&lt;SendResult&lt;K, V&gt;&gt; future = <span class="keyword">new</span> SettableListenableFuture&lt;&gt;();</span><br><span class="line">  producer.send(producerRecord, buildCallback(producerRecord, producer, future));</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span>.autoFlush) &#123;</span><br><span class="line">    flush();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> future;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 省略部分代码...</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> Callback <span class="title">buildCallback</span><span class="params">(<span class="keyword">final</span> ProducerRecord&lt;K, V&gt; producerRecord, <span class="keyword">final</span> Producer&lt;K, V&gt; producer,</span></span></span><br><span class="line"><span class="function"><span class="params">      <span class="keyword">final</span> SettableListenableFuture&lt;SendResult&lt;K, V&gt;&gt; future)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> (metadata, exception) -&gt; &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (exception == <span class="keyword">null</span>) &#123;</span><br><span class="line">        future.set(<span class="keyword">new</span> SendResult&lt;&gt;(producerRecord, metadata));</span><br><span class="line">        <span class="keyword">if</span> (KafkaTemplate.<span class="keyword">this</span>.producerListener != <span class="keyword">null</span>) &#123;</span><br><span class="line">          KafkaTemplate.<span class="keyword">this</span>.producerListener.onSuccess(producerRecord, metadata);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">else</span> &#123;</span><br><span class="line">        future.setException(<span class="keyword">new</span> KafkaProducerException(producerRecord, <span class="string">"Failed to send"</span>, exception));</span><br><span class="line">        <span class="keyword">if</span> (KafkaTemplate.<span class="keyword">this</span>.producerListener != <span class="keyword">null</span>) &#123;</span><br><span class="line">          <span class="comment">// producerListener 默认是LoggingProducerListener，仅在错误是打印日志</span></span><br><span class="line">          KafkaTemplate.<span class="keyword">this</span>.producerListener.onError(producerRecord, exception);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (!KafkaTemplate.<span class="keyword">this</span>.transactional) &#123;</span><br><span class="line">        closeProducer(producer, <span class="keyword">false</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>SettableListenableFuture是一个可设置，可监听的Future对象，用它构建异步发送消息后的Callback对象，大家可以认为Spring使用SettableListenableFuture对象对返回结果和异常进行了封装，Callback的作用在下文揭晓。</p><p>ListenableFuture同样的也可以添加回调函数,使用方法如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ListenableFuture future = kafkaTemplate.send(record);</span><br><span class="line">future.addCallback(result -&gt; &#123;</span><br><span class="line">    System.out.println(result);</span><br><span class="line">&#125;, error-&gt;&#123;</span><br><span class="line">    System.out.println(error);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p><p>接着send方法由CloseSafeProducer委托给KafkaProducer执行，KafkaProducer的send方法如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// intercept the record, which can be potentially modified; this method does not throw exceptions</span></span><br><span class="line">    ProducerRecord&lt;K, V&gt; interceptedRecord = <span class="keyword">this</span>.interceptors.onSend(record);</span><br><span class="line">    <span class="keyword">return</span> doSend(interceptedRecord, callback);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ProducerInterceptor通过for循环遍历依次执行<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 省略部分代码...</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ProducerRecord&lt;K, V&gt; <span class="title">onSend</span><span class="params">(ProducerRecord&lt;K, V&gt; record)</span> </span>&#123;</span><br><span class="line">    ProducerRecord&lt;K, V&gt; interceptRecord = record;</span><br><span class="line">    <span class="keyword">for</span> (ProducerInterceptor&lt;K, V&gt; interceptor : <span class="keyword">this</span>.interceptors) &#123;</span><br><span class="line">      interceptRecord = interceptor.onSend(interceptRecord);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> interceptRecord;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>send方法的官方文档翻译如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">异步发送一条消息到一个topic，并且在应答之后立即调用已提供的回调</span><br><span class="line">发送是异步的，一旦消息存储到了等待发送的缓冲区，该方法会立即返回。这样就不用阻塞在等待每一次发送消息的响应，允许并行的发送大量消息。</span><br><span class="line">发送后的结果对象RecordMetadata具体说明了消息被发送到了哪个分区，被分配的位移和时间戳。</span><br><span class="line">如果topic使用了TimestampType#CREATE_TIME，那么使用用户指定的时间，如果未指定，则使用发送时间。</span><br><span class="line">如果使用了TimestampType#LOG_APPEND_TIME，则使用消息在broker端追加到日志的时间</span><br><span class="line">send方法会为RecordMetadata对象返回一个Future对象，调用Future#get将会阻塞到请求完成，返回消息的元数据，或者返回在发送请求期间的任何异常</span><br><span class="line">如果你想模拟一下，你可以send之后立即调用get</span><br><span class="line">producer.send(record).get()</span><br><span class="line">完全非阻塞的用法是用Callback参数来提供一个回调，它将在请求结束之后被调用</span><br><span class="line">producer.send(myRecord, <span class="keyword">new</span> Callback()&#123;...&#125;)</span><br><span class="line"></span><br><span class="line">Callback将在producer的I/O线程中触发，所以它必须轻量，快速，否则其他线程的消息会延迟发送。如果你在Callback中有耗时的逻辑处理，建议使用你自己的Executor，在Callback体中并发的执行</span><br></pre></td></tr></table></figure></p><p>Spring同样支持同步和异步，将结果和异常都保存在了SettableListenableFuture中<br>这里再提一下Callback和Producerinterceptor的使用</p><h3 id="Callback"><a href="#Callback" class="headerlink" title="Callback"></a>Callback</h3><p>这里提一下Callback类，这是一个函数式接口，仅有一个onCompletion方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span></span>;</span><br></pre></td></tr></table></figure></p><p>两个参数分别为成功之后的消息元数据对象，和失败之后的异常对象，两者总是只有一个不为空(要么成功，要么失败)，而Exception分为两类异常：可重试异常，不可重试异常<br>可重试</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CorruptRecordException</span><br><span class="line">InvalidMetadataException</span><br><span class="line">NotEnoughReplicasAfterAppendException</span><br><span class="line">NotEnoughReplicasException</span><br><span class="line">OffsetOutOfRangeException</span><br><span class="line">TimeoutException</span><br><span class="line">UnknownTopicOrPartitionException</span><br></pre></td></tr></table></figure><p>不可重试<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">InvalidTopicException</span><br><span class="line">OffsetMetadataTooLargeException</span><br><span class="line">RecordBatchTooLargeException</span><br><span class="line">RecordTooLargeException</span><br><span class="line">UnknownServerException</span><br></pre></td></tr></table></figure></p><p>可重试异常都继承自RetriableException，常见的判断方式如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(e <span class="keyword">instanceof</span> RetriableException)&#123;</span><br><span class="line">    ...</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="拦截器"><a href="#拦截器" class="headerlink" title="拦截器"></a>拦截器</h3><p>在发送消息之前，开发者都可以自定义拦截器，实现Producerinterceptor即可<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 每条消息发送之前调用</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ProducerRecord&lt;K, V&gt; <span class="title">onSend</span><span class="params">(ProducerRecord&lt;K, V&gt; record)</span></span>;</span><br><span class="line"><span class="comment">//发送请求应答之后调用</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onAcknowledgement</span><span class="params">(RecordMetadata metadata, Exception exception)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure></p><h4 id="添加拦截器"><a href="#添加拦截器" class="headerlink" title="添加拦截器"></a>添加拦截器</h4><p>kafka原生配置方式</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">List&lt;String&gt; interceptors = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">interceptors.add(<span class="string">"your class"</span>); </span><br><span class="line">props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);</span><br></pre></td></tr></table></figure><p>在spring-kafka中配置更加简单<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spring.kafka.producer.properties.interceptor.classes=your class</span><br></pre></td></tr></table></figure></p><h3 id="消息发送-doSend"><a href="#消息发送-doSend" class="headerlink" title="消息发送(doSend)"></a>消息发送(doSend)</h3><p>经过拦截器拦截后，发送消息的流程又是如何呢</p><p><img src="https://ae01.alicdn.com/kf/H0d7dcdd1533945eda1d032ad9b7b7c5e8.png" alt="发送流程"></p><p>上图摘自胡夕老师的《Apache kafka实战》，十分形象的描绘了消息发送流程，正如上图所示，doSend方法只有有一个入参ProducerRecord，用于封装消息，一个出参RecordMetadata，它是broker应答之后的返回信息。二者的源码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// key长度，value长度可计算</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerRecord</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Integer partition;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Headers headers;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> K key;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> V value;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Long timestamp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">RecordMetadata</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> offset;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> timestamp;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> serializedKeySize;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> serializedValueSize;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> TopicPartition topicPartition;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> Long checksum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里提一下ProducerRecord的timestamp，取决于message.timestamp.type的配置<br>CreateTime：客户端发送消息时的时间戳，默认值。<br>LogAppendTime：消息在broker追加日志时的时间戳。</p><h4 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h4><p>为了便于理解接下来的流程，有几个类需要为大家介绍清楚</p><p>在KafkaProducer的构造函数中初始化了以下几个关键类，有兴趣的读者可自行研究，可省略JMX和事务相关的内容</p><ul><li><p>Partitioner：分区选择器，你要发送的这条消息应该分配到哪个分区？</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">this</span>.partitioner = </span><br><span class="line">        config.getConfiguredInstance(ProducerConfig.PARTITIONER_CLASS_CONFIG,Partitioner.class);</span><br></pre></td></tr></table></figure></li><li><p>KafkaClient：用于和broker做网络交互的客户端</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KafkaClient client = kafkaClient != null ? kafkaClient : new NetworkClient(...);</span><br></pre></td></tr></table></figure></li><li><p>Sender：用于批量发送消息的I/O线程，也称sender线程</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">this</span>.sender = <span class="keyword">new</span> Sender(...);</span><br></pre></td></tr></table></figure><p>sender.wakeup()的作用是：消息达到了batch.size了，起来干活</p></li><li><p>KafkaThread：继承了Thread，构造函数可以传入线程名，和设置守护线程</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">this</span>.ioThread = <span class="keyword">new</span> KafkaThread(ioThreadName, <span class="keyword">this</span>.sender, <span class="keyword">true</span>);</span><br><span class="line"><span class="keyword">this</span>.ioThread.start();</span><br></pre></td></tr></table></figure></li><li><p>RecordAccumulator：消息累加器，其实也就是常说的消息的内存缓冲区</p></li></ul><p>在前期基本工作做好后，kafka便可以开始发送了，发送过程比较复杂，首先要获取broker端集群信息，broker到底是个什么情况，地址是什么，有几台服务器，里面已有的topic，topic已有的分区，分区在broker的分布，ISR列表，OLR列表等等信息，这些都是发送之前要关心的</p><ul><li>Metadata：这些元信息都封装在了Metadata类中，Metadata还负责这些元信息的缓存及刷新</li><li><p>Cluster: Metadata中持有一个Cluster对象，kafka每一个broker都保存了topic的leader副本分区信息，producer只需要随机向一个broker发送请求就可以获取获取到，同时该对象还有每一个kafka broker节点的元信息，如ip端口等</p></li><li><p>TopicPartition：将topic和计算好的分区封装到一起</p></li><li>InterceptorCallback：如果没有拦截器，它就是Callback回调</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本来文章主要介绍了spring对kafka-client生产者做了哪些封装，spring使用ProducerFactory来创建KafkaProducer对象，将其传给CloseSafeProducer作为委托对象<br>ListenableFuture作为send方法的返回值，在buildCallback方法中对Kafka原生的Callback做了封装，并加入了spring自己的producerListener</p><p>本文至此结束，剥离spring的封装，接下来发送的具体源码将在下文揭晓</p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 消息 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SpringMVC源码分析</title>
      <link href="/2019/10/05/SpringMVC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2019/10/05/SpringMVC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      <content type="html"><![CDATA[<blockquote><p>曾经debug了一次SpringMVC的源码，但是平时比较忙(lan)，一直没有放在博客上，现在忙里偷闲整理上来</p></blockquote><h1 id="DispatcherServlet-doDispatch方法分析"><a href="#DispatcherServlet-doDispatch方法分析" class="headerlink" title="DispatcherServlet#doDispatch方法分析"></a>DispatcherServlet#doDispatch方法分析</h1><p>查找HandlerExecutionChain，它的名称为mappedHandler</p><p><img src="https://ae01.alicdn.com/kf/H16c856f002a54ed2978dc4b1d33f2a6bD.png" alt=""></p><p>遍历HandlerMapping集合handlerMappings, 根据HandlerMapping的getHandler方法查找HandlerExecutionChain</p><p><img src="https://ae01.alicdn.com/kf/H67d3c69356214afa9c0e7c328d1badedW.png" alt=""></p><p>HandlerMapping 接口的实现类AbstractHandlerMapping提供getHandler方法</p><p><img src="https://ae01.alicdn.com/kf/H71b8c8a53ce94783a7c9b8a34676915e3.png" alt=""></p><p>HandlerMapping，AbstractHandlerMapping和AbstractHandlerMethodMapping三者之间的关系如下</p><p><img src="https://ae01.alicdn.com/kf/Hc152e4b7c20e433b8cc4a74a3935115ef.png" alt=""></p><p>其主要实现流程如下：<br>1&gt; 依靠getHandlerInternal方法获取对应的handler，handler指的就是Controller类中的方法，它处理接口请求<br>该方法由AbstractHandlerMapping 的子类AbstractHandlerMethodMapping提供</p><p><img src="https://ae01.alicdn.com/kf/H3025ea329acb4328a6415047a3da6a6fD.png" alt=""></p><p>2&gt; 由lookupHandlerMethod方法查找HandlerMethod</p><p><img src="https://ae01.alicdn.com/kf/Hbe25bad47d0845d98b9f659464346fa8N.png" alt=""></p><p>找到合适的HandlerMethod并组装成一个Match对象，包装了url，请求方式和HandlerMethod对象</p><p><img src="https://ae01.alicdn.com/kf/H7fc9dfd40f724de6b0ed432a0d9e017fA.png" alt=""></p><p>MappingRegistry中的<em>mappingLookup</em>是所有url和HandlerMethod的映射关系，最终组成了Match对象，如果发现有多个就取第一个作为bestMatch，并返回HandlerMethod</p><p><img src="https://ae01.alicdn.com/kf/Ha2630f9cebab45678ef9e84e6247eff7e.png" alt=""></p><p>3&gt; getHandlerInternal方法的最后，createWithResolvedBean方法是在初始化HandlerMethod中的Handler，它定义为Object bean，如果是String类型，就从BeanFactory中获取，最后（new HandlerMethod(this,handler)</p><p>getHandler方法执行完getHandlerInternal获取到HandlerMethod之后，获取HandlerExecutionChain<br><code>HandlerExecutionChain executionChain = getHandlerExecutionChain(handler, request)</code>，</p><p>getHandlerExecutionChain在HandlerExecutionChain里填充了所有的HandlerInterceptor</p><h1 id="继续doDispatch"><a href="#继续doDispatch" class="headerlink" title="继续doDispatch"></a>继续doDispatch</h1><p>找到HandlerExecutionChain后，然后查找HandlerAdapter，实现抽象类为AbstractHandlerMethodAdapter<br><img src="https://ae01.alicdn.com/kf/Hb81c2ffa03154ba09a88839a6e2e357eh.png" alt=""><br>接下来判断请求方式为GET或HEAD，满足<em>Last-Modified</em>的请求直接返回<br>前文提到过HandlerExecutionChain里包含了所有的HandlerInterceptor，HandlerExecutionChain的applyPreHandle方法用于执行每个HandlerInterceptor的preHandle方法<br>如果有一个没通过，返回了false，同时出发afterCompletion，那么整个请求结束<br>最后HandlerAdapter的实现类RequestMappingHandlerAdapter调用handle开始处理请求，注释里也说明了”真正开始调用handler“</p><p>HandlerAdapter类图如下<br><img src="https://ae01.alicdn.com/kf/Hac81cd901f654da69db0976c91765d6fw.png" alt=""><br>HandlerAdapter ha调用handle的流程如下，核心处理过程在其子类RequestMappingHandlerAdapter的handleInternal方法中调用的invokeHandlerMethod中(红框处)<br><img src="https://ae01.alicdn.com/kf/H14d4d6d09b8d4716ad79def79ddd48d3D.png" alt=""><br><img src="https://ae01.alicdn.com/kf/Hcfc0a4cb73f24d6ea49d169831f5c2dbx.png" alt=""><br><img src="https://ae01.alicdn.com/kf/Ha5a165c031ff4de897937582f4e25dbd8.png" alt=""></p><h2 id="invokeHandlerMethod方法解析"><a href="#invokeHandlerMethod方法解析" class="headerlink" title="invokeHandlerMethod方法解析"></a>invokeHandlerMethod方法解析</h2><p><img src="https://ae01.alicdn.com/kf/H870bfbf42e454aa9aafb69c8d7fbe459A.png" alt=""></p><p>invokeHandlerMethod的方法很长，但重点关注红框内的代码,首先HandlerMethod类图的某一条类分支如下</p><p><img src="https://ae01.alicdn.com/kf/H4b768a2b8d0b4806b3c6c9a277759ae2A.png" alt=""></p><p>InvocableHandlerMethod翻译为可调用的HandlerMethod，里面有三个字段</p><ol><li>WebDataBinderFactory： 用于创建 WebDataBinder的工厂，而WebDataBinder主要用于请求数据和方法参数的绑定</li><li>HandlerMethodArgumentResolverComposite：一组HandlerMethodArgumentResolver的集合，HandlerMethodArgumentResolver主要用于参数解析</li><li>ParameterNameDiscoverer：用于获取方法或者构造方法的参数名称(很有意思的东西，普通反射等手段是获取不到的)</li></ol><p>ServletInvocableHandlerMethod:多了个HandlerMethodReturnValueHandlerComposite，里面是一组HandlerMethodReturnValueHandler，而HandlerMethodReturnValueHandler用于处理返回值</p><p>第二处红框内的ServletInvocableHandlerMethod invocableMethod.invokeAndHandle(webRequest, mavContainer) 方法为入口<br>第一行代码就已经处理结束，获取了返回值，可以预料它的处理过程很长，注意上层没有providedArgs参数<br><img src="https://ae01.alicdn.com/kf/H8230848f16fb403f907332bb61261ea8U.png" alt=""></p><p>而真正的调用过程都在ServletInvocableHandlerMethod的父类InvocableHandlerMethod中，过程只有两行代码，解析参数，调用方法，最后返回结果<br><img src="https://ae01.alicdn.com/kf/Hcc1af06c535c469b90a0cd21e322dac1I.png" alt=""></p><h2 id="参数解析"><a href="#参数解析" class="headerlink" title="参数解析"></a>参数解析</h2><p>承接上文，getMethodParameters请request中获取参数，那么具体过程是如何的呢<br><img src="https://ae01.alicdn.com/kf/H0cc6db5534574e20a2a71375af5e4cedM.png" alt=""></p><ol><li>首先MethodParameter是spring对方法参数的抽象封装， 可以理解为Method或者Constructor(二者共同父类为Executable) + Parameter，以及参数index，所在的class，参数类型，参数的泛型类型，参数的注解，参数名称</li><li>遍历参数数组，由于providedArgs为空，所以暂时忽略args[i] = resolveProvidedArgument(parameter, providedArgs);</li><li>判断是否可以解析这个参数，HandlerMethodArgumentResolver可以是多个，但是每个参数都有对应的Resolver解析，具体就由supportsParameter方法判断，前文提到HandlerMethodArgumentResolverComposite(即argumentResolvers)是一个HandlerMethodArgumentResolver集合，Composite的supportsParameter就是遍历里面的HandlerMethodArgumentResolver，通过Resolver的supportsParameter方法找到合适Resolver，如果找不到就说明不支持<br><img src="https://ae01.alicdn.com/kf/H30c46b35c7244e81b925361a300f5608F.png" alt=""><br><img src="https://ae01.alicdn.com/kf/H3e58404a2dd7408bb633d5123cbd96aaR.png" alt=""></li><li>resolveArgument也是在HandlerMethodArgumentResolverComposite中执行的<br> <code>args[i] = this.argumentResolvers.resolveArgument(parameter, mavContainer, request, *this*.*dataBinderFactory*);</code><br>视为过渡代码<br><img src="https://ae01.alicdn.com/kf/Hfb9706db3fb74f708636a8a40ad2fe4cN.png" alt=""></li></ol><p>接下来就是HandlerMethodArgumentResolver的解析了，其关键实现类为RequestResponseBodyMethodProcessor，它同时继承了ReturnValueHandler和ArgumentResolver接口，之后的很多地方都用到了它和它的Abstractxxx父类<br><img src="https://ae01.alicdn.com/kf/H9045100b3ee1498cadf9ae26a09db0dem.png" alt=""></p><p>RequestResponseBodyMethodProcessor解析过程如下，首先就是MessageConverters解析，这里spring用了三个readWithMessageConverters，看得我眼晕，吐槽<br><img src="https://ae01.alicdn.com/kf/H18b244aea3614aa3993484b20e0e9f83m.png" alt=""></p><p>第二个红框出的readWithMessageConverters是在RequestResponseBodyMethodProcessor的父类AbstractMessageConverterMethodArgumentResolver中<br>该方法有点长，只截取关键代码部分，简单来说就是遍历所有的messageConverter，根据messageConverter 的canRead方法判断是否要解析参数，然后根据getAdvice方法返回的RequestResponseBodyAdviceChain分别在解析前后执行<br>RequestResponseBodyAdviceChain比较简单，里面是一组RequestBodyAdvice集合和一组ResponseBodyAdvice集合，它们允许用户对请求参数和响应结果做修改(希望统一封装项目请求参数和返回值的童鞋看黑板)<br>最后返回的body就是方法参数对象<br><img src="https://ae01.alicdn.com/kf/H9381d3a466414d969964de3795b8bb44A.png" alt=""></p><p>获取到参数后，回到RequestResponseBodyMethodProcessor的resolveArgument方法，这里的arg就是刚才返回的body，然后我们要把这个Object绑定到Controller方法里的参数对象上去，绑定之前要通过JSR303校验，因此validateIfApplicable主要就是做校验的，如果校验不通过，BindingResult就会携带着异常抛出，请求结束<br><img src="https://ae01.alicdn.com/kf/H81e2c8aa48924025bd24721318885302v.png" alt=""></p><p>校验过程<br><img src="https://ae01.alicdn.com/kf/Hca013c6334704efcbbefa03bb25a93beY.png" alt=""></p><h3 id="调用"><a href="#调用" class="headerlink" title="调用"></a>调用</h3><p>当解析，校验，绑定参数完成之后，便可以开始调用方法了，InvocableHandlerMethod#invokeForRequest继续执行<br><img src="https://ae01.alicdn.com/kf/H5b71d02a027e4dd4923fc58f5d32cde17.png" alt=""><br>调用过程十分简单</p><ol><li>如果方法不是public，就先setAccessible(<em>true</em>)</li><li>通过反射执行方法，getBean() 返回的是Controller对象<br><img src="https://ae01.alicdn.com/kf/H3792b5c8d7a14038bdda3a619411f329m.png" alt=""></li></ol><p>ServletInvocableHandlerMethod#invokeAndHandle在调用完父类InvocableHandlerMethod的invokeForRequest方法后，开始处理返回结果<br><img src="https://ae01.alicdn.com/kf/He14f1031b43c4275b7f0502e60853b792.png" alt=""></p><p>返回结果由HandlerMethodReturnValueHandlerComposite 中某一个的HandlerMethodReturnValueHandler处理，根据supportsReturnType决定谁处理<br>然后发现还是交给了RequestResponseBodyMethodProcessor处理，因为它不仅是HandlerMethodArgumentResolver<br>还是HandlerMethodReturnValueHandler的实现类，也就是说解析参数，处理返回值的活都是它干的<br><img src="https://ae01.alicdn.com/kf/Hc6518f793c654369a1a417e3f0b3a71dB.png" alt=""><br><img src="https://ae01.alicdn.com/kf/H3da3d4369222482fa6674e59eefc05beb.png" alt=""></p><p>RequestResponseBodyAdviceChain中的ResponseBodyAdvice集合，根据各自的supports方法，判断要不要处理这个返回结果<br>然后再有真正的messageConverter处理，这里由AbstractGenericHttpMessageConverter#write<br>交给AbstractJackson2HttpMessageConverter#writeInternal做json序列化处理<br><img src="https://ae01.alicdn.com/kf/H3ec8bbe3dbde4c779d60354c83735b9dP.png" alt=""></p><h1 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h1><p>剩下的代码大部分都索然无味了，一路跳回到DispatcherServlet的doDispatch方法<br><img src="https://ae01.alicdn.com/kf/Had821ec5f1144629949b04a78dd6b6fdc.png" alt=""><br>这里执行了所有HandlerInterceptor的postHandle方法</p>]]></content>
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
            <tag> Spring 扩展 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ElasticSearch7.2 父子文档</title>
      <link href="/2019/09/27/ElasticSearch7-2-%E7%88%B6%E5%AD%90%E6%96%87%E6%A1%A3/"/>
      <url>/2019/09/27/ElasticSearch7-2-%E7%88%B6%E5%AD%90%E6%96%87%E6%A1%A3/</url>
      <content type="html"><![CDATA[<blockquote><p>写这篇文章的目的是为了帮助大家了解7.2版本中的父子文档，之前希望通过百度的博客快速了解一下，然而大失所望，建立索引的语法在7.2版本没有一个能通过，决定仔细看一遍<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.2/parent-join.html#_searching_with_parent_join" target="_blank" rel="noopener">官方文档</a></p></blockquote><h2 id="建立父-子文档语法"><a href="#建立父-子文档语法" class="headerlink" title="建立父-子文档语法"></a>建立父-子文档语法</h2><p>首先看一下如何建立父子文档，明显和网上”_parent”的方式不一样，说明es后期版本已经修改了语法<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">      &quot;my_join_field&quot;: &#123; </span><br><span class="line">        &quot;type&quot;: &quot;join&quot;,</span><br><span class="line">        &quot;relations&quot;: &#123;</span><br><span class="line">          &quot;question&quot;: &quot;answer&quot; </span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这段代码建立了一个my_index的索引，其中my_join_field是一个用于join的字段，type为join，关系relations为：父为question, 子为answer<br>至于建立一父多子关系，只需要改为数组即可：<code>&quot;question&quot;: [&quot;answer&quot;, &quot;comment&quot;]</code></p><h2 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h2><p>插入两个父文档，语法如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index/_doc/1?refresh</span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;: &quot;This is a question&quot;,</span><br><span class="line">  &quot;my_join_field&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;question&quot; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>同时也可以省略name<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index/_doc/1?refresh</span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;: &quot;This is a question&quot;,</span><br><span class="line">  &quot;my_join_field&quot;: &quot;question&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="插入子文档"><a href="#插入子文档" class="headerlink" title="插入子文档"></a>插入子文档</h3><p>子文档的插入语法如下，注意routing是父文档的id，平时我们插入文档时routing的默认就是id<br>此时name为answer，表示这是个子文档<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">PUT /my_index/_doc/3?routing=1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;: &quot;This is an answer&quot;,</span><br><span class="line">  &quot;my_join_field&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;answer&quot;, </span><br><span class="line">    &quot;parent&quot;: &quot;1&quot; </span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p><h3 id="通过parent-id查询子文档"><a href="#通过parent-id查询子文档" class="headerlink" title="通过parent_id查询子文档"></a>通过parent_id查询子文档</h3><p>通过parent_id query传入父文档id即可<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">GET my_index/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;parent_id&quot;: &#123; </span><br><span class="line">      &quot;type&quot;: &quot;answer&quot;,</span><br><span class="line">      &quot;id&quot;: &quot;1&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="父-子文档的性能及限制性"><a href="#父-子文档的性能及限制性" class="headerlink" title="父-子文档的性能及限制性"></a>父-子文档的性能及限制性</h2><p>父-子文档主要适用于一对多的实体关系，将其反范式存入文档中</p><p>父-子文档主要由以下特性：</p><ul><li>Only one join field mapping is allowed per index.<br>每个索引只能有一个join字段</li><li>Parent and child documents must be indexed on the same shard. This means that the same routing value needs to be provided when getting, deleting, or updating a child document.<br>父-子文档必须在同一个分片上，也就是说增删改查一个子文档，必须使用和父文档一样的routing key(默认是id)</li><li>An element can have multiple children but only one parent.<br>每个元素可以有多个子，但只有一个父</li><li>It is possible to add a new relation to an existing join field.<br>可以为一个已存在的join字段添加新的关联关系</li><li>It is also possible to add a child to an existing element but only if the element is already a parent.<br>可以在一个元素已经是父的情况下添加一个子</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>es中通过父子文档来实现join，但在一个索引中只能有一个一父多子的join</p><h2 id="关系字段"><a href="#关系字段" class="headerlink" title="关系字段"></a>关系字段</h2><p>es会自动生成一个额外的用于表示关系的字段：field#parent<br>我们可以通过以下方式查询<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">POST my_index/_search</span><br><span class="line">&#123;</span><br><span class="line"> &quot;script_fields&quot;: &#123;</span><br><span class="line">    &quot;parent&quot;: &#123;</span><br><span class="line">      &quot;script&quot;: &#123;</span><br><span class="line">         &quot;source&quot;: &quot;doc[&apos;my_join_field#question&apos;]&quot; </span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>部分响应为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">&quot;_index&quot; : &quot;my_index&quot;,</span><br><span class="line">&quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">&quot;_id&quot; : &quot;8&quot;,</span><br><span class="line">&quot;_score&quot; : 1.0,</span><br><span class="line">&quot;fields&quot; : &#123;</span><br><span class="line">  &quot;parent&quot; : [</span><br><span class="line">    &quot;8&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">&quot;_index&quot; : &quot;my_index&quot;,</span><br><span class="line">&quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">&quot;_id&quot; : &quot;4&quot;,</span><br><span class="line">&quot;_score&quot; : 1.0,</span><br><span class="line">&quot;_routing&quot; : &quot;10&quot;,</span><br><span class="line">&quot;fields&quot; : &#123;</span><br><span class="line">  &quot;parent&quot; : [</span><br><span class="line">    &quot;10&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>有_routing字段的说明是子文档，它的parent字段是父文档id，如果没有_routing就是父文档，它的parent指向当前id</p><h2 id="全局序列"><a href="#全局序列" class="headerlink" title="全局序列"></a>全局序列</h2><p>父-子文档的join查询使用一种叫做全局序列(Global ordinals)的技术来加速查询，它采用预加载的方式构建，防止在第一次查询或聚合时出现太长时间的延迟，但在索引元数据改变时重建，父文档越多，构建时间就越长，重建在refresh时进行，这会造成refresh大量延迟时间(在refresh时也是预加载).<br>如果join字段很少用，可以关闭这种预加载模式:<code>&quot;eager_global_ordinals&quot;: false</code></p><h3 id="全局序列的监控"><a href="#全局序列的监控" class="headerlink" title="全局序列的监控"></a>全局序列的监控</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 每个索引</span><br><span class="line">curl -X GET &quot;localhost:9200/_stats/fielddata?human&amp;fields=my_join_field#question&amp;pretty&quot;</span><br><span class="line"># 每个节点上的每个索引</span><br><span class="line">curl -X GET &quot;localhost:9200/_nodes/stats/indices/fielddata?human&amp;fields=my_join_field#question&amp;pretty&quot;</span><br></pre></td></tr></table></figure><h2 id="一父多子的祖孙结构"><a href="#一父多子的祖孙结构" class="headerlink" title="一父多子的祖孙结构"></a>一父多子的祖孙结构</h2><p>考虑以下结构<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">   question</span><br><span class="line">    /    \</span><br><span class="line">   /      \</span><br><span class="line">comment  answer</span><br><span class="line">           |</span><br><span class="line">           |</span><br><span class="line">          vote</span><br></pre></td></tr></table></figure></p><p>建立索引<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">      &quot;my_join_field&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;join&quot;,</span><br><span class="line">        &quot;relations&quot;: &#123;</span><br><span class="line">          &quot;question&quot;: [&quot;answer&quot;, &quot;comment&quot;],  </span><br><span class="line">          &quot;answer&quot;: &quot;vote&quot; </span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="插入孙子节点"><a href="#插入孙子节点" class="headerlink" title="插入孙子节点"></a>插入孙子节点</h3><p>注意这里的routing和parent值不一样,routing指的是祖父字段，即question,而parent指的就是字面意思answer<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index/_doc/3?routing=1&amp;refresh </span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;: &quot;This is a vote&quot;,</span><br><span class="line">  &quot;my_join_field&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;vote&quot;,</span><br><span class="line">    &quot;parent&quot;: &quot;2&quot; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="has-child查询"><a href="#has-child查询" class="headerlink" title="has-child查询"></a>has-child查询</h2><p>查询包含特定子文档的父文档，这是一种很耗性能的查询，尽量少用。它的查询标准格式如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">GET my_index/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;has_child&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;child&quot;,</span><br><span class="line">            &quot;query&quot; : &#123;</span><br><span class="line">                &quot;match_all&quot; : &#123;&#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;max_children&quot;: 10, //可选，符合查询条件的子文档最大返回数</span><br><span class="line">            &quot;min_children&quot;: 2, //可选，符合查询条件的子文档最小返回数</span><br><span class="line">            &quot;score_mode&quot; : &quot;min&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="测试代码"><a href="#测试代码" class="headerlink" title="测试代码"></a>测试代码</h2><p>部分测试代码如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">DELETE my_index</span><br><span class="line"></span><br><span class="line">PUT /my_index?pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">      &quot;my_join_field&quot;: &#123; </span><br><span class="line">        &quot;type&quot;: &quot;join&quot;,</span><br><span class="line">        &quot;relations&quot;: &#123;</span><br><span class="line">          &quot;question&quot;: &quot;answer&quot; </span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 插入父</span><br><span class="line">PUT /my_index/_doc/8?refresh&amp;pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;: &quot;This is a question&quot;,</span><br><span class="line">  &quot;my_join_field&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;question&quot; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT /my_index/_doc/10?refresh&amp;pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;: &quot;This is a new question&quot;,</span><br><span class="line">  &quot;my_join_field&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;question&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT /my_index/_doc/12?refresh&amp;pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;: &quot;This is a new question&quot;,</span><br><span class="line">  &quot;my_join_field&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;question&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 插入子</span><br><span class="line">PUT /my_index/_doc/3?routing=8&amp;refresh&amp;pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;: &quot;This is an answer&quot;,</span><br><span class="line">  &quot;my_join_field&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;answer&quot;, </span><br><span class="line">    &quot;parent&quot;: &quot;8&quot; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">PUT /my_index/_doc/4?routing=10&amp;refresh&amp;pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;text&quot;: &quot;This is another answer&quot;,</span><br><span class="line">  &quot;my_join_field&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;answer&quot;,</span><br><span class="line">    &quot;parent&quot;: &quot;10&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 通过parent_id查询子文档</span><br><span class="line">GET my_index/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;parent_id&quot;: &#123; </span><br><span class="line">      &quot;type&quot;: &quot;answer&quot;,</span><br><span class="line">      &quot;id&quot;: &quot;8&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 查询relation</span><br><span class="line">POST my_index/_search</span><br><span class="line">&#123;</span><br><span class="line"> &quot;script_fields&quot;: &#123;</span><br><span class="line">    &quot;parent&quot;: &#123;</span><br><span class="line">      &quot;script&quot;: &#123;</span><br><span class="line">         &quot;source&quot;: &quot;doc[&apos;my_join_field#question&apos;]&quot; </span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
      
      <categories>
          
          <category> ELK Stack </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>spring-boot原理之@EnableXxx注解的实现</title>
      <link href="/2019/09/25/spring-boot%E5%8E%9F%E7%90%86%E4%B9%8B-EnableXxx%E6%B3%A8%E8%A7%A3%E7%9A%84%E5%AE%9E%E7%8E%B0/"/>
      <url>/2019/09/25/spring-boot%E5%8E%9F%E7%90%86%E4%B9%8B-EnableXxx%E6%B3%A8%E8%A7%A3%E7%9A%84%E5%AE%9E%E7%8E%B0/</url>
      <content type="html"><![CDATA[<blockquote><p>Spring boot各种领人眼花缭乱的starter层出不穷，它实现了各种组件与spring的集成，本文以spring-cloud-openfeign 2.2.0版本为例，介绍@EnableXxx注解的实现原理</p></blockquote><h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p><em>注 由于有包扫描相关，本文约定包名为com.ttyc，启动类名为MainApplication</em></p><p>@EnableFeignClients的源码大致如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Import</span>(FeignClientsRegistrar.class)</span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> EnableFeignClients &#123;</span><br><span class="line"><span class="comment">// value和basePackages的作用一样，互为别名</span></span><br><span class="line">String[] value() <span class="keyword">default</span> &#123;&#125;;</span><br><span class="line">String[] basePackages() <span class="keyword">default</span> &#123;&#125;;</span><br><span class="line"></span><br><span class="line">Class&lt;?&gt;[] basePackageClasses() <span class="keyword">default</span> &#123;&#125;;</span><br><span class="line">Class&lt;?&gt;[] defaultConfiguration() <span class="keyword">default</span> &#123;&#125;;</span><br><span class="line">Class&lt;?&gt;[] clients() <span class="keyword">default</span> &#123;&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>它引入了FeignClientsRegistrar，而FeignClientsRegistrar实现了ImportBeanDefinitionRegistrar接口</p><h2 id="Import注解"><a href="#Import注解" class="headerlink" title="@Import注解"></a>@Import注解</h2><p>@Import注解通常用于导入@Configuration注解的配置类，但在它的文档描述中也明确说明了支持ImportSelector和ImportBeanDefinitionRegistrar的实现类<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">* &lt;p&gt;Provides functionality equivalent to the &#123;@code &lt;import/&gt;&#125; element in Spring XML.</span><br><span class="line">* Allows for importing &#123;@code @Configuration&#125; classes, &#123;@link ImportSelector&#125; and</span><br><span class="line">* &#123;@link ImportBeanDefinitionRegistrar&#125; implementations</span><br></pre></td></tr></table></figure></p><p>ImportBeanDefinitionRegistrar接口提供import类的注解元信息，下文将会解释它是什么，以及一个BeanDefinition的注册表用于注册<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">registerBeanDefinitions</span><span class="params">(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry)</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><h2 id="FeignClientsRegistrar"><a href="#FeignClientsRegistrar" class="headerlink" title="FeignClientsRegistrar"></a>FeignClientsRegistrar</h2><p>FeignClientsRegistrar实现的registerBeanDefinitions调用了2个方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeignClientsRegistrar</span> <span class="keyword">implements</span> <span class="title">ImportBeanDefinitionRegistrar</span>, <span class="title">ResourceLoaderAware</span>, <span class="title">EnvironmentAware</span> </span>&#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">registerBeanDefinitions</span><span class="params">(AnnotationMetadata metadata,</span></span></span><br><span class="line"><span class="function"><span class="params">BeanDefinitionRegistry registry)</span> </span>&#123;</span><br><span class="line">registerDefaultConfiguration(metadata, registry);</span><br><span class="line">registerFeignClients(metadata, registry);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="registerDefaultConfiguration"><a href="#registerDefaultConfiguration" class="headerlink" title="registerDefaultConfiguration"></a>registerDefaultConfiguration</h3><p>registerDefaultConfiguration注册了一个FeignClientSpecification的bean，它的beanName经过一系列字符串拼接，最终是default.com.ttyc.MainApplication<br>用于Feign的同学都知道Feign可以自定义一些配置，如Decoder，Encoder，Contract，这里是注册了一个默认的配置<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">registerDefaultConfiguration</span><span class="params">(AnnotationMetadata metadata,</span></span></span><br><span class="line"><span class="function"><span class="params">BeanDefinitionRegistry registry)</span> </span>&#123;</span><br><span class="line"><span class="comment">// 拿到EnableFeignClients注解的配置项</span></span><br><span class="line">Map&lt;String, Object&gt; defaultAttrs = metadata</span><br><span class="line">.getAnnotationAttributes(EnableFeignClients.class.getName(), <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 肯定包含defaultConfiguration</span></span><br><span class="line"><span class="keyword">if</span> (defaultAttrs != <span class="keyword">null</span> &amp;&amp; defaultAttrs.containsKey(<span class="string">"defaultConfiguration"</span>)) &#123;</span><br><span class="line">String name;</span><br><span class="line"><span class="comment">// 有没有标注在内部类上</span></span><br><span class="line"><span class="keyword">if</span> (metadata.hasEnclosingClass()) &#123;</span><br><span class="line">name = <span class="string">"default."</span> + metadata.getEnclosingClassName();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line"><span class="comment">// 基本都走这 name = default.com.ttyc.MainApplication</span></span><br><span class="line">name = <span class="string">"default."</span> + metadata.getClassName();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 注册bean</span></span><br><span class="line">registerClientConfiguration(registry, name,</span><br><span class="line">defaultAttrs.get(<span class="string">"defaultConfiguration"</span>));</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h4 id="AnnotationMetadata"><a href="#AnnotationMetadata" class="headerlink" title="AnnotationMetadata"></a>AnnotationMetadata</h4><p>至此可以看出AnnotationMetadata其实就是EnableFeignClients注解所在类的元信息，通过AnnotationMetadata的getAnnotationAttributes方法可以很方便的获到一个注解所有属性和值的map。但EnableFeignClients注解不是随便什么类都可以写的，通常标注在启动类上也是原因的。</p><h3 id="registerFeignClients"><a href="#registerFeignClients" class="headerlink" title="registerFeignClients"></a>registerFeignClients</h3><p>我们写的FeignClient接口由ClassPathScanningCandidateComponentProvider负责扫描，它需要指定路径，以及过滤器<br>过滤器的作用是在扫描是获取匹配的类，在这里就是有FeignClient注解的类，最终组装成BeanDefinition集合<br>registerFeignClients的源码主要分为：获取basePackages，扫码到所有类封装为BeanDefinition，注册到spring IOC容器中</p><h4 id="获取basePackages流程"><a href="#获取basePackages流程" class="headerlink" title="获取basePackages流程"></a>获取basePackages流程</h4><p>这一部分代码主要是希望大家不要随意设置clients属性，它会获取clients数组里每一个类所在的包，添加到basePackages集合中，实际开发中维护性并不是很好<br>那么在没有设置clients属性时，执行basePackages = getBasePackages(metadata)，它会依次添加用户在@EnableFeignClients中设置的value，basePackages以及basePackageClasses中每一个类所在的包路径，<br>如果这三个属性你都没有设置，就获取@EnableFeignClients注解所在类的包路径作为basePackages<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">registerFeignClients</span><span class="params">(AnnotationMetadata metadata,</span></span></span><br><span class="line"><span class="function"><span class="params">BeanDefinitionRegistry registry)</span> </span>&#123;</span><br><span class="line">ClassPathScanningCandidateComponentProvider scanner = getScanner();</span><br><span class="line">scanner.setResourceLoader(<span class="keyword">this</span>.resourceLoader);</span><br><span class="line"></span><br><span class="line">Set&lt;String&gt; basePackages;</span><br><span class="line"></span><br><span class="line">Map&lt;String, Object&gt; attrs = metadata</span><br><span class="line">.getAnnotationAttributes(EnableFeignClients.class.getName());</span><br><span class="line">AnnotationTypeFilter annotationTypeFilter = <span class="keyword">new</span> AnnotationTypeFilter(</span><br><span class="line">FeignClient.class);</span><br><span class="line"><span class="keyword">final</span> Class&lt;?&gt;[] clients = attrs == <span class="keyword">null</span> ? <span class="keyword">null</span></span><br><span class="line">: (Class&lt;?&gt;[]) attrs.get(<span class="string">"clients"</span>);</span><br><span class="line"><span class="keyword">if</span> (clients == <span class="keyword">null</span> || clients.length == <span class="number">0</span>) &#123;</span><br><span class="line">scanner.addIncludeFilter(annotationTypeFilter);</span><br><span class="line">basePackages = getBasePackages(metadata);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line"><span class="comment">// @EnableFeignClients可以设置clients属性，如果设置了FeignClient类，就以它所在包为路径扫描</span></span><br><span class="line"><span class="keyword">final</span> Set&lt;String&gt; clientClasses = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">basePackages = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line"><span class="keyword">for</span> (Class&lt;?&gt; clazz : clients) &#123;</span><br><span class="line">basePackages.add(ClassUtils.getPackageName(clazz));</span><br><span class="line">clientClasses.add(clazz.getCanonicalName());</span><br><span class="line">&#125;</span><br><span class="line">AbstractClassTestingTypeFilter filter = <span class="keyword">new</span> AbstractClassTestingTypeFilter() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">match</span><span class="params">(ClassMetadata metadata)</span> </span>&#123;</span><br><span class="line">String cleaned = metadata.getClassName().replaceAll(<span class="string">"\\$"</span>, <span class="string">"."</span>);</span><br><span class="line"><span class="keyword">return</span> clientClasses.contains(cleaned);</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line">scanner.addIncludeFilter(</span><br><span class="line"><span class="keyword">new</span> AllTypeFilter(Arrays.asList(filter, annotationTypeFilter)));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 见下文</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="注册FeignClient到IOC容器"><a href="#注册FeignClient到IOC容器" class="headerlink" title="注册FeignClient到IOC容器"></a>注册FeignClient到IOC容器</h3><p>在获取到所有的basePackages后，对其进行遍历，scanner扫描每一个路径，获取所有带有@FeignClient的类，并解析为BeanDefinition集合，<br>第二个for循环对BeanDefinition集合遍历，通过registerFeignClient方法注册到IOC容器中<br>而registerClientConfiguration是为每一个FeignClient的configuration注册bean，它的beanName为：@FeignClient的name值 + .FeignClientSpecification<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (String basePackage : basePackages) &#123;</span><br><span class="line"><span class="comment">// 扫描包下所有类，把满足TypeFilter的类解析为BeanDefinition返回</span></span><br><span class="line"><span class="comment">// 通常情况下scanner只addIncludeFilter一个annotationTypeFilter</span></span><br><span class="line"><span class="comment">// TypeFilter: AnnotationTypeFilter过滤有FeignClient注解的类</span></span><br><span class="line">Set&lt;BeanDefinition&gt; candidateComponents = scanner</span><br><span class="line">.findCandidateComponents(basePackage);</span><br><span class="line"><span class="keyword">for</span> (BeanDefinition candidateComponent : candidateComponents) &#123;</span><br><span class="line"><span class="keyword">if</span> (candidateComponent <span class="keyword">instanceof</span> AnnotatedBeanDefinition) &#123;</span><br><span class="line"><span class="comment">// verify annotated class is an interface</span></span><br><span class="line">AnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent;</span><br><span class="line"><span class="comment">// 获取FeignClient类上的所有注解及其配置项，除了@FeignClient，还会有别的注解</span></span><br><span class="line">AnnotationMetadata annotationMetadata = beanDefinition.getMetadata();</span><br><span class="line">Assert.isTrue(annotationMetadata.isInterface(),</span><br><span class="line"><span class="string">"@FeignClient can only be specified on an interface"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 单独获取@FeignClient的配置项</span></span><br><span class="line">Map&lt;String, Object&gt; attributes = annotationMetadata</span><br><span class="line">.getAnnotationAttributes(</span><br><span class="line">FeignClient.class.getCanonicalName());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从attributes中获取@FeignClient的name</span></span><br><span class="line">String name = getClientName(attributes);</span><br><span class="line">registerClientConfiguration(registry, name,</span><br><span class="line">attributes.get(<span class="string">"configuration"</span>));</span><br><span class="line"></span><br><span class="line">registerFeignClient(registry, annotationMetadata, attributes);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h4 id="registerFeignClient"><a href="#registerFeignClient" class="headerlink" title="registerFeignClient"></a>registerFeignClient</h4><p>registerFeignClient方法就比较简单了，就是组装BeanDefinition，然后注册成一个FeignClientFactoryBean，它的beanName为FeignClient的类全名，里面还有一些别名，primary的设置，内部细节见源码里的注释</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">registerFeignClient</span><span class="params">(BeanDefinitionRegistry registry,</span></span></span><br><span class="line"><span class="function"><span class="params">AnnotationMetadata annotationMetadata, Map&lt;String, Object&gt; attributes)</span> </span>&#123;</span><br><span class="line">String className = annotationMetadata.getClassName();</span><br><span class="line">BeanDefinitionBuilder definition = BeanDefinitionBuilder</span><br><span class="line">.genericBeanDefinition(FeignClientFactoryBean.class);</span><br><span class="line">validate(attributes);</span><br><span class="line">definition.addPropertyValue(<span class="string">"url"</span>, getUrl(attributes));</span><br><span class="line">definition.addPropertyValue(<span class="string">"path"</span>, getPath(attributes));</span><br><span class="line">String name = getName(attributes);</span><br><span class="line">definition.addPropertyValue(<span class="string">"name"</span>, name);</span><br><span class="line"><span class="comment">// contextId新版本加入的，用于自定义bean的别名，以前总是用name作为别名</span></span><br><span class="line">String contextId = getContextId(attributes);</span><br><span class="line">definition.addPropertyValue(<span class="string">"contextId"</span>, contextId);</span><br><span class="line">definition.addPropertyValue(<span class="string">"type"</span>, className);</span><br><span class="line">definition.addPropertyValue(<span class="string">"decode404"</span>, attributes.get(<span class="string">"decode404"</span>));</span><br><span class="line">definition.addPropertyValue(<span class="string">"fallback"</span>, attributes.get(<span class="string">"fallback"</span>));</span><br><span class="line">definition.addPropertyValue(<span class="string">"fallbackFactory"</span>, attributes.get(<span class="string">"fallbackFactory"</span>));</span><br><span class="line">definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置bean的别名</span></span><br><span class="line">String alias = contextId + <span class="string">"FeignClient"</span>;</span><br><span class="line">AbstractBeanDefinition beanDefinition = definition.getBeanDefinition();</span><br><span class="line"></span><br><span class="line"><span class="keyword">boolean</span> primary = (Boolean) attributes.get(<span class="string">"primary"</span>); <span class="comment">// has a default, won't be</span></span><br><span class="line"><span class="comment">// null</span></span><br><span class="line"></span><br><span class="line">beanDefinition.setPrimary(primary);</span><br><span class="line"></span><br><span class="line">String qualifier = getQualifier(attributes);</span><br><span class="line"><span class="keyword">if</span> (StringUtils.hasText(qualifier)) &#123;</span><br><span class="line"><span class="comment">// qualifier属性也是新加的，它会覆盖contextId的别名</span></span><br><span class="line">alias = qualifier;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 类全名来作为beanName来注册bean</span></span><br><span class="line">BeanDefinitionHolder holder = <span class="keyword">new</span> BeanDefinitionHolder(beanDefinition, className,</span><br><span class="line"><span class="keyword">new</span> String[] &#123; alias &#125;);</span><br><span class="line">BeanDefinitionReaderUtils.registerBeanDefinition(holder, registry);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>@EnableFeignClients依赖了@Import可以导入ImportBeanDefinitionRegistrar实现类的特性，将FeignClient的接口类，配置注册到spring容器中，而在注册之前，需要对用户配置的一系列包扫描路径解析，获取到FeignClient的BeanDefinition，最终完成注册<br>FeignClientSpecification表示每一个FeignClient对应的配置，FeignClientFactoryBean表示每一个FeignClient</p>]]></content>
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>跳表的研究与实现</title>
      <link href="/2019/09/20/%E8%B7%B3%E8%A1%A8%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E7%8E%B0/"/>
      <url>/2019/09/20/%E8%B7%B3%E8%A1%A8%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E7%8E%B0/</url>
      <content type="html"><![CDATA[<blockquote><p>跳表的基本原理介绍我是从极客学院王争老师的课程中了解到的，由于其实现相比红黑树简单，并且有与之媲美的性能，便想要实现一下，但纸上得来终觉浅，实际编码过程中遇到了不少的困难，希望本文对大家实现跳表有所帮助。</p></blockquote><h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>待补充，可先移步至csdn<a href="https://blog.csdn.net/pcwl1206/article/details/83512600" target="_blank" rel="noopener">相关博客</a>，内容和王争老师文章差别不大</p><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p>本文采用java语言实现，为了让删除的时间复杂度达到O(1),采用了双链表结构，代码地址在我的Github<a href="https://github.com/GreedyPirate/data-structure/blob/master/src/com/ttyc/algorithm/SkipList.java" target="_blank" rel="noopener">数据结构专栏</a>。</p><h2 id="节点数据结构"><a href="#节点数据结构" class="headerlink" title="节点数据结构"></a>节点数据结构</h2><p>首先说下节点的数据结构代码<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 用双链表存储</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Integer data;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Node[] forwards;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 为删除等操作提供O(1)</span></span><br><span class="line">    <span class="keyword">private</span> Node[] previous;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Node</span><span class="params">(Integer data, <span class="keyword">int</span> level)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.data = data;</span><br><span class="line">        <span class="comment">// ++level , level层有level+1个后继节点</span></span><br><span class="line">        forwards = <span class="keyword">new</span> Node[level];</span><br><span class="line">        previous = <span class="keyword">new</span> Node[level];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> data == <span class="keyword">null</span> ? <span class="string">""</span> : String.valueOf(data);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取节点在level层的下一个节点</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Node <span class="title">boyNextDoor</span><span class="params">(<span class="keyword">int</span> level)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> forwards[level];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Node <span class="title">previous</span><span class="params">(<span class="keyword">int</span> level)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> previous[level];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>可以看到有两个数组，相信一开始很多人和我一样百思不得解两个数组是干什么的，相信大家见到的跳表差不多是这样的<br><img src="https://ae01.alicdn.com/kf/Hc2f9c6a99fb84d59ac89ea21ec23a564S.png" alt="跳表1"><br>上图红线给出了查找20的路径，一开始我也觉得很好理解，但随即两个问题困扰了我很久</p><ol><li>图中有必要每层都存数据域吗，比如图中的10，为什么有5个？一个数据域+N和前后指针就可以了啊</li><li>向下的箭头怎么表示？ 再来个down指针？</li></ol><p>在找跳表相关文章时，看到一位作者引用了跳表的论文，点进去一看有种恍然大悟的感觉，跳表其实应该是这样的<br><img src="https://ae01.alicdn.com/kf/H4e6846925103438a96ec7b9c8b908655K.png" alt="跳表2"></p><p>于是我又手绘了一张跳表的结构图(省略了前驱指针)，一边画一边思考，发现问题1和问题2解决之后变得很简单<br><img src="https://ae01.alicdn.com/kf/H2b256f768e5b4e4189df038dfbf4fb16i.png" alt="跳表3"><br>最终得到了上面的代码，而forwards正是红色部分表示的后驱指针，这个后驱指针数组的长度完全取决于它所在的层数，但HEAD节点默认初始化为最大层数</p><p>可以看到previous和boyNextDoor(手动斜眼)两个方法提供了获取一个节点在x层上获取前驱和后继节点的能力</p><h2 id="初始化及成员变量介绍"><a href="#初始化及成员变量介绍" class="headerlink" title="初始化及成员变量介绍"></a>初始化及成员变量介绍</h2><h4 id="成员变量如下"><a href="#成员变量如下" class="headerlink" title="成员变量如下"></a>成员变量如下</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 最高16层</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> MAX_LEVEL = <span class="number">16</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * head节点</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> Node head;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 元素个数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> size;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 跳表高度, 从1开始算</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> height;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 用于随机节点所在层数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> Random random = <span class="keyword">new</span> Random();</span><br></pre></td></tr></table></figure><h4 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 初始化数据</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">SkipList</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    head = <span class="keyword">new</span> Node(<span class="keyword">null</span>, MAX_LEVEL);</span><br><span class="line">    height = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="公共方法findFirstGreater"><a href="#公共方法findFirstGreater" class="headerlink" title="公共方法findFirstGreater"></a>公共方法findFirstGreater</h2><p>在讲解插入，删除，查找之前，先介绍findFirstGreater方法，这是一个简单且重要的公共方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> data    要查找的数据</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> current 查询的起始节点</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> level   要查找的层数</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> 如果当前节点的下一个节点比data大(不能包含等于)，返回当前节点</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> Node <span class="title">findFirstGreater</span><span class="params">(<span class="keyword">int</span> data, Node current, <span class="keyword">int</span> level)</span> </span>&#123;</span><br><span class="line">    Node nextDoor = current.boyNextDoor(level);</span><br><span class="line">    <span class="comment">// current在后，nextDoor在前，两个同时往右走， 就像两个快慢指针</span></span><br><span class="line">    <span class="comment">// 只要发现nextDoor比data大，直接返回current</span></span><br><span class="line">    <span class="keyword">while</span> (nextDoor != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 这个if写到while里也可以</span></span><br><span class="line">        <span class="keyword">if</span> (data &lt; nextDoor.data) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 往前走一个</span></span><br><span class="line">        current = nextDoor;</span><br><span class="line">        nextDoor = current.boyNextDoor(level); </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 当前层没有比data大的，但是下一层可能有</span></span><br><span class="line">    <span class="keyword">return</span> current;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>无论是查找，插入，删除，我们都要找到第一个比data大的节点的前一个节点,假设data=5，链表为 2 3(5) 7, 第一个大于5的是7，则返回3(5)，该值&lt;=5</p><h2 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h2><p>插入的思路是这样的，首先通过随机函数决定节点有多高，当然最高不超过MAX_LEVEL，这个随机算法直接从redis源码里拿过来的，然后在每一层通过findFirstGreater方法找到第一个比data大的节点的前一个节点，剩下的就是双链表的插入了</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">insert</span><span class="params">(<span class="keyword">int</span> data)</span> </span>&#123;</span><br><span class="line"><span class="comment">// 先判断是否已经存在</span></span><br><span class="line">    <span class="keyword">if</span> (contains(data)) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 构造节点</span></span><br><span class="line">    <span class="keyword">int</span> level = randomLevel();</span><br><span class="line">    Node newNode = <span class="keyword">new</span> Node(data, level);</span><br><span class="line">    <span class="comment">// 必须先赋值，下面开始--了，或者用临时变量保存</span></span><br><span class="line">    <span class="keyword">if</span> (level &gt; height) &#123;</span><br><span class="line">        height = level;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// level-1， 下面的leve都用做forwards数组的下标了</span></span><br><span class="line">    level--;</span><br><span class="line">    <span class="comment">// 从上往下插入</span></span><br><span class="line">    Node current = head;</span><br><span class="line">    <span class="keyword">while</span> (level &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 最关键的一行代码</span></span><br><span class="line">        current = findFirstGreater(data, head, level);</span><br><span class="line">        <span class="comment">// 双链表插入</span></span><br><span class="line">        Node nextDoor = current.boyNextDoor(level);</span><br><span class="line">        newNode.forwards[level] = nextDoor;</span><br><span class="line">        newNode.previous[level] = current;</span><br><span class="line">        current.forwards[level] = newNode;</span><br><span class="line">        <span class="keyword">if</span> (nextDoor != <span class="keyword">null</span>)</span><br><span class="line">            nextDoor.previous[level] = newNode;</span><br><span class="line">        <span class="comment">// 体会level-1对findFirstGreater方法影响，是不是达到了节点向下一层的目的？问题2搞定</span></span><br><span class="line">        level--;</span><br><span class="line">    &#125;</span><br><span class="line">    size++;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="contains方法"><a href="#contains方法" class="headerlink" title="contains方法"></a>contains方法</h3><p>contains的实现很简单，就是调用了查找方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">contains</span><span class="params">(<span class="keyword">int</span> data)</span> </span>&#123;</span><br><span class="line">    Node node = find(data);</span><br><span class="line">    <span class="keyword">return</span> node != <span class="keyword">null</span> &amp;&amp; node.data != <span class="keyword">null</span> &amp;&amp; data == node.data;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="随机算法"><a href="#随机算法" class="headerlink" title="随机算法"></a>随机算法</h3><p>返回1到MAX_LEVEL之间的随机数，符合正态分布<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">randomLevel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// the following implementation is basically as same as Redis ZSET implementation</span></span><br><span class="line">    <span class="comment">// see https://github.com/antirez/redis/blob/4.0/src/t_zset.c</span></span><br><span class="line">    <span class="keyword">int</span> newLevel = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> ((random.nextInt() &amp; <span class="number">0xFFFF</span>) &lt; (<span class="number">0xFFFF</span> &gt;&gt; <span class="number">2</span>)) &#123;</span><br><span class="line">        newLevel++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> (newLevel &lt; MAX_LEVEL) ? newLevel : MAX_LEVEL;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h2><p>查找就是我们所熟知的跳表查询方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 查找节点</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Node <span class="title">find</span><span class="params">(<span class="keyword">int</span> data)</span> </span>&#123;</span><br><span class="line">    Node node = head;</span><br><span class="line">    <span class="keyword">int</span> level = height - <span class="number">1</span>;</span><br><span class="line">    <span class="comment">// 必须找到最后一层</span></span><br><span class="line">    <span class="keyword">while</span> (level &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">        node = findFirstGreater(data, node, level);</span><br><span class="line">        level--;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> node;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h2><p>删除相比查找，需要判断findFirstGreater返回的节点值等于data才能删，然后就是简单的双链表删除操作，过程也很简单<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(<span class="keyword">int</span> data)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!contains(data)) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    Node current = head;</span><br><span class="line">    <span class="keyword">int</span> level = height - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (level &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">        current = findFirstGreater(data, current, level);</span><br><span class="line">        <span class="keyword">if</span> (current != head &amp;&amp; current.data == data) &#123;</span><br><span class="line">            <span class="comment">// 双链表删除</span></span><br><span class="line">            Node previous = current.previous(level);</span><br><span class="line">            Node nextDoor = current.boyNextDoor(level);</span><br><span class="line">            System.out.println(previous.data + <span class="string">"--&gt;"</span> + current.data + <span class="string">"--&gt;"</span> + (nextDoor == <span class="keyword">null</span> ? <span class="string">""</span> : nextDoor.data));</span><br><span class="line"></span><br><span class="line">            previous.forwards[level] = nextDoor;</span><br><span class="line">            <span class="keyword">if</span> (nextDoor != <span class="keyword">null</span>) &#123;</span><br><span class="line">                nextDoor.previous[level] = previous;</span><br><span class="line">            &#125;</span><br><span class="line">            size--;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 下一层</span></span><br><span class="line">        level--;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="打印"><a href="#打印" class="headerlink" title="打印"></a>打印</h2><p>说实话最耽误时间的反而是这个打印功能，我希望打印出如下形式，这我心目中这是最直观的，但这就要考虑两个节点间的空格数量，看我的代码会比较复杂，但只要自己沉下心来认真想一下，相信大家都能很快有思路<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">level 2:         29                                                                                                                                                                                                                               </span><br><span class="line">level 1:         29          57         148                                                                                                         </span><br><span class="line">level 0: 2 13 18 29 48 50 51 57 131 132 148</span><br></pre></td></tr></table></figure></p><p>我的方式不一定适合每个人，遇到两个节点只是简单的从level0遍历，大数据量不适合<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">easyPrint</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = height - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--) &#123;</span><br><span class="line">        System.out.print(<span class="string">"level "</span> + i + <span class="string">": "</span>);</span><br><span class="line">        Node current = head.forwards[i];</span><br><span class="line">        Node next = current.boyNextDoor(i);</span><br><span class="line"></span><br><span class="line">        StringBuilder builder = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">        <span class="keyword">if</span> (current.data != head.forwards[<span class="number">0</span>].data) &#123;</span><br><span class="line">            builder.append(whiteSpaceHelper(current.data));</span><br><span class="line">        &#125;</span><br><span class="line">        builder.append(current.data);</span><br><span class="line">        <span class="keyword">while</span> (next != <span class="keyword">null</span>) &#123;</span><br><span class="line">            builder.append(whiteSpaceHelper(current.data, next.data)).append(next.data);</span><br><span class="line">            current = current.boyNextDoor(i);</span><br><span class="line">            next = next.boyNextDoor(i);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(builder.toString());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> String <span class="title">whiteSpaceHelper</span><span class="params">(<span class="keyword">int</span> pre, <span class="keyword">int</span> next)</span> </span>&#123;</span><br><span class="line">    Node current = head.boyNextDoor(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">while</span> (current != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (current.data == pre) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        current = current.boyNextDoor(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    Node node = current.boyNextDoor(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (node != <span class="keyword">null</span>) &#123;</span><br><span class="line">        count++;</span><br><span class="line">        <span class="keyword">if</span> (node.data == next) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        count += node.data.toString().length();</span><br><span class="line">        node = node.boyNextDoor(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    StringBuilder builder = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; count; i++) &#123;</span><br><span class="line">        builder.append(<span class="string">" "</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> builder.toString();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> String <span class="title">whiteSpaceHelper</span><span class="params">(<span class="keyword">int</span> next)</span> </span>&#123;</span><br><span class="line">    Node node = head.forwards[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (node != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (node.data == next) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        count += node.data.toString().length();</span><br><span class="line">        count++;</span><br><span class="line">        node = node.boyNextDoor(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    StringBuilder builder = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; count; i++) &#123;</span><br><span class="line">        builder.append(<span class="string">" "</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> builder.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="测试用例"><a href="#测试用例" class="headerlink" title="测试用例"></a>测试用例</h2><p>依次对跳表的插入，删除，打印查找做测试<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    SkipList skipList = <span class="keyword">new</span> SkipList();</span><br><span class="line">    <span class="comment">/*skipList.insert(300);</span></span><br><span class="line"><span class="comment">    skipList.insert(54);</span></span><br><span class="line"><span class="comment">    skipList.insert(14);</span></span><br><span class="line"><span class="comment">    skipList.insert(1010);</span></span><br><span class="line"><span class="comment">    skipList.insert(23);</span></span><br><span class="line"><span class="comment">    skipList.insert(8);</span></span><br><span class="line"><span class="comment">    skipList.insert(325);</span></span><br><span class="line"><span class="comment">    skipList.find(325);</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">int</span> number = skipList.random.nextInt(<span class="number">1000</span>);</span><br><span class="line">        skipList.insert(number);</span><br><span class="line">        <span class="keyword">if</span> (i == <span class="number">15</span>) &#123;</span><br><span class="line">            skipList.insert(<span class="number">666</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    skipList.easyPrint();</span><br><span class="line">    skipList.remove(<span class="number">666</span>);</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">"===================split line================="</span>);</span><br><span class="line">    skipList.easyPrint();</span><br><span class="line"></span><br><span class="line">    System.out.println(skipList.find(<span class="number">666</span>));</span><br><span class="line">    System.out.println(skipList.find(<span class="number">1024</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h2><p>纵观跳表的插入，查找，删除操作，只涉及了简单的查找，双链表的增加，删除节点等基本操作，比起红黑树的实现简单太多，但红黑树在java中有jdk实现，跳表却没有，有些遗憾</p><h2 id="跳表与红黑树"><a href="#跳表与红黑树" class="headerlink" title="跳表与红黑树"></a>跳表与红黑树</h2><p>跳表与红黑树相比有以下特性</p><ol><li>跳表采用的是空间换时间策略，也就是多了两个指针数组，如果对内存空间十分敏感的场景不太适合，即使是redis也是基于大内存+分布式</li><li>跳表和红黑树都有O(logN)的时间复杂度，并且跳表更易于维护</li><li>跳表适合做区间查找，且十分高效</li></ol>]]></content>
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>层级时间轮的研究与实现</title>
      <link href="/2019/09/19/%E5%B1%82%E7%BA%A7%E6%97%B6%E9%97%B4%E8%BD%AE%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E7%8E%B0/"/>
      <url>/2019/09/19/%E5%B1%82%E7%BA%A7%E6%97%B6%E9%97%B4%E8%BD%AE%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E7%8E%B0/</url>
      <content type="html"><![CDATA[]]></content>
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ElasticSearch7.2 X-pack安全认证</title>
      <link href="/2019/08/12/ElasticSearch7-2-X-pack%E5%AE%89%E5%85%A8%E8%AE%A4%E8%AF%81/"/>
      <url>/2019/08/12/ElasticSearch7-2-X-pack%E5%AE%89%E5%85%A8%E8%AE%A4%E8%AF%81/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>ElasticSearch于6.8及7.1版本开始提供免费的x-pack, 并已默认集成，只需通过简单的配置即可开启。 <a href="https://www.elastic.co/cn/blog/security-for-elasticsearch-is-now-free" target="_blank" rel="noopener">官方链接</a>，主要包含以下特性:</p><ol><li>TLS 功能，可对通信进行加密</li><li>文件和原生 Realm，可用于创建和管理用户</li><li>基于角色的访问控制，可用于控制用户对集群 API 和索引的访问权限；通过针对 Kibana Spaces 的安全功能，还可允许在 Kibana 中实现多租户</li></ol><p>安全是个很大的话题,本章只针对用户权限方面做初步尝试，旨在为kibana添加用户认证。<br>通常我们的ES节点部署在内网当中，不对外暴露9200等端口，kibana是一款非常强大的可视化工具(由衷赞叹)，devTools使开发人员可以方便的操作集群，索引，<br>但是这个页面非开发人员也是可以看到的，因此第一步就是先要屏蔽非es使用方，提供一个登录认证功能。</p><h2 id="ES配置"><a href="#ES配置" class="headerlink" title="ES配置"></a>ES配置</h2><p>首先在<em>elasticsearch.yml</em>中加入以下配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">xpack.security.enabled: true</span><br><span class="line">xpack.license.self_generated.type: basic</span><br><span class="line">xpack.security.transport.ssl.enabled: true</span><br></pre></td></tr></table></figure></p><p>然后在bin目录执行以下命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./elasticsearch-setup-passwords interactive</span><br></pre></td></tr></table></figure></p><p>为各个组件设置密码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">➜  bin ./elasticsearch-setup-passwords interactive</span><br><span class="line">future versions of Elasticsearch will require Java 11; your Java version from [/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre] does not meet this requirement</span><br><span class="line">Initiating the setup of passwords for reserved users elastic,apm_system,kibana,logstash_system,beats_system,remote_monitoring_user.</span><br><span class="line">You will be prompted to enter passwords as the process progresses.</span><br><span class="line">Please confirm that you would like to continue [y/N]y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Enter password for [elastic]:</span><br><span class="line">passwords must be at least [6] characters long</span><br><span class="line">Try again.</span><br><span class="line">Enter password for [elastic]:</span><br><span class="line">Reenter password for [elastic]:</span><br><span class="line">Enter password for [apm_system]:</span><br><span class="line">Reenter password for [apm_system]:</span><br><span class="line">Enter password for [kibana]:</span><br><span class="line">Reenter password for [kibana]:</span><br><span class="line">Enter password for [logstash_system]:</span><br><span class="line">Reenter password for [logstash_system]:</span><br><span class="line">Enter password for [beats_system]:</span><br><span class="line">Reenter password for [beats_system]:</span><br><span class="line">Enter password for [remote_monitoring_user]:</span><br><span class="line">Reenter password for [remote_monitoring_user]:</span><br><span class="line">Changed password for user [apm_system]</span><br><span class="line">Changed password for user [kibana]</span><br><span class="line">Changed password for user [logstash_system]</span><br><span class="line">Changed password for user [beats_system]</span><br><span class="line">Changed password for user [remote_monitoring_user]</span><br><span class="line">Changed password for user [elastic]</span><br></pre></td></tr></table></figure><p>ES的设置结束，接下来是kibana，切换至kibana/bin目录</p><h2 id="kibana"><a href="#kibana" class="headerlink" title="kibana"></a>kibana</h2><h3 id="删除原有"><a href="#删除原有" class="headerlink" title="删除原有"></a>删除原有</h3><p>先查看是否已经设置过，新安装的同学可以跳过<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kibana-keystore list</span><br></pre></td></tr></table></figure></p><p>如果发现已安装，但忘记了密码，可以删除原有的配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./kibana-keystore remove elasticsearch.username</span><br><span class="line">./kibana-keystore remove elasticsearch.password</span><br></pre></td></tr></table></figure></p><h3 id="添加"><a href="#添加" class="headerlink" title="添加"></a>添加</h3><p>最后添加ES密码，虽然可以在kibana.yml中配置，但是不安全，要考虑该目录的Linux权限，增加了复杂性，这也是官方提供keystore工具的原因之一<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./kibana-keystore add elasticsearch.username</span><br><span class="line">./kibana-keystore add elasticsearch.password</span><br></pre></td></tr></table></figure></p><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><p>打开kibana，输入账号密码，账号为elastic<br>效果图如下<br><img src="https://ae01.alicdn.com/kf/H8359357d94e24907b332a72a2054dde4e.jpg" alt="登录"></p>]]></content>
      
      <categories>
          
          <category> ELK Stack </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
            <tag> X-pack </tag>
            
            <tag> kibana </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>[译]Kafka Consumer介绍:使用新的0.9版本kafka消费者</title>
      <link href="/2019/01/21/%E8%AF%91-Kafka-Consumer%E4%BB%8B%E7%BB%8D-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8%E6%96%B0%E7%9A%840-9%E7%89%88%E6%9C%ACkafka%E6%B6%88%E8%B4%B9%E8%80%85%E5%AE%A2%E6%88%B7%E7%AB%AF/"/>
      <url>/2019/01/21/%E8%AF%91-Kafka-Consumer%E4%BB%8B%E7%BB%8D-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8%E6%96%B0%E7%9A%840-9%E7%89%88%E6%9C%ACkafka%E6%B6%88%E8%B4%B9%E8%80%85%E5%AE%A2%E6%88%B7%E7%AB%AF/</url>
      <content type="html"><![CDATA[<blockquote><p>原文地址：<a href="https://www.confluent.io/blog/tutorial-getting-started-with-the-new-apache-kafka-0-9-consumer-client/" target="_blank" rel="noopener">Introducing the Kafka Consumer: Getting Started with the New Apache Kafka 0.9 Consumer Client</a></p></blockquote><p>Kafka创建之初，自带了用Scala编写的生产者和消费者客户端，随着时间的推移，我们开始认识到这些API的许多局限性。例如，我们有一个”high-level”消费者API，它支持消费者组和故障转移，但却不支持更多更复杂的使用场景。我们还有一个”简版”消费者API，它提供了完全的控制，但需要用户自己处理故障转移和错误。因此我们开始重新设计这些客户端，以开启许多旧客户端难以支持甚至不可能支持的用例，并建立一组我们能够长期支持的API</p><p>第一阶段是在0.8.1版本重写了的生产者API，最近发布的0.9版本完成了第二阶段，引入了新版消费者API，建立在一个kafka自身提供的新的组协调者协议之上，新的消费者带来了以下优势：</p><ul><li>新的消费者结合了”简版”和”高级”API的功能，同时提供了组协调者和低级别访问，以构建你自己的消费策略</li><li>减少依赖：新版消费者API使用原生java，不依赖Scala运行时环境或者Zookeeper，这使得它以一个轻量库包含在你的项目中</li><li>更安全：kafka 0.9中的安全扩展只支持新版消费者</li><li>新的消费者还增加了一组用于管理消费者进程组容错的协议。以前这个功能在java客户端中的实现很笨重(有许多和ZooKeeper的重量交互)，这种复杂的逻辑使得用其他语言构建时变得十分困难，随着新协议的引进，这变得容易的多，实际上我们已经将C client迁移到新协议上了</li></ul><p>即使消费者使用了重新设计的API和组协调者协议，这些概念并没有变，因此熟悉老消费者的用户理解它应该没有太多问题。但是，在组管理和线程模型方面有一些细微的细节需要特别注意。这篇教程的目的是覆盖new consumer的基本用法，并解释这些细节</p><h1 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h1><p>深入代码之前，我们回顾一下基本概念。在kafka中，topic以partition为维度划分为一组日志，producer追加写入这些日志的尾部，消费者按自己的速度读取日志，kafka在消费者组间通过分布式分区扩展消息消费，消费者组是一组消费者共享的组标识，下图展示了一个topic，它有三个分区，还有一个消费者组，它有两个消费者成员，topic里的每一个分区只分配给组内的一个成员<br><img src="https://www.confluent.io/wp-content/uploads/2016/08/New_Consumer_figure_1.png" alt=""></p><p>老的消费者依赖Zookeeper管理组，新消费者用一个建立在kafka本身之上的组协调者协议。对每一个消费者组，一个kafka broker被选为组协调者。该协调者负责管理消费者组的状态，它主要的工作是在新消费者加入组时，原有消费者离开时，和topic元信息发生改变时调节分区分配，重新分配分区的行为称之为重平衡组</p><p>当组首次初始化，消费者通常会从分区的最早或最近位移开始读取消息，然后按顺序读取每个分区。随着消费者的运行，它会提交它已经成功处理的消息的位移，如下图，消费者消费的位置在6，它上一次提交的位移是1<br><img src="https://www.confluent.io/wp-content/uploads/2016/08/New_Consumer_Figure_2.png" alt=""></p><p>当一个分区重新分配给了组内的另一个消费者，初始的位移被设置到上一次提交的位移。如果上图中的消费者突然挂了，消费者组成员接管这个分区，位移从1开始消费。这种情况下，必须重新处理崩溃消费者分区的第6个位置</p><p>这张图里还展示了日志里的2个重点，日志末端位移(LEO)表示最后一条被写入日志的消息的位移，high watermark是最后一条被成功复制到副本的消息的位移。从消费者的角度来看，最重要的事情是你只能从high watermark的位置处开始读取，防止了消费者读取副本未同步完成，有可能丢失的消息</p><h1 id="配置与初始化"><a href="#配置与初始化" class="headerlink" title="配置与初始化"></a>配置与初始化</h1><p>在开始消费者学习之前，添加kafka-client依赖到你的项目，maven片段如下<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.9.0.0-cp1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>和其它kafka-client一样，使用properties文件构造consumer，在下面的例子中，我们提供了一个使用消费者组的最小配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Properties props = new Properties();</span><br><span class="line">props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);</span><br><span class="line">props.put(&quot;group.id&quot;, &quot;consumer-tutorial&quot;);</span><br><span class="line">props.put(&quot;key.deserializer&quot;, StringDeserializer.class.getName());</span><br><span class="line">props.put(&quot;value.deserializer&quot;, StringDeserializer.class.getName());</span><br><span class="line">KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);</span><br></pre></td></tr></table></figure></p><p>和原来的消费者，生产者一样，我们需要为consumer配置一个broker初始化列表，让consumer发现集群的其余部分, 不需要提供集群里的所有server地址，消费者会从给定列表的broker中确定所有存活的broker集合，这里我们假设broker运行在本地。consumer还需要知道如何反序列化key和value。最终为了加入一个消费者组，我们需要指定gruop id。在接下来的学习中，我们将介绍更多的配置</p><h1 id="topic-订阅"><a href="#topic-订阅" class="headerlink" title="topic 订阅"></a>topic 订阅</h1><p>开始消费之前，你必须首先订阅你的应用要读取的topic，在下面的例子中，我们订阅了主题”foo”和”bar”<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">consumer.subscribe(Arrays.asList(“foo”, “bar”));</span><br></pre></td></tr></table></figure></p><p>订阅之后，消费者可以和组内其它成员协调以获取分区分配，这些都是在你消费数据之后自动处理的，之后我们会展示如何通过assign API手动分配，但要记住不能自动和手动混合分配。</p><p>订阅方法是不可增加的：你必须在列表中包含所有的你想消费的topic。你可以随时改变你已经订阅过的topic，以前订阅的topic都会在你重新调用subscribe方法之后覆盖</p><h1 id="基本的轮询"><a href="#基本的轮询" class="headerlink" title="基本的轮询"></a>基本的轮询</h1><p>消费者需要能够并行的获取数据，可能来自多个broker上的多个topic的多个分区。consumer使用类似unix poll或select风格的API来做这件事：一旦topic被注册，所有以后的协调，重平衡和数据获取都由一个基于在事件循环调用的poll方法来驱动的，这是一个能够用单线程处理IO的简单，高效的实现。</p><p>订阅topic之后，你需要开始时间循环，以分配到一个分区并开始获取数据，这听起来很复杂，但你只需要在循环里调用poll方法，然后consumer处理剩下的事情。每次调用poll方法，它会返回一组来自分配的分区里的消息(可能为空)，下面的例子展示了poll循环的基本用法，打印了offset和vlaue：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="keyword">while</span> (running) &#123;</span><br><span class="line">    ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">1000</span>);</span><br><span class="line">    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records)</span><br><span class="line">      System.out.println(record.offset() + <span class="string">": "</span> + record.value());</span><br><span class="line">  &#125;</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">  consumer.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>poll方法基于当前位置获取数据，当消费者组首次创建，会根据reset策略设置位置(通常为每个分区设置成earliest或latest位移)。一旦消费者开始提交位移，然后每次rebalance会重置到上次提交的位置。poll方法的参数控制了当前位置的消息消费者需要阻塞的最大时间，一旦有消息可用，消费者立即返回，但如果没有任何消息，则会等待到给定的超时时间后返回</p><p>consumer对象被设计成在自己的线程中允许，这在内部没有同步机制的情况下对于多线程是不安全的，这也不是个好主意，在这个例子中，我们使用一个标志位，当应用关闭时终止poll循环。当标志位在另一个线程中被设置为false时，一旦poll返回就会终止，不管返回了什么消息，应用也会停止处理。</p><p>你应该在完成消费后关闭它，不仅仅是清理它使用的socket连接，它还提醒了消费者组它要从组中离开了</p><p>这里例子使用了一个相对较小的超时时间，来保证关闭consumer时没有太多的延迟。可选的，你可以使用一个很大的超时时间，并用wakeup方法结束循环。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">        ConsumerRecords&lt;String, String&gt; records = consumer.poll(Long.MAX_VALUE);</span><br><span class="line">        <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) </span><br><span class="line">            System.out.println(record.offset() + <span class="string">": "</span>+record.value());</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (WakeupException e) &#123;   </span><br><span class="line">    <span class="comment">// ignore for shutdown</span></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;  </span><br><span class="line">consumer.close(); </span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> value;</span><br></pre></td></tr></table></figure><p>我们将超时时间改为Long.MAX_VALUE，这基本意味着consumer无限的阻塞，直到返回下一批消息。不像前面的例子设置一个标志位那样，线程可以通过consumer.wakeup()触发一个shutdown事件来中断运行中的poll，并抛出WakeupException，这个方法是线程安全的。注意如果当前没有运行中的poll，这个异常将会延续到下次请求，在这个例子中我们捕获了这个异常防止它传播</p><h1 id="汇总到一起"><a href="#汇总到一起" class="headerlink" title="汇总到一起"></a>汇总到一起</h1><p>接下来的例子，我们将所有东西都放在一起构建一个简单的Runnable任务，该任务初始化消费者，订阅一组topic，无限循环地执行poll，直到在外面关闭</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerLoop</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> KafkaConsumer&lt;String, String&gt; consumer;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> List&lt;String&gt; topics;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> id;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">ConsumerLoop</span><span class="params">(<span class="keyword">int</span> id,</span></span></span><br><span class="line"><span class="function"><span class="params">                      String groupId, </span></span></span><br><span class="line"><span class="function"><span class="params">                      List&lt;String&gt; topics)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.id = id;</span><br><span class="line">    <span class="keyword">this</span>.topics = topics;</span><br><span class="line">    Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">    props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</span><br><span class="line">    props.put(“group.id”, groupId);</span><br><span class="line">    props.put(“key.deserializer”, StringDeserializer.class.getName());</span><br><span class="line">    props.put(“value.deserializer”, StringDeserializer.class.getName());</span><br><span class="line">    <span class="keyword">this</span>.consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      consumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">        ConsumerRecords&lt;String, String&gt; records = consumer.poll(Long.MAX_VALUE);</span><br><span class="line">        <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">          Map&lt;String, Object&gt; data = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">          data.put(<span class="string">"partition"</span>, record.partition());</span><br><span class="line">          data.put(<span class="string">"offset"</span>, record.offset());</span><br><span class="line">          data.put(<span class="string">"value"</span>, record.value());</span><br><span class="line">          System.out.println(<span class="keyword">this</span>.id + <span class="string">": "</span> + data);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (WakeupException e) &#123;</span><br><span class="line">      <span class="comment">// ignore for shutdown </span></span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      consumer.close();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">shutdown</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    consumer.wakeup();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>要测试这个用例，你要运行release 0.9.0.0版本的kafka，和一个用字符串数据的topic，最简单的方式使用kafka-verifiable-producer.sh监本写一批数据到一个topic。为了更有意思，我们应该确保topic有多个分区，这样一个消费者就不需要做所有事（？？）。例如，一个broker和Zookeeper都运行在本地，你可能会做以下的事：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># bin/kafka-topics.sh --create --topic consumer-tutorial --replication-factor 1 --partitions 3 --zookeeper localhost:2181</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># bin/kafka-verifiable-producer.sh --topic consumer-tutorial --max-messages 200000 --broker-list localhost:9092</span></span><br></pre></td></tr></table></figure><p>然后我们创建一个小的驱动来创建一个含有三个消费者的消费者组，都订阅了我们刚刚创建的topic<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123; </span><br><span class="line">  <span class="keyword">int</span> numConsumers = <span class="number">3</span>;</span><br><span class="line">  String groupId = <span class="string">"consumer-tutorial-group"</span></span><br><span class="line">  List&lt;String&gt; topics = Arrays.asList(<span class="string">"consumer-tutorial"</span>);</span><br><span class="line">  ExecutorService executor = Executors.newFixedThreadPool(numConsumers);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">final</span> List&lt;ConsumerLoop&gt; consumers = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numConsumers; i++) &#123;</span><br><span class="line">    ConsumerLoop consumer = <span class="keyword">new</span> ConsumerLoop(i, groupId, topics);</span><br><span class="line">    consumers.add(consumer);</span><br><span class="line">    executor.submit(consumer);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  Runtime.getRuntime().addShutdownHook(<span class="keyword">new</span> Thread() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">for</span> (ConsumerLoop consumer : consumers) &#123;</span><br><span class="line">        consumer.shutdown();</span><br><span class="line">      &#125; </span><br><span class="line">      executor.shutdown();</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        executor.awaitTermination(<span class="number">5000</span>, TimeUnit.MILLISECONDS);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">        e.printStackTrace;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这个例子向线程池提交了3个consumer线程，每个线程都分配了一个id，这样你可以观察到是哪个线程在接收数据，当你关闭应用时，将会执行shutdown hook，它会用wakeup暂停三个线程，并等待它们关闭。运行之后，你讲看到许多来自线程中的数据，下面是一个样例：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2</span>: &#123;partition=<span class="number">0</span>, offset=<span class="number">928</span>, value=<span class="number">2786</span>&#125;</span><br><span class="line"><span class="number">2</span>: &#123;partition=<span class="number">0</span>, offset=<span class="number">929</span>, value=<span class="number">2789</span>&#125;</span><br><span class="line"><span class="number">1</span>: &#123;partition=<span class="number">2</span>, offset=<span class="number">297</span>, value=<span class="number">891</span>&#125;</span><br><span class="line"><span class="number">2</span>: &#123;partition=<span class="number">0</span>, offset=<span class="number">930</span>, value=<span class="number">2792</span>&#125;</span><br><span class="line"><span class="number">1</span>: &#123;partition=<span class="number">2</span>, offset=<span class="number">298</span>, value=<span class="number">894</span>&#125;</span><br><span class="line"><span class="number">2</span>: &#123;partition=<span class="number">0</span>, offset=<span class="number">931</span>, value=<span class="number">2795</span>&#125;</span><br><span class="line"><span class="number">0</span>: &#123;partition=<span class="number">1</span>, offset=<span class="number">278</span>, value=<span class="number">835</span>&#125;</span><br><span class="line"><span class="number">2</span>: &#123;partition=<span class="number">0</span>, offset=<span class="number">932</span>, value=<span class="number">2798</span>&#125;</span><br><span class="line"><span class="number">0</span>: &#123;partition=<span class="number">1</span>, offset=<span class="number">279</span>, value=<span class="number">838</span>&#125;</span><br><span class="line"><span class="number">1</span>: &#123;partition=<span class="number">2</span>, offset=<span class="number">299</span>, value=<span class="number">897</span>&#125;</span><br><span class="line"><span class="number">1</span>: &#123;partition=<span class="number">2</span>, offset=<span class="number">300</span>, value=<span class="number">900</span>&#125;</span><br><span class="line"><span class="number">1</span>: &#123;partition=<span class="number">2</span>, offset=<span class="number">301</span>, value=<span class="number">903</span>&#125;</span><br><span class="line"><span class="number">1</span>: &#123;partition=<span class="number">2</span>, offset=<span class="number">302</span>, value=<span class="number">906</span>&#125;</span><br><span class="line"><span class="number">1</span>: &#123;partition=<span class="number">2</span>, offset=<span class="number">303</span>, value=<span class="number">909</span>&#125;</span><br><span class="line"><span class="number">1</span>: &#123;partition=<span class="number">2</span>, offset=<span class="number">304</span>, value=<span class="number">912</span>&#125;</span><br><span class="line"><span class="number">0</span>: &#123;partition=<span class="number">1</span>, offset=<span class="number">280</span>, value=<span class="number">841</span>&#125;</span><br><span class="line"><span class="number">2</span>: &#123;partition=<span class="number">0</span>, offset=<span class="number">933</span>, value=<span class="number">2801</span>&#125;</span><br></pre></td></tr></table></figure></p><p>这些展示了三个分区交叉消费情况，每个分区分配给了一个消费者线程，在每个分区里，正如预期的显示了offset的增加，你可以用Ctrl+C或者通过你的IDE来终止进程。</p><h1 id="消费者活力-求生欲"><a href="#消费者活力-求生欲" class="headerlink" title="消费者活力(求生欲?)"></a>消费者活力(求生欲?)</h1><p>当作为消费者组的一部分时，每个消费者都会从其订阅的主题中分配分区的一个子集。通常是分区上的一组锁，只要持有锁，就没有其他消费者读取它们。当你的消费者是健康的，这就是你想要的结果。这是你避免重复消费的唯一方式。但如果消费者由于机器或应用死亡，你需要锁被释放，以便分配给其它的健康消费者</p><p>笔者解读：对于一个消费者组来说，一个分区只能被一个消费者消费，作者想表达的是读取时加锁，防止别的消费者读取，实现了消费者之间避免重复消费</p><p>kafka的组协调者协议使用心跳机制来解决这个问题，每次rebalance之后，当代所有的消费者开始发送周期性的心跳给组协调者，只要协调者继续接收心跳，它就会假定消费者是健康的，每收到一次心跳，协调者就会开启或重置一个计时器，如果计时器过期了还没有心跳，协调者就会标记这个消费者死亡了，给组内其余成员发送重新入组的信号，以便分区被重新分配，这个计时器的间隔被称为session timeOut，在客户端通过以下方式配置：session.timeout.ms<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">props.put(“session.timeout.ms”, “<span class="number">60000</span>”);</span><br></pre></td></tr></table></figure></p><p>会话过期保证在机器，应用崩溃，或消费者与协调者之间的网络被隔离的情况下释放锁，但是应用失败有点棘手，因为消费者仍在发送心跳给协调者，并不表明应用时健康的</p><p>consumer的poll方法旨在解决这个问题，当你调用poll或者其它阻塞API时，所有的网络IO都在前台完成(？？)。consumer从不使用后台线程，这表示在你调用poll时只有心跳发送给了协调者，当你的应用停止poll(抛出异常或是下有系统挂了)时，就不再发送心跳，会话就会过期，组内开始rebalance。<br>唯一的问题是如果消费者处理消息的时间超过了会话过期时间就会触发一次假的rebalance，你应该因此将session timeout设置的足够大，来使这不太可能发送，默认是30秒，但设置成几分钟也是没道理的。更大的session timeout的缺点是，协调者将会更多的时间检测到消费者真的挂了的情况</p><h1 id="消息传递语义"><a href="#消息传递语义" class="headerlink" title="消息传递语义"></a>消息传递语义</h1><p>当消费者组首次创建，根据auto.offset.reset设置的值来初始化位移，一旦消费者开始执行，它会根据应用需要定期的提交位移。在每个后来的rebalance之后，分区的位移会被设置到上一次组提交的位置上，如果consumer在成功处理消息，却又在提交之前崩溃了，结果是另一个consumer会重复复工作。你提交的越频繁，你在崩溃期间看到的重复消费就越少。</p><p>在目前为止的例子中，我们假设自动提交是开启的。当前enable.auto.commit为true(默认值),consumer会根据auto.commit.interval.ms设置的值，周期性的自动提交位移。通过较少提交间隔的方式，你可以限制在consumer崩溃时的重复消费数量。</p><p>为了使用提交的API，首先你应该禁止位移自动提交，设置enable.auto.commit为false</p>]]></content>
      
      <categories>
          
          <category> Kafka Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> 中间件 </tag>
            
            <tag> 翻译 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>java 8日期类学习</title>
      <link href="/2019/01/18/java-8%E6%97%A5%E6%9C%9F%E7%B1%BB%E5%AD%A6%E4%B9%A0/"/>
      <url>/2019/01/18/java-8%E6%97%A5%E6%9C%9F%E7%B1%BB%E5%AD%A6%E4%B9%A0/</url>
      <content type="html"><![CDATA[<blockquote><p>最近开发过程中遇到了很多时间类处理，由于对Calender类不熟悉，我说这个类设计的烂，谁赞成，谁反对？也被推荐过joda-time类库，鉴于项目用的都是java 8了，是时候了解一下java.time包下的类了</p></blockquote><h1 id="导言"><a href="#导言" class="headerlink" title="导言"></a>导言</h1><h2 id="java-8-日期类的优势"><a href="#java-8-日期类的优势" class="headerlink" title="java 8 日期类的优势"></a>java 8 日期类的优势</h2><p>用完java 8的API之后，只有一个感觉：爽，没有啰嗦的方法，很多静态工厂方法，of，from见名知意，用到后面，一些api自己都可以猜出来了，同时api更人性化，例如对比之前的获取月份方法，是从0开始，机械化的思维，反观java 8，我能通过getMonthValue直接获取，无须+1</p><p>对于joda-time，从个人角度讲，实在不想再去记忆一套api，同时从项目角度来说，我能用jdk实现的，为什么要依赖第三方jar包，这点对于实际开发来说更重要。但对于还在使用java 8以下版本的同学joda-time还是值得推荐的</p><h2 id="API的记忆方法"><a href="#API的记忆方法" class="headerlink" title="API的记忆方法"></a>API的记忆方法</h2><p>在Effective java读书笔记一文中，静态方法相较构造方法有更多的优势，尤其是在提供给开发者使用时。java 8这方面做得很好，of，from，parse，format，minus，plus等等都是见名知意的方法</p><h2 id="时间分类"><a href="#时间分类" class="headerlink" title="时间分类"></a>时间分类</h2><p>java 8提供了3个基础时间类：LocalDate, LocalDateTime, LocalTime，分别代表日期，日期+时间，时间(时分秒)</p><p>同时三者之间可以部分转换，之所以称之为部分，很简单的例子是日期无法直接转换为具体的日期+时间，因为它缺少时分秒，这可以理解为一种精度损失，当然你可以通过默认值来补全</p><p>Instant表示瞬时时间，精确到毫秒，可用于记录时间戳</p><p>java 8支持通过时区id，时区偏移量来获取时间</p><p>在实际开发中我们关注的有以下几个方面的时间：</p><ol><li>时间戳，既有毫秒，也有秒，秒主要是PHP等服务返回的标准时间戳</li><li>Date，不要忘了数据库对应的实体中，使用的时间对象仍是Date</li><li>待格式化的字符串，很常见的需求，将字符串解析为时间，或是将时间格式化为文本<br>这几个方面时间的互相转换也需要关注</li></ol><h1 id="API"><a href="#API" class="headerlink" title="API"></a>API</h1><h2 id="获取时间"><a href="#获取时间" class="headerlink" title="获取时间"></a>获取时间</h2><h3 id="now"><a href="#now" class="headerlink" title="now"></a>now</h3><p>now方法用于获取日期类的当前值，例如LocalDate获取当前日期，LocalTime获取当前时间的时分秒等信息</p><h3 id="获取年月日"><a href="#获取年月日" class="headerlink" title="获取年月日"></a>获取年月日</h3><p>根据常识，仅LocalDate, LocalDateTime可以获取年月日，分别由getYear,getMonthValue,getDayOfMonth获取，时分秒的获取方式同理LocalDateTime</p><h3 id="获取自1970-01-01T00-00-00的毫秒数，秒数，天数"><a href="#获取自1970-01-01T00-00-00的毫秒数，秒数，天数" class="headerlink" title="获取自1970-01-01T00:00:00的毫秒数，秒数，天数"></a>获取自1970-01-01T00:00:00的毫秒数，秒数，天数</h3><p>不用死记硬背，只要想清楚这几个类分别代表了什么类型的时间即可推断出api<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Instant.now().toEpochMilli();</span><br><span class="line">LocalDateTime.now().toEpochSecond(ZoneOffset.ofHours(<span class="number">8</span>));</span><br><span class="line">LocalDate.now().toEpochDay();</span><br></pre></td></tr></table></figure></p><p>ZoneOffset.ofHours(8)可以理解为北京时间位于东八区</p><h3 id="获取前一天，一个月，一年等等"><a href="#获取前一天，一个月，一年等等" class="headerlink" title="获取前一天，一个月，一年等等"></a>获取前一天，一个月，一年等等</h3><p>记住两个单词即可，minus表示减，plus表示加<br>至于你想加减些什么，首先要确定要加减的单位是什么，比如分钟，那肯定是在LocalDateTime，LocalTime里找，加年，加月同理，剩下的api就不啰嗦了，授人以鱼不如授人以渔，读者有兴趣自己探索。</p><h2 id="时间转换"><a href="#时间转换" class="headerlink" title="时间转换"></a>时间转换</h2><h3 id="文本与时间之间的相互转换"><a href="#文本与时间之间的相互转换" class="headerlink" title="文本与时间之间的相互转换"></a>文本与时间之间的相互转换</h3><p>parse用于处理从文本到日期的转换，根据DateTimeFormatter的格式解析成日期<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LocalDate date = LocalDate.parse(<span class="string">"2019-01-11"</span>, DateTimeFormatter.ofPattern(<span class="string">"yyyy-MM-dd"</span>))</span><br></pre></td></tr></table></figure></p><p>yyyy-MM-dd是默认的格式，可以省略第二个参数，类似的HH:mm:ss在转换为时分秒时也可以省略</p><p>将日期格式化为文本<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">String text = LocalDate.now().format(DateTimeFormatter.ofPattern(<span class="string">"yyyy-MM-dd"</span>))</span><br></pre></td></tr></table></figure></p><h3 id="时间戳与时间之间的转换"><a href="#时间戳与时间之间的转换" class="headerlink" title="时间戳与时间之间的转换"></a>时间戳与时间之间的转换</h3><p>注意两点：</p><ol><li><p>Instant用于表示瞬时值，它和秒，毫秒是相关联的，再将Instant转换为LocalDateTime</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> time = <span class="number">1548154964271L</span>;</span><br><span class="line">Instant instant = Instant.ofEpochMilli(time);</span><br><span class="line">LocalDateTime dateTime = LocalDateTime.ofInstant(instant, ZoneId.systemDefault());</span><br></pre></td></tr></table></figure></li><li><p>需要判断时间戳是毫秒还是秒，PHP等语言只能精确到秒，请求这类接口时需注意<br>给出一个转换方法示例</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> MAX_TIME_STAMP = <span class="number">10000_000_000L</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> MIN_TIME_STAMP = <span class="number">1000_000_000L</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Instant <span class="title">transToInstant</span><span class="params">(<span class="keyword">long</span> time)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (time &lt; MAX_TIME_STAMP &amp;&amp; time &gt; MIN_TIME_STAMP) &#123;</span><br><span class="line">        <span class="keyword">return</span> Instant.ofEpochSecond(time);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (time &lt; MAX_TIME_STAMP * <span class="number">1000</span> &amp;&amp; time &gt; MIN_TIME_STAMP * <span class="number">1000</span>)&#123;</span><br><span class="line">        <span class="keyword">return</span> Instant.ofEpochMilli(time);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"illegal time value"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h3 id="与Date类的转换"><a href="#与Date类的转换" class="headerlink" title="与Date类的转换"></a>与Date类的转换</h3><p>记住一点，旧版的Date与java 8中的日期类的转换桥梁是Instant<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Date date = Date.from(LocalDateTime.now().atZone(ZoneId.systemDefault()).toInstant());</span><br><span class="line"></span><br><span class="line">LocalDateTime dateTime = date.toInstant().atZone(ZoneId.systemDefault()).toLocalDateTime();</span><br></pre></td></tr></table></figure></p><h2 id="获取时间段"><a href="#获取时间段" class="headerlink" title="获取时间段"></a>获取时间段</h2><p>Period和ChronoUnit都可以做到计算时间段，但又有区别，下面以计算两个时间时间的天数为例<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Period period = Period.between(LocalDate.of(<span class="number">2017</span>, <span class="number">1</span>, <span class="number">19</span>), LocalDate.of(<span class="number">2019</span>, <span class="number">5</span>, <span class="number">10</span>));</span><br><span class="line"><span class="keyword">long</span> days = ChronoUnit.DAYS.between(LocalDate.of(<span class="number">2017</span>, <span class="number">1</span>, <span class="number">19</span>), LocalDate.of(<span class="number">2019</span>, <span class="number">5</span>, <span class="number">10</span>));</span><br></pre></td></tr></table></figure></p><p>Period返回的是两个日期之间相差几年几月几日，以上面两个日期为例，以下三个方法分别返回: 2年, 3个月, 21天<br>period.getYears(),period.getMonths(),period.getDays()</p><p>ChronoUnit则计算出了两个日期直接具体的天数，结果为841天</p><h2 id="与周相关的几个API"><a href="#与周相关的几个API" class="headerlink" title="与周相关的几个API"></a>与周相关的几个API</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">LocalDate now = LocalDate.now();</span><br><span class="line"><span class="comment">// 今天是周几</span></span><br><span class="line">DayOfWeek dayOfWeek = now.getDayOfWeek();</span><br><span class="line"><span class="comment">// 获取下周一</span></span><br><span class="line">LocalDate nextMonday = now.with(TemporalAdjusters.next(DayOfWeek.MONDAY));</span><br><span class="line"><span class="comment">// 获取本月最后一天</span></span><br><span class="line">LocalDate lastDayofMonth = now.with(TemporalAdjusters.lastDayOfMonth());</span><br><span class="line"><span class="comment">// 获取本周属于当月第几周</span></span><br><span class="line"><span class="keyword">int</span> weekth = now.get(ChronoField.ALIGNED_WEEK_OF_MONTH);</span><br></pre></td></tr></table></figure><p>打印输出为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dayOfWeek = TUESDAY</span><br><span class="line">nextMonday = 2019-05-06</span><br><span class="line">lastDayofMonth = 2019-04-30</span><br><span class="line">weekth = 5</span><br></pre></td></tr></table></figure></p><p>以前是笔者开发中遇到的api，还有很多有用的api未介绍，大家可以用到时查阅文档</p><h1 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h1><p>java 8时间类的使用写到这里告一段落，关于时区的使用，也见缝插针的介绍了下，写这篇文章对笔者最大的挑战是表达能力，api很多，我想表达的是有规律的使用api，而不是死记硬背，最后分享一个自己写的DateUtils</p><h1 id="DateUtils"><a href="#DateUtils" class="headerlink" title="DateUtils"></a>DateUtils</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 舍弃对Calendar，joda-time的依赖，用java 8重写</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> yangjie</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createTime</span> 2019/1/17</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span> 1.0.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DateUtils</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> LocalDate today = LocalDate.now();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> LocalDateTime now = LocalDateTime.now();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String GENERAL_PATTERN = <span class="string">"yyyy-MM-dd HH:mm:ss"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String GENERAL_DATE_PATTERN = <span class="string">"yyyy-MM-dd"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> MAX_TIME_STAMP = <span class="number">10000_000_000L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> MIN_TIME_STAMP = <span class="number">1000_000_000L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/***</span></span><br><span class="line"><span class="comment">     * 分别获取年月日的值</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> &lt;L, M, R&gt; <span class="function">Triple&lt;Integer, Integer, Integer&gt; <span class="title">getYearMonthDay</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ImmutableTriple.of(today.getYear(), today.getMonthValue(), today.getDayOfMonth());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取日期文本</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getDateText</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> today.format(DateTimeFormatter.ofPattern(GENERAL_DATE_PATTERN));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取时间本文</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getDateTimeText</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> now.format(DateTimeFormatter.ofPattern(GENERAL_PATTERN));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 根据毫秒数获取时间文本</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getDateTimeText</span><span class="params">(<span class="keyword">long</span> time)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> now.format(DateTimeFormatter.ofPattern(GENERAL_PATTERN));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 给定日期是否是今日</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isToday</span><span class="params">(String time)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> LocalDate.parse(time).isEqual(today);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 当前时间戳是否是今天</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isToday</span><span class="params">(<span class="keyword">long</span> time)</span> </span>&#123;</span><br><span class="line">        LocalDate date = LocalDateTime.ofInstant(transToInstant(time), ZoneId.systemDefault()).toLocalDate();</span><br><span class="line">        <span class="keyword">return</span> date.isEqual(today);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取n天之前至今的时间段</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Pair&lt;Long, Long&gt; <span class="title">getDaysAgoTime</span><span class="params">(Integer days)</span> </span>&#123;</span><br><span class="line">        LocalDate localDate = LocalDate.now().minusDays(days);</span><br><span class="line">        <span class="keyword">long</span> begin = localDate.atTime(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>).toEpochSecond(ZoneOffset.ofHours(<span class="number">8</span>));</span><br><span class="line">        <span class="keyword">long</span> end = localDate.atTime(<span class="number">23</span>, <span class="number">59</span>, <span class="number">59</span>).toEpochSecond(ZoneOffset.ofHours(<span class="number">8</span>));</span><br><span class="line">        <span class="keyword">return</span> ImmutablePair.of(begin, end);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取两个时间段区间 00:00:00 - 23:59:59</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Pair&lt;Long, Long&gt; <span class="title">getDurationPair</span><span class="params">(String beginStr, String endStr)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> begin = LocalDate.parse(beginStr, DateTimeFormatter.ofPattern(GENERAL_DATE_PATTERN)).atTime(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>).toEpochSecond(ZoneOffset.ofHours(<span class="number">8</span>));</span><br><span class="line">        <span class="keyword">long</span> end = LocalDate.parse(endStr, DateTimeFormatter.ofPattern(GENERAL_DATE_PATTERN)).atTime(<span class="number">23</span>, <span class="number">59</span>, <span class="number">59</span>).toEpochSecond(ZoneOffset.ofHours(<span class="number">8</span>));</span><br><span class="line">        <span class="keyword">return</span> ImmutablePair.of(begin, end);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取两个时间段之间的天数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">long</span> <span class="title">getBetweenDays</span><span class="params">(<span class="keyword">long</span> start, <span class="keyword">long</span> end)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ChronoUnit</span><br><span class="line">                .DAYS</span><br><span class="line">                .between(</span><br><span class="line">                        LocalDateTime.ofInstant(transToInstant(start), ZoneId.systemDefault()),</span><br><span class="line">                        LocalDateTime.ofInstant(transToInstant(end), ZoneId.systemDefault())</span><br><span class="line">                );</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取两个时间段之间的天数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">long</span> <span class="title">getBetweenDays</span><span class="params">(String start, String end)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ChronoUnit.DAYS.between(LocalDate.parse(start), LocalDate.parse(end));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取两个时间段之间的所有日期</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> List&lt;String&gt; <span class="title">getBetweenDates</span><span class="params">(String start, String end)</span> </span>&#123;</span><br><span class="line">        List&lt;String&gt; list = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        LocalDate startDate = LocalDate.parse(start);</span><br><span class="line">        LocalDate endDate = LocalDate.parse(end);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> distance = ChronoUnit.DAYS.between(startDate, endDate);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (distance &lt; <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> list;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (distance == <span class="number">0</span>) &#123;</span><br><span class="line">            list.add(start);</span><br><span class="line">            <span class="keyword">return</span> list;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Stream.iterate(startDate, d -&gt; d.plusDays(<span class="number">1</span>)).limit(distance + <span class="number">1</span>).forEach(f -&gt; &#123;</span><br><span class="line">            list.add(f.toString());</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">return</span> list;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 技术积累 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 积累 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Guava实现大数据量sql分段批量插入</title>
      <link href="/2019/01/18/Guava%E5%AE%9E%E7%8E%B0%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%87%8Fsql%E5%88%86%E6%AE%B5%E6%89%B9%E9%87%8F%E6%8F%92%E5%85%A5/"/>
      <url>/2019/01/18/Guava%E5%AE%9E%E7%8E%B0%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%87%8Fsql%E5%88%86%E6%AE%B5%E6%89%B9%E9%87%8F%E6%8F%92%E5%85%A5/</url>
      <content type="html"><![CDATA[<blockquote><p>最近做一个数据拉取的需求，由于有上万的数据量，想到分段批量插入数据库，经同事推荐，Guava有好的工具类，特此记录并分享给大家</p></blockquote><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>一开始在网上搜索，基本用到的都是List接口的sublist方法，第一版自己实现了一遍，功能没问题，但很啰嗦，下面介绍guava的partition方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 分段批量插入</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> ticketLists</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">batchSegmentInsertList</span><span class="params">(List&lt;TicketList&gt; ticketLists)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(CollectionUtils.isEmpty(ticketLists))&#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    List&lt;List&lt;TicketList&gt;&gt; lists = Lists.partition(ticketLists,<span class="number">1000</span>);</span><br><span class="line">    lists.forEach(tickets -&gt;&#123;</span><br><span class="line">        ticketListDao.batchInsert(tickets);</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码是笔者实际开发中的代码，首先需要自己在mybatis中实现批量插入，然后使用Lists.partition方法对原有的集合做分段，1000代表分段大小</p><h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><p>进入partition源码，省略中间多余过程，最终发现一个静态类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Partition</span>&lt;<span class="title">T</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractList</span>&lt;<span class="title">List</span>&lt;<span class="title">T</span>&gt;&gt;</span></span><br></pre></td></tr></table></figure><p>其实现了AbstractList，有趣的是泛型参数是List<t>，结合ArrayList类的实现，该泛型参数代表集合的一个元素，说明Partition本身是一个集合，里面的元素是一个个的小集合，结合我们要实现的功能，说明这就是我们要的对大集合切割之后的每一个小集合，而下面的get方法也佐证了我们的猜想</t></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> List&lt;T&gt; <span class="title">get</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">  checkElementIndex(index, size());</span><br><span class="line">  <span class="keyword">int</span> start = index * size;</span><br><span class="line">  <span class="keyword">int</span> end = Math.min(start + size, list.size());</span><br><span class="line">  <span class="keyword">return</span> list.subList(start, end);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同时还可以看出Partition底层还是用的sublist方法，不过最后我想说的还是那句老话，不要重复造轮子，遇到这种大批量sql分段插入，你肯定不是第一个人遇到，多用大牛写好的轮子，同时去看看他们是如何实现的，解放生产力的同时，也提升自己的技术</p>]]></content>
      
      <categories>
          
          <category> 技术积累 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 积累 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring boot实践之自定义starter</title>
      <link href="/2019/01/16/Spring-boot%E5%AE%9E%E8%B7%B5%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89starter/"/>
      <url>/2019/01/16/Spring-boot%E5%AE%9E%E8%B7%B5%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89starter/</url>
      <content type="html"><![CDATA[<blockquote><p>为何要自定义starter，使用场景是什么，又该如何去自定义呢？本文围绕这几个方面展示自定义starter的过程</p></blockquote><h1 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h1><p>在Spring-Boot实践系列文章中，对日常开发中的许多功能做了统一封装，那么在分布式开发的组织架构下，开发组内个人单独使用是没有意义的，应该将其封装成一个SDK，发布到maven私服，供大家使用，分享精神先放一边，这样做的好处是统一标准，提升开发效率，同时又需要投入部分人力维护这个项目，不断更新和修复。</p><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><p>项目是一个多模块结构，不同的公共模块封装各自的公用功能，例如可以把统一的接口请求，返回，日志等放到web模块，对监控有要求的可以抽取一个监控模块，依赖了中间件时，对该中间的公用配置抽取一个模块。</p><p>项目名称可参考spring-cloud组件，例如叫base-starter-web, base-start-logger等</p><h1 id="封装starter"><a href="#封装starter" class="headerlink" title="封装starter"></a>封装starter</h1>]]></content>
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring boot实践之多数据源最佳实践</title>
      <link href="/2019/01/05/Spring-boot%E5%AE%9E%E8%B7%B5%E4%B9%8B%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
      <url>/2019/01/05/Spring-boot%E5%AE%9E%E8%B7%B5%E4%B9%8B%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</url>
      <content type="html"><![CDATA[<blockquote><p>多数据源主要用于mysql主从，多库等场景，笔者初始接触时也在网上找了很多资料如何配置，但做法百花齐放，有很多用到了ThreadLocal，注解，数据源路由等技术，最终选择了一个简单，易用，易理解的方式：每一个数据源只扫描自己的mapper</p></blockquote><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>基于以上思想，只需要以下步骤：</p><ol><li>配置文件中采用不同的前缀配置各个数据源</li><li>为每个数据源初始化DataSource，SqlSessionFactory，TransactionManager</li><li>每个数据源都有自己的配置，扫描自己的mapper.xml，DAO接口</li></ol><h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><h3 id="数据源配置"><a href="#数据源配置" class="headerlink" title="数据源配置"></a>数据源配置</h3><p>注意，笔者遇到的情况是多库，以订单库和用户库举例，如果是主从，可以起名master，slave<br>配置文件如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#db1</span><br><span class="line">spring.datasource.default.url = jdbc:mysql://localhost:3306/order?characterEncoding=utf-8&amp;connectTimeout=2000&amp;socketTimeout=2000&amp;zeroDateTimeBehavior=convertToNull</span><br><span class="line">spring.datasource.default.username = root</span><br><span class="line">spring.datasource.default.password = 123</span><br><span class="line"></span><br><span class="line">#db2</span><br><span class="line">spring.datasource.user.url = jdbc:mysql://localhost:3306/user?characterEncoding=utf-8&amp;connectTimeout=2000&amp;socketTimeout=2000&amp;zeroDateTimeBehavior=convertToNull</span><br><span class="line">spring.datasource.user.username = root</span><br><span class="line">spring.datasource.user.password = 123</span><br></pre></td></tr></table></figure><h3 id="配置数据源相关对象"><a href="#配置数据源相关对象" class="headerlink" title="配置数据源相关对象"></a>配置数据源相关对象</h3><h4 id="抽取公共类"><a href="#抽取公共类" class="headerlink" title="抽取公共类"></a>抽取公共类</h4><p>如果数据源很多，建议抽取公共类，封装一些公共方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BaseDataSourceConfig</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 初始化SqlSessionFactory</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> dataSource 数据源</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> location mapper.xml位置</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> SqlSessionFactory</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">SqlSessionFactory <span class="title">getSqlSessionFactory</span><span class="params">(DataSource dataSource, String location)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> SqlSessionFactoryBean sqlSessionFactoryBean = <span class="keyword">new</span> SqlSessionFactoryBean();</span><br><span class="line">        sqlSessionFactoryBean.setDataSource(dataSource);</span><br><span class="line">        sqlSessionFactoryBean.setConfiguration(configuration());</span><br><span class="line">        sqlSessionFactoryBean.setMapperLocations(<span class="keyword">new</span> PathMatchingResourcePatternResolver()</span><br><span class="line">                .getResources(location));</span><br><span class="line">        <span class="keyword">return</span> sqlSessionFactoryBean.getObject();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 配置下划线转驼峰</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Configuration <span class="title">configuration</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">        configuration.setMapUnderscoreToCamelCase(<span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">return</span> configuration;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="配置主数据源"><a href="#配置主数据源" class="headerlink" title="配置主数据源"></a>配置主数据源</h4><p>将order库作为项目的主数据源,@MapperScan用于扫描DAO接口，MAPPER_LOCATION传入父类指定mapper.xml位置<br>同时@Primary标注这是我们项目的主数据源<br><code>@ConfigurationProperties(&quot;spring.datasource.default&quot;)</code> 表示数据源配置采用的前缀</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@MapperScan</span>(basePackages = <span class="string">"com.ttyc.dao.order"</span>, sqlSessionFactoryRef = <span class="string">"defaultSqlSessionFactory"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DefaultDataSourceConfig</span> <span class="keyword">extends</span> <span class="title">BaseDataSourceConfig</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String MAPPER_LOCATION = <span class="string">"classpath:mapper/order/*.xml"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Primary</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="meta">@ConfigurationProperties</span>(<span class="string">"spring.datasource.default"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> DataSource <span class="title">defaultDataSource</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> DruidDataSourceBuilder.create()</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Primary</span></span><br><span class="line">    <span class="meta">@Bean</span>(name = <span class="string">"defaultSqlSessionFactory"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> SqlSessionFactory <span class="title">defaultSqlSessionFactory</span><span class="params">(@Qualifier(<span class="string">"defaultDataSource"</span>)</span> DataSource defaultDataSource)</span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> getSqlSessionFactory(defaultDataSource, MAPPER_LOCATION);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Primary</span></span><br><span class="line">    <span class="meta">@Bean</span>(name = <span class="string">"defaultTransactionManager"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> DataSourceTransactionManager <span class="title">defaultTransactionManager</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">            @Qualifier(<span class="string">"defaultDataSource"</span>)</span> DataSource defaultDataSource) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> DataSourceTransactionManager(defaultDataSource);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同理配置user库数据源，只不过去除@Primary注解，至此配置结束</p><h3 id="如何使用"><a href="#如何使用" class="headerlink" title="如何使用"></a>如何使用</h3><p>正常编程即可，因为数据源已经按路径扫描了DAO接口和mapper.xml文件</p><h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>以微服务的思想，多库是不应该存在的， 每个服务应该数据自治，职责单一，对于user库应该调用用户微服务接口，而不应该访问用户DB，造成耦合，目前笔者遇到的需求属于临时需求，并且将来会废弃该接口，所以从成本考虑，采用直接访问DB的形式，希望大家引以为戒！</p>]]></content>
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring-boot实践之请求日志切面</title>
      <link href="/2019/01/02/Spring-boot%E5%AE%9E%E8%B7%B5%E4%B9%8B%E8%AF%B7%E6%B1%82%E6%97%A5%E5%BF%97%E5%88%87%E9%9D%A2/"/>
      <url>/2019/01/02/Spring-boot%E5%AE%9E%E8%B7%B5%E4%B9%8B%E8%AF%B7%E6%B1%82%E6%97%A5%E5%BF%97%E5%88%87%E9%9D%A2/</url>
      <content type="html"><![CDATA[<blockquote><p>记录请求日志切面的写法，和别人写的相比并无特殊之处</p></blockquote><h1 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h1><h2 id="日志信息"><a href="#日志信息" class="headerlink" title="日志信息"></a>日志信息</h2><p>将controller中方法参数作为请求参数，返回值作为响应，这样做的前提是请求参数和返回值都已使用javabean封装，不一定适合每个人</p><h2 id="耗时统计"><a href="#耗时统计" class="headerlink" title="耗时统计"></a>耗时统计</h2><p>tomcat为每个请求分配一个线程，自然想到使用ThreadLocal保存计时器，最后不要忘了remove</p><h2 id="HttpServletRequest对象的获取"><a href="#HttpServletRequest对象的获取" class="headerlink" title="HttpServletRequest对象的获取"></a>HttpServletRequest对象的获取</h2><p>直接注入即可，Spring底层也是用ThreadLocal实现的，具体实现参考RequestContextHolder</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSON;</span><br><span class="line"><span class="keyword">import</span> lombok.extern.slf4j.Slf4j;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.JoinPoint;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.annotation.*;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.util.StopWatch;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletResponse;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Aspect</span></span><br><span class="line"><span class="meta">@Slf</span>4j</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RequestLogAspect</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ThreadLocal&lt;StopWatch&gt; timer = <span class="keyword">new</span> ThreadLocal&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 线程安全，可直接注入</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    HttpServletRequest request;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    HttpServletResponse response;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Pointcut</span>(<span class="string">"execution(* com.ttyc..controller.*(..))"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">controller</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Before</span>(<span class="string">"controller()"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">beforeRequest</span><span class="params">(JoinPoint joinPoint)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        timer.get().start(<span class="string">"requestTimeKeeperTask"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            log.info(<span class="string">"request url: &#123;&#125;, \nparams are &#123;&#125;"</span>, request.getRequestURI(), JSON.toJSONString(joinPoint.getArgs()[<span class="number">0</span>]));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            log.warn(<span class="string">"转换请求参数时异常"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@AfterReturning</span>(value = <span class="string">"controller()"</span>, returning = <span class="string">"response"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">afterResponse</span><span class="params">(Object response)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> latency = timer.get().getTotalTimeMillis();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            log.info(<span class="string">"response &#123;&#125;\nlatency is &#123;&#125;ms"</span>, JSON.toJSONString(response), latency);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            log.warn(<span class="string">"转换结果时异常"</span>);</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            timer.remove();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@AfterThrowing</span>(value = <span class="string">"controller()"</span>, throwing = <span class="string">"ex"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">afterThrows</span><span class="params">(Throwable ex)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> latency = timer.get().getTotalTimeMillis();</span><br><span class="line"></span><br><span class="line">        log.warn(<span class="string">"请求异常，错误信息为：&#123;&#125;\n 耗时&#123;&#125;ms"</span>, ex.getMessage(), latency);</span><br><span class="line"></span><br><span class="line">        timer.remove();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Effective-java读书笔记(三)：类和接口</title>
      <link href="/2018/11/28/Effective-java%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E4%B8%89-%EF%BC%9A%E7%B1%BB%E5%92%8C%E6%8E%A5%E5%8F%A3/"/>
      <url>/2018/11/28/Effective-java%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E4%B8%89-%EF%BC%9A%E7%B1%BB%E5%92%8C%E6%8E%A5%E5%8F%A3/</url>
      <content type="html"><![CDATA[<h1 id="使类和接口的可访问性最小化"><a href="#使类和接口的可访问性最小化" class="headerlink" title="使类和接口的可访问性最小化"></a>使类和接口的可访问性最小化</h1><p>模块设计原则：对外隐藏内部数据和实现细节，把api和他的实现隔离开来，模块之间通过api通信，一个模块不需要知道其它模块的内部细节，这称之为封装。</p><p>封装有效地让各模块直接解耦，解耦之后模块可以独立的开发，测试，优化，使用及修改。</p><ol><li>尽可能地使每个类或者成员不被外界访问<ol><li>类或接口尽可能的做成包级私有的，在以后的版本中，可以对他修改</li><li>如果你把类做成公有的，你就有责任永远对它负责，保证后续版本的兼任性</li><li>如果一个类只在某个类中使用，则考虑使用嵌套类(nested-class)</li></ol></li></ol><p>如果</p>]]></content>
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Effective java读书笔记(二)：对象通用方法</title>
      <link href="/2018/11/26/Effective-java%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E4%BA%8C-%EF%BC%9A%E5%AF%B9%E8%B1%A1%E9%80%9A%E7%94%A8%E6%96%B9%E6%B3%95/"/>
      <url>/2018/11/26/Effective-java%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E4%BA%8C-%EF%BC%9A%E5%AF%B9%E8%B1%A1%E9%80%9A%E7%94%A8%E6%96%B9%E6%B3%95/</url>
      <content type="html"><![CDATA[<h1 id="对象通用方法"><a href="#对象通用方法" class="headerlink" title="对象通用方法"></a>对象通用方法</h1><h2 id="覆盖equals时的约定"><a href="#覆盖equals时的约定" class="headerlink" title="覆盖equals时的约定"></a>覆盖equals时的约定</h2><p>当类具有特有的”逻辑相等”概念时，必须覆盖equals方法，这样也可以使这个类作为map的key，或者set中的元素</p><p>当对象非null时，equals方法满足以下四个特性：</p><ol><li>自反性：<code>x.equals(x)=true</code></li><li>对称性：<code>x.equals(y)=true</code>时，<code>y.equals(x)</code>必须为true</li><li>传递性：x=y，y=z，则x=z</li><li>一致性：<code>x.equals(y)</code>在多次调用后返回相同的值</li></ol><p>理解即可，不必要记忆</p><h3 id="高效的编写equals方法"><a href="#高效的编写equals方法" class="headerlink" title="高效的编写equals方法"></a>高效的编写equals方法</h3><p>首先了解一个小知识点</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">null</span> <span class="keyword">instanceof</span> Object = <span class="keyword">false</span></span><br></pre></td></tr></table></figure><p>null不属于任何一个类型，所以对equals方法传入的对象不必做空指针判断</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object anObject)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span> == anObject) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (anObject <span class="keyword">instanceof</span> MyClass) &#123;</span><br><span class="line">        MyClass castObj = (MyClass)anObject;</span><br><span class="line">    <span class="comment">// 自己的判断逻辑</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="编写步骤"><a href="#编写步骤" class="headerlink" title="编写步骤"></a>编写步骤</h4><ol><li>首先用==检查参数是否是当前对象</li><li>判断参数是否是要判断的类型，</li><li>将对象强转成要比较的对象类型</li><li>根据类中的字段编写自己的判断逻辑，返回相应的true或false</li></ol><h3 id="与equals"><a href="#与equals" class="headerlink" title="==与equals"></a>==与equals</h3><p>相信很多新手同学分不清这二者的区别，以及使用场景，二者区别如下：</p><ol><li><p>先说基本类型的==判断：值相等就返回true</p></li><li><p>再说引用类型的==：指向同一个对象才返回true</p></li><li><p>最后是equals：在Object里，它和==时一样的，但是类可以有自己的判断依据，比如String类</p></li></ol><h4 id="包装类的比较"><a href="#包装类的比较" class="headerlink" title="包装类的比较"></a>包装类的比较</h4><p>问题：<code>Integer i = 1, Integer j = 1</code>,如何比较二者是否相等?</p><p>答案是<code>i.equals(j)</code>,切不可写成<code>i==j,因为Integer内部采用了缓存，-128至127之间的数字被视为同一个对象，此时是可以通过==判断两个数字是否相等，但这只是假象，超过这个区间的数字就会返回</code>false</p><h2 id="覆盖equals是同时覆盖hashcode"><a href="#覆盖equals是同时覆盖hashcode" class="headerlink" title="覆盖equals是同时覆盖hashcode"></a>覆盖equals是同时覆盖hashcode</h2><h3 id="约定"><a href="#约定" class="headerlink" title="约定"></a>约定</h3><p>Java规范中包含以下约定：</p><ol><li>只要equals中用来判断两个对象是否相等的字段没有发生改变，那么调用多少次返回的结果都应该相同</li><li>如果通过equals判断出两个对象相等，那么它们的hashcode方法的返回值一定相等；如果不相等，那么hashcode方法的返回值不一定不等，但这必然降低了散列表的性能</li></ol><h3 id="编写hashcode方法"><a href="#编写hashcode方法" class="headerlink" title="编写hashcode方法"></a>编写hashcode方法</h3><p>hashcode方法编写的好坏，直接影响对象能否在集合中均匀分布，具体的编写方法见书41页，这里记下注意的几点：</p><ol><li>冗余字段不参与计算与比较，例如单价，数量，总价三者的关系，很明显总价可以通过另外二者计算出来，那么总价不必参与计算hashcode的过程，同时必须也不能参数equals的比较过程</li></ol><h2 id="覆盖toString方法"><a href="#覆盖toString方法" class="headerlink" title="覆盖toString方法"></a>覆盖toString方法</h2><p>toString方法的作用显而易见，如果不覆盖Object中的toString方法，返回<code>类名@对象hashcode十六进制值</code>的表现方式</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">getClass().getName() + <span class="string">"@"</span> + Integer.toHexString(hashCode())</span><br></pre></td></tr></table></figure><p>在实际开发中，toString用于记录日志是必不可少，例如打印用户信息，如果输出原始形式，则毫无价值，我们更关系的是用户id，用户名等关键信息</p><h2 id="谨慎覆盖clone方法"><a href="#谨慎覆盖clone方法" class="headerlink" title="谨慎覆盖clone方法"></a>谨慎覆盖clone方法</h2><h2 id="考虑实现Comparable接口"><a href="#考虑实现Comparable接口" class="headerlink" title="考虑实现Comparable接口"></a>考虑实现Comparable接口</h2>]]></content>
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Effective java读书笔记(一)：对象的创建与销毁篇</title>
      <link href="/2018/11/23/Effective-java%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E4%B8%80-%EF%BC%9A%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E9%94%80%E6%AF%81%E7%AF%87/"/>
      <url>/2018/11/23/Effective-java%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E4%B8%80-%EF%BC%9A%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E9%94%80%E6%AF%81%E7%AF%87/</url>
      <content type="html"><![CDATA[<h1 id="对象的创建与销毁篇"><a href="#对象的创建与销毁篇" class="headerlink" title="对象的创建与销毁篇"></a>对象的创建与销毁篇</h1><h2 id="使用静态工厂创建对象"><a href="#使用静态工厂创建对象" class="headerlink" title="使用静态工厂创建对象"></a>使用静态工厂创建对象</h2><p>创建一个对象最常用的方式是构造方法，但有时也要考虑使用静态工厂创建对象：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserFactory</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> User <span class="title">createUser</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        User user = <span class="keyword">new</span> User();</span><br><span class="line">        user.setName(<span class="string">"tom"</span>);</span><br><span class="line">        <span class="keyword">return</span> user;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>静态工厂的好处有三:</p><ol><li>有名称，不同于构造方法，静态工厂作为一个普通的静态方法，可以使用名称更清晰的表达作者的想法，对比多个构造方法的情况，往往读者看见多个不同参数类型，不同顺序的构造方法时，不知道它们是干什么的，静态工厂使用方法名提高了代码可读性，私以为在企业开发中，多人合作时，面对复杂的业务逻辑，可读性尤为重要</li><li>不必每次都创建一个对象，或者说对象可以被重复利用，例如初始化一个数据库连接对象，不必每次设置用户名密码创建这个对象</li><li>可以使用多态，返回子类类型的对象，例如通过参数来判断应该返回哪种子类型</li></ol><p>同时它也是有缺点的，在看到构造方法时，我们能一眼看出是用于创建对象，但是静态工厂则不一定，因此静态工厂的方法名遵从一些惯用名称：valueOf，getInstance，newInstance等等</p><h2 id="构造方法参数过多时，使用Builder"><a href="#构造方法参数过多时，使用Builder" class="headerlink" title="构造方法参数过多时，使用Builder"></a>构造方法参数过多时，使用Builder</h2><h3 id="Builder是什么"><a href="#Builder是什么" class="headerlink" title="Builder是什么"></a>Builder是什么</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">User tom = User.builder().name(<span class="string">"tom"</span>).age(<span class="number">18</span>).build();</span><br></pre></td></tr></table></figure><h3 id="出现原因"><a href="#出现原因" class="headerlink" title="出现原因"></a>出现原因</h3><p>静态工厂和构造方法都不能很好的解决参数过多时，参数是否必传问题，通常先写一个大而全的参数方法，然后提供多个部分参数方法。</p><p>以静态工厂为例，比如：有三个参数，其中address，age可不传，先写出一个三参数的，然后下面的方法传null来调用</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> User <span class="title">createUser</span><span class="params">(String name, Integer age, String address)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//... </span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> User <span class="title">createUser</span><span class="params">(String name, Integer age)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> createUser(name,age, <span class="keyword">null</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> User <span class="title">createUser</span><span class="params">(String name, String address)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> createUser(name, <span class="keyword">null</span>,address);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样做的弊端很明显，参数多了不利于扩展，不扩展又会导致调用者必须传一些无用的参数，并且代码难以阅读，调用方还容易出错</p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="1-JavaBean"><a href="#1-JavaBean" class="headerlink" title="1.JavaBean"></a>1.JavaBean</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">User user = <span class="keyword">new</span> User();</span><br><span class="line">user.setXxx();</span><br><span class="line"><span class="comment">// ...</span></span><br></pre></td></tr></table></figure><p>通过setter可以很好的避免上述问题，但书中所说JavaBean本身时可变类，无法成为不可变类，在这set的过程中有可能会产生线程安全问题，笔者认为实际业务开发中JavaBean多用于方法形参，属于线程私有，除非定义在成员变量位置，否则线程安全问题极低</p><h4 id="2-Builder模式"><a href="#2-Builder模式" class="headerlink" title="2.Builder模式"></a>2.Builder模式</h4><p>由于Builder模式代码编写很多，我们在实际开发中使用lombok可以更快的达到目的，事先引入依赖</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>JavaBean类上加入<code>@Builder</code>注解，即可像开头那样调用</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Builder</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> Integer age;</span><br><span class="line">    <span class="keyword">private</span> String address;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>如果类的构造方法或者静态工厂有多个参数时，优先考虑Builder模式，特别是某些参数可选时</p><h2 id="使用枚举来创建单例模式"><a href="#使用枚举来创建单例模式" class="headerlink" title="使用枚举来创建单例模式"></a>使用枚举来创建单例模式</h2><p>使用工厂模式创建单例模式分为：懒汉式，饿汉式。使用枚举作为替代主要有以下两个原因</p><ol><li>懒汉式通常需要与double-check配合使用来保证线程安全，而枚举本身就是线程安全的</li><li>工厂模式在对象反序列化无法保证单例，需要重写readResolve，而枚举自动实现了反序列化</li></ol><h3 id="使用枚举创建User单例"><a href="#使用枚举创建User单例" class="headerlink" title="使用枚举创建User单例"></a>使用枚举创建User单例</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> UserSingleton &#123;</span><br><span class="line">    INSTANCE;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> User user;</span><br><span class="line"></span><br><span class="line">    UserSingleton() &#123;</span><br><span class="line">        <span class="keyword">this</span>.user = <span class="keyword">new</span> User();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">showName</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> user.getName();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="枚举的线程安全性"><a href="#枚举的线程安全性" class="headerlink" title="枚举的线程安全性"></a>枚举的线程安全性</h3><p>枚举类在反编译之后，是一个不可变类，因此它是线程安全的</p><h3 id="测试饿汉式的反序列化失效情况"><a href="#测试饿汉式的反序列化失效情况" class="headerlink" title="测试饿汉式的反序列化失效情况"></a>测试饿汉式的反序列化失效情况</h3><p>使用饿汉式创建User单例模式类,并为<code>User</code>类实现<code>Serializable</code>接口</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserSingletonFactory</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">UserSingletonFactory</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> User user = <span class="keyword">new</span> User();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> User <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> user;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException </span>&#123;</span><br><span class="line">    User instance = UserSingletonFactory.getInstance();</span><br><span class="line">    User other = UserSingletonFactory.getInstance();</span><br><span class="line">    <span class="comment">// 此时单例模式的结果返回true</span></span><br><span class="line">    System.out.println(instance == other);</span><br><span class="line">    </span><br><span class="line">    ObjectOutputStream oos =</span><br><span class="line">            <span class="keyword">new</span> ObjectOutputStream(<span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(<span class="string">"obj.txt"</span>)));</span><br><span class="line">    oos.writeObject(instance);</span><br><span class="line">    oos.close();</span><br><span class="line"></span><br><span class="line">    ObjectInputStream ois =</span><br><span class="line">            <span class="keyword">new</span> ObjectInputStream(<span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(<span class="string">"obj.txt"</span>)));</span><br><span class="line">    User user = (User) ois.readObject();</span><br><span class="line">    ois.close();</span><br><span class="line"></span><br><span class="line">    System.out.println(instance == user);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果最后的输出为false</p><h2 id="通过私有的构造方法让类不可实例化"><a href="#通过私有的构造方法让类不可实例化" class="headerlink" title="通过私有的构造方法让类不可实例化"></a>通过私有的构造方法让类不可实例化</h2><h3 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h3><ol><li>私有的构造方法，指用private修饰构造方法</li><li>不可实例化，通过私有的构造方法，让类无法产生对象</li></ol><h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><p>作为一些工具类，例如JDK中的<code>Math</code>类，只希望使用它的静态成员变量和静态方法，所以我们可以看到源码中的Math类构造方法如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Math</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Don't let anyone instantiate this class.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Math</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="避免创建不必要的对象"><a href="#避免创建不必要的对象" class="headerlink" title="避免创建不必要的对象"></a>避免创建不必要的对象</h2><p>原则：尽量重用对象，如果是不可变类产生的对象，那它始终可以被重用</p><p>典型的不可变类如<code>String</code>,只要是相同的字符串，内存中只有一个String对象</p><p>同时有静态工厂和构造器的不可变类，优先使用静态工厂创建对象，静态工厂不会重复创建对象，如</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Boolean.valueOf(<span class="string">"true"</span>);</span><br></pre></td></tr></table></figure><p>优先于</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> Boolean(<span class="string">"true"</span>);</span><br></pre></td></tr></table></figure><p>除了不可变对象，还可以重用那些被认为不会被修改的可变对象，书中用一个日期类举例，将只需要初始化一次的对象放在静态代码块中，在实际开发中，诸如数据库连接池，http client请求线程池等重量级的对象，为了提高性能，必须重用</p><h2 id="清理过期的对象引用"><a href="#清理过期的对象引用" class="headerlink" title="清理过期的对象引用"></a>清理过期的对象引用</h2><p>为了防止内存泄漏，需要将不再使用的对象，解除引用，即obj = null，将引用指向空，让GC回收对象</p><p>例如List的remove方法中的代码片段</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">elementData[--size] = <span class="keyword">null</span>; <span class="comment">// clear to let GC do its work</span></span><br></pre></td></tr></table></figure><p>需要注意的是清除对象引用是在特殊情况下的处理，并不是一种规范，我们在实际开发中并不需要小心翼翼的处理</p><h3 id="何时清除对象引用"><a href="#何时清除对象引用" class="headerlink" title="何时清除对象引用"></a>何时清除对象引用</h3><p>如果类自己管理内存空间，如<code>ArrayList</code>内部使用<code>Object</code>数组存储，一旦其中的元素被删除，则需要清空对象引用</p><h3 id="避免使用finalize方法"><a href="#避免使用finalize方法" class="headerlink" title="避免使用finalize方法"></a>避免使用finalize方法</h3><p>老生常谈的<code>finalize</code>方法问题，不要尝试调用它，GC并不会立即回收对象，甚至不保证执行。经过测试，调用finalize还会降低性能，花费更多的时间销毁对象，书中后面讲解的内容实用性太低，不做记录</p>]]></content>
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>11.22日映客架构师讲座</title>
      <link href="/2018/11/22/11.22%E6%97%A5%E6%98%A0%E5%AE%A2%E6%9E%B6%E6%9E%84%E5%B8%88%E8%AE%B2%E5%BA%A7/"/>
      <url>/2018/11/22/11.22%E6%97%A5%E6%98%A0%E5%AE%A2%E6%9E%B6%E6%9E%84%E5%B8%88%E8%AE%B2%E5%BA%A7/</url>
      <content type="html"><![CDATA[<ol><li>不要把每一个单独的服务优化到极致，心中要有一个架构的演进方向，根据这个方向优化分散的点，如存储，mq，服务等，最终达到一个我们心中理想的架构。同时要融入到公司，理解业务，要有将产品带向好的方向的心态，不是完成上级的任务，产品的需求，常年下来没有进步</li><li>业务服务不要直连DB，应该抽取成基础服务，业务服务都是用基础服务拼接而成的，这样做利于基础服务的扩展</li><li>作为基础服务一定要考虑限流，服务的熔断和降级</li><li>要保证业务的关键路径高可用，其他服务挂了，不能影响它，例如淘宝，下单流程，确认收货流程一定是可用的，提高用户体验</li><li>服务的取舍，比如手机直播，100w用户在一个直播间，当前用户只关心自己送出的礼物，发出的评论有没有显示，这是我们一定要保证的<br>同时，别的用户评论，一秒只显示几百条都是没问题的，丢弃其余的消息，做到流量削峰，保证良好的用户体验</li><li>分布式事务：预占型和给予型。 预占型可以记录日志，重新请求时看有没有日志来判断上一次是否执行成功了；给予型具有延时特性，比如手机转账，总是过几秒才转过来</li><li>分库分表：如何从主从切换到分库分表，先用mysql binlog同步到分库分表中，并进行比对，一直到没有差异为止，ABA问题在多次比对后出现的几率已经很低了，此时线上业务可以将读操作切换到分库分表，因为读是不会产生脏数据的</li><li>云服务的好处：按流量计费，比如某天有秒杀活动，用户量激增，如果是自己的机房，需要增加服务器，等过了这个时间后，流量又下来了，而云服务是按流量计费的，增加缩减机器都十分方便。云服务的不足之处是要和别的企业共享资源，因为稳定性不高，还会有资源限制，如带宽限制，mysql连接数限制</li><li>对恶意用户的思考，比如刷金币，刷粉丝，刷广告等等，是否有必要赶尽杀绝，如果涉黄涉政，必然是要屏蔽的，而例如微博，用户是否也有刷粉丝的实际需要<br>如何防止恶意用户呢，可以用工具，例如内容识别，账号防刷等，但是有效期不长，建议用大数据进行行为特征分析</li><li>需求和开发：施行2周制，第一周产品和开发都是ready状态，产品准备好需求，开发人员开始开发，测试，直到第二周结束上线，同时从第一周开始并行地，开始准备下一轮新的需求，到第二周结束准备好下一轮新需求，以此往复</li><li>定期梳理自己的代码，线上服务正常运行很近，突然出现问题，说”我没动代码啊”，这样做是不对的，没动过并不代表没有隐患，可以每天上下班看一眼自己的业务指标监控(open-falcon)</li><li>线上出现问题的正确做法，立即采取一切手段修复故障，保障用户体验，及时止损，而不是在保护故障现场，排查问题。事后要对故障复盘，并且组内开会讨论，不要抱有职责，内疚的情绪，让组员都从这次问题中成长</li><li>语言和技术栈一定要统一，降低成本</li><li>抽取通用服务，如鉴权，不要每个服务都开发一套</li></ol>]]></content>
      
      <categories>
          
          <category> 架构随笔录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring boot实践之请求参数校验</title>
      <link href="/2018/10/14/Spring-boot%E5%AE%9E%E8%B7%B5%E4%B9%8B%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0%E6%A0%A1%E9%AA%8C/"/>
      <url>/2018/10/14/Spring-boot%E5%AE%9E%E8%B7%B5%E4%B9%8B%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0%E6%A0%A1%E9%AA%8C/</url>
      <content type="html"><![CDATA[<h1 id="Spring-boot实践之请求参数校验"><a href="#Spring-boot实践之请求参数校验" class="headerlink" title="Spring boot实践之请求参数校验"></a>Spring boot实践之请求参数校验</h1><blockquote><p>本文讲述的是后端参数校验，在实际开发中，参数校验是前后端都要做的工作，因为请求接口的人除了普通用户，还有有各路神仙。</p></blockquote><h2 id="常规校验的痛楚"><a href="#常规校验的痛楚" class="headerlink" title="常规校验的痛楚"></a>常规校验的痛楚</h2><p>通常的校验代码如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@PostMapping</span>(<span class="string">"login"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> User <span class="title">login</span><span class="params">(@RequestBody User user)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(StringUtils.isBlank(user.getUsername()))&#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"请输入用户名"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> user;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果还有n个接口需要校验username，你可能会抽取<code>if</code>语句到一个方法中，过段时间你又会发现，不光要校验username，还要password，adress等等一堆字段，总结起来</p><ol><li>重复劳动</li><li>代码冗长，不利于阅读业务逻辑</li><li>出现问题要去不同的接口中查看校验逻辑</li></ol><p>这无疑是件让人崩溃的事情，此时作为一个开发人员，你已经意识到需要一个小而美的工具来解决这个问题，你可以去google，去github搜索这类项目，而不是毫无作为，抑或者是自己去造轮子</p><h2 id="JSR303"><a href="#JSR303" class="headerlink" title="JSR303"></a>JSR303</h2><p>JSR303规范应运而生，其中比较出名的实现就是Hibernate Validator，已包含在<code>spring-boot-starter-web</code>其中,不需要重新引入，<code>javax.validation.constraints</code>包下常用的注解有</p><table><thead><tr><th style="text-align:left">注解</th><th style="text-align:left">含义</th></tr></thead><tbody><tr><td style="text-align:left">@NotNUll</td><td style="text-align:left">值不能为空</td></tr><tr><td style="text-align:left">@Null</td><td style="text-align:left">值必须为空</td></tr><tr><td style="text-align:left">@Pattern(regex=)</td><td style="text-align:left">值必须匹配正则表达式</td></tr><tr><td style="text-align:left">@Size(min=,max=)</td><td style="text-align:left">集合的大小必须在min~max之间，如List，数组</td></tr><tr><td style="text-align:left">@Length(min=,max=)</td><td style="text-align:left">字符串长度</td></tr><tr><td style="text-align:left">@Range(min,max)</td><td style="text-align:left">数字的区间范围</td></tr><tr><td style="text-align:left">@NotBlank</td><td style="text-align:left">字符串必须有字符</td></tr><tr><td style="text-align:left">@NotEmpty</td><td style="text-align:left">集合必须有元素，字符串</td></tr><tr><td style="text-align:left">@Email</td><td style="text-align:left">字符串必须是邮箱</td></tr><tr><td style="text-align:left">@URL</td><td style="text-align:left">字符串必须是url</td></tr><tr><td style="text-align:left">@AssertFalse</td><td style="text-align:left">值必须是false</td></tr><tr><td style="text-align:left">@AssertTrue</td><td style="text-align:left">值必须是true</td></tr><tr><td style="text-align:left">@DecimalMax(value=,inclusive=)</td><td style="text-align:left">值必须小于等于(inclusive=true)/小于(inclusive=false) value属性指定的值。可以注解在字符串类型的属性上</td></tr><tr><td style="text-align:left">@DecimalMin(value=,inclusive=)</td><td style="text-align:left">值必须大于等于(inclusive=true)/大f (inclusive=false) value属性指定的值。可以注解在字符串类型的属性上</td></tr><tr><td style="text-align:left">@Digits(integer-,fraction=)</td><td style="text-align:left">数字格式检查。integer指定整 数部分的最大长度，fraction指定小数部分的最大长度</td></tr><tr><td style="text-align:left">@Future</td><td style="text-align:left">值必须是未来的日期</td></tr><tr><td style="text-align:left">@Past</td><td style="text-align:left">值必须是过去的日期</td></tr><tr><td style="text-align:left">@Max(value=)</td><td style="text-align:left">值必须小于等于value指定的值。不能注解在字符串类型的属性上</td></tr><tr><td style="text-align:left">@Min(value=)</td><td style="text-align:left">值必须大于等于value指定的值。不能注解在字符串类型的属性上</td></tr><tr><td style="text-align:left">…</td><td style="text-align:left">…</td></tr></tbody></table><h2 id="校验实战"><a href="#校验实战" class="headerlink" title="校验实战"></a>校验实战</h2><p>接下来我们尝试一个入门例子,有一个User java bean, 为username字段加入@NotBlank注解，注意@NotBlank的包名</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> lombok.Data;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.validation.constraints.NotBlank;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Long id;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@NotBlank</span>(message = <span class="string">"请输入用户名"</span>)</span><br><span class="line">    <span class="keyword">private</span> String username;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String password;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>表明将对username字段做非null，非空字符串校验，并为user参数添加@Valid</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> User <span class="title">login</span><span class="params">(@RequestBody @Valid User user)</span></span></span><br></pre></td></tr></table></figure><p>按照<a href="">Spring boot实践之编写接口测试用例</a>编写一个测试用例</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testBlankName</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    String params = <span class="string">"&#123;\"id\": 101,\"username\": \"\",\"password\": \"1234\"&#125;"</span>;</span><br><span class="line">    mockMvc.perform(post(<span class="string">"/user/login"</span>)</span><br><span class="line">    .contentType(MediaType.APPLICATION_JSON_UTF8)</span><br><span class="line">    .content(params))</span><br><span class="line">    .andExpect(status().isBadRequest());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于参数为空，将返回BadRequest—400响应码，但是此时我们获取不到错误信息，由于spring的拦截，甚至你会发现不进方法断点，仅仅得到一个400响应码，对前端提示错误信息帮助不大，因此我们需要获取错误信息</p><h2 id="获取错误信息"><a href="#获取错误信息" class="headerlink" title="获取错误信息"></a>获取错误信息</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@PostMapping</span>(<span class="string">"login"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> User <span class="title">login</span><span class="params">(@Valid @RequestBody User user, BindingResult result)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(result.hasErrors())&#123;</span><br><span class="line">        result.getFieldErrors().stream().forEach(error -&gt; &#123;</span><br><span class="line">            <span class="comment">// ....</span></span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> user;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此时我们发现已经进入方法断点</p><p><img src="https://ae01.alicdn.com/kf/H954c71c251af4bbbb3b337fb595cdaa5c.png" alt="进入断点"></p><h2 id="统一异常处理"><a href="#统一异常处理" class="headerlink" title="统一异常处理"></a>统一异常处理</h2><p>继续优化，想必大家也发现了，难道每个方法都要写<code>if</code>? 当然不用，ControllerAdvice不就是专门封装错误信息的吗，仿照<a href="">异常处理</a>中的处理方式，我们很容易写出以下代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ExceptionHandler</span>(&#123;MethodArgumentNotValidException.class&#125;)</span><br><span class="line"><span class="meta">@ResponseStatus</span>(HttpStatus.BAD_REQUEST)</span><br><span class="line"><span class="function"><span class="keyword">public</span> ResponseModel <span class="title">exception</span><span class="params">(MethodArgumentNotValidException ex)</span> </span>&#123;</span><br><span class="line">    ResponseModel model = <span class="keyword">new</span> ResponseModel();</span><br><span class="line">    model.setCode(HttpStatus.BAD_REQUEST.value());</span><br><span class="line">    model.setMsg(buildErrorMessage(ex));</span><br><span class="line">    <span class="keyword">return</span> model;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 构建错误信息</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> ex</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> String <span class="title">buildErrorMessage</span><span class="params">(MethodArgumentNotValidException ex)</span></span>&#123;</span><br><span class="line">    List&lt;ObjectError&gt; objectErrors = ex.getBindingResult().getAllErrors();</span><br><span class="line">    StringBuilder messageBuilder = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">    objectErrors.stream().forEach(error -&gt; &#123;</span><br><span class="line">        <span class="keyword">if</span>(error <span class="keyword">instanceof</span> FieldError)&#123;</span><br><span class="line">            FieldError fieldError = (FieldError) error;</span><br><span class="line">            messageBuilder.append(fieldError.getDefaultMessage()).append(<span class="string">","</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    String message  = messageBuilder.deleteCharAt(messageBuilder.length() - <span class="number">1</span>).toString();</span><br><span class="line">    log.error(message);</span><br><span class="line">    <span class="keyword">return</span> message;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h3><p>除了使用<code>@ExceptionHandler</code>来捕获<code>MethodArgumentNotValidException</code>以外，还可以覆盖<code>ResponseEntityExceptionHandler</code>抽象类的handleMethodArgumentNotValid方法，但是二者不可以混用</p><h2 id="自定义校验规则"><a href="#自定义校验规则" class="headerlink" title="自定义校验规则"></a>自定义校验规则</h2><p>由于JSR303提供的注解有限，实际开发过程中校验往往需要结合实际需求，JSR303提供了自定义校验扩展接口</p><p>典型的一个请求场景是枚举类型参数，假设用户分为3类: 普通用户，VIP玩家，氪金玩家，分别用1，2，3表示，此时如何校验前端传入的值在范围内，抖机灵的朋友可能会想到@Range，万一是离散的不连续数呢？</p><p>自定义注解类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> javax.validation.Constraint;</span><br><span class="line"><span class="keyword">import</span> javax.validation.Payload;</span><br><span class="line"><span class="keyword">import</span> java.lang.annotation.*;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Documented</span></span><br><span class="line"><span class="comment">// 指定校验类</span></span><br><span class="line"><span class="meta">@Constraint</span>(validatedBy = InValidator.class)</span><br><span class="line"><span class="meta">@Target</span>( &#123; ElementType.METHOD, ElementType.FIELD &#125;)</span><br><span class="line"><span class="meta">@Retention</span>(RetentionPolicy.RUNTIME)</span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> In &#123;</span><br><span class="line">    <span class="function">String <span class="title">message</span><span class="params">()</span> <span class="keyword">default</span> "必须在允许的数值内"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span>[] values();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 用于分组校验</span></span><br><span class="line">    Class&lt;?&gt;[] groups() <span class="keyword">default</span> &#123;&#125;;</span><br><span class="line"></span><br><span class="line">    Class&lt;? extends Payload&gt;[] payload() <span class="keyword">default</span> &#123;&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注解的校验器</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.google.common.collect.Sets;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.validation.ConstraintValidator;</span><br><span class="line"><span class="keyword">import</span> javax.validation.ConstraintValidatorContext;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InValidator</span> <span class="keyword">implements</span> <span class="title">ConstraintValidator</span>&lt;<span class="title">In</span>, <span class="title">Number</span>&gt; </span>&#123;<span class="comment">// 校验Number类型 </span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Set&lt;Integer&gt; inValues;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">(In in)</span> </span>&#123; </span><br><span class="line">    inValues = Sets.newHashSet();</span><br><span class="line">    <span class="keyword">int</span>[] arr = in.values();</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> a : arr)&#123;</span><br><span class="line">       inValues.add(a);</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isValid</span><span class="params">(Number propertyValue, ConstraintValidatorContext cxt)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(propertyValue==<span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">       <span class="keyword">return</span> inValues.contains(propertyValue.intValue());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>至此，生产级别的参数校验基本完成</p><h2 id="分组校验"><a href="#分组校验" class="headerlink" title="分组校验"></a>分组校验</h2><p>在不同接口中，指定不同的校验规则，如：</p><ol><li>不同的接口，校验不同的字段</li><li>同一个字段，在不同的接口中有不同的校验规则</li></ol><p>以下实现第一种情况</p><p>首先定义两个空接口，代表不同的分组，也就是不同的业务</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">NewUser</span> </span>&#123; &#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">RMBUser</span> </span>&#123; &#125;</span><br></pre></td></tr></table></figure><p>在指定校验规则时，指定分组</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line"><span class="comment">// 省略...</span></span><br><span class="line">    <span class="meta">@NotBlank</span>(groups = &#123;NewUser.class&#125;, message = <span class="string">"请输入密码"</span>)   </span><br><span class="line">    <span class="keyword">private</span> String password;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@In</span>(groups = &#123;RMBUser.class&#125;, values = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;, message = <span class="string">"非法的用户类型"</span>)</span><br><span class="line">    <span class="keyword">private</span> Integer type;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="不同的接口指定不同的校验分组"><a href="#不同的接口指定不同的校验分组" class="headerlink" title="不同的接口指定不同的校验分组"></a>不同的接口指定不同的校验分组</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 省略类定义...</span></span><br><span class="line"><span class="meta">@PostMapping</span>(<span class="string">"normal"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> User <span class="title">normal</span><span class="params">(@Validated(&#123;NewUser.class&#125;)</span> @RequestBody User user)</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> user;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@PostMapping</span>(<span class="string">"rmb"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> User <span class="title">rmb</span><span class="params">(@Validated(&#123;RMBUser.class&#125;)</span> @RequestBody User user)</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> user;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编写测试用例</p><p>只检验密码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testNormal</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">       String params = <span class="string">"&#123;\"id\": 101,\"username\": \"tom\",\"password\": \"\",\"type\": \"5\"&#125;"</span>;</span><br><span class="line">       String result = mockMvc.perform(post(<span class="string">"/user/normal"</span>)</span><br><span class="line">               .contentType(MediaType.APPLICATION_JSON_UTF8)</span><br><span class="line">               .content(params))</span><br><span class="line">               .andExpect(status().isBadRequest())</span><br><span class="line">               .andReturn().getResponse().getContentAsString();</span><br><span class="line">       System.out.println(result);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>输出：<code>{&quot;data&quot;:null,&quot;code&quot;:400,&quot;msg&quot;:&quot;请输入密码&quot;}</code><br>只检验用户类型</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testRMB</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">       String params = <span class="string">"&#123;\"id\": 101,\"username\": \"tom\",\"password\": \"\",\"type\": \"5\"&#125;"</span>;</span><br><span class="line">       String result = mockMvc.perform(post(<span class="string">"/user/rmb"</span>)</span><br><span class="line">               .contentType(MediaType.APPLICATION_JSON_UTF8)</span><br><span class="line">               .content(params))</span><br><span class="line">               .andExpect(status().isBadRequest())</span><br><span class="line">               .andReturn().getResponse().getContentAsString();</span><br><span class="line">       System.out.println(result);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>输出：<code>{&quot;data&quot;:null,&quot;code&quot;:400,&quot;msg&quot;:&quot;非法的用户类型&quot;}</code></p>]]></content>
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring boot实践之异常处理</title>
      <link href="/2018/10/13/Spring-boot%E5%AE%9E%E8%B7%B5%E4%B9%8B%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/"/>
      <url>/2018/10/13/Spring-boot%E5%AE%9E%E8%B7%B5%E4%B9%8B%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</url>
      <content type="html"><![CDATA[<h1 id="Spring-boot实践之异常处理"><a href="#Spring-boot实践之异常处理" class="headerlink" title="Spring boot实践之异常处理"></a>Spring boot实践之异常处理</h1><h2 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h2><p>在上一章<a href="">封装返回体</a>中，已经对请求成功的情况进行了封装，接下来便是处理异常，服务的生产者需要通过状态码此次请求是否成功，出现异常时，错误信息是什么，形如:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"code"</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="attr">"msg"</span>: <span class="string">"FAILED"</span>,</span><br><span class="line">    <span class="attr">"data"</span>: <span class="literal">null</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="异常接口"><a href="#异常接口" class="headerlink" title="异常接口"></a>异常接口</h2><p>可以看出只需要<code>code</code>与<code>msg</code>, 参考 <code>org.springframework.http.HttpStatus</code>的实现，我们可以定义一个枚举来封装错误信息，对外暴露<code>getCode</code>，<code>getMsg</code>方法即可。由于异常属于一个基础模块，将这两个方法抽象到一个接口中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ExceptionEntity</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function">Integer <span class="title">getCode</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">String <span class="title">getMsg</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="异常枚举"><a href="#异常枚举" class="headerlink" title="异常枚举"></a>异常枚举</h3><p>以用户模块为例，所有用户相关的业务异常信息封装到<code>UserError</code>中，例如用户不存在，密码错误</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> UserError implements ExceptionEntity &#123;</span><br><span class="line"></span><br><span class="line">    NO_SUCH_USER(<span class="number">1</span>, <span class="string">"用户不存在"</span>),</span><br><span class="line">    ERROR_PASSWORD(<span class="number">2</span>, <span class="string">"密码错误"</span>),</span><br><span class="line">    ;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Integer MODULE = <span class="number">10000</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Integer code;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String msg;</span><br><span class="line"></span><br><span class="line">    UserError(Integer code, String msg) &#123;</span><br><span class="line">        <span class="keyword">this</span>.code = code;</span><br><span class="line">        <span class="keyword">this</span>.msg = msg;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Integer <span class="title">getCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> MODULE + <span class="keyword">this</span>.code;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getMsg</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.msg;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="模块标识"><a href="#模块标识" class="headerlink" title="模块标识"></a>模块标识</h4><p>需要注意的地方是笔者定义了一个<code>MODULE</code>字段，10000代表用户微服务，这样在拿到错误信息之后，可以很快定位报错的应用</p><h2 id="自定义异常"><a href="#自定义异常" class="headerlink" title="自定义异常"></a>自定义异常</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="comment">// lombok自动生成构造方法</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ServiceException</span> <span class="keyword">extends</span> <span class="title">RuntimeException</span></span>&#123;</span><br><span class="line">    ExceptionEntity error;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>需要说明的是错误接口与自定义异常属于公共模块，而<code>UserError</code>属于用户服务</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>之后，便可以抛出异常</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> ServiceException(UserError.ERROR_PASSWORD);</span><br></pre></td></tr></table></figure><p>目前来看，我们只是较为优雅的封装了异常，此时请求接口返回的仍然是Spring boot默认的错误体，没有错误信息</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">"timestamp"</span>: <span class="string">"2018-10-18T12:28:59.150+0000"</span>,</span><br><span class="line">    <span class="string">"status"</span>: <span class="number">500</span>,</span><br><span class="line">    <span class="string">"error"</span>: <span class="string">"Internal Server Error"</span>,</span><br><span class="line">    <span class="string">"message"</span>: <span class="string">"No message available"</span>,</span><br><span class="line">    <span class="string">"path"</span>: <span class="string">"/user/error"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="统一异常处理"><a href="#统一异常处理" class="headerlink" title="统一异常处理"></a>统一异常处理</h2><p>接下来的异常拦截方式，各路神仙都有自己的方法，笔者只说Spring boot项目中比较通用的<code>@ControllerAdvice</code>，由于是Restful接口，这里使用<code>@RestControllerAdvice</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 注意这属于基础模块，扫描路径不要包含具体的模块，用..代替</span></span><br><span class="line"><span class="meta">@RestControllerAdvice</span>(basePackages=<span class="string">"com.ttyc..controller"</span>,annotations=&#123;RestController.class&#125;)</span><br><span class="line"><span class="comment">// lombok的日志简写</span></span><br><span class="line"><span class="meta">@Slf</span>4j</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ControllerExceptionAdvisor</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@ExceptionHandler</span>(&#123;ServiceException.class&#125;)</span><br><span class="line">    <span class="meta">@ResponseStatus</span>(HttpStatus.INTERNAL_SERVER_ERROR)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ResponseModel <span class="title">handleServiceException</span><span class="params">(ServiceException ex)</span></span>&#123;</span><br><span class="line">        Integer code = ex.getError().getCode();</span><br><span class="line">        String msg = ex.getError().getMsg();</span><br><span class="line">        log.error(msg);</span><br><span class="line"></span><br><span class="line">        ResponseModel model = <span class="keyword">new</span> ResponseModel();</span><br><span class="line">        model.setCode(code);</span><br><span class="line">        model.setMsg(msg);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> model;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 其他错误</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> ex</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@ExceptionHandler</span>(&#123;Exception.class&#125;)</span><br><span class="line">    <span class="meta">@ResponseStatus</span>(HttpStatus.INTERNAL_SERVER_ERROR)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ResponseModel <span class="title">exception</span><span class="params">(Exception ex)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> code = HttpStatus.INTERNAL_SERVER_ERROR.value();</span><br><span class="line">        String msg = HttpStatus.INTERNAL_SERVER_ERROR.getReasonPhrase();</span><br><span class="line">        log.error(msg);</span><br><span class="line"></span><br><span class="line">        ResponseModel model = <span class="keyword">new</span> ResponseModel();</span><br><span class="line">        model.setCode(code);</span><br><span class="line">        model.setMsg(msg);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> model;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>具有争议的一点是捕获<code>ServiceExcption</code>之后，应该返回200还是500的响应码，有的公司返回200，使用<code>code</code>字段判断成功失败，这完全没有问题，但是按照Restful的开发风格，这里的<code>@ResponseStatus</code>笔者返回了500，请读者根据自身情况返回响应码</p><h3 id="测试接口与测试用例"><a href="#测试接口与测试用例" class="headerlink" title="测试接口与测试用例"></a>测试接口与测试用例</h3><h4 id="测试接口"><a href="#测试接口" class="headerlink" title="测试接口"></a>测试接口</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GetMapping</span>(<span class="string">"error"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">error</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">// 抛出业务异常示例</span></span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> ServiceException(UserError.NO_SUCH_USER);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="测试用例"><a href="#测试用例" class="headerlink" title="测试用例"></a>测试用例</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testError</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    String result =</span><br><span class="line">            mockMvc.perform(get(<span class="string">"/user/error"</span>))</span><br><span class="line">                    .andExpect(status().isInternalServerError())</span><br><span class="line">                    .andReturn().getResponse().getContentAsString();</span><br><span class="line">    System.out.println(result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果为:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"data"</span>: <span class="literal">null</span>,</span><br><span class="line"><span class="attr">"code"</span>: <span class="number">10001</span>,</span><br><span class="line"><span class="attr">"msg"</span>: <span class="string">"用户不存在"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring boot实践之编写接口测试用例</title>
      <link href="/2018/10/13/Spring-boot%E5%AE%9E%E8%B7%B5%E4%B9%8B%E7%BC%96%E5%86%99%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B/"/>
      <url>/2018/10/13/Spring-boot%E5%AE%9E%E8%B7%B5%E4%B9%8B%E7%BC%96%E5%86%99%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B/</url>
      <content type="html"><![CDATA[<h1 id="Spring-boot实践之编写接口测试用例"><a href="#Spring-boot实践之编写接口测试用例" class="headerlink" title="Spring boot实践之编写接口测试用例"></a>Spring boot实践之编写接口测试用例</h1><blockquote><p> 测试用例对开发者降低bug率,方便测试人员回归测试有十分重要的意义。</p></blockquote><p>本文介绍如何使用<code>MockMvc</code>编写测试用例. </p><p>在Spring boot项目中编写测试用例十分简单，通常建立一个Spring boot项目都会test目录下生成一个Test类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RunWith</span>(SpringRunner.class)</span><br><span class="line"><span class="meta">@SpringBootTest</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DemoApplicationTests</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">contextLoads</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以用户查询为例，通常有一个用户实体，以及<code>UserController</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// @Data注解来自lombok</span></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Long id;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String username;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String password;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>getInfo方法是一个restful接口，模拟查询用户详情</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping</span>(<span class="string">"user"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span>(<span class="string">"info"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">getInfo</span><span class="params">(@RequestParam(name = <span class="string">"name"</span>, required = <span class="keyword">true</span>)</span> String username)</span>&#123;</span><br><span class="line">        User user = <span class="keyword">new</span> User();</span><br><span class="line">        user.setUsername(username + <span class="string">"s"</span>);</span><br><span class="line">        <span class="keyword">return</span> user;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以下通过MockMvc对象，测试<code>/user/info}</code>请求是否成功，并符合预期</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONObject;</span><br><span class="line"><span class="keyword">import</span> org.junit.Before;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"><span class="keyword">import</span> org.junit.runner.RunWith;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.test.context.SpringBootTest;</span><br><span class="line"><span class="keyword">import</span> org.springframework.http.MediaType;</span><br><span class="line"><span class="keyword">import</span> org.springframework.test.context.junit4.SpringRunner;</span><br><span class="line"><span class="keyword">import</span> org.springframework.test.web.servlet.MockMvc;</span><br><span class="line"><span class="keyword">import</span> org.springframework.test.web.servlet.setup.MockMvcBuilders;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.context.WebApplicationContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.springframework.test.web.servlet.request.MockMvcRequestBuilders.get;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.springframework.test.web.servlet.result.MockMvcResultMatchers.jsonPath;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RunWith</span>(SpringRunner.class)</span><br><span class="line"><span class="meta">@SpringBootTest</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SecurityDemoApplicationTests</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//注入上下文对象</span></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> WebApplicationContext context;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> MockMvc mockMvc;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Before</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">//初始化mockMvc对象</span></span><br><span class="line">        mockMvc = MockMvcBuilders.webAppContextSetup(context).build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testQuery</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String result =</span><br><span class="line">                <span class="comment">//执行get请求，这里有个小坑，第一个/必须有</span></span><br><span class="line">                mockMvc.perform(get(<span class="string">"/user/info"</span>)</span><br><span class="line">                        <span class="comment">//设置content-type请求头</span></span><br><span class="line">                        .contentType(MediaType.APPLICATION_FORM_URLENCODED)</span><br><span class="line">                        <span class="comment">//设置参数  </span></span><br><span class="line">                        .param(<span class="string">"name"</span>, <span class="string">"jay"</span>))</span><br><span class="line">                        <span class="comment">//预期的相应码是200-ok</span></span><br><span class="line">                        .andExpect(status().isOk())</span><br><span class="line">                        <span class="comment">//预测username的值为jays</span></span><br><span class="line">                        .andExpect(jsonPath(<span class="string">"$.username"</span>).value(<span class="string">"jays"</span>))</span><br><span class="line">                        <span class="comment">//获取响应体</span></span><br><span class="line">                        .andReturn().getResponse().getContentAsString();</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最终通过测试，并输出响应体</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"id"</span>: <span class="number">101</span>,</span><br><span class="line">    <span class="attr">"username"</span>: <span class="string">"jays"</span>,</span><br><span class="line">    <span class="attr">"password"</span>: <span class="string">"1234"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>关于<code>$.id</code>jsonpath的使用，参考<a href="https://github.com/json-path/JsonPath" target="_blank" rel="noopener">JsonPath</a></p><p>同时付一段使用json参数的post请求方式，大同小异，</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">String params = <span class="string">"&#123;\"id\": 101,\"username\": \"jason\",\"password\": \"1234\"&#125;"</span>;</span><br><span class="line">mockMvc.perform(post(<span class="string">"/user/login"</span>)</span><br><span class="line">        .contentType(MediaType.APPLICATION_JSON_UTF8)</span><br><span class="line">        .content(params))</span><br><span class="line">        .andExpect(status().isOk());</span><br></pre></td></tr></table></figure><p>注意后端接受json格式参数的方式：<code>方法名(@RequestBody User user)</code> </p>]]></content>
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring boot实践之封装返回体</title>
      <link href="/2018/10/11/Spring-boot%E5%AE%9E%E8%B7%B5%E4%B9%8B%E5%B0%81%E8%A3%85%E8%BF%94%E5%9B%9E%E4%BD%93/"/>
      <url>/2018/10/11/Spring-boot%E5%AE%9E%E8%B7%B5%E4%B9%8B%E5%B0%81%E8%A3%85%E8%BF%94%E5%9B%9E%E4%BD%93/</url>
      <content type="html"><![CDATA[<h1 id="Spring-boot实践之封装返回体"><a href="#Spring-boot实践之封装返回体" class="headerlink" title="Spring boot实践之封装返回体"></a>Spring boot实践之封装返回体</h1><p>在实际开发中，一个项目会形成一套统一的返回体接口规范，常见的结构如下</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"code"</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="attr">"msg"</span>: <span class="string">"SUCCESS"</span>,</span><br><span class="line">    <span class="attr">"data"</span>: 真正的数据</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>读者可以根据自己的实际情况封装一个java bean，刑如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ResponseModel</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> T data;</span><br><span class="line">    <span class="keyword">private</span> Integer code;</span><br><span class="line">    <span class="keyword">private</span> String msg;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在spring boot中，会将返回的实体类，通过jackson自动转换成json</p><p>Spring提供了<code>ResponseBodyAdvice</code>接口拦截响应体</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ResponseAdvisor</span> <span class="keyword">implements</span> <span class="title">ResponseBodyAdvice</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">supports</span><span class="params">(MethodParameter methodParameter, Class aClass)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">beforeBodyWrite</span><span class="params">(Object body,</span></span></span><br><span class="line"><span class="function"><span class="params">                                  MethodParameter methodParameter, </span></span></span><br><span class="line"><span class="function"><span class="params">                                  MediaType mediaType,</span></span></span><br><span class="line"><span class="function"><span class="params">                                  Class aClass, </span></span></span><br><span class="line"><span class="function"><span class="params">                                  ServerHttpRequest serverHttpRequest, </span></span></span><br><span class="line"><span class="function"><span class="params">                                  ServerHttpResponse serverHttpResponse)</span> </span>&#123;</span><br><span class="line">        ResponseModel model = <span class="keyword">new</span> ResponseModel();</span><br><span class="line">        model.setCode(<span class="number">0</span>);</span><br><span class="line">        model.setData(body);</span><br><span class="line">        model.setMsg(<span class="string">"SUCCESS"</span>);</span><br><span class="line">        <span class="keyword">return</span> model;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这只是一个最初的功能，值得优化的地方有很多，读者应根据自己的情况进行扩展</p><p>根据笔者遇到的情况，抛砖引玉一下</p><ol><li>是否需要对所有的响应拦截，可以在supports方法中判断</li><li>下载返回的是字节数据，再进行包装必然得不到正确的文件，不应该进行包装</li></ol>]]></content>
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring Cloud系列: Spring Boot Admin</title>
      <link href="/2018/09/07/Spring-Cloud%E7%B3%BB%E5%88%97-Spring-Boot-Admin/"/>
      <url>/2018/09/07/Spring-Cloud%E7%B3%BB%E5%88%97-Spring-Boot-Admin/</url>
      <content type="html"><![CDATA[<p>本文主要介绍了Spring Boot Admin的使用，参考Spring Boot Admin 2.0.2版本(以下简称SBA，来自官方)官方文档，主要实现了其中案例，也包括一些自己的想法</p><p>文档地址：<a href="http://codecentric.github.io/spring-boot-admin/current/" target="_blank" rel="noopener">http://codecentric.github.io/spring-boot-admin/current/</a></p><p>以下文章内容的例子都可以在我的<a href="https://github.com/GreedyPirate/Spring-Cloud-Stack" target="_blank" rel="noopener">GitHub</a>找到</p><h1 id="Spring-Boot-Admin介绍"><a href="#Spring-Boot-Admin介绍" class="headerlink" title="Spring Boot Admin介绍"></a>Spring Boot Admin介绍</h1><h2 id="What"><a href="#What" class="headerlink" title="What"></a>What</h2><p>SBA是一个用于管理和监控Spring Boot项目的工具，包括线程，内存，Spring bean加载情况，日志等一系列可视化界面</p><h2 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h2><p>熟悉Spring Boot的读者都知道Spring Boot actuator这款组件，它使用HTTP端点或JMX来管理和监控应用程序，但是没有提供图形化界面，仅仅提供了JSON格式的数据，同时无法做到集中管理应用，对运维十分不友好，SBA基于actuator不但解决了这些痛点，并且通过扩展实现了很多强大的功能，如日志级别动态更改，查看实时日志，查看URL映射等等，对管理微服务十分有意义</p><h2 id="How"><a href="#How" class="headerlink" title="How"></a>How</h2><p>环境的搭建将配合注册中心Eureka，当然也可以不使用注册中心，参考<a href="http://codecentric.github.io/spring-boot-admin/current/#set-up-admin-server" target="_blank" rel="noopener">Spring Boot Admin Server</a>一节,或使用别的注册中心，如<a href="http://cloud.spring.io/spring-cloud-consul/" target="_blank" rel="noopener">Consul</a>，Zookeeper，这些官方都已经在github给出了<a href="https://github.com/codecentric/spring-boot-admin/tree/master/spring-boot-admin-samples" target="_blank" rel="noopener">案例</a></p><h1 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h1><p>服务端和客户端均加入了spring-security组件，同时都配置了关闭请求拦截和跨域防范，详见笔者的GitHub<a href="https://github.com/GreedyPirate/Spring-Cloud-Stack" target="_blank" rel="noopener">Spring-Cloud-Stack</a>项目，<a href="https://github.com/GreedyPirate/Spring-Cloud-Stack/tree/master/admin-server" target="_blank" rel="noopener">admin-server</a>和<a href="https://github.com/GreedyPirate/Spring-Cloud-Stack/tree/master/admin-client" target="_blank" rel="noopener">admin-client</a>模块<br><strong>注意：</strong> 按常理IDEA在勾选依赖生成项目之后，会加入bom版本管理，可是笔者也遇到了没有自动生成的情况，请读者注意pom文件是否有以下内容<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencyManagement</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-dependencies<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spring-cloud.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">type</span>&gt;</span>pom<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>import<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>de.codecentric<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-admin-dependencies<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spring-boot-admin.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">type</span>&gt;</span>pom<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>import<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencyManagement</span>&gt;</span></span><br></pre></td></tr></table></figure></p><h2 id="SBA-服务端"><a href="#SBA-服务端" class="headerlink" title="SBA 服务端"></a>SBA 服务端</h2><h3 id="pom依赖"><a href="#pom依赖" class="headerlink" title="pom依赖"></a>pom依赖</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>de.codecentric<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-admin-starter-server<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-security<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-netflix-eureka-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="注册Eureka并添加-EnableAdminServer注解"><a href="#注册Eureka并添加-EnableAdminServer注解" class="headerlink" title="注册Eureka并添加@EnableAdminServer注解"></a>注册Eureka并添加@EnableAdminServer注解</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@EnableAdminServer</span></span><br><span class="line"><span class="meta">@EnableEurekaClient</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AdminServerApplication</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">SpringApplication.run(AdminServerApplication.class, args);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="spring-security配置"><a href="#spring-security配置" class="headerlink" title="spring-security配置"></a>spring-security配置</h3><p><code>anyRequest.permitAll</code>表示允许所有请求通过校验<br><code>csrf.disable</code>表示关闭跨域防范</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SecurityPermitAllConfig</span> <span class="keyword">extends</span> <span class="title">WebSecurityConfigurerAdapter</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(HttpSecurity http)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        http.authorizeRequests().anyRequest().permitAll()  </span><br><span class="line">            .and().csrf().disable();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="yml配置"><a href="#yml配置" class="headerlink" title="yml配置"></a>yml配置</h3><p>简要说明: 主要配置端口，eureka，必须暴露所有web actuator断点，生产环境考虑到安全性，应当酌情开放，最后配置了spring-security的用户名和密码</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">8115</span></span><br><span class="line"><span class="attr">eureka:</span></span><br><span class="line"><span class="attr">  client:</span></span><br><span class="line"><span class="attr">    serviceUrl:</span></span><br><span class="line"><span class="attr">      defaultZone:</span> <span class="attr">http://localhost:8000/eureka/,http://localhost:8001/eureka/</span></span><br><span class="line"><span class="attr">management:</span></span><br><span class="line"><span class="attr">  endpoints:</span></span><br><span class="line"><span class="attr">    web:</span></span><br><span class="line"><span class="attr">      exposure:</span></span><br><span class="line"><span class="attr">        include:</span> <span class="string">"*"</span></span><br><span class="line"><span class="attr">  endpoint:</span></span><br><span class="line"><span class="attr">    health:</span></span><br><span class="line"><span class="attr">      show-details:</span> <span class="string">ALWAYS</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  security:</span></span><br><span class="line"><span class="attr">    user:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">user</span></span><br><span class="line"><span class="attr">      password:</span> <span class="string">admin</span></span><br></pre></td></tr></table></figure><h2 id="SBA-客户端"><a href="#SBA-客户端" class="headerlink" title="SBA 客户端"></a>SBA 客户端</h2><h2 id="pom依赖-1"><a href="#pom依赖-1" class="headerlink" title="pom依赖"></a>pom依赖</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-security<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>de.codecentric<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-admin-starter-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="Spring-Security配置"><a href="#Spring-Security配置" class="headerlink" title="Spring-Security配置"></a>Spring-Security配置</h2><p><a href="#spring-security配置">同服务端</a></p><h2 id="yml配置-1"><a href="#yml配置-1" class="headerlink" title="yml配置"></a>yml配置</h2><p>这里提一个小坑点, server的地址必须加<strong>http://</strong> 前缀，否则会在启动日志中看到WARN，注册失败</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">server:</span><br><span class="line">  port: 8116</span><br><span class="line">spring:</span><br><span class="line">  boot:</span><br><span class="line">    admin:</span><br><span class="line">      client:</span><br><span class="line">        url: http://localhost:8115</span><br><span class="line">  security:</span><br><span class="line">    user:</span><br><span class="line">      name: user</span><br><span class="line">      password: admin</span><br><span class="line">management:</span><br><span class="line">  endpoints:</span><br><span class="line">    web:</span><br><span class="line">      exposure:</span><br><span class="line">        include: &quot;*&quot;</span><br><span class="line">  endpoint:</span><br><span class="line">    health:</span><br><span class="line">      show-details: ALWAYS</span><br></pre></td></tr></table></figure><h1 id="最初效果"><a href="#最初效果" class="headerlink" title="最初效果"></a>最初效果</h1><p>在启动注册中心，以及服务端，客户端之后，打开<a href="http://localhost:8115" target="_blank" rel="noopener">http://localhost:8115</a>，输入配置的用户名和密码即可登录</p><h2 id="报错"><a href="#报错" class="headerlink" title="报错"></a>报错</h2><p>java.io.IOException: Broken pipe, SBA 的issue中有回复：</p><p>This is a quite normal. The browser does some long polling and keeps the tcp connection open. If the browser window is closed the tcp connection is aborted and on the next write the exception is thrown. there is nothing to do about this, except changing the loglevel.<br>这是很正常的。浏览器执行一些长轮询并保持TCP连接打开。如果浏览器窗口关闭，则中止TCP连接，并在下一次写入时抛出异常。除了更改日志级别之外，这没有什么可做的。 </p><h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><h2 id="UI配置"><a href="#UI配置" class="headerlink" title="UI配置"></a>UI配置</h2><h3 id="如何显示项目的版本号"><a href="#如何显示项目的版本号" class="headerlink" title="如何显示项目的版本号"></a>如何显示项目的版本号</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">info:</span><br><span class="line">  version: @project.version@</span><br></pre></td></tr></table></figure><p>此处的project.version引用了maven中的变量</p><p>效果图如下</p><p><img src="https://ae01.alicdn.com/kf/H333f7d74baad4ccc92a57ed4a6d88fa9u.png" width="65%" align="left"></p><h2 id="查看实时滚动日志"><a href="#查看实时滚动日志" class="headerlink" title="查看实时滚动日志"></a>查看实时滚动日志</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">logging:</span><br><span class="line">  file: client.log</span><br></pre></td></tr></table></figure><p>配置日志文件位置即可，根据官方文档说明，SBA可以自动检测出url链接，同时支持日志颜色配置，但是项目启动时报错，遂放弃之<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">logging.pattern.file=%clr(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;)&#123;faint&#125; %clr(%5p) %clr($&#123;PID&#125;)&#123;magenta&#125; %clr(---)&#123;faint&#125; %clr([%15.15t])&#123;faint&#125; %clr(%-40.40logger&#123;39&#125;)&#123;cyan&#125; %clr(:)&#123;faint&#125; %m%n%wEx</span><br><span class="line">`</span><br></pre></td></tr></table></figure></p><p>日志效果如下图：<br><img src="https://ae01.alicdn.com/kf/H61eae22c490944e195e0ed73a306cb62J.png" width="65%" align="left"></p><p>可以看到提供了下载按钮，其实是打开了一个网页页签，可复制出来，中文日志会出现乱码</p><h2 id="tag"><a href="#tag" class="headerlink" title="tag"></a>tag</h2><p>tag可以给每一个客户端标识，有两种途径加入tag:</p><h3 id="1-元数据"><a href="#1-元数据" class="headerlink" title="1. 元数据"></a>1. 元数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  boot:</span><br><span class="line">    admin:</span><br><span class="line">      client:</span><br><span class="line">        url: http://localhost:8115</span><br><span class="line">        instance:</span><br><span class="line">          metadata:</span><br><span class="line">            tags:</span><br><span class="line">              content: mesh</span><br></pre></td></tr></table></figure><h3 id="2-info端点"><a href="#2-info端点" class="headerlink" title="2. info端点"></a>2. info端点</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">info:</span><br><span class="line">  tags:</span><br><span class="line">    title: mosi</span><br></pre></td></tr></table></figure><p><img src="https://ae01.alicdn.com/kf/H8f6d48f10cc04dc898df3e62d109b7258.png" width="65%" align="left"></p><p><strong>值得注意的是，两种方式的k-v表现形式, 第一个是tags.content为key，第二个是tags为key</strong></p><h2 id="静态配置客户端"><a href="#静态配置客户端" class="headerlink" title="静态配置客户端"></a>静态配置客户端</h2><p>这一小节的内容单独用了两个项目，分别是<a href="https://github.com/GreedyPirate/Spring-Cloud-Stack/tree/master/admin-static-client" target="_blank" rel="noopener">admin-static-client</a>，<a href="https://github.com/GreedyPirate/Spring-Cloud-Stack/tree/master/admin-static-server" target="_blank" rel="noopener">admin-static-server</a></p><p>通过Spring Cloud提供的静态配置，SBA支持静态配置client，首先建立客户端项目，只需要web，actuator两个依赖即可，</p><p>server端将Eureka依赖改为如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>接下来配置客户端的地址等信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  cloud:</span><br><span class="line">    discovery:</span><br><span class="line">      client:</span><br><span class="line">        simple:</span><br><span class="line">          instances:</span><br><span class="line">            admin-static-client:</span><br><span class="line">              - uri: http://localhost:8117</span><br><span class="line">                metadata:</span><br><span class="line">                  management.context-path: /actuator</span><br></pre></td></tr></table></figure></p><p>admin-static-client将是在界面上显示的客户端地址</p><h1 id="提醒"><a href="#提醒" class="headerlink" title="提醒"></a>提醒</h1><h2 id="邮件提醒"><a href="#邮件提醒" class="headerlink" title="邮件提醒"></a>邮件提醒</h2><p>当注册在SBA server上的应用出现DOWN/OFFLINE等情况时，需要通过告警的方式告知运维人员，而邮件告警是常用的方式之一，SBA支持邮件告警，使用了spring-boot-mail组件来完成这一功能，需要在server端做以下工作：</p><p><strong>注: </strong> 以下邮件有关内容,通常情况需要获取授权码，以qq邮箱为例，请参照<a href="http://service.mail.qq.com/cgi-bin/help?subtype=1&amp;&amp;id=28&amp;&amp;no=1001256" target="_blank" rel="noopener">http://service.mail.qq.com/cgi-bin/help?subtype=1&amp;&amp;id=28&amp;&amp;no=1001256</a>获取授权码</p><h3 id="pom中加入依赖"><a href="#pom中加入依赖" class="headerlink" title="pom中加入依赖"></a>pom中加入依赖</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><h3 id="需要的配置如下"><a href="#需要的配置如下" class="headerlink" title="需要的配置如下"></a>需要的配置如下</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">boot:</span><br><span class="line">  admin:</span><br><span class="line">    ui:</span><br><span class="line">      title: &quot;Spring Boot Admin监控管理中心&quot;</span><br><span class="line">    notify:</span><br><span class="line">      mail:</span><br><span class="line">        from: 发送方</span><br><span class="line">        to: 收件方，多个逗号分隔</span><br><span class="line">        cc: 抄送，多个逗号分隔</span><br><span class="line">        template: classpath:/META-INF/spring-boot-admin-server/mail/status-changed.html # 定制邮件模板，请参考官方实现</span><br><span class="line">mail:</span><br><span class="line">  host: smtp.qq.com</span><br><span class="line">  port: 25</span><br><span class="line">  username: 发送方用户名</span><br><span class="line">  password: 授权码</span><br><span class="line">  protocol: smtp</span><br><span class="line">  test-connection: false</span><br><span class="line">  properties:</span><br><span class="line">    mail:</span><br><span class="line">      smtp:</span><br><span class="line">        auth: true</span><br><span class="line">        starttls:</span><br><span class="line">          enable: true</span><br><span class="line">          required: true</span><br></pre></td></tr></table></figure><h3 id="最终收到的邮件如图"><a href="#最终收到的邮件如图" class="headerlink" title="最终收到的邮件如图"></a>最终收到的邮件如图</h3><p>将客户端下线之后，收到的邮件如下<br><img src="https://ae01.alicdn.com/kf/H20620d2d3d824685bbbe9970ca308c9e9.png" width="65%" align="left"></p><p>余下的第三方应用接入以及安全防护不再介绍，直接进入自定义通知</p><h1 id="通知"><a href="#通知" class="headerlink" title="通知"></a>通知</h1><p>当应用(实例)宕机时，服务端应该主动通知运维人员，达到告警的作用，在SBA中提供了这样的扩展，可以继承<code>AbstractEventNotifier</code>或<code>AbstractStatusChangeNotifier</code>，由于二者属于继承关系，读者直接继承AbstractStatusChangeNotifier即可</p><p><strong>注: </strong>通知的方式有很多种，如钉钉，邮件，短信，大家按需扩展即可，以邮件举例，注入<code>JavaMailSender</code>对象即可实现邮件报警</p><p>下面给出一个告警样例代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyNotifier</span> <span class="keyword">extends</span> <span class="title">AbstractStatusChangeNotifier</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Logger LOGGER = LoggerFactory.getLogger(<span class="keyword">this</span>.getClass());</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MyNotifier</span><span class="params">(InstanceRepository repositpry)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(repositpry);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> Mono&lt;Void&gt; <span class="title">doNotify</span><span class="params">(InstanceEvent event, Instance instance)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Mono.fromRunnable(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">if</span> (event <span class="keyword">instanceof</span> InstanceStatusChangedEvent) &#123;</span><br><span class="line">                StatusInfo statusInfo = ((InstanceStatusChangedEvent) event).getStatusInfo();</span><br><span class="line">                String status = statusInfo.getStatus();</span><br><span class="line">                Map&lt;String, Object&gt; details = statusInfo.getDetails();</span><br><span class="line">                String detailStr = details.toString();</span><br><span class="line">                <span class="keyword">boolean</span> isOffline = statusInfo.isOffline();</span><br><span class="line">                LOGGER.info(<span class="string">"status info are: status:&#123;&#125;, detail:&#123;&#125;, isOffline:&#123;&#125;"</span>, status, detailStr, isOffline);</span><br><span class="line"></span><br><span class="line">                String mavenVersion = instance.getBuildVersion().getValue();</span><br><span class="line">                String healthUrl = instance.getRegistration().getHealthUrl();</span><br><span class="line">                LOGGER.info(<span class="string">"instance build version is &#123;&#125;, health check url is &#123;&#125;"</span>, mavenVersion, healthUrl);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 获取事件信息，instance(客户端)信息，包括前面说过的元信息，可用来发钉钉消息，短信等等的通知</span></span><br><span class="line">                LOGGER.info(<span class="string">"Instance &#123;&#125; (&#123;&#125;) is &#123;&#125;"</span>, instance.getRegistration().getName(), event.getInstance(),</span><br><span class="line">                        ((InstanceStatusChangedEvent) event).getStatusInfo().getStatus());</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                LOGGER.info(<span class="string">"Instance &#123;&#125; (&#123;&#125;) &#123;&#125;"</span>, instance.getRegistration().getName(), event.getInstance(),</span><br><span class="line">                        event.getType());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h1><p>最后聊聊一些细节内容，读者有需求的可深入了解</p><ol><li>对于监控的url请求，可以<a href="http://codecentric.github.io/spring-boot-admin/current/#customizing-headers" target="_blank" rel="noopener">添加header</a>，并对request，response<a href="http://codecentric.github.io/spring-boot-admin/current/#customizing-instance-filter" target="_blank" rel="noopener">拦截</a></li><li>使用2.0的服务端监控1.5版本的spring boot客户端，需要做一些<a href="http://codecentric.github.io/spring-boot-admin/current/#monitoring-spring-boot-1.5.x" target="_blank" rel="noopener">兼容处理</a></li><li>扩展UI，由于2.0使用了Vue.js重构，可以很方便的<a href="http://codecentric.github.io/spring-boot-admin/current/#customizing-custom-views" target="_blank" rel="noopener">扩展</a></li></ol><p>完结撒花</p>]]></content>
      
      <categories>
          
          <category> Spring Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 官方文档阅读 </tag>
            
            <tag> Spring Cloud </tag>
            
            <tag> 监控 </tag>
            
            <tag> 翻译 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>linux命令手记</title>
      <link href="/2018/08/27/linux%E5%91%BD%E4%BB%A4%E6%89%8B%E8%AE%B0/"/>
      <url>/2018/08/27/linux%E5%91%BD%E4%BB%A4%E6%89%8B%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h2 id="从后往前查看日志"><a href="#从后往前查看日志" class="headerlink" title="从后往前查看日志"></a>从后往前查看日志</h2><ol><li>less 文件名</li><li>shift+g跳转到末尾，向上滑动</li></ol><h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><p>首先不推荐cat,vim等命令,大日志文件容易导致内存不足，线上排查问题时容易引起服务崩溃</p><p>有时想要查看最后五分钟内的日志，tail命令指定行数也可以大致做到，但是行数不好指定时，less会很方便</p><h2 id="查找进程命令如何排除自带的grep"><a href="#查找进程命令如何排除自带的grep" class="headerlink" title="查找进程命令如何排除自带的grep"></a>查找进程命令如何排除自带的grep</h2><p>这个技巧常用在编写shell脚本时，希望查找到某个进程的pid，但是grep命令本身也会产生一条数据，因此需要排除<br>例如查找xxx进程时<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef|grep xxx |grep -v <span class="string">'grep'</span></span><br></pre></td></tr></table></figure></p><h2 id="查看前十个最占内存的应用"><a href="#查看前十个最占内存的应用" class="headerlink" title="查看前十个最占内存的应用"></a>查看前十个最占内存的应用</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps aux|head -1;ps aux|grep -v PID|sort -rn -k +4|head</span><br></pre></td></tr></table></figure><h2 id="查看前十个最占CPU的应用"><a href="#查看前十个最占CPU的应用" class="headerlink" title="查看前十个最占CPU的应用"></a>查看前十个最占CPU的应用</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps aux|grep -v PID|sort -rn -k 3| head | awk <span class="string">'BEGIN&#123;print "USER PID %CPU %MEM VSZ RSS STAT"&#125; &#123;print $1,$2,$3,$4,$5,$6,$8&#125;'</span></span><br></pre></td></tr></table></figure><h2 id="按端口终止进程"><a href="#按端口终止进程" class="headerlink" title="按端口终止进程"></a>按端口终止进程</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line">PORT=2181</span><br><span class="line">PID=`lsof -i:<span class="variable">$&#123;PORT&#125;</span> |grep -v PID |awk <span class="string">'&#123;print $2&#125;'</span>`</span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$&#123;PID&#125;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"kill pid : <span class="variable">$&#123;PID&#125;</span>"</span></span><br><span class="line">        <span class="built_in">kill</span> <span class="variable">$&#123;PID&#125;</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"could not find process with port:<span class="variable">$&#123;PORT&#125;</span>"</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><h2 id="生成UUID"><a href="#生成UUID" class="headerlink" title="生成UUID"></a>生成UUID</h2><p>uuidgen命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uuidgen</span><br></pre></td></tr></table></figure><p>结果</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d4586ba5-22da-42e5-9662-acad5942988d</span><br></pre></td></tr></table></figure><h2 id="启动shell脚本"><a href="#启动shell脚本" class="headerlink" title="启动shell脚本"></a>启动shell脚本</h2><p>编写shell脚本之后，可以通过<code>chmod +x</code>的方式，然后启动，不过用<code>sh 脚本名</code>的方式更加简洁，目前没有对比二者的优劣</p><h2 id="查找占用磁盘空间的文件"><a href="#查找占用磁盘空间的文件" class="headerlink" title="查找占用磁盘空间的文件"></a>查找占用磁盘空间的文件</h2><p>一层一层目录查找最占磁盘空间的文件夹</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">du -h --max-depth=1</span><br></pre></td></tr></table></figure><h2 id="top命令技巧"><a href="#top命令技巧" class="headerlink" title="top命令技巧"></a>top命令技巧</h2><p>shift+p: 按CPU使用率降序排序，用户查找CPU使用率最高的进程<br>shift+m: 按内存使用率降序排序<br>shift+h: 显示线程占用cpu情况</p><p>top -p <pid> -H ：查看进程中各线程详情</pid></p><h2 id="netstat命令技巧"><a href="#netstat命令技巧" class="headerlink" title="netstat命令技巧"></a>netstat命令技巧</h2><p>按pid统计连接数<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -natp|awk <span class="string">'print $7'</span>|uniq -c|sort -rn</span><br></pre></td></tr></table></figure></p><h2 id="awk入门"><a href="#awk入门" class="headerlink" title="awk入门"></a>awk入门</h2><p>test.txt<br>red,10,jay<br>black,20,tom<br>yellow,30,jim</p><p>awk -F “,” ‘$3&gt;15 {print $1,$2}’ test.txt<br>持续积累中 ……</p>]]></content>
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 日志 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring Cloud系列前言</title>
      <link href="/2018/08/10/Spring-Cloud%E7%B3%BB%E5%88%97%E5%89%8D%E8%A8%80/"/>
      <url>/2018/08/10/Spring-Cloud%E7%B3%BB%E5%88%97%E5%89%8D%E8%A8%80/</url>
      <content type="html"><![CDATA[<p>笔者一些无聊的思考，也有一些对新手的建议</p><ol><li>了解一个新技术之前，它为什么出现，解决了什么问题，和现有的解决方案相比，它有什么优点，又有什么缺点(没有完美的方案)</li><li>DevOps，微服务dev易，ops难，有哪些技术可以实现ops，做到可持续交付，微服务的监控，管理怎么做，如何减少排查问题的复杂度</li><li>微服务如何根据业务拆分模块</li><li>Spring Cloud如何实现真正意义上的多语言，不要觉得公司只用java，同时用PHP，Go，Python太正常了，举个例子，阿里收购个公司，发现用的不是java就不收购了？收购之后要整合业务就让别人全改成java吗，现有的”老”系统重做吗</li><li>一口就吃个大胖子，一套框架解决公司所有业务？不可能的，架构应该遵循演进式原则</li><li>如何去学习Spring Cloud，由于Spring Boot 1.x版本和2.x版本的差别较大，往往因为一些教程的版本落后让人痛不欲生，所以自己摸索是一方面，比如找最新的教程，遇到问题多看官方文档也是个好习惯</li><li>关于看英文文档，只是一个适应的过程，下载一个有道翻译，只要有一些英语基础的人都能看懂，ps:本人四级考了2次飘过的学渣，:)逃，看多英文文档之后，甚至有种看不进去中文翻译的感觉，因为不好理解，还不如看英文，虽然浪费点时间，但是理解的快</li><li>关于遇到问题如何解决这件事，给新人一些建议，不要问leader一些很low的问题，我本人属于内向的人，习惯do my best之后再去问人，说下我的解决思路<ol><li>首先尽量看懂英文的错误提示</li><li>百度能帮你解决很多”常见”的问题</li><li>百度也不是个好东西，遇到难题，就会发现天下文章一大抄，抄来抄去就那么几篇</li><li>谷歌，多留意Stack Overflow的网站，同样需要你有耐心看懂英文</li><li>既然是开源项目，为什么不去github的issue搜一搜，笔者很喜欢这样做，不急的问题搜不到提个issue也比去某个论坛强</li><li>现在Github流行gitter在线聊天，可以更好和别人交流，尤其是项目作者。ps: 也可以看看别人的问题，毕竟都是坑</li><li>当然这些要看问题的具体情况，比如一个业务问题，你去github是没有意义的，最后多看官方文档，会避免很多问题，也会给你解决问题带来思路</li></ol></li><li>如何减少bug量，请正视测试用例，测试用例，测试用例</li></ol><p>咳咳，接下来说正题，<strong>Spring cloud</strong></p><p>在学习Spring cloud之后，我对它最直观的理解是: Spring cloud是用于构建分布式系统的一组通用工具集，秉承Spring的集成理念，Spring cloud并不会自己去开发一套工具，而是集成业界现有的优秀开源项目，这里的优秀必然是经得起生产环境验证，并且持续维护。Spring cloud自1.0开始就集成了Netflix OSS套件，通过Spring boot的autoconfigure简化配置，并且为其注入Spring运行环境，让开发者通过几个简单的注解就构建一个基于Netflix生产级别的分布式系统</p>]]></content>
      
      <categories>
          
          <category> Spring Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Cloud </tag>
            
            <tag> 微服务 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring boot实践之事件监听</title>
      <link href="/2018/07/31/Spring-boot%E5%AE%9E%E8%B7%B5%E4%B9%8B%E4%BA%8B%E4%BB%B6%E7%9B%91%E5%90%AC/"/>
      <url>/2018/07/31/Spring-boot%E5%AE%9E%E8%B7%B5%E4%B9%8B%E4%BA%8B%E4%BB%B6%E7%9B%91%E5%90%AC/</url>
      <content type="html"><![CDATA[<p>在Spring Boot doc的<em>Application Events and Listeners</em>一章中提到，Spring Boot按以下顺序提供了6个事件，供开发者编写<code>ApplicationListener</code>监听相应的事件</p><pre><code>1.ApplicationStartingEvent：在开始运行时，监听器注册和初始化之后被触发2.ApplicationEnvironmentPreparedEvent：发现 Environment 被上下文使用时，上下文被创建之前触发3.ApplicationPreparedEvent：在启动刷新之前，bean定义被加载之后被触发4.ApplicationStartedEvent：上下文刷新之前，应用和命令行启动器运行之前触发5.ApplicationReadyEvent：在所有应用和命令行启动器调用之后，这表明应用已经准备好处理请求6.ApplicationFailedEvent：启动时出现异常触发</code></pre><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>编写代码的难度不高，读者可根据自己的需求编写相应的listener，以ApplicationStartingEvent为例</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@Component</span><br><span class="line">public class SpringBootListener implements ApplicationListener&lt;ApplicationStartingEvent&gt; &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public void onApplicationEvent(ApplicationStartingEvent event) &#123;</span><br><span class="line">        System.out.println(&quot;listening spring boot starting event&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><p>根据文档中的提示，可以使用三种方式添加这6个事件的监听器</p><p>1.通过SpringApplication的addApplicationListener方法添加</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SpringApplication.run(SpringBootDocApplication.class,args).addApplicationListener(<span class="keyword">new</span> SpringBootListener());</span><br></pre></td></tr></table></figure><p>2.类似的用SpringApplicationBuilder实现</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> SpringApplicationBuilder(SpringBootDocApplication.class).listeners(<span class="keyword">new</span> SpringBootListener()).run(args);</span><br></pre></td></tr></table></figure><p>3.如果Listener很多，也可以写在配置文件中，在resources目录下新建META-INF/spring.factories</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">org.springframework.context.ApplicationListener=com.ttyc.doc.extend.event.customer.SpringBootListener</span><br></pre></td></tr></table></figure><p>最终项目一启动便输出: listening spring boot starting event</p>]]></content>
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>观察者模式</title>
      <link href="/2018/07/26/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/"/>
      <url>/2018/07/26/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/</url>
      <content type="html"><![CDATA[<h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><p>一个对象的属性发生改变时，需要通知到依赖它的对象并自动更新</p><h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>针对使用场景，如何用代码去实现这种效果，只要理解了观察者模式的基本原理，代码一目了然</p><ol><li>首先明确有两个对象: 观察者，被观察者，我更喜欢理解为监视器和目标</li><li>目标对象里维护一个注册列表，里面记录了注册过的监视器，对外提供注册列表的添加和移除api</li><li>目标发生改变时，遍历这个列表里的所有监视器，通过调用监视器的一个方法通知监视器</li></ol><h2 id="代码思路"><a href="#代码思路" class="headerlink" title="代码思路"></a>代码思路</h2><p>原理并不难，可以说十分简单，两个类，注册列表用一个List集合表示，是否发生改变用一个布尔值表示，很容易手写出来。</p><p>首先是目标类，读者根据上述思路阅读代码应该没有什么障碍</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Target</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 要发生改变的属性</span></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 监视器的注册列表</span></span><br><span class="line">    <span class="keyword">private</span> List&lt;Monitor&gt; monitors = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 是否发生改变的标志位</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> isChanged = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 注册监视器</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">registMonitor</span><span class="params">(Monitor monitor)</span></span>&#123;</span><br><span class="line">        Objects.requireNonNull(monitor);</span><br><span class="line">        monitors.add(monitor);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 注销监视器</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">deregistMonitor</span><span class="params">(Monitor monitor)</span></span>&#123;</span><br><span class="line">        Objects.requireNonNull(monitor);</span><br><span class="line">        monitors.remove(monitor);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 改变属性</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.isChanged = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">this</span>.notifyMonitor();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 通知监视器</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">notifyMonitor</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (monitors.size() &gt; <span class="number">0</span> &amp;&amp; <span class="keyword">this</span>.isChanged)&#123;</span><br><span class="line">            <span class="keyword">for</span> (Monitor monitor: monitors)&#123;</span><br><span class="line">                monitor.update(<span class="keyword">this</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 通知结束后清除标志位</span></span><br><span class="line">            <span class="keyword">this</span>.isChanged = <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后是监视者类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Monitor</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 起个名字</span></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 根据目前对象发生的改变，做出反应</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">update</span><span class="params">(Target target)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"当前监视器为："</span> + getName() + <span class="string">",监视的对象已发生改变，目标名称为："</span> + target.getName());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后通过测试类测试一下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Monitor monitor1 = <span class="keyword">new</span> Monitor();</span><br><span class="line">        monitor1.setName(<span class="string">"1号"</span>);</span><br><span class="line">        Monitor monitor2 = <span class="keyword">new</span> Monitor();</span><br><span class="line">        monitor2.setName(<span class="string">"2号"</span>);</span><br><span class="line"></span><br><span class="line">        Target target = <span class="keyword">new</span> Target();</span><br><span class="line">        <span class="comment">// 测试两个监视器</span></span><br><span class="line">        target.registMonitor(monitor1);</span><br><span class="line">        target.registMonitor(monitor2);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 改变属性</span></span><br><span class="line">        target.setName(<span class="string">"jim"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 注销其中一个</span></span><br><span class="line">        target.deregistMonitor(monitor1);</span><br><span class="line">        target.setName(<span class="string">"tom"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>输出结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">当前监视器为：1号,监视的对象已发生改变，目标名称为：jim</span><br><span class="line">当前监视器为：2号,监视的对象已发生改变，目标名称为：jim</span><br><span class="line">当前监视器为：2号,监视的对象已发生改变，目标名称为：tom</span><br></pre></td></tr></table></figure><p>说明通知成功，并且注销监视器对象后，不再接收到通知</p><h2 id="JDK自带的观察者模式接口"><a href="#JDK自带的观察者模式接口" class="headerlink" title="JDK自带的观察者模式接口"></a>JDK自带的观察者模式接口</h2><p>为什么要用JDK自带的Observable(被观察者)，Observer(观察者)呢？</p><p>点开Observable的源码，since JDK1.0就有的一个类，十分古老，所以出现Vector也不足为奇了，再看里面的方法，关于修改Vector和changed的地方都被synchronized修饰，说明JDK对线程安全性考虑的很好</p><h2 id="JDK源码"><a href="#JDK源码" class="headerlink" title="JDK源码"></a>JDK源码</h2><p>Observable类中用于通知观察者的源码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">notifyObservers</span><span class="params">(Object arg)</span> </span>&#123;</span><br><span class="line">        Object[] arrLocal;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 自己翻译了下注释：我们不希望观察者在处理自己的监视器时，</span></span><br><span class="line"><span class="comment">         * 回调到所有的代码。我们从集合里取出每一个被观察者，并且</span></span><br><span class="line"><span class="comment">         * 存储观察者的需要同步的状态，但是不应该通知观察者们。</span></span><br><span class="line"><span class="comment">         * 任意竞争锁的最糟糕结果是</span></span><br><span class="line"><span class="comment">         *  1.一个新增的观察者可能错过通知</span></span><br><span class="line"><span class="comment">         *  2.一个最近注销的观察者在它不需要的时候被通知了</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!changed)</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            arrLocal = obs.toArray();</span><br><span class="line">            clearChanged();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = arrLocal.length - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--)</span><br><span class="line">            ((Observer) arrLocal[i]).update(<span class="keyword">this</span>, arg);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>实现流程大致类似</p><h2 id="JDK方式代码实现"><a href="#JDK方式代码实现" class="headerlink" title="JDK方式代码实现"></a>JDK方式代码实现</h2><h3 id="Step-1-被观察者"><a href="#Step-1-被观察者" class="headerlink" title="Step 1: 被观察者"></a>Step 1: 被观察者</h3><p>继承Observable</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Target</span> <span class="keyword">extends</span> <span class="title">Observable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.setChanged();</span><br><span class="line">        <span class="keyword">this</span>.notifyObservers(<span class="string">"name has been changed, now is "</span> + name);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Step-2-观察者"><a href="#Step-2-观察者" class="headerlink" title="Step 2: 观察者"></a>Step 2: 观察者</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Watcher</span> <span class="keyword">implements</span> <span class="title">Observer</span> </span>&#123;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">update</span><span class="params">(Observable o, Object arg)</span> </span>&#123;</span><br><span class="line">        Target target = (Target) o;</span><br><span class="line">        System.out.println(<span class="string">"I am be notified by "</span> + target.getName() + <span class="string">", message is "</span> + arg);</span><br><span class="line">    &#125;&#125;</span><br></pre></td></tr></table></figure><h3 id="Step-3-验证"><a href="#Step-3-验证" class="headerlink" title="Step 3: 验证"></a>Step 3: 验证</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Target target = <span class="keyword">new</span> Target();</span><br><span class="line"></span><br><span class="line">        Watcher foo = <span class="keyword">new</span> Watcher();</span><br><span class="line">        Watcher bar = <span class="keyword">new</span> Watcher();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 注册</span></span><br><span class="line">        target.addObserver(foo);</span><br><span class="line">        target.addObserver(bar);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 目标发生改变, 自动通知监视器，并调用update方法</span></span><br><span class="line">        target.setName(<span class="string">"Jim"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 移除监视器</span></span><br><span class="line">        target.deleteObserver(bar);</span><br><span class="line">        target.setName(<span class="string">"Kim"</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h3 id="控制台输出"><a href="#控制台输出" class="headerlink" title="控制台输出"></a>控制台输出</h3><p>第一次setName通知了两个观察者，然后移除了bar观察者，下一次通知就只有一个观察者收到了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">I am be notified by Jim, message is name has been changed, now is Jim</span><br><span class="line">I am be notified by Jim, message is name has been changed, now is Jim</span><br><span class="line">I am be notified by Kim, message is name has been changed, now is Kim</span><br></pre></td></tr></table></figure><p>如果对JDK自带的线程安全实现方式不满意，可以自行实现这两个类</p>]]></content>
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring ContextRefreshedEvent事件</title>
      <link href="/2018/07/26/Spring-ContextRefreshedEvent%E4%BA%8B%E4%BB%B6/"/>
      <url>/2018/07/26/Spring-ContextRefreshedEvent%E4%BA%8B%E4%BB%B6/</url>
      <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">遇到的单词</span><br><span class="line">infrastructure ： 基础设施</span><br><span class="line">arbitrary : 任何的，所有的</span><br></pre></td></tr></table></figure><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>本文主要在<a href="https://greedypirate.github.io/2018/07/26/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/">观察者模式</a>的基础上研究Spring中的事件机制</p><p>ApplicationListener监听以下4个事件：ContextStartedEvent，ContextRefreshedEvent，ContextStartedEvent，ContextClosedEvent</p><p>实现对ApplicationContext刷新或初始化时的监听，测试中未出现加载两次的情况，如果需要加入<code>event.getApplicationContext().getParent()</code>判断</p><h2 id="监听ContextRefreshedEvent"><a href="#监听ContextRefreshedEvent" class="headerlink" title="监听ContextRefreshedEvent"></a>监听ContextRefreshedEvent</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ContextEnvent</span> <span class="keyword">implements</span> <span class="title">ApplicationListener</span>&lt;<span class="title">ContextRefreshedEvent</span>&gt; </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onApplicationEvent</span><span class="params">(ContextRefreshedEvent event)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"Spring Refreshed"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>自从Spring 4.2以后，可以使用@EventListener注解实现，相信用过Spring-Kafka的读者不会陌生这种写法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AnnotateContextEvent</span></span>&#123;</span><br><span class="line">    <span class="meta">@EventListener</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleRefresh</span><span class="params">(ContextRefreshedEvent event)</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"Spring Refreshed by annotated approach"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h2 id="自定义事件"><a href="#自定义事件" class="headerlink" title="自定义事件"></a>自定义事件</h2><p>实现起来很简单，接下来尝试下Spring中的自定义事件</p><p>自定义事件需要继承ApplicationEvent，这个类并没有什么深意，只是简单封装EventObject加入了时间戳</p><h3 id="Step-1-定义事件——被观察者"><a href="#Step-1-定义事件——被观察者" class="headerlink" title="Step 1 : 定义事件——被观察者"></a>Step 1 : 定义事件——被观察者</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerEvent</span> <span class="keyword">extends</span> <span class="title">ApplicationEvent</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">CustomerEvent</span><span class="params">(Object source, String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(source);</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Step-2-定义监听器——观察者"><a href="#Step-2-定义监听器——观察者" class="headerlink" title="Step 2 : 定义监听器——观察者"></a>Step 2 : 定义监听器——观察者</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerListener</span> <span class="keyword">implements</span> <span class="title">ApplicationListener</span>&lt;<span class="title">CustomerEvent</span>&gt;</span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onApplicationEvent</span><span class="params">(CustomerEvent event)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"CustomerListener listening： CustomerEvent has been triggered, event name is "</span> + event.getName());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Step-3-多了一步事件发布"><a href="#Step-3-多了一步事件发布" class="headerlink" title="Step 3 : 多了一步事件发布"></a>Step 3 : 多了一步事件发布</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomEventPublisher</span> <span class="keyword">implements</span> <span class="title">ApplicationEventPublisherAware</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> ApplicationEventPublisher publisher;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">publish</span><span class="params">()</span></span>&#123;</span><br><span class="line">        CustomerEvent customerEvent = <span class="keyword">new</span> CustomerEvent(<span class="keyword">this</span>,<span class="string">"click"</span>);</span><br><span class="line">        publisher.publishEvent(customerEvent);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setApplicationEventPublisher</span><span class="params">(ApplicationEventPublisher applicationEventPublisher)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.publisher = applicationEventPublisher;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringBootDocApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">SpringApplication.run(SpringBootDocApplication.class, args)</span><br><span class="line">                .getBean(CustomEventPublisher.class).publish();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="控制台输出"><a href="#控制台输出" class="headerlink" title="控制台输出"></a>控制台输出</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CustomerListener listening： CustomerEvent has been triggered, event name is click</span><br></pre></td></tr></table></figure><h3 id="如果再加入一个监听者呢？是否能通知到"><a href="#如果再加入一个监听者呢？是否能通知到" class="headerlink" title="如果再加入一个监听者呢？是否能通知到"></a>如果再加入一个监听者呢？是否能通知到</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExtraListener</span> <span class="keyword">implements</span> <span class="title">ApplicationListener</span>&lt;<span class="title">CustomerEvent</span>&gt; </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onApplicationEvent</span><span class="params">(CustomerEvent event)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"ExtraListener listening： CustomerEvent has been triggered, event name is "</span> + event.getName());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CustomerListener listening： CustomerEvent has been triggered, event name is click</span><br><span class="line">ExtraListener listening： CustomerEvent has been triggered, event name is click</span><br></pre></td></tr></table></figure><hr><h2 id="源码跟踪"><a href="#源码跟踪" class="headerlink" title="源码跟踪"></a>源码跟踪</h2><p><img src="https://ae01.alicdn.com/kf/H01d163bde58c41e0b908f08d02d02af1N.png" width="65%" align="left"></p><p>这里和观察者模式的遍历一样，调用所有的监听器<br><img src="https://ae01.alicdn.com/kf/H9c5679f3036b4c40b70c684e1d7cf4972.png" width="65%" align="left"></p><p>进入getApplicationListeners方法，可以看到如何查找注册在event上的Listener<br><img src="https://ae01.alicdn.com/kf/Ha30a903295484252a75561e2fc2717b2f.png" width="65%" align="left"></p><p>根据@Order注解对Listener排序，<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AnnotationAwareOrderComparator.sort(allListeners);</span><br></pre></td></tr></table></figure></p><p>对两个Listener加入@Order注解，果然值较小的ExtraListener先执行</p><p>注：@Order Lower values have higher priority</p><h2 id="心得"><a href="#心得" class="headerlink" title="心得"></a>心得</h2><pre><code>对自己的猜想要多验证</code></pre><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://spring.io/blog/2015/02/11/better-application-events-in-spring-framework-4-2" target="_blank" rel="noopener">https://spring.io/blog/2015/02/11/better-application-events-in-spring-framework-4-2</a><br><a href="http://wiki.jikexueyuan.com/project/spring/custom-events-in-spring.html" target="_blank" rel="noopener">http://wiki.jikexueyuan.com/project/spring/custom-events-in-spring.html</a><br><a href="https://blog.csdn.net/tuzongxun/article/details/53637159" target="_blank" rel="noopener">https://blog.csdn.net/tuzongxun/article/details/53637159</a><br><a href="https://blog.csdn.net/zhangningzql/article/details/52515890" target="_blank" rel="noopener">https://blog.csdn.net/zhangningzql/article/details/52515890</a></p>]]></content>
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
            <tag> Spring 扩展 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring InitializingBean接口</title>
      <link href="/2018/07/25/Spring-InitializingBean%E6%8E%A5%E5%8F%A3/"/>
      <url>/2018/07/25/Spring-InitializingBean%E6%8E%A5%E5%8F%A3/</url>
      <content type="html"><![CDATA[<h2 id="源文档"><a href="#源文档" class="headerlink" title="源文档"></a>源文档</h2><p>InitializingBean接口的doc文档解释如下，大意为：</p><p>实现这个接口的bean，可以在BeanFactory设置完所有的属性之后生效，例如，执行自定义的bean初始化，或者只是为了检查所有的属性被设置了</p><p>另一个选择是指定<code>init-method</code>，例如在XML中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Interface to be implemented by beans that need to react once all their</span><br><span class="line"> * properties have been set by a BeanFactory: for example, to perform custom</span><br><span class="line"> * initialization, or merely to check that all mandatory properties have been set.</span><br><span class="line"> *</span><br><span class="line"> * An alternative to implementing InitializingBean is specifying a custom</span><br><span class="line"> * init-method, for example in an XML bean definition.</span><br><span class="line"> */</span><br></pre></td></tr></table></figure><h2 id="测试代码"><a href="#测试代码" class="headerlink" title="测试代码"></a>测试代码</h2><p>从接口描述上可以看出和指定<em>init-method</em>的作用应该是类似的,测试代码如下</p><h3 id="Step-1：实现InitializingBean接口"><a href="#Step-1：实现InitializingBean接口" class="headerlink" title="Step 1：实现InitializingBean接口"></a>Step 1：实现InitializingBean接口</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InitBeanExtend</span> <span class="keyword">implements</span> <span class="title">InitializingBean</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">afterPropertiesSet</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"after properties set"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"bean inited"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Step-2-使用java-config定义bean，指定init-method"><a href="#Step-2-使用java-config定义bean，指定init-method" class="headerlink" title="Step 2: 使用java config定义bean，指定init-method"></a>Step 2: 使用java config定义bean，指定init-method</h3><p>为了方便指定init-method,使用java config</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InitConfig</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Bean</span>(initMethod = <span class="string">"init"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> InitBeanExtend <span class="title">initBeanExtend</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> InitBeanExtend();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Step-3-编写测试用例"><a href="#Step-3-编写测试用例" class="headerlink" title="Step 3: 编写测试用例"></a>Step 3: 编写测试用例</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RunWith</span>(SpringRunner.class)</span><br><span class="line"><span class="meta">@SpringBootTest</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringBootDocApplicationTests</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line">InitBeanExtend initBeanExtend;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">contextLoads</span><span class="params">()</span> </span>&#123;</span><br><span class="line">InitBeanExtend bean = InitBeanExtend.class.cast(initBeanExtend);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="控制台输出"><a href="#控制台输出" class="headerlink" title="控制台输出"></a>控制台输出</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">after properties <span class="built_in">set</span></span><br><span class="line">bean inited</span><br></pre></td></tr></table></figure><p>结果表明init-method是在afterPropertiesSet方法执行之后调用的</p><hr><p>查看<code>AbstractAutowireCapableBeanFactory</code>类源码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">invokeCustomInitMethod</span><span class="params">(String beanName, <span class="keyword">final</span> Object bean, RootBeanDefinition mbd)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">...</span><br><span class="line">String initMethodName = mbd.getInitMethodName();</span><br><span class="line"><span class="keyword">final</span> Method initMethod = (mbd.isNonPublicAccessAllowed() ?</span><br><span class="line">BeanUtils.findMethod(bean.getClass(), initMethodName) :</span><br><span class="line">ClassUtils.getMethodIfAvailable(bean.getClass(), initMethodName));</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>二者除了先后顺序的明显区别之外，可以看出init-method是通过反射达到目的的，而InitializingBean接口具有代码侵入性，有对Spring的依赖</p><p>注意: init-method方法不能有参数，否则将抛出异常</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">org.springframework.beans.factory.support.BeanDefinitionValidationException: Couldn&apos;t find an init method named &apos;init&apos; on bean with name &apos;initBeanExtend&apos;</span><br></pre></td></tr></table></figure><p>在IDEA下会有编译警告<br><img src="https://ae01.alicdn.com/kf/Hb3803affca7840a190a0a6a76efa6185L.png" width="65%" align="left"></p><h2 id="实际应用"><a href="#实际应用" class="headerlink" title="实际应用"></a>实际应用</h2><p>看过Spring源码的读者经常可以看到这个接口的使用，比如在bean初始化完属性之后，进行参数检查</p><h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><h3 id="DisposableBean接口"><a href="#DisposableBean接口" class="headerlink" title="DisposableBean接口"></a><code>DisposableBean</code>接口</h3><p>与初始化相对应的还有销毁，在Spring中提供DisposableBean接口，可用来优雅的退出Spring Boot程序，对前面的代码添加实现<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InitBeanExtend</span> <span class="keyword">implements</span> <span class="title">InitializingBean</span>,<span class="title">DisposableBean</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">afterPropertiesSet</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"after properties set"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"bean inited"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"gracefully close applicationContext"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="Java-EE5规范-PostConstruct和-PreDestroy"><a href="#Java-EE5规范-PostConstruct和-PreDestroy" class="headerlink" title="Java EE5规范@PostConstruct和@PreDestroy"></a>Java EE5规范<code>@PostConstruct</code>和<code>@PreDestroy</code></h3><p>Java EE5规范提出的两个影响Servlet声明周期的方法，添加在非静态方法上，分别会在Servlet实例初始化之后和被销毁之前执行一次</p>]]></content>
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
            <tag> Spring 扩展 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring Boot 官方文档阅读</title>
      <link href="/2018/07/24/Spring%20Boot%E6%96%87%E6%A1%A3%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
      <url>/2018/07/24/Spring%20Boot%E6%96%87%E6%A1%A3%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>Spring Boot 版本 2.0.3.RELEASE</p><p>文档地址：<a href="https://docs.spring.io/spring-boot/docs/2.0.3.RELEASE/reference/html/" target="_blank" rel="noopener">https://docs.spring.io/spring-boot/docs/2.0.3.RELEASE/reference/html/</a></p><h2 id="遇到的英文单词"><a href="#遇到的英文单词" class="headerlink" title="遇到的英文单词"></a>遇到的英文单词</h2><ul><li>typical: 典型的</li><li>transitively: 可传递地</li><li>Several of : 几个</li><li>dives into : 深入</li><li>bootstrap : 引导</li><li>delegate : 委托</li><li>approach : 方法</li><li>perform : 执行</li><li>detect : 察觉，侦测，发现</li></ul><h2 id="Spring-CLI的使用"><a href="#Spring-CLI的使用" class="headerlink" title="Spring CLI的使用"></a>Spring CLI的使用</h2><p>step 1： sdkman安装spring-boot</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sdk install springboot</span><br></pre></td></tr></table></figure><p>step 2：运行groovy脚本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spring run app.groovy</span><br></pre></td></tr></table></figure><p>示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ThisWillActuallyRun</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RequestMapping</span>(<span class="string">"/"</span>)</span><br><span class="line"><span class="function">String <span class="title">home</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="string">"Hello World!"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="从低版本的Spring-Boot升级到2-0"><a href="#从低版本的Spring-Boot升级到2-0" class="headerlink" title="从低版本的Spring Boot升级到2.0"></a>从低版本的Spring Boot升级到2.0</h2><p>加入依赖</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-properties-migrator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>运行一次后移除该依赖</p><h2 id="使用maven命令启动Spring-Boot"><a href="#使用maven命令启动Spring-Boot" class="headerlink" title="使用maven命令启动Spring Boot"></a>使用maven命令启动Spring Boot</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn spring-boot:run</span><br></pre></td></tr></table></figure><p>相应的gradle有:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gradle bootRun</span><br></pre></td></tr></table></figure></p><p>可以export系统变量(<strong>没有测试</strong>):</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> MAVEN_OPTS=-Xmx1024m</span><br></pre></td></tr></table></figure><h2 id="社区提供的Spring-Boot-starter"><a href="#社区提供的Spring-Boot-starter" class="headerlink" title="社区提供的Spring Boot starter"></a>社区提供的Spring Boot starter</h2><p><a href="https://github.com/spring-projects/spring-boot/tree/master/spring-boot-project/spring-boot-starters" target="_blank" rel="noopener">starters列表</a></p><h2 id="如何排除不想生效的Bean"><a href="#如何排除不想生效的Bean" class="headerlink" title="如何排除不想生效的Bean"></a>如何排除不想生效的Bean</h2><p>方式一：使用exclude属性<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span>(exclude = DataSourceAutoConfiguration.class)</span><br></pre></td></tr></table></figure></p><p>方式二：如果classpath下没有这个类，使用类全名<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span>(excludeName = <span class="string">"org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration"</span>)</span><br></pre></td></tr></table></figure></p><p>方式三：如果有多个，可以使用spring.autoconfigure.exclude属性<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spring.autoconfigure.exclude=DataSourceAutoConfiguration.class</span><br></pre></td></tr></table></figure></p><p>你可以同时在注解和属性上使用exclude</p><p>You can define exclusions both at the annotation level and by using the property.</p><h2 id="构造器注入可以省略-Autowired"><a href="#构造器注入可以省略-Autowired" class="headerlink" title="构造器注入可以省略@Autowired"></a>构造器注入可以省略@Autowired</h2><p><strong>If a bean has one constructor, you can omit the @Autowired</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DatabaseAccountService</span> <span class="keyword">implements</span> <span class="title">AccountService</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> RiskAssessor riskAssessor;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">DatabaseAccountService</span><span class="params">(RiskAssessor riskAssessor)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.riskAssessor = riskAssessor;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="使用Remote-Debug时的启动参数"><a href="#使用Remote-Debug时的启动参数" class="headerlink" title="使用Remote Debug时的启动参数"></a>使用Remote Debug时的启动参数</h2><p>仅供参考，自己还没有试</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">java -Xdebug -Xrunjdwp:server=y,transport=dt_socket,address=8000,<span class="built_in">suspend</span>=n </span><br><span class="line">-jar target/myapplication-0.0.1-SNAPSHOT.jar</span><br></pre></td></tr></table></figure><h2 id="IDEA中使用devtools的正确姿势"><a href="#IDEA中使用devtools的正确姿势" class="headerlink" title="IDEA中使用devtools的正确姿势"></a>IDEA中使用devtools的正确姿势</h2><p>修改代码后，需要点击: <strong>Build-&gt;Build Project</strong></p><h2 id="编程式的属性设置"><a href="#编程式的属性设置" class="headerlink" title="编程式的属性设置"></a>编程式的属性设置</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">System.setProperty(<span class="string">"spring.devtools.restart.enabled"</span>, <span class="string">"false"</span>);</span><br><span class="line">SpringApplication.run(MyApp.class, args);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Spring-Boot提供的几个很有用的事件"><a href="#Spring-Boot提供的几个很有用的事件" class="headerlink" title="Spring Boot提供的几个很有用的事件"></a>Spring Boot提供的几个很有用的事件</h2><p>针对Spring boot提供的事件，编写自己的Listener,详见<strong><a href="https://greedypirate.github.io/2018/07/26/Spring-ContextRefreshedEvent%E4%BA%8B%E4%BB%B6/">Spring-ContextRefreshedEvent事件</a></strong></p><ol><li>ApplicationStartingEvent：在开始运行时，监听器注册和初始化之后被触发</li><li>ApplicationEnvironmentPreparedEvent：发现 Environment 被上下文使用时，上下文被创建之前触发</li><li>ApplicationPreparedEvent：在启动刷新之前，bean定义被加载之后被触发</li><li>ApplicationStartedEvent：上下文刷新之前，应用和命令行启动器运行之前触发</li><li>ApplicationReadyEvent：在所有应用和命令行启动器调用之后，这表明应用已经准备好处理请求<br> 6.ApplicationFailedEvent：启动时出现异常触发</li></ol><h2 id="配置文件的名称和位置"><a href="#配置文件的名称和位置" class="headerlink" title="配置文件的名称和位置"></a>配置文件的名称和位置</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spring.config.name</span><br><span class="line">spring.config.location</span><br></pre></td></tr></table></figure><p><strong>注</strong>：这是两个需要很早初始化的属性，只能写在环境变量里(OS environment variable, a system property, or a command-line argument)</p><h2 id="获取命令行参数"><a href="#获取命令行参数" class="headerlink" title="获取命令行参数"></a>获取命令行参数</h2><ul><li>通过注入ApplicationArguments</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BootstrapArgs</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">BootstrapArgs</span><span class="params">(ApplicationArguments args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">boolean</span> myargs = args.containsOption(<span class="string">"myargs"</span>);</span><br><span class="line">        Assert.state(myargs, <span class="string">"无法获取自定义参数"</span>);</span><br><span class="line">        List&lt;String&gt; nonOptionArgs = args.getNonOptionArgs();</span><br><span class="line">        System.out.println(<span class="string">"nonOptionArgs : "</span> + StringUtils.collectionToCommaDelimitedString(nonOptionArgs));</span><br><span class="line">        Set&lt;String&gt; optionNames = args.getOptionNames();</span><br><span class="line">        <span class="keyword">for</span> (String optionName : optionNames) &#123;</span><br><span class="line">            List&lt;String&gt; optionValues = args.getOptionValues(optionName);</span><br><span class="line">            System.out.println(optionValues);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>实现CommandLineRunner或ApplicationRunner接口</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RunnerBean</span> <span class="keyword">implements</span> <span class="title">CommandLineRunner</span></span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(String... args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(String arg:args)&#123;</span><br><span class="line">            System.out.println(arg);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="日志按环境生效"><a href="#日志按环境生效" class="headerlink" title="日志按环境生效"></a>日志按环境生效</h2><p>以下配置文件展示了多个环境，特定环境，非某个环境</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 测试环境+开发环境. 多个使用逗号隔开. --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">springProfile</span> <span class="attr">name</span>=<span class="string">"test,dev"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.example.demo.controller"</span> <span class="attr">level</span>=<span class="string">"DEBUG"</span> <span class="attr">additivity</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"consoleLog"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">springProfile</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 生产环境. --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">springProfile</span> <span class="attr">name</span>=<span class="string">"production"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">springProfile</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- 非生产环境 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">springProfile</span> <span class="attr">name</span>=<span class="string">"!production"</span>&gt;</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="tag">&lt;/<span class="name">springProfile</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="日志使用Spring环境变量"><a href="#日志使用Spring环境变量" class="headerlink" title="日志使用Spring环境变量"></a>日志使用Spring环境变量</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">springProperty</span> <span class="attr">scope</span>=<span class="string">"context"</span> <span class="attr">name</span>=<span class="string">"fluentHost"</span> <span class="attr">source</span>=<span class="string">"myapp.fluentd.host"</span></span></span><br><span class="line"><span class="tag"><span class="attr">defaultValue</span>=<span class="string">"localhost"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"FLUENT"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.more.appenders.DataFluentAppender"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">remoteHost</span>&gt;</span>$&#123;fluentHost&#125;<span class="tag">&lt;/<span class="name">remoteHost</span>&gt;</span></span><br><span class="line">...</span><br><span class="line"><span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="项目首页查找规则"><a href="#项目首页查找规则" class="headerlink" title="项目首页查找规则"></a>项目首页查找规则</h2><p>支持html和模板引擎作为首页，首先会查找index.html，然后查找index template，还是没有时，会默认用一个欢迎页</p><h2 id="WebBindingInitializer"><a href="#WebBindingInitializer" class="headerlink" title="WebBindingInitializer"></a>WebBindingInitializer</h2><p>用于配置全局的类型转换器, 局部的可以在Controller中使用@InitBinder标记在方法上(<strong>百度所得</strong>)</p><h2 id="Todo-List"><a href="#Todo-List" class="headerlink" title="Todo List"></a>Todo List</h2><ol><li style="list-style: none"><input type="checkbox" checked> 搭建jenkins，配合git自动构建发布Spring Boot项目</li><li>研究编排系统Docker，K8s</li><li>研究项目里的Spring扩展</li><li>总结分布式链路追踪</li><li>mybatis官方文档, 源码, mybatis-plus, 通用mapper，代码生成</li><li>spring boot多数据源，分库分表，sharding-jdbc</li></ol>]]></content>
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
            <tag> 官方文档阅读 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>栈之链栈</title>
      <link href="/2017/07/19/%E6%A0%88%E4%B9%8B%E9%93%BE%E6%A0%88/"/>
      <url>/2017/07/19/%E6%A0%88%E4%B9%8B%E9%93%BE%E6%A0%88/</url>
      <content type="html"><![CDATA[<h1 id="链栈"><a href="#链栈" class="headerlink" title="链栈"></a>链栈</h1><p>链栈只是单链表的一个简单应用，只要理解单链表的头插法，链栈的出栈入栈很好理解。</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>linkstack.h如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;malloc.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stddef.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> ElemType;</span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">Node</span>&#123;</span></span><br><span class="line">ElemType data;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span> * <span class="title">next</span>;</span></span><br><span class="line">&#125;LinkStack;</span><br></pre></td></tr></table></figure><p>LinkStack.cpp如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"linkstack.h"</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">initLinkStack</span><span class="params">(LinkStack *&amp;ls)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">push</span><span class="params">(LinkStack *&amp;ls, ElemType e)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">pop</span><span class="params">(LinkStack *&amp;ls, ElemType &amp;e)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">peek</span><span class="params">(LinkStack *ls, ElemType &amp;e)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printStack</span><span class="params">(LinkStack *ls)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">LinkStack * ls;</span><br><span class="line">initLinkStack(ls);</span><br><span class="line"></span><br><span class="line">push(ls,<span class="number">10</span>);</span><br><span class="line">push(ls,<span class="number">20</span>);</span><br><span class="line">push(ls,<span class="number">30</span>);</span><br><span class="line">printStack(ls);</span><br><span class="line"></span><br><span class="line">ElemType e;</span><br><span class="line">pop(ls,e);</span><br><span class="line">printStack(ls);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">initLinkStack</span><span class="params">(LinkStack *&amp;ls)</span></span>&#123;</span><br><span class="line">ls = (LinkStack *) <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(LinkStack));</span><br><span class="line">ls-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">destroy</span><span class="params">(LinkStack *&amp;ls)</span></span>&#123;</span><br><span class="line">LinkStack *p = ls, *q;</span><br><span class="line">q = p-&gt;next;</span><br><span class="line"><span class="keyword">while</span>(q != <span class="literal">NULL</span>)&#123;</span><br><span class="line"><span class="built_in">free</span>(p);</span><br><span class="line">p = q;</span><br><span class="line">q = q-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">free</span>(p);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//入栈，就是一个头插法，很简单</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">push</span><span class="params">(LinkStack *&amp;ls, ElemType e)</span></span>&#123;</span><br><span class="line">LinkStack* node = (LinkStack*) <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(LinkStack));</span><br><span class="line">node-&gt;next = ls-&gt;next;</span><br><span class="line">node-&gt;data = e;</span><br><span class="line">ls-&gt;next = node;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//出栈</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">pop</span><span class="params">(LinkStack *&amp;ls, ElemType &amp;e)</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(ls-&gt;next == <span class="literal">NULL</span>)&#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"栈空，无法出栈"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line">LinkStack *p = ls-&gt;next;</span><br><span class="line">e = p-&gt;data;</span><br><span class="line">ls-&gt;next = p-&gt;next;</span><br><span class="line"><span class="built_in">free</span>(p);</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//取栈顶</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">peek</span><span class="params">(LinkStack *ls, ElemType &amp;e)</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(ls-&gt;next == <span class="literal">NULL</span>)&#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"栈空，无栈顶元素"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line">e = ls-&gt;next-&gt;data;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printStack</span><span class="params">(LinkStack *ls)</span></span>&#123;</span><br><span class="line">LinkStack *q = ls-&gt;next;</span><br><span class="line"><span class="keyword">while</span>(q!=<span class="literal">NULL</span>)&#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"%d\t"</span>,q-&gt;data);</span><br><span class="line">q = q-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"\n"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果为:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">302010</span><br><span class="line">2010</span><br></pre></td></tr></table></figure><p>记录:二进制和十进制的转换<br>我们知道十进制转换为二进制采用余数倒转法，二进制转换为十进制使用2的指数与位数乘积之和</p><p>101000101<br>第一个1之和有8位，2^8为256，第二个1之和有6位，2^6为64，以此类推，相加为256+64+4+1=325</p><p>417<br>417位于256到512之间，256=2^8，则100000000，1后有8个0，<br>417减去256=161，位于128到256之间，1后有7个0，和之前的拼接，即110000000<br>以此类推，得出110100001</p>]]></content>
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>栈之顺序栈</title>
      <link href="/2017/07/14/%E6%A0%88%E4%B9%8B%E9%A1%BA%E5%BA%8F%E8%A1%A8/"/>
      <url>/2017/07/14/%E6%A0%88%E4%B9%8B%E9%A1%BA%E5%BA%8F%E8%A1%A8/</url>
      <content type="html"><![CDATA[<h1 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h1><p>栈也是线性表的一种，它描述了一种后入先出的操作，可以用顺序存储结构和链式存储结构实现<br>顺序栈的定义由两部分组成：</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span>&#123;</span></span><br><span class="line">ElemType data[MAX_SIZE]; <span class="comment">//存储数据的数组</span></span><br><span class="line"><span class="keyword">int</span> top; <span class="comment">//栈顶指针，它一开始指向-1</span></span><br><span class="line">&#125;SqStack;</span><br></pre></td></tr></table></figure><p>sqstack.h如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;malloc.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAX_SIZE 10</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> ElemType;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span>&#123;</span></span><br><span class="line">ElemType data[MAX_SIZE];</span><br><span class="line"><span class="keyword">int</span> top;</span><br><span class="line">&#125;SqStack;</span><br></pre></td></tr></table></figure><p>SqStack.cpp如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"sqstack.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">initStack</span><span class="params">(SqStack *&amp;<span class="built_in">stack</span>)</span></span>; <span class="comment">//初始化栈</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">destoryStack</span><span class="params">(SqStack *&amp;<span class="built_in">stack</span>)</span></span>; <span class="comment">//销毁栈</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getLength</span><span class="params">(SqStack *<span class="built_in">stack</span>)</span></span>; <span class="comment">//获取长度</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printStack</span><span class="params">(SqStack *<span class="built_in">stack</span>)</span></span>; <span class="comment">//输出栈</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isEmpty</span><span class="params">(SqStack *<span class="built_in">stack</span>)</span></span>; <span class="comment">//判空</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">push</span><span class="params">(SqStack *&amp;<span class="built_in">stack</span>, ElemType e)</span></span>; <span class="comment">//进栈</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">pop</span><span class="params">(SqStack *&amp;<span class="built_in">stack</span>, ElemType &amp;e)</span></span>; <span class="comment">//出栈</span></span><br><span class="line"><span class="function">ElemType <span class="title">peek</span><span class="params">(SqStack *<span class="built_in">stack</span>)</span></span>; <span class="comment">//栈顶元素</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">SqStack *<span class="built_in">stack</span>;</span><br><span class="line">initStack(<span class="built_in">stack</span>);</span><br><span class="line"></span><br><span class="line">push(<span class="built_in">stack</span>,<span class="number">10</span>);</span><br><span class="line">push(<span class="built_in">stack</span>,<span class="number">20</span>);</span><br><span class="line">push(<span class="built_in">stack</span>,<span class="number">30</span>);</span><br><span class="line">printStack(<span class="built_in">stack</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"栈长度为:%d\n"</span>,getLength(<span class="built_in">stack</span>));</span><br><span class="line"></span><br><span class="line">ElemType e;</span><br><span class="line">pop(<span class="built_in">stack</span>,e);</span><br><span class="line">printStack(<span class="built_in">stack</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"栈长度为:%d\n"</span>,getLength(<span class="built_in">stack</span>));</span><br><span class="line"></span><br><span class="line">e = peek(<span class="built_in">stack</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"栈顶元素为:%d"</span>,e);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">initStack</span><span class="params">(SqStack *&amp;<span class="built_in">stack</span>)</span></span>&#123;</span><br><span class="line"><span class="built_in">stack</span> = (SqStack *) <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(SqStack));</span><br><span class="line"><span class="built_in">stack</span>-&gt;top = <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">destoryStack</span><span class="params">(SqStack *&amp;<span class="built_in">stack</span>)</span></span>&#123;</span><br><span class="line"><span class="built_in">free</span>(<span class="built_in">stack</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getLength</span><span class="params">(SqStack *<span class="built_in">stack</span>)</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> (<span class="built_in">stack</span>-&gt;top + <span class="number">1</span>) ;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isEmpty</span><span class="params">(SqStack *<span class="built_in">stack</span>)</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">stack</span>-&gt;top == <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printStack</span><span class="params">(SqStack *<span class="built_in">stack</span>)</span></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="keyword">for</span>(i = <span class="number">0</span>; i&lt;=<span class="built_in">stack</span>-&gt;top; i++)&#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"%d\t"</span>,<span class="built_in">stack</span>-&gt;data[i]);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">push</span><span class="params">(SqStack *&amp;<span class="built_in">stack</span>, ElemType e)</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(<span class="built_in">stack</span>-&gt;top+<span class="number">1</span> == MAX_SIZE)&#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"栈满，无法入栈\n"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">stack</span>-&gt;top++;</span><br><span class="line"><span class="built_in">stack</span>-&gt;data[<span class="built_in">stack</span>-&gt;top] = e;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">pop</span><span class="params">(SqStack *&amp;<span class="built_in">stack</span>, ElemType &amp;e)</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(<span class="built_in">stack</span>-&gt;top == <span class="number">-1</span>)&#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"栈空，无可出栈元素"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line">e = <span class="built_in">stack</span>-&gt;data[<span class="built_in">stack</span>-&gt;top];</span><br><span class="line"><span class="built_in">stack</span>-&gt;top--;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">ElemType <span class="title">peek</span><span class="params">(SqStack *<span class="built_in">stack</span>)</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">stack</span>-&gt;data[<span class="built_in">stack</span>-&gt;top];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="输出结果"><a href="#输出结果" class="headerlink" title="输出结果"></a>输出结果</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">102030栈长度为:3</span><br><span class="line">1020栈长度为:2</span><br><span class="line">栈顶元素为:20</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>线性表之双链表</title>
      <link href="/2017/07/12/%E7%BA%BF%E6%80%A7%E8%A1%A8%E4%B9%8B%E5%8F%8C%E9%93%BE%E8%A1%A8/"/>
      <url>/2017/07/12/%E7%BA%BF%E6%80%A7%E8%A1%A8%E4%B9%8B%E5%8F%8C%E9%93%BE%E8%A1%A8/</url>
      <content type="html"><![CDATA[<h1 id="双链表概述"><a href="#双链表概述" class="headerlink" title="双链表概述"></a>双链表概述</h1><p>双链表也是线性表的一种，它的全称是：线性双向链接表，它有以下特点：<br>在每个节点中除包含有数值域外,设置有两个指针域，分别用以指向其前驱节点和后继节点。<br>既可以依次向后访问每一个节点，也可以依次向前访问每一个节点。<br><img src="https://img.blog.csdn.net/20160724112429339" alt="这里写图片描述"></p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>dlinklist.h如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;malloc.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> ElemType;</span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">Node</span>&#123;</span></span><br><span class="line">ElemType data;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span> * <span class="title">prior</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span> * <span class="title">next</span>;</span></span><br><span class="line">&#125;DLinkList;</span><br></pre></td></tr></table></figure><p>DLinkList.cpp如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"dlinklist.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stddef.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">headInit</span><span class="params">(DLinkList * &amp;dll,ElemType arr[], <span class="keyword">int</span> n)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printDoubleLinkList</span><span class="params">(DLinkList * dll)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">tailInit</span><span class="params">(DLinkList * &amp;dll,ElemType arr[], <span class="keyword">int</span> n)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">insertElement</span><span class="params">(DLinkList *&amp;dll, <span class="keyword">int</span> pos, ElemType e)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">deleteElement</span><span class="params">(DLinkList *&amp;dll, <span class="keyword">int</span> pos, ElemType &amp;e)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">DLinkList * dll;</span><br><span class="line">ElemType arr[] = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;;</span><br><span class="line">headInit(dll,arr,<span class="number">5</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"头插法:\t"</span>);</span><br><span class="line">printDoubleLinkList(dll);</span><br><span class="line"></span><br><span class="line">tailInit(dll,arr,<span class="number">5</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"尾插法:\t"</span>);</span><br><span class="line">printDoubleLinkList(dll);</span><br><span class="line"></span><br><span class="line">insertElement(dll,<span class="number">3</span>,<span class="number">6</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"在第3个位置上插入6之后:\t"</span>);</span><br><span class="line">printDoubleLinkList(dll);</span><br><span class="line"></span><br><span class="line">ElemType e;</span><br><span class="line">deleteElement(dll,<span class="number">3</span>,e);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"删除第3个元素之后:\t"</span>);</span><br><span class="line">printDoubleLinkList(dll);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//头插法</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">headInit</span><span class="params">(DLinkList * &amp;dll,ElemType arr[], <span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line">dll = (DLinkList *) <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(DLinkList));</span><br><span class="line"><span class="comment">//头节点两个指针为NULL</span></span><br><span class="line">dll-&gt;next = dll-&gt;prior = <span class="literal">NULL</span>;</span><br><span class="line">DLinkList * node;</span><br><span class="line"><span class="keyword">for</span>(i = <span class="number">0</span>; i&lt;n; i++)&#123;</span><br><span class="line">node = (DLinkList *) <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(DLinkList));</span><br><span class="line">node-&gt;data = arr[i];</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> *插入,画图，依次赋值node-&gt;next，node-&gt;prior，dll-&gt;next(dll-&gt;prior永远为null)</span></span><br><span class="line"><span class="comment"> *可以发现除了第一次插入，以后插入的节点都要设置dll-&gt;next-&gt;prior = node</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">node-&gt;next = dll-&gt;next;</span><br><span class="line"><span class="keyword">if</span>(dll-&gt;next != <span class="literal">NULL</span>)&#123;</span><br><span class="line">dll-&gt;next-&gt;prior = node;</span><br><span class="line">&#125;</span><br><span class="line">node-&gt;prior = dll;</span><br><span class="line">dll-&gt;next = node;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//尾插法</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">tailInit</span><span class="params">(DLinkList * &amp;dll,ElemType arr[], <span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line">dll = (DLinkList *) <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(DLinkList));</span><br><span class="line"><span class="comment">//头节点两个指针为NULL</span></span><br><span class="line">dll-&gt;next = dll-&gt;prior = <span class="literal">NULL</span>;</span><br><span class="line">DLinkList * node, *r;</span><br><span class="line">r = dll;</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">node = (DLinkList *) <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(DLinkList));</span><br><span class="line">node-&gt;data = arr[i];</span><br><span class="line"><span class="comment">//尾插,画图很简单</span></span><br><span class="line">node-&gt;prior = r;</span><br><span class="line">r-&gt;next = node;</span><br><span class="line">r=node;</span><br><span class="line">&#125;</span><br><span class="line">r=<span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//插入节点，找出前一个节点</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">insertElement</span><span class="params">(DLinkList *&amp;dll, <span class="keyword">int</span> pos, ElemType e)</span></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">DLinkList *p = dll, *node;</span><br><span class="line"><span class="keyword">while</span>(i&lt;pos<span class="number">-1</span> &amp;&amp; p!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">p = p-&gt;next;</span><br><span class="line">i++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(p==<span class="literal">NULL</span>)&#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"插入的位置不合法"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line"><span class="comment">//分配节点</span></span><br><span class="line">node = (DLinkList *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(DLinkList));</span><br><span class="line">node-&gt;data = e;</span><br><span class="line">node-&gt;next = p-&gt;next;</span><br><span class="line">node-&gt;prior = p;</span><br><span class="line"><span class="keyword">if</span>(p-&gt;next != <span class="literal">NULL</span>)&#123;</span><br><span class="line">p-&gt;next-&gt;prior = node;</span><br><span class="line">&#125;</span><br><span class="line">p-&gt;next = node;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">deleteElement</span><span class="params">(DLinkList *&amp;dll, <span class="keyword">int</span> pos, ElemType &amp;e)</span></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">DLinkList *p = dll, *node;</span><br><span class="line"><span class="keyword">while</span>(i&lt;pos<span class="number">-1</span> &amp;&amp; p!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">p = p-&gt;next;</span><br><span class="line">i++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(p==<span class="literal">NULL</span>)&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">node = p-&gt;next;</span><br><span class="line"><span class="keyword">if</span>(node == <span class="literal">NULL</span>)&#123;<span class="comment">//如果p是尾节点，要删除的是尾节点的下一个节点，错误</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line">e = node-&gt;data;</span><br><span class="line">p-&gt;next = node-&gt;next;</span><br><span class="line"><span class="keyword">if</span>(p-&gt;next != <span class="literal">NULL</span>)&#123; <span class="comment">//此时p-&gt;next已经改变，如果node-&gt;next为NULL.NULL不需要设置prior</span></span><br><span class="line">node-&gt;next-&gt;prior = p;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">free</span>(node);</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printDoubleLinkList</span><span class="params">(DLinkList * dll)</span></span>&#123;</span><br><span class="line"><span class="comment">//不需要输出头节点的data</span></span><br><span class="line">DLinkList *p = dll-&gt;next;</span><br><span class="line"><span class="keyword">while</span>(p != <span class="literal">NULL</span>)&#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"%d\t"</span>,p-&gt;data);</span><br><span class="line">p = p-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"\n"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="输出结果"><a href="#输出结果" class="headerlink" title="输出结果"></a>输出结果</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">头插法:54321</span><br><span class="line">尾插法:12345</span><br><span class="line">在第3个位置上插入6之后:126345</span><br><span class="line">删除第3个元素之后:12345</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>线性表之单链表</title>
      <link href="/2017/07/10/%E7%BA%BF%E6%80%A7%E8%A1%A8%E4%B9%8B%E5%8D%95%E9%93%BE%E8%A1%A8/"/>
      <url>/2017/07/10/%E7%BA%BF%E6%80%A7%E8%A1%A8%E4%B9%8B%E5%8D%95%E9%93%BE%E8%A1%A8/</url>
      <content type="html"><![CDATA[<h1 id="单链表概述"><a href="#单链表概述" class="headerlink" title="单链表概述"></a>单链表概述</h1><p>一张图简单解释下单链表的结果，对头节点，头指针，首节点混肴的同学可以再看看<br><img src="https://img-blog.csdn.net/20160723154837259" alt="这里写图片描述"></p><p>以下是单链表的头文件和相关操作，这门课很抽象，我个人认为只在脑海中去理解很难做到，因为指针指来指去是个人都会晕，建议大家用笔在纸上画出来，更容易理解<br>比如单链表的尾插法， 在纸上一画瞬间理解了</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>linklist.h如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;malloc.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> ElemType;</span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">Node</span>&#123;</span></span><br><span class="line">ElemType data;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span> *<span class="title">next</span>;</span></span><br><span class="line">&#125;LinkList;</span><br></pre></td></tr></table></figure><p>LinkList.cpp如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"linklist.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stddef.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">headInit</span><span class="params">(LinkList * &amp;ls, <span class="keyword">int</span> msg[], <span class="keyword">int</span> n)</span></span>;<span class="comment">//头插法</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">tailInit</span><span class="params">(LinkList * &amp;ls, <span class="keyword">int</span> msg[], <span class="keyword">int</span> n)</span></span>;<span class="comment">//尾插法</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printLinkList</span><span class="params">(LinkList *ls)</span></span>;<span class="comment">//输出链表</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">destory</span><span class="params">(LinkList *&amp;ls)</span></span>;<span class="comment">//销毁链表</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getLength</span><span class="params">(LinkList *ls)</span></span>;<span class="comment">//获取长度</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">getElementByIndex</span><span class="params">(LinkList *ls, <span class="keyword">int</span> pos, ElemType &amp;e)</span></span>;<span class="comment">//通过下标获取元素</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getElementIndex</span><span class="params">(LinkList *ls,ElemType e)</span></span>;<span class="comment">//获取元素的下标</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">insert</span><span class="params">(LinkList *&amp;ls,<span class="keyword">int</span> pos, ElemType e)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">deleteElement</span><span class="params">(LinkList *&amp;ls, <span class="keyword">int</span> pos, ElemType &amp;e)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 相比于顺序表，单链表不需要连续的空间，没有冗余的空间，而且不用扩容，插入和删除操作效率高</span></span><br><span class="line"><span class="comment"> * 但是其他操作复杂</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">LinkList * ls;</span><br><span class="line"></span><br><span class="line">ElemType arr1[] = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;;</span><br><span class="line">headInit(ls,arr1,<span class="number">5</span>);</span><br><span class="line">printLinkList(ls);</span><br><span class="line"></span><br><span class="line">ElemType arr2[] = &#123;<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>&#125;;</span><br><span class="line">tailInit(ls,arr2,<span class="number">5</span>);</span><br><span class="line">printLinkList(ls);</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"\n单链表的长度是:%d\n"</span>,getLength(ls));</span><br><span class="line"></span><br><span class="line">ElemType e;</span><br><span class="line"><span class="keyword">if</span>(getElementByIndex(ls,<span class="number">5</span>,e))&#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"第%d个元素的值是:%d\n"</span>,<span class="number">5</span>,e);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> pos = getElementIndex(ls,<span class="number">10</span>);</span><br><span class="line"><span class="keyword">if</span>(pos)&#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"%d的位置是:%d\n"</span>,<span class="number">10</span>,pos);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">e = <span class="number">11</span>;</span><br><span class="line"><span class="keyword">if</span>(insert(ls,<span class="number">6</span>,<span class="number">11</span>))&#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"%d插入成功\n"</span>,e);</span><br><span class="line">&#125;</span><br><span class="line">printLinkList(ls);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(deleteElement(ls,<span class="number">5</span>,e))&#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"\n要删除的第%d个元素是%d,已删除成功\n"</span>,<span class="number">5</span>,e);</span><br><span class="line">&#125;</span><br><span class="line">printLinkList(ls);</span><br><span class="line">destory(ls);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">头插法</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">headInit</span><span class="params">(LinkList * &amp;ls, ElemType msg[], <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line">LinkList *node;</span><br><span class="line">ls = (LinkList*)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(LinkList));</span><br><span class="line">ls-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; n; i++)&#123;</span><br><span class="line"><span class="comment">//产生一个新节点</span></span><br><span class="line">node = (LinkList*)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(LinkList));</span><br><span class="line">node-&gt;data = msg[i];</span><br><span class="line"><span class="comment">//把该节点插到头节点的后面，画图</span></span><br><span class="line">node-&gt;next = ls-&gt;next;</span><br><span class="line">ls-&gt;next = node;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">尾插法:定义一个尾指针指向尾节点，因为每次都在尾节点后面插，就把尾节点当作头节点去插</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">tailInit</span><span class="params">(LinkList * &amp;ls, <span class="keyword">int</span> msg[], <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">ls = (LinkList*)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(LinkList));</span><br><span class="line">ls-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line">LinkList *node,*tail = ls; <span class="comment">//尾指针最初也指向头节点</span></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; n; i++)&#123;</span><br><span class="line">node = (LinkList*)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(LinkList));</span><br><span class="line">node-&gt;data = msg[i];</span><br><span class="line">tail-&gt;next = node;</span><br><span class="line">tail = node; <span class="comment">//尾指针指向新插入的节点，即尾节点</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//一开始没加这句，导致tail-&gt;next成为野指针,导致一直输出</span></span><br><span class="line">tail-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//打印</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printLinkList</span><span class="params">(LinkList *ls)</span> </span>&#123;</span><br><span class="line">LinkList *p = ls-&gt;next;</span><br><span class="line"><span class="keyword">while</span> (p != <span class="literal">NULL</span>) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"%d\t"</span>, p-&gt;data);</span><br><span class="line">p = p-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 链表的消耗要把每一个节点都free</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">destory</span><span class="params">(LinkList *&amp;ls)</span></span>&#123;</span><br><span class="line">LinkList * head = ls, * p = ls-&gt;next;</span><br><span class="line"><span class="keyword">while</span>(p!=<span class="literal">NULL</span>)&#123;</span><br><span class="line"><span class="built_in">free</span>(head);</span><br><span class="line">head = p;</span><br><span class="line">p = p-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//销毁最后一个</span></span><br><span class="line"><span class="built_in">free</span>(head);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//判断是否是空表</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isEmpty</span><span class="params">(LinkList *ls)</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> (ls-&gt;next == <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//求表长</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getLength</span><span class="params">(LinkList *ls)</span></span>&#123;</span><br><span class="line">LinkList * p = ls;</span><br><span class="line"><span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span>(p-&gt;next != <span class="literal">NULL</span>)&#123;</span><br><span class="line">i++;</span><br><span class="line">p = p-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> i;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//获取第i个节点</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">getElementByIndex</span><span class="params">(LinkList *ls, <span class="keyword">int</span> pos, ElemType &amp;e)</span></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">LinkList * p = ls;</span><br><span class="line"><span class="keyword">while</span>(i&lt;pos &amp;&amp; p!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">p = p-&gt;next;</span><br><span class="line">i++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//循环结束后要么i&lt;pos不成立，也就是找到了，要么ls==NULL，也就是到表尾了</span></span><br><span class="line"><span class="keyword">if</span>(p == <span class="literal">NULL</span>)&#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"不存在第%d个元素\n"</span>,pos);</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">e = p-&gt;data;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//获取元素下标</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getElementIndex</span><span class="params">(LinkList *ls,ElemType e)</span></span>&#123;</span><br><span class="line"><span class="comment">//用pos记录下标</span></span><br><span class="line"><span class="keyword">int</span> pos = <span class="number">1</span>;</span><br><span class="line">LinkList *p = ls-&gt;next;</span><br><span class="line"><span class="keyword">while</span>(p != <span class="literal">NULL</span> &amp;&amp; p-&gt;data != e)&#123;</span><br><span class="line">p = p-&gt;next;</span><br><span class="line">pos++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//对循环结束后的条件进行判断</span></span><br><span class="line"><span class="keyword">if</span>(p == <span class="literal">NULL</span>)&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line"><span class="keyword">return</span> pos;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 单链表的插入需要记录前一个节点,所以找到pos-1即可</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">insert</span><span class="params">(LinkList *&amp;ls,<span class="keyword">int</span> pos, ElemType e)</span></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">LinkList * p = ls; <span class="comment">//不要直接用ls</span></span><br><span class="line"><span class="comment">//pos-1,假如在第5个位置插入，就找出第四个节点，让它指向e</span></span><br><span class="line"><span class="keyword">while</span>(i &lt; pos<span class="number">-1</span> &amp;&amp; p != <span class="literal">NULL</span>)&#123;</span><br><span class="line">i++;</span><br><span class="line">p = p-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(p==<span class="literal">NULL</span>)&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line"><span class="comment">//为插入的节点分配空间</span></span><br><span class="line">LinkList * node = (LinkList *) <span class="built_in">malloc</span> (<span class="keyword">sizeof</span>(LinkList));</span><br><span class="line">node-&gt;data = e;</span><br><span class="line"></span><br><span class="line"><span class="comment">//插入</span></span><br><span class="line">node-&gt;next = p-&gt;next;</span><br><span class="line">p-&gt;next = node;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//删除同样也要找到pos-1个节点</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">deleteElement</span><span class="params">(LinkList *&amp;ls, <span class="keyword">int</span> pos, ElemType &amp;e)</span></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">LinkList * p = ls , *temp;</span><br><span class="line"><span class="keyword">while</span>(i &lt; pos<span class="number">-1</span> &amp;&amp; p!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">p = p-&gt;next;</span><br><span class="line">i++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(p==<span class="literal">NULL</span>)&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line"><span class="comment">//删除节点，记得先把地址用temp保存起来，用于free</span></span><br><span class="line">temp = p-&gt;next;</span><br><span class="line">e = temp-&gt;data;</span><br><span class="line">p-&gt;next = temp-&gt;next;</span><br><span class="line"><span class="built_in">free</span>(temp);</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="输出结果"><a href="#输出结果" class="headerlink" title="输出结果"></a>输出结果</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">54321678910</span><br><span class="line">单链表的长度是:5</span><br><span class="line">第5个元素的值是:10</span><br><span class="line">10的位置是:5</span><br><span class="line">11插入成功</span><br><span class="line">67891011</span><br><span class="line">要删除的第5个元素是10,已删除成功</span><br><span class="line">678911</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>线性表之顺序表</title>
      <link href="/2017/07/07/%E7%BA%BF%E6%80%A7%E8%A1%A8%E4%B9%8B%E9%A1%BA%E5%BA%8F%E8%A1%A8/"/>
      <url>/2017/07/07/%E7%BA%BF%E6%80%A7%E8%A1%A8%E4%B9%8B%E9%A1%BA%E5%BA%8F%E8%A1%A8/</url>
      <content type="html"><![CDATA[<blockquote><p>作为一个计科大学生，没有学好数据结构一直是我的遗憾，博主主攻java web方向，为了不当一个低端码农，决心静下心来学习数据结构，但是和我当初自学java一样，都存在入门难的问题，严蔚敏的数据结构一直是我的噩梦，概念多且抽象，我希望通过敲代码这种实战的方式学习数据结构，也就放弃了课本。<br>后来在CSDN上看到贺利坚的课程(收费)，和很多人一样，并不想买，后来在贴吧看到免费的观看地址（百度锐聘），就慢慢地开始学，同时写博客记录我的学习过程。<br>在此十分感谢贺利坚老师，看了他的博客后不止教会了我数据结构，也为我解开了诸多学习上的疑惑</p></blockquote><h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><p>数据结构系列文章时从博主的CSDN中迁移过来的，重新进行排版优化，切莫闹出举报博主自己抄袭自己的笑话(咳咳，我已经授权抄袭自己了)</p><h1 id="线性表概述"><a href="#线性表概述" class="headerlink" title="线性表概述"></a>线性表概述</h1><p>线性表描述了一种线性的逻辑结构，元素之间是一对一的关系，而在存储结构上分为顺序存储和链式存储，<br>分别简称为：顺序表和链表<br>以下是顺序表的定义方式以及操作，运行环境为Eclipse CDT，程序用到少部分C++特性，新建时选择C++ project，在运行main之前，先要右键项目，进行build project</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>sqlist.h</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAX_SIZE 50</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> INCREMENT_SIZE 10</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">ElemType可以表示一个复杂的结构体</span></span><br><span class="line"><span class="comment">typedef struct &#123;</span></span><br><span class="line"><span class="comment">int age;</span></span><br><span class="line"><span class="comment">char name[32];</span></span><br><span class="line"><span class="comment">&#125;ElemType;</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> ElemType;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">ElemType data[MAX_SIZE];</span><br><span class="line"><span class="keyword">int</span> length;</span><br><span class="line">&#125;SqList;</span><br></pre></td></tr></table></figure><p>SqList.cpp</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"sqlist.h"</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">initSqList</span><span class="params">(SqList *&amp;sl)</span></span>; <span class="comment">//初始化</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isEmpty</span><span class="params">(SqList *sl)</span></span>; <span class="comment">//判空</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">addCapacity</span><span class="params">(SqList *&amp;sl)</span></span>; <span class="comment">//扩容</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">destorySqList</span><span class="params">(SqList *&amp;sl)</span></span>; <span class="comment">//销毁</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getLength</span><span class="params">(SqList *sl)</span></span>; <span class="comment">//获取长度</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printList</span><span class="params">(SqList *sl)</span></span>; <span class="comment">//输出顺序表</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">deleteElement</span><span class="params">(SqList *&amp;sl, <span class="keyword">int</span> i, ElemType &amp;e)</span></span>; <span class="comment">//删除下标为i的元素</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insertElement</span><span class="params">(SqList *&amp;sl, <span class="keyword">int</span> i, ElemType e)</span></span>; <span class="comment">//在i处插入元素</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">getElementByIndex</span><span class="params">(SqList *sl, <span class="keyword">int</span> i, ElemType &amp;e)</span></span>; <span class="comment">//通过下标i获取元素</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getElementIndex</span><span class="params">(SqList *&amp;sl, ElemType e)</span></span>;<span class="comment">//获取元素的下标</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">SqList *sl;</span><br><span class="line">ElemType ele;</span><br><span class="line">initSqList(sl);</span><br><span class="line">insertElement(sl, <span class="number">1</span>, <span class="number">10</span>);</span><br><span class="line">insertElement(sl, <span class="number">2</span>, <span class="number">20</span>);</span><br><span class="line">insertElement(sl, <span class="number">3</span>, <span class="number">30</span>);</span><br><span class="line">insertElement(sl, <span class="number">4</span>, <span class="number">40</span>);</span><br><span class="line"></span><br><span class="line">deleteElement(sl,<span class="number">4</span>,ele);</span><br><span class="line">printList(sl);</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"元素%d的位置是：%d\n"</span>,<span class="number">20</span>, getElementIndex(sl,<span class="number">20</span>));</span><br><span class="line"></span><br><span class="line">getElementByIndex(sl, <span class="number">2</span>, ele);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"第%d个元素是：%d\n"</span>,<span class="number">2</span>, ele);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">initSqList</span><span class="params">(SqList *&amp;sl)</span> </span>&#123;</span><br><span class="line">sl = (SqList *)<span class="built_in">malloc</span>(MAX_SIZE*<span class="keyword">sizeof</span>(SqList));</span><br><span class="line">sl-&gt;length = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isEmpty</span><span class="params">(SqList *sl)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> (sl-&gt;length == <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">addCapacity</span><span class="params">(SqList *&amp;sl)</span> </span>&#123;</span><br><span class="line">sl = (SqList *)<span class="built_in">realloc</span>(sl,(sl-&gt;length + INCREMENT_SIZE));</span><br><span class="line"><span class="keyword">if</span> (!sl) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"扩容失败"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//注意是length，不是MAX_SIZE,假如这不是第一次扩容</span></span><br><span class="line">sl-&gt;length += INCREMENT_SIZE;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">destorySqList</span><span class="params">(SqList *&amp;sl)</span> </span>&#123;</span><br><span class="line"><span class="built_in">free</span>(sl);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getLength</span><span class="params">(SqList *sl)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> sl-&gt;length;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printList</span><span class="params">(SqList *sl)</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="keyword">if</span> (isEmpty(sl)) &#123;<span class="comment">//是否是空表</span></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"List is empty\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> ( i = <span class="number">0</span>; i &lt; sl-&gt;length; i++)&#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"%d\t"</span>,sl-&gt;data[i]);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insertElement</span><span class="params">(SqList *&amp;sl, <span class="keyword">int</span> i, ElemType e)</span> </span>&#123;</span><br><span class="line"><span class="comment">//如果list里只有10个元素，你最多能在11的位置上插入，不能大于11</span></span><br><span class="line"><span class="keyword">if</span> (i&lt;<span class="number">1</span> || i&gt;sl-&gt;length+<span class="number">1</span>) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"插入的位置不合法\n"</span>);</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//如果超过容量，就扩容</span></span><br><span class="line"><span class="keyword">if</span> (sl-&gt;length == MAX_SIZE) &#123;</span><br><span class="line">addCapacity(sl);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">int</span> j;</span><br><span class="line"><span class="comment">//从最后一个元素 到第i-1个元素后移，自己在纸上画出来，很容易理解j&gt;=i-1</span></span><br><span class="line"><span class="keyword">for</span> (j=sl-&gt;length<span class="number">-1</span>; j&gt;=i - <span class="number">1</span>; j--)&#123;</span><br><span class="line"><span class="comment">//为什么是j+1 = j,不是j = j-1，想想最后一个元素是怎么移动的就很好理解了</span></span><br><span class="line">sl-&gt;data[j + <span class="number">1</span>] = sl-&gt;data[j];</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//把元素插入到下标为(i-1)的位置</span></span><br><span class="line">sl-&gt;data[i - <span class="number">1</span>] = e;</span><br><span class="line"><span class="comment">//记得length++</span></span><br><span class="line">sl-&gt;length++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">deleteElement</span><span class="params">(SqList *&amp;sl, <span class="keyword">int</span> i, ElemType &amp;e)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (i&lt;<span class="number">1</span> || i&gt;sl-&gt;length) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"插入的位置不合法\n"</span>);</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line">e = sl-&gt;data[i - <span class="number">1</span>];</span><br><span class="line"><span class="keyword">int</span> j;</span><br><span class="line"><span class="keyword">for</span> (j = i; j &lt; sl-&gt;length; j++) &#123;</span><br><span class="line">sl-&gt;data[j - <span class="number">1</span>] = sl-&gt;data[j];</span><br><span class="line">&#125;</span><br><span class="line">sl-&gt;length--;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getElementIndex</span><span class="params">(SqList *&amp;sl, ElemType e)</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (i &lt; sl-&gt;length &amp;&amp; sl-&gt;data[i] != e) &#123;</span><br><span class="line">i++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (i &lt; sl-&gt;length) &#123;</span><br><span class="line"><span class="keyword">return</span> i + <span class="number">1</span>; <span class="comment">//这个时候的i是从0开始算的，所以要+1</span></span><br><span class="line">&#125;<span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">getElementByIndex</span><span class="params">(SqList *sl, <span class="keyword">int</span> i, ElemType &amp;e)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (i&lt;<span class="number">1</span> || i&gt;sl-&gt;length) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"访问的位置不合法"</span>);</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line">e = sl-&gt;data[i - <span class="number">1</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">删除元素x，x不止一个</span></span><br><span class="line"><span class="comment">找到，然后删除, O(n) = n*n</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">deleteEle_1</span><span class="params">(SqList *sl, ElemType x)</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line">ElemType e;</span><br><span class="line"><span class="keyword">while</span> ((i = getElementIndex(sl, x)) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">deleteElement(sl, i, e);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">删除元素x，x不止一个</span></span><br><span class="line"><span class="comment">将O(n) 降低到 O(n)</span></span><br><span class="line"><span class="comment">算法：用复制的思想</span></span><br><span class="line"><span class="comment">重新从0开始计数，只要第n个元素不等于x，就移动到前面去(同时把以前的覆盖)</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">deleteEle_2</span><span class="params">(SqList *sl, ElemType x)</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> k = <span class="number">0</span>, i;</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; sl-&gt;length; i++) &#123;</span><br><span class="line"><span class="keyword">if</span> (sl-&gt;data[i] != x) &#123;</span><br><span class="line">sl-&gt;data[k] = sl-&gt;data[i];</span><br><span class="line">k++;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">sl-&gt;length = k; <span class="comment">//删除x后，k就是长度</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
